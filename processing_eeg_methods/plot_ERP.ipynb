{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T22:39:15.987602500Z",
     "start_time": "2024-04-06T22:39:14.227634900Z"
    }
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Failed to interpret file 'C:\\\\Users\\\\rosit\\\\Documents\\\\workprojects\\\\bci_complete\\\\voting_system_platform/Datasets/nieto_dataset\\\\derivatives\\\\sub-01\\\\ses-01\\\\sub-01_ses-01_events.dat' as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnpicklingError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[1;32m~\\Documents\\workprojects\\bci_complete\\venv_bci\\lib\\site-packages\\numpy\\lib\\npyio.py:465\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[0;32m    464\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mload(fid, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_kwargs)\n\u001B[0;32m    466\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mUnpicklingError\u001B[0m: unpickling stack underflow",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mUnpicklingError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 18\u001B[0m\n\u001B[0;32m     16\u001B[0m epochs_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m subject_id \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, dataset_info[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msubjects\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m---> 18\u001B[0m     individual_epochs, data, labels \u001B[38;5;241m=\u001B[39m \u001B[43mload_data_labels_based_on_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubject_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     epochs_list\u001B[38;5;241m.\u001B[39mappend(individual_epochs)\n\u001B[0;32m     22\u001B[0m epochs \u001B[38;5;241m=\u001B[39m mne\u001B[38;5;241m.\u001B[39mconcatenate_epochs(epochs_list)\n",
      "File \u001B[1;32m~\\Documents\\workprojects\\bci_complete\\voting_system_platform\\processing_eeg_methods\\data_loaders.py:222\u001B[0m, in \u001B[0;36mload_data_labels_based_on_dataset\u001B[1;34m(dataset_name, subject_id, data_path, transpose, normalize)\u001B[0m\n\u001B[0;32m    220\u001B[0m     data \u001B[38;5;241m=\u001B[39m epochs\u001B[38;5;241m.\u001B[39mget_data()\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m dataset_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnieto\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 222\u001B[0m     data, label, event_dict \u001B[38;5;241m=\u001B[39m \u001B[43mnieto_dataset_loader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubject_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m dataset_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcoretto\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    224\u001B[0m     foldername \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;132;01m{:02d}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(subject_id)\n",
      "File \u001B[1;32m~\\Documents\\workprojects\\bci_complete\\voting_system_platform\\processing_eeg_methods\\data_loaders.py:97\u001B[0m, in \u001B[0;36mnieto_dataset_loader\u001B[1;34m(root_dir, N_S)\u001B[0m\n\u001B[0;32m     94\u001B[0m t_end \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3.5\u001B[39m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;66;03m# Load all trials for a single subject\u001B[39;00m\n\u001B[1;32m---> 97\u001B[0m X, Y \u001B[38;5;241m=\u001B[39m \u001B[43mextract_data_from_subject\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN_S\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatatype\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# This uses the derivatives folder\u001B[39;00m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# Cut useful time. i.e action interval\u001B[39;00m\n\u001B[0;32m    100\u001B[0m X \u001B[38;5;241m=\u001B[39m select_time_window(X\u001B[38;5;241m=\u001B[39mX, t_start\u001B[38;5;241m=\u001B[39mt_start, t_end\u001B[38;5;241m=\u001B[39mt_end, fs\u001B[38;5;241m=\u001B[39mfs)\n",
      "File \u001B[1;32m~\\Documents\\workprojects\\bci_complete\\voting_system_platform\\processing_eeg_methods\\Inner_Speech_Dataset\\Python_Processing\\Data_extractions.py:66\u001B[0m, in \u001B[0;36mextract_data_from_subject\u001B[1;34m(root_dir, n_s, datatype)\u001B[0m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n_b \u001B[38;5;129;01min\u001B[39;00m n_b_arr:\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;66;03m# Name correction if N_Subj is less than 10\u001B[39;00m\n\u001B[0;32m     64\u001B[0m     num_s \u001B[38;5;241m=\u001B[39m sub_name(n_s)\n\u001B[1;32m---> 66\u001B[0m     y[n_b] \u001B[38;5;241m=\u001B[39m \u001B[43mload_events\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_s\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_b\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m datatype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meeg\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     69\u001B[0m         \u001B[38;5;66;03m# Load data and events\u001B[39;00m\n\u001B[0;32m     70\u001B[0m         file_name \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     71\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mroot_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/derivatives/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_s\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/ses-0\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_b\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_s\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_ses-0\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_b\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_eeg-epo.fif\u001B[39m\u001B[38;5;124m\"\u001B[39m             \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[0;32m     72\u001B[0m         )\n",
      "File \u001B[1;32m~\\Documents\\workprojects\\bci_complete\\voting_system_platform\\processing_eeg_methods\\Inner_Speech_Dataset\\Python_Processing\\Data_extractions.py:302\u001B[0m, in \u001B[0;36mload_events\u001B[1;34m(root_dir, n_s, n_b)\u001B[0m\n\u001B[0;32m    299\u001B[0m file_name \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root_dir, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mderivatives\u001B[39m\u001B[38;5;124m\"\u001B[39m, num_s, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mses-0\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_b\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_s\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_ses-0\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_b\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_events.dat\u001B[39m\u001B[38;5;124m\"\u001B[39m)       \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[0;32m    301\u001B[0m \u001B[38;5;66;03m# Load events\u001B[39;00m\n\u001B[1;32m--> 302\u001B[0m events \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    304\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m events\n",
      "File \u001B[1;32m~\\Documents\\workprojects\\bci_complete\\venv_bci\\lib\\site-packages\\numpy\\lib\\npyio.py:467\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[0;32m    465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mload(fid, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_kwargs)\n\u001B[0;32m    466\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 467\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(\n\u001B[0;32m    468\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to interpret file \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m as a pickle\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[1;31mUnpicklingError\u001B[0m: Failed to interpret file 'C:\\\\Users\\\\rosit\\\\Documents\\\\workprojects\\\\bci_complete\\\\voting_system_platform/Datasets/nieto_dataset\\\\derivatives\\\\sub-01\\\\ses-01\\\\sub-01_ses-01_events.dat' as a pickle"
     ]
    }
   ],
   "source": [
    "from data_loaders import load_data_labels_based_on_dataset\n",
    "from share import datasets_basic_infos, ROOT_VOTING_SYSTEM_PATH\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_utils import train_test_val_split\n",
    "import mne\n",
    "\n",
    "dataset_name = 'coretto'  # Only two things I should be able to change\n",
    "\n",
    "# Folders and paths\n",
    "dataset_foldername = dataset_name + '_dataset'\n",
    "computer_root_path = ROOT_VOTING_SYSTEM_PATH + \"/Datasets/\"\n",
    "data_path = computer_root_path + dataset_foldername\n",
    "dataset_info = datasets_basic_infos[dataset_name]\n",
    "\n",
    "epochs_list = []\n",
    "for subject_id in range(1, dataset_info['subjects']+1):\n",
    "    individual_epochs, data, labels = load_data_labels_based_on_dataset(dataset_name, subject_id, data_path)\n",
    "    epochs_list.append(individual_epochs)\n",
    "    \n",
    "\n",
    "epochs = mne.concatenate_epochs(epochs_list)\n",
    "\n",
    "data_train, data_test, _, labels_train, labels_test, _ = train_test_val_split(\n",
    "        dataX=data, dataY=labels, valid_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def indexes(l, chosen_key):\n",
    "    _indices = defaultdict(list)\n",
    "    for index, item in enumerate(l):\n",
    "        _indices[item].append(index)\n",
    "\n",
    "    for key, value in _indices.items():\n",
    "        if key == chosen_key:\n",
    "            return value\n",
    "#indexes(labels, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T22:39:15.993182200Z",
     "start_time": "2024-04-06T22:39:15.988771600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I think there is something there: 1, 3, 8, 10, 11, 13, 15, 18, 21, 23"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for channel in range(len(dataset_info[\"channels_names\"])):\n",
    "    for word_index in range(len(dataset_info[\"target_names\"])):\n",
    "        plt.clf()\n",
    "        samples_to_time = np.linspace(0, dataset_info[\"samples\"]/dataset_info[\"sample_rate\"], num=dataset_info[\"samples\"])\n",
    "        for i_index in indexes(labels, word_index):\n",
    "            plt.plot(samples_to_time, data[i_index,channel,:])\n",
    "        plt.plot(samples_to_time, np.mean(data[:,channel,:], axis=0), linewidth=5, color='k')\n",
    "        plt.title(f'{dataset_name} - {dataset_info[\"target_names\"][word_index]} - {dataset_info[\"channels_names\"][channel]}')\n",
    "        plt.xlabel('Time [ms]')\n",
    "        plt.ylabel('Normalized Voltage')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.savefig(f'{ROOT_VOTING_SYSTEM_PATH}/Results/{dataset_name}/ERP/ERP_{dataset_name}_{dataset_info[\"target_names\"][word_index]}_{dataset_info[\"channels_names\"][channel]}.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-06T22:39:15.991073Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Do the XDAWN DENOISING HERE AND SEE THE SIGNALS\n",
    "https://mne.tools/stable/auto_examples/preprocessing/xdawn_denoising.html#sphx-glr-auto-examples-preprocessing-xdawn-denoising-py"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
