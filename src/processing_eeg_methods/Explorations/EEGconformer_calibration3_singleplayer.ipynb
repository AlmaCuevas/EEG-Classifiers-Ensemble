{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667cbb0e-b42e-4ea6-a195-b296702614ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:10.879322700Z",
     "start_time": "2024-10-16T15:50:10.864310200Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'conformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c504eba-a256-4ddb-bc17-55b59d27a609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:17.694456300Z",
     "start_time": "2024-10-16T15:50:11.178070700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\moabb\\pipelines\\__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from braindecode.models import EEGConformer\n",
    "\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae83aafa-2a37-42f7-9ace-d937ca00c107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:17.729681300Z",
     "start_time": "2024-10-16T15:50:17.695945900Z"
    }
   },
   "outputs": [],
   "source": [
    "from processing_eeg_methods.data_utils import (\n",
    "    convert_into_independent_channels,\n",
    "    get_dataset_basic_info,\n",
    "    get_input_data_path,\n",
    "    standard_saving_path,\n",
    "    write_model_info,\n",
    ")\n",
    "from processing_eeg_methods.data_loaders import load_data_labels_based_on_dataset\n",
    "from processing_eeg_methods.share import datasets_basic_infos\n",
    "\n",
    "subject_id = 19  # Only two things I should be able to change\n",
    "dataset_name = \"braincommand\"  # Only two things I should be able to change\n",
    "\n",
    "dataset_info = get_dataset_basic_info(datasets_basic_infos, dataset_name)\n",
    "\n",
    "data_path = r\"C:\\Users\\rosit\\Documents\\workprojects\\bci_complete\\EEG-Classifiers-Ensemble\\Datasets\\braincommand_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load calibration and singleplayer with labels 0 and 1, respectively."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b02cfc902e0443e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 104\n",
      "label 1 is 50\n",
      "label 2 is 47\n",
      "label 3 is 27\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs_calibration, X_calibration, y_calibration_original = load_data_labels_based_on_dataset(\n",
    "    dataset_info,\n",
    "    subject_id,\n",
    "    data_path,\n",
    "    game_mode=\"calibration3\",\n",
    ")\n",
    "\n",
    "epochs_singleplayer, X_singleplayer, y_singleplayer_original = load_data_labels_based_on_dataset(\n",
    "    dataset_info,\n",
    "    subject_id,\n",
    "    data_path,\n",
    "    game_mode=\"singleplayer\",\n",
    ")\n",
    "y_calibration = [0] * len(y_calibration_original)\n",
    "y_singleplayer = [1] * len(y_singleplayer_original)\n",
    "\n",
    "X = np.concatenate((X_calibration, X_singleplayer), axis=0)\n",
    "y = y_calibration + y_singleplayer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T15:34:44.001343800Z",
     "start_time": "2024-10-16T15:34:39.446177300Z"
    }
   },
   "id": "2295ef4877e545bd",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load calibration from the clean .set file after EEGLAB manual rejection."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1527695aa317824d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "_, X, y = load_data_labels_based_on_dataset(\n",
    "    dataset_info,\n",
    "    subject_id,\n",
    "    data_path,\n",
    "    game_mode=\"calibration3\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:33.620604600Z",
     "start_time": "2024-10-16T15:50:31.177821800Z"
    }
   },
   "id": "34e833b36917c8bc",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84caa094-f91e-45cd-bb84-e4b502230981",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:33.630605500Z",
     "start_time": "2024-10-16T15:50:33.616604600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 2 0 1 3 3 3 1 3 2 1 2 2 0 2 0 2 0 1 0 2 3 2 3 2 2 3 0 0 0 1 1 2 0 2\n",
      " 3 1 0 3 0 0 0 3 3 1 1 1 2 2 0 3 0 0 3 1 1 3 0 0 1 3 1 0 3 0 1 1 3 0 2 1 2\n",
      " 1 3 3 3 2 2 2 0 1 3 3 3 2 3 1 1 1 1 3 1 1 1 0 0 0 1 0 2 2 2 3 1 3 0 0 3 3\n",
      " 3 3 3]\n",
      "There are 4 unique classes in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Split the data into 50% training and 50% temp (which will later be split into test and validation)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Split the temp data into 50% test and 50% validation, resulting in 25% of the original data each\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print(y_train)\n",
    "num_classess = len(set(y_train))\n",
    "print(f'There are {num_classess} unique classes in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c53d556-affe-4b90-a202-237624ae2400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:33.650135800Z",
     "start_time": "2024-10-16T15:50:33.632605400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (114, 8, 325)\n",
      "114 train samples\n",
      "57 test samples\n"
     ]
    }
   ],
   "source": [
    "kernels, chans, samples = 1, dataset_info[\"#_channels\"], dataset_info[\"samples\"]\n",
    "\n",
    "# y_train = y_train - 1\n",
    "# y_val = y_val - 1\n",
    "# y_test = y_test - 1\n",
    "\n",
    "# X_train      = X_train.reshape(X_train.shape[0], chans, samples)\n",
    "# X_val   = X_val.reshape(X_val.shape[0], chans, samples)\n",
    "# X_test       = X_test.reshape(X_test.shape[0], chans, samples)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Keep as integers\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303908e7-1ac7-4491-8ac4-a83aa51c49bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:33.669133300Z",
     "start_time": "2024-10-16T15:50:33.646617200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in train_loader: 2\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of batches in train_loader\n",
    "train_loader_size = len(train_loader)\n",
    "print(f\"Number of batches in train_loader: {train_loader_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84bd7fd7-e279-4068-9e75-5aa6321f1870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:33.699138900Z",
     "start_time": "2024-10-16T15:50:33.663135600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1.0, 0: 1.0, 2: 1.0, -1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(y)\n",
    "\n",
    "total_samples = sum(counts.values())\n",
    "\n",
    "num_classes = len(counts)\n",
    "\n",
    "class_weights = {class_label-1: total_samples / (num_classes * count) for class_label, count in counts.items()}\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "094b6a7c-ec20-44c0-a3e2-99cee2a60f9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:33.960845500Z",
     "start_time": "2024-10-16T15:50:33.902340300Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1664cc4c-f8e6-40d3-9389-0a9a8732b5c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:35.121497700Z",
     "start_time": "2024-10-16T15:50:34.873670400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "n_classes = dataset_info[\"#_class\"]\n",
    "classes = list(range(n_classes))\n",
    "\n",
    "n_outputs = dataset_info[\"#_class\"]\n",
    "n_chans = dataset_info[\"#_channels\"]\n",
    "n_filters_time = 40\n",
    "filter_time_length = 25\n",
    "pool_time_length = 75\n",
    "pool_time_stride = 15\n",
    "drop_prob = 0.5\n",
    "att_depth = 6\n",
    "att_heads = 10\n",
    "att_drop_prob = 0.5\n",
    "final_fc_length = 640\n",
    "return_features = False\n",
    "n_times = dataset_info[\"samples\"]\n",
    "chs_info = None\n",
    "input_window_seconds = None\n",
    "sfreq = dataset_info[\"sample_rate\"]\n",
    "add_log_softmax = True\n",
    "\n",
    "# Initialize the EEGConformer model\n",
    "conformer = EEGConformer(\n",
    "    n_outputs=n_outputs,\n",
    "    n_chans=n_chans,\n",
    "    n_filters_time=n_filters_time,\n",
    "    filter_time_length=filter_time_length,\n",
    "    pool_time_length=pool_time_length,\n",
    "    pool_time_stride=pool_time_stride,\n",
    "    drop_prob=drop_prob,\n",
    "    att_depth=att_depth,\n",
    "    att_heads=att_heads,\n",
    "    att_drop_prob=att_drop_prob,\n",
    "    final_fc_length=final_fc_length,\n",
    "    return_features=return_features,\n",
    "    n_times=n_times,\n",
    "    chs_info=chs_info,\n",
    "    input_window_seconds=input_window_seconds,\n",
    "    sfreq=sfreq,\n",
    "    add_log_softmax=add_log_softmax\n",
    ")\n",
    "conformer = conformer.to(device)\n",
    "\n",
    "print(conformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f5f63-82a0-4fe3-94fe-d48aac560d54",
   "metadata": {},
   "source": [
    "Do this to find the right final_fc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba38c99-5812-4e07-8566-5b50d2abd7ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:36.569110400Z",
     "start_time": "2024-10-16T15:50:36.556110200Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(conformer.parameters(), lr =  0.0002,betas  = [0.5, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e52920c-c26b-4d99-8636-7fb75e0c4b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:37.280778Z",
     "start_time": "2024-10-16T15:50:37.247261300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "conformer.to(device)\n",
    "\n",
    "# Create a dummy input with the correct shape and move it to the same device\n",
    "dummy_input = torch.randn(kernels, chans, samples).to(device)  # Batch size\n",
    "\n",
    "# Pass the dummy input through the model up to the transformer encoder\n",
    "try:\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        x = torch.unsqueeze(dummy_input, dim=1)  # Add an extra dimension to match input shape\n",
    "        x = conformer.patch_embedding(x)  # Pass through Patch Embedding\n",
    "        x = conformer.transformer(x)  # Pass through Transformer Encoder\n",
    "        \n",
    "        # Get the shape after the transformer and calculate the new `final_fc_length`\n",
    "        print(f\"Output shape after transformer: {x.shape}\")\n",
    "        final_fc_length_calculated = x.shape[1] * x.shape[2]\n",
    "        print(f\"Calculated `final_fc_length`: {final_fc_length_calculated}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error during partial forward pass:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40d5e274-df80-4d85-a648-9535b0b270ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:47.238745600Z",
     "start_time": "2024-10-16T15:50:38.163977200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.4433, Accuracy: 0.2105\n",
      "Validation Loss: 1.3790, Validation Accuracy: 0.3158\n",
      "Epoch [2/250], Loss: 1.4022, Accuracy: 0.3684\n",
      "Validation Loss: 1.3752, Validation Accuracy: 0.3158\n",
      "Epoch [3/250], Loss: 1.4455, Accuracy: 0.2632\n",
      "Validation Loss: 1.3754, Validation Accuracy: 0.3158\n",
      "Epoch [4/250], Loss: 1.3625, Accuracy: 0.3421\n",
      "Validation Loss: 1.3742, Validation Accuracy: 0.3158\n",
      "Epoch [5/250], Loss: 1.3813, Accuracy: 0.2895\n",
      "Validation Loss: 1.3768, Validation Accuracy: 0.3158\n",
      "Epoch [6/250], Loss: 1.4129, Accuracy: 0.2982\n",
      "Validation Loss: 1.3737, Validation Accuracy: 0.3158\n",
      "Epoch [7/250], Loss: 1.3485, Accuracy: 0.3509\n",
      "Validation Loss: 1.3761, Validation Accuracy: 0.3158\n",
      "Epoch [8/250], Loss: 1.3728, Accuracy: 0.2895\n",
      "Validation Loss: 1.3759, Validation Accuracy: 0.3158\n",
      "Epoch [9/250], Loss: 1.4370, Accuracy: 0.2632\n",
      "Validation Loss: 1.3778, Validation Accuracy: 0.3158\n",
      "Epoch [10/250], Loss: 1.4234, Accuracy: 0.3158\n",
      "Validation Loss: 1.3798, Validation Accuracy: 0.2807\n",
      "Epoch [11/250], Loss: 1.4245, Accuracy: 0.3596\n",
      "Validation Loss: 1.3791, Validation Accuracy: 0.3158\n",
      "Epoch [12/250], Loss: 1.3963, Accuracy: 0.3158\n",
      "Validation Loss: 1.3808, Validation Accuracy: 0.3158\n",
      "Epoch [13/250], Loss: 1.4522, Accuracy: 0.2895\n",
      "Validation Loss: 1.3977, Validation Accuracy: 0.2456\n",
      "Epoch [14/250], Loss: 1.3812, Accuracy: 0.2982\n",
      "Validation Loss: 1.3952, Validation Accuracy: 0.2632\n",
      "Epoch [15/250], Loss: 1.4204, Accuracy: 0.3158\n",
      "Validation Loss: 1.3794, Validation Accuracy: 0.3158\n",
      "Epoch [16/250], Loss: 1.4047, Accuracy: 0.2632\n",
      "Validation Loss: 1.3790, Validation Accuracy: 0.2632\n",
      "Epoch [17/250], Loss: 1.3908, Accuracy: 0.2895\n",
      "Validation Loss: 1.3784, Validation Accuracy: 0.2982\n",
      "Epoch [18/250], Loss: 1.4052, Accuracy: 0.2807\n",
      "Validation Loss: 1.3816, Validation Accuracy: 0.2982\n",
      "Epoch [19/250], Loss: 1.3851, Accuracy: 0.2719\n",
      "Validation Loss: 1.3863, Validation Accuracy: 0.3158\n",
      "Epoch [20/250], Loss: 1.3967, Accuracy: 0.2368\n",
      "Validation Loss: 1.3895, Validation Accuracy: 0.2281\n",
      "Epoch [21/250], Loss: 1.3542, Accuracy: 0.3246\n",
      "Validation Loss: 1.3951, Validation Accuracy: 0.2456\n",
      "Epoch [22/250], Loss: 1.4190, Accuracy: 0.2982\n",
      "Validation Loss: 1.3985, Validation Accuracy: 0.2632\n",
      "Epoch [23/250], Loss: 1.3948, Accuracy: 0.3246\n",
      "Validation Loss: 1.4088, Validation Accuracy: 0.2456\n",
      "Epoch [24/250], Loss: 1.4005, Accuracy: 0.3070\n",
      "Validation Loss: 1.3972, Validation Accuracy: 0.2632\n",
      "Epoch [25/250], Loss: 1.3908, Accuracy: 0.3158\n",
      "Validation Loss: 1.3956, Validation Accuracy: 0.2632\n",
      "Epoch [26/250], Loss: 1.3477, Accuracy: 0.4035\n",
      "Validation Loss: 1.4022, Validation Accuracy: 0.1930\n",
      "Epoch [27/250], Loss: 1.3749, Accuracy: 0.3421\n",
      "Validation Loss: 1.4243, Validation Accuracy: 0.2281\n",
      "Epoch [28/250], Loss: 1.3630, Accuracy: 0.3070\n",
      "Validation Loss: 1.4256, Validation Accuracy: 0.2281\n",
      "Epoch [29/250], Loss: 1.3552, Accuracy: 0.3246\n",
      "Validation Loss: 1.4283, Validation Accuracy: 0.2281\n",
      "Epoch [30/250], Loss: 1.4007, Accuracy: 0.3070\n",
      "Validation Loss: 1.4430, Validation Accuracy: 0.2281\n",
      "Epoch [31/250], Loss: 1.4298, Accuracy: 0.2895\n",
      "Validation Loss: 1.4480, Validation Accuracy: 0.2281\n",
      "Epoch [32/250], Loss: 1.4326, Accuracy: 0.3684\n",
      "Validation Loss: 1.4318, Validation Accuracy: 0.2281\n",
      "Epoch [33/250], Loss: 1.3891, Accuracy: 0.3246\n",
      "Validation Loss: 1.4246, Validation Accuracy: 0.1754\n",
      "Epoch [34/250], Loss: 1.4055, Accuracy: 0.2982\n",
      "Validation Loss: 1.4216, Validation Accuracy: 0.2456\n",
      "Epoch [35/250], Loss: 1.3852, Accuracy: 0.3070\n",
      "Validation Loss: 1.4279, Validation Accuracy: 0.2456\n",
      "Epoch [36/250], Loss: 1.3542, Accuracy: 0.3509\n",
      "Validation Loss: 1.4241, Validation Accuracy: 0.2456\n",
      "Epoch [37/250], Loss: 1.3687, Accuracy: 0.2982\n",
      "Validation Loss: 1.4207, Validation Accuracy: 0.2632\n",
      "Epoch [38/250], Loss: 1.3802, Accuracy: 0.2719\n",
      "Validation Loss: 1.4325, Validation Accuracy: 0.2632\n",
      "Epoch [39/250], Loss: 1.3772, Accuracy: 0.3070\n",
      "Validation Loss: 1.4161, Validation Accuracy: 0.2456\n",
      "Epoch [40/250], Loss: 1.3751, Accuracy: 0.3421\n",
      "Validation Loss: 1.4208, Validation Accuracy: 0.1228\n",
      "Epoch [41/250], Loss: 1.3978, Accuracy: 0.3246\n",
      "Validation Loss: 1.4463, Validation Accuracy: 0.1228\n",
      "Epoch [42/250], Loss: 1.3881, Accuracy: 0.2632\n",
      "Validation Loss: 1.4188, Validation Accuracy: 0.1404\n",
      "Epoch [43/250], Loss: 1.4020, Accuracy: 0.3246\n",
      "Validation Loss: 1.4060, Validation Accuracy: 0.1754\n",
      "Epoch [44/250], Loss: 1.3409, Accuracy: 0.3947\n",
      "Validation Loss: 1.4157, Validation Accuracy: 0.2105\n",
      "Epoch [45/250], Loss: 1.3975, Accuracy: 0.3158\n",
      "Validation Loss: 1.4223, Validation Accuracy: 0.2105\n",
      "Epoch [46/250], Loss: 1.3765, Accuracy: 0.2982\n",
      "Validation Loss: 1.4068, Validation Accuracy: 0.2632\n",
      "Epoch [47/250], Loss: 1.3828, Accuracy: 0.2982\n",
      "Validation Loss: 1.4070, Validation Accuracy: 0.2632\n",
      "Epoch [48/250], Loss: 1.3635, Accuracy: 0.2281\n",
      "Validation Loss: 1.3994, Validation Accuracy: 0.2281\n",
      "Epoch [49/250], Loss: 1.3122, Accuracy: 0.4123\n",
      "Validation Loss: 1.3918, Validation Accuracy: 0.2281\n",
      "Epoch [50/250], Loss: 1.3146, Accuracy: 0.3333\n",
      "Validation Loss: 1.4033, Validation Accuracy: 0.1754\n",
      "Epoch [51/250], Loss: 1.3747, Accuracy: 0.3421\n",
      "Validation Loss: 1.4200, Validation Accuracy: 0.1930\n",
      "Epoch [52/250], Loss: 1.3843, Accuracy: 0.2807\n",
      "Validation Loss: 1.4447, Validation Accuracy: 0.1930\n",
      "Epoch [53/250], Loss: 1.4042, Accuracy: 0.3246\n",
      "Validation Loss: 1.4546, Validation Accuracy: 0.1930\n",
      "Epoch [54/250], Loss: 1.3755, Accuracy: 0.3333\n",
      "Validation Loss: 1.4725, Validation Accuracy: 0.1930\n",
      "Epoch [55/250], Loss: 1.3713, Accuracy: 0.2895\n",
      "Validation Loss: 1.5068, Validation Accuracy: 0.1930\n",
      "Epoch [56/250], Loss: 1.3600, Accuracy: 0.3333\n",
      "Validation Loss: 1.5951, Validation Accuracy: 0.1930\n",
      "Epoch [57/250], Loss: 1.3754, Accuracy: 0.3070\n",
      "Validation Loss: 1.5346, Validation Accuracy: 0.1930\n",
      "Epoch [58/250], Loss: 1.3562, Accuracy: 0.3158\n",
      "Validation Loss: 1.4254, Validation Accuracy: 0.2456\n",
      "Epoch [59/250], Loss: 1.3462, Accuracy: 0.3947\n",
      "Validation Loss: 1.3827, Validation Accuracy: 0.2807\n",
      "Epoch [60/250], Loss: 1.3517, Accuracy: 0.2982\n",
      "Validation Loss: 1.3768, Validation Accuracy: 0.3158\n",
      "Epoch [61/250], Loss: 1.3528, Accuracy: 0.3421\n",
      "Validation Loss: 1.3917, Validation Accuracy: 0.3333\n",
      "Epoch [62/250], Loss: 1.3785, Accuracy: 0.2193\n",
      "Validation Loss: 1.4011, Validation Accuracy: 0.2632\n",
      "Epoch [63/250], Loss: 1.3757, Accuracy: 0.2982\n",
      "Validation Loss: 1.4080, Validation Accuracy: 0.2105\n",
      "Epoch [64/250], Loss: 1.3779, Accuracy: 0.2807\n",
      "Validation Loss: 1.4244, Validation Accuracy: 0.2632\n",
      "Epoch [65/250], Loss: 1.3680, Accuracy: 0.3158\n",
      "Validation Loss: 1.4017, Validation Accuracy: 0.2632\n",
      "Epoch [66/250], Loss: 1.3135, Accuracy: 0.3684\n",
      "Validation Loss: 1.3923, Validation Accuracy: 0.2632\n",
      "Epoch [67/250], Loss: 1.3707, Accuracy: 0.2982\n",
      "Validation Loss: 1.3973, Validation Accuracy: 0.2632\n",
      "Epoch [68/250], Loss: 1.3623, Accuracy: 0.2632\n",
      "Validation Loss: 1.3956, Validation Accuracy: 0.2632\n",
      "Epoch [69/250], Loss: 1.3410, Accuracy: 0.3246\n",
      "Validation Loss: 1.4044, Validation Accuracy: 0.2281\n",
      "Epoch [70/250], Loss: 1.3485, Accuracy: 0.3421\n",
      "Validation Loss: 1.4338, Validation Accuracy: 0.2456\n",
      "Epoch [71/250], Loss: 1.3626, Accuracy: 0.3158\n",
      "Validation Loss: 1.6035, Validation Accuracy: 0.2456\n",
      "Epoch [72/250], Loss: 1.3778, Accuracy: 0.2895\n",
      "Validation Loss: 1.4010, Validation Accuracy: 0.3158\n",
      "Epoch [73/250], Loss: 1.3509, Accuracy: 0.3772\n",
      "Validation Loss: 1.4209, Validation Accuracy: 0.2982\n",
      "Epoch [74/250], Loss: 1.3476, Accuracy: 0.2982\n",
      "Validation Loss: 1.3860, Validation Accuracy: 0.3333\n",
      "Epoch [75/250], Loss: 1.3518, Accuracy: 0.3246\n",
      "Validation Loss: 1.3982, Validation Accuracy: 0.3158\n",
      "Epoch [76/250], Loss: 1.3036, Accuracy: 0.3333\n",
      "Validation Loss: 1.4563, Validation Accuracy: 0.2632\n",
      "Epoch [77/250], Loss: 1.3591, Accuracy: 0.3421\n",
      "Validation Loss: 1.4566, Validation Accuracy: 0.2632\n",
      "Epoch [78/250], Loss: 1.3260, Accuracy: 0.3860\n",
      "Validation Loss: 1.4736, Validation Accuracy: 0.1930\n",
      "Epoch [79/250], Loss: 1.3622, Accuracy: 0.3070\n",
      "Validation Loss: 1.6277, Validation Accuracy: 0.1930\n",
      "Epoch [80/250], Loss: 1.3683, Accuracy: 0.2982\n",
      "Validation Loss: 1.6810, Validation Accuracy: 0.1930\n",
      "Epoch [81/250], Loss: 1.3669, Accuracy: 0.2895\n",
      "Validation Loss: 1.9246, Validation Accuracy: 0.1930\n",
      "Epoch [82/250], Loss: 1.3324, Accuracy: 0.3333\n",
      "Validation Loss: 1.9507, Validation Accuracy: 0.1930\n",
      "Epoch [83/250], Loss: 1.3167, Accuracy: 0.3596\n",
      "Validation Loss: 1.9384, Validation Accuracy: 0.1930\n",
      "Epoch [84/250], Loss: 1.3329, Accuracy: 0.3246\n",
      "Validation Loss: 1.7634, Validation Accuracy: 0.1930\n",
      "Epoch [85/250], Loss: 1.3463, Accuracy: 0.3070\n",
      "Validation Loss: 1.6211, Validation Accuracy: 0.1930\n",
      "Epoch [86/250], Loss: 1.3694, Accuracy: 0.2982\n",
      "Validation Loss: 1.5519, Validation Accuracy: 0.1930\n",
      "Epoch [87/250], Loss: 1.3752, Accuracy: 0.3333\n",
      "Validation Loss: 1.5397, Validation Accuracy: 0.1930\n",
      "Epoch [88/250], Loss: 1.3678, Accuracy: 0.3158\n",
      "Validation Loss: 1.6576, Validation Accuracy: 0.1930\n",
      "Epoch [89/250], Loss: 1.3704, Accuracy: 0.2632\n",
      "Validation Loss: 1.5117, Validation Accuracy: 0.1930\n",
      "Epoch [90/250], Loss: 1.3453, Accuracy: 0.3509\n",
      "Validation Loss: 1.4461, Validation Accuracy: 0.2456\n",
      "Epoch [91/250], Loss: 1.3625, Accuracy: 0.3421\n",
      "Validation Loss: 1.4824, Validation Accuracy: 0.2456\n",
      "Epoch [92/250], Loss: 1.3288, Accuracy: 0.3860\n",
      "Validation Loss: 1.4618, Validation Accuracy: 0.2632\n",
      "Epoch [93/250], Loss: 1.3382, Accuracy: 0.3158\n",
      "Validation Loss: 1.4979, Validation Accuracy: 0.1228\n",
      "Epoch [94/250], Loss: 1.3237, Accuracy: 0.3684\n",
      "Validation Loss: 1.4635, Validation Accuracy: 0.2632\n",
      "Epoch [95/250], Loss: 1.3370, Accuracy: 0.3947\n",
      "Validation Loss: 1.4609, Validation Accuracy: 0.1754\n",
      "Epoch [96/250], Loss: 1.3843, Accuracy: 0.2982\n",
      "Validation Loss: 1.4638, Validation Accuracy: 0.1579\n",
      "Epoch [97/250], Loss: 1.2860, Accuracy: 0.3947\n",
      "Validation Loss: 1.4623, Validation Accuracy: 0.2456\n",
      "Epoch [98/250], Loss: 1.3322, Accuracy: 0.3509\n",
      "Validation Loss: 1.4978, Validation Accuracy: 0.2105\n",
      "Epoch [99/250], Loss: 1.3434, Accuracy: 0.3596\n",
      "Validation Loss: 1.4683, Validation Accuracy: 0.2456\n",
      "Epoch [100/250], Loss: 1.3649, Accuracy: 0.2982\n",
      "Validation Loss: 1.5133, Validation Accuracy: 0.1930\n",
      "Epoch [101/250], Loss: 1.3487, Accuracy: 0.3246\n",
      "Validation Loss: 1.8059, Validation Accuracy: 0.1930\n",
      "Epoch [102/250], Loss: 1.3281, Accuracy: 0.3246\n",
      "Validation Loss: 1.6956, Validation Accuracy: 0.1930\n",
      "Epoch [103/250], Loss: 1.3270, Accuracy: 0.3684\n",
      "Validation Loss: 1.4553, Validation Accuracy: 0.2105\n",
      "Epoch [104/250], Loss: 1.2962, Accuracy: 0.4123\n",
      "Validation Loss: 1.4808, Validation Accuracy: 0.1930\n",
      "Epoch [105/250], Loss: 1.3430, Accuracy: 0.3246\n",
      "Validation Loss: 1.4832, Validation Accuracy: 0.1930\n",
      "Epoch [106/250], Loss: 1.3324, Accuracy: 0.3158\n",
      "Validation Loss: 1.5133, Validation Accuracy: 0.2105\n",
      "Epoch [107/250], Loss: 1.2988, Accuracy: 0.3596\n",
      "Validation Loss: 1.5634, Validation Accuracy: 0.2105\n",
      "Epoch [108/250], Loss: 1.3204, Accuracy: 0.3684\n",
      "Validation Loss: 1.6912, Validation Accuracy: 0.1930\n",
      "Epoch [109/250], Loss: 1.3729, Accuracy: 0.2895\n",
      "Validation Loss: 1.7936, Validation Accuracy: 0.1930\n",
      "Epoch [110/250], Loss: 1.3471, Accuracy: 0.4035\n",
      "Validation Loss: 1.8482, Validation Accuracy: 0.1930\n",
      "Epoch [111/250], Loss: 1.3884, Accuracy: 0.3421\n",
      "Validation Loss: 1.6105, Validation Accuracy: 0.2456\n",
      "Epoch [112/250], Loss: 1.2897, Accuracy: 0.3158\n",
      "Validation Loss: 1.4450, Validation Accuracy: 0.2105\n",
      "Epoch [113/250], Loss: 1.3438, Accuracy: 0.3070\n",
      "Validation Loss: 1.4347, Validation Accuracy: 0.2632\n",
      "Epoch [114/250], Loss: 1.3276, Accuracy: 0.3421\n",
      "Validation Loss: 1.4481, Validation Accuracy: 0.2105\n",
      "Epoch [115/250], Loss: 1.3406, Accuracy: 0.3421\n",
      "Validation Loss: 1.7090, Validation Accuracy: 0.2281\n",
      "Epoch [116/250], Loss: 1.3596, Accuracy: 0.3070\n",
      "Validation Loss: 1.6028, Validation Accuracy: 0.2281\n",
      "Epoch [117/250], Loss: 1.3451, Accuracy: 0.2895\n",
      "Validation Loss: 1.5383, Validation Accuracy: 0.2281\n",
      "Epoch [118/250], Loss: 1.3317, Accuracy: 0.3684\n",
      "Validation Loss: 1.6089, Validation Accuracy: 0.1930\n",
      "Epoch [119/250], Loss: 1.3329, Accuracy: 0.3333\n",
      "Validation Loss: 1.5865, Validation Accuracy: 0.2456\n",
      "Epoch [120/250], Loss: 1.3986, Accuracy: 0.3158\n",
      "Validation Loss: 1.7200, Validation Accuracy: 0.1930\n",
      "Epoch [121/250], Loss: 1.3760, Accuracy: 0.3158\n",
      "Validation Loss: 2.0161, Validation Accuracy: 0.1930\n",
      "Epoch [122/250], Loss: 1.3394, Accuracy: 0.2807\n",
      "Validation Loss: 1.8274, Validation Accuracy: 0.1930\n",
      "Epoch [123/250], Loss: 1.3348, Accuracy: 0.3596\n",
      "Validation Loss: 1.7627, Validation Accuracy: 0.1930\n",
      "Epoch [124/250], Loss: 1.3657, Accuracy: 0.3246\n",
      "Validation Loss: 1.9199, Validation Accuracy: 0.1930\n",
      "Epoch [125/250], Loss: 1.3329, Accuracy: 0.3333\n",
      "Validation Loss: 1.7956, Validation Accuracy: 0.1930\n",
      "Epoch [126/250], Loss: 1.3615, Accuracy: 0.3333\n",
      "Validation Loss: 1.6296, Validation Accuracy: 0.1930\n",
      "Epoch [127/250], Loss: 1.3012, Accuracy: 0.3596\n",
      "Validation Loss: 1.8012, Validation Accuracy: 0.1930\n",
      "Epoch [128/250], Loss: 1.3316, Accuracy: 0.3421\n",
      "Validation Loss: 1.5761, Validation Accuracy: 0.1930\n",
      "Epoch [129/250], Loss: 1.3066, Accuracy: 0.3947\n",
      "Validation Loss: 1.5194, Validation Accuracy: 0.1930\n",
      "Epoch [130/250], Loss: 1.3172, Accuracy: 0.3772\n",
      "Validation Loss: 1.6152, Validation Accuracy: 0.2105\n",
      "Epoch [131/250], Loss: 1.3761, Accuracy: 0.2368\n",
      "Validation Loss: 1.7403, Validation Accuracy: 0.2982\n",
      "Epoch [132/250], Loss: 1.3888, Accuracy: 0.2895\n",
      "Validation Loss: 1.7020, Validation Accuracy: 0.3158\n",
      "Epoch [133/250], Loss: 1.3547, Accuracy: 0.2982\n",
      "Validation Loss: 1.6480, Validation Accuracy: 0.1930\n",
      "Epoch [134/250], Loss: 1.3297, Accuracy: 0.3772\n",
      "Validation Loss: 1.7752, Validation Accuracy: 0.1930\n",
      "Epoch [135/250], Loss: 1.3162, Accuracy: 0.3772\n",
      "Validation Loss: 1.7399, Validation Accuracy: 0.1930\n",
      "Epoch [136/250], Loss: 1.3106, Accuracy: 0.3947\n",
      "Validation Loss: 1.8783, Validation Accuracy: 0.1930\n",
      "Epoch [137/250], Loss: 1.3708, Accuracy: 0.3246\n",
      "Validation Loss: 1.7206, Validation Accuracy: 0.1930\n",
      "Epoch [138/250], Loss: 1.3274, Accuracy: 0.3158\n",
      "Validation Loss: 1.6703, Validation Accuracy: 0.1930\n",
      "Epoch [139/250], Loss: 1.3720, Accuracy: 0.3070\n",
      "Validation Loss: 1.6276, Validation Accuracy: 0.1930\n",
      "Epoch [140/250], Loss: 1.3056, Accuracy: 0.3684\n",
      "Validation Loss: 1.6270, Validation Accuracy: 0.1930\n",
      "Epoch [141/250], Loss: 1.3474, Accuracy: 0.3772\n",
      "Validation Loss: 1.7345, Validation Accuracy: 0.1930\n",
      "Epoch [142/250], Loss: 1.3562, Accuracy: 0.3158\n",
      "Validation Loss: 1.7178, Validation Accuracy: 0.1930\n",
      "Epoch [143/250], Loss: 1.3557, Accuracy: 0.2719\n",
      "Validation Loss: 1.7561, Validation Accuracy: 0.1930\n",
      "Epoch [144/250], Loss: 1.3524, Accuracy: 0.3509\n",
      "Validation Loss: 1.8796, Validation Accuracy: 0.1930\n",
      "Epoch [145/250], Loss: 1.3500, Accuracy: 0.3246\n",
      "Validation Loss: 1.5701, Validation Accuracy: 0.1930\n",
      "Epoch [146/250], Loss: 1.3221, Accuracy: 0.2895\n",
      "Validation Loss: 1.5652, Validation Accuracy: 0.1930\n",
      "Epoch [147/250], Loss: 1.3360, Accuracy: 0.3860\n",
      "Validation Loss: 1.6282, Validation Accuracy: 0.1930\n",
      "Epoch [148/250], Loss: 1.3645, Accuracy: 0.2456\n",
      "Validation Loss: 1.6385, Validation Accuracy: 0.1930\n",
      "Epoch [149/250], Loss: 1.3473, Accuracy: 0.2982\n",
      "Validation Loss: 1.6016, Validation Accuracy: 0.1930\n",
      "Epoch [150/250], Loss: 1.3304, Accuracy: 0.3860\n",
      "Validation Loss: 1.4647, Validation Accuracy: 0.2632\n",
      "Epoch [151/250], Loss: 1.3182, Accuracy: 0.3596\n",
      "Validation Loss: 1.4927, Validation Accuracy: 0.1930\n",
      "Epoch [152/250], Loss: 1.3483, Accuracy: 0.3509\n",
      "Validation Loss: 1.5989, Validation Accuracy: 0.1930\n",
      "Epoch [153/250], Loss: 1.3008, Accuracy: 0.3509\n",
      "Validation Loss: 1.6524, Validation Accuracy: 0.1930\n",
      "Epoch [154/250], Loss: 1.3430, Accuracy: 0.3509\n",
      "Validation Loss: 1.8513, Validation Accuracy: 0.1930\n",
      "Epoch [155/250], Loss: 1.3462, Accuracy: 0.2982\n",
      "Validation Loss: 1.8074, Validation Accuracy: 0.1930\n",
      "Epoch [156/250], Loss: 1.3118, Accuracy: 0.4035\n",
      "Validation Loss: 1.7560, Validation Accuracy: 0.1930\n",
      "Epoch [157/250], Loss: 1.3407, Accuracy: 0.2895\n",
      "Validation Loss: 1.5037, Validation Accuracy: 0.1930\n",
      "Epoch [158/250], Loss: 1.3765, Accuracy: 0.2895\n",
      "Validation Loss: 1.7694, Validation Accuracy: 0.1930\n",
      "Epoch [159/250], Loss: 1.2889, Accuracy: 0.3421\n",
      "Validation Loss: 2.1879, Validation Accuracy: 0.1930\n",
      "Epoch [160/250], Loss: 1.3553, Accuracy: 0.2895\n",
      "Validation Loss: 2.1186, Validation Accuracy: 0.1930\n",
      "Epoch [161/250], Loss: 1.3488, Accuracy: 0.2895\n",
      "Validation Loss: 2.0375, Validation Accuracy: 0.1930\n",
      "Epoch [162/250], Loss: 1.3191, Accuracy: 0.3509\n",
      "Validation Loss: 1.9400, Validation Accuracy: 0.1930\n",
      "Epoch [163/250], Loss: 1.3092, Accuracy: 0.3509\n",
      "Validation Loss: 1.8166, Validation Accuracy: 0.1930\n",
      "Epoch [164/250], Loss: 1.3681, Accuracy: 0.3684\n",
      "Validation Loss: 1.8032, Validation Accuracy: 0.1930\n",
      "Epoch [165/250], Loss: 1.2979, Accuracy: 0.3684\n",
      "Validation Loss: 1.9662, Validation Accuracy: 0.1930\n",
      "Epoch [166/250], Loss: 1.3346, Accuracy: 0.3333\n",
      "Validation Loss: 1.7509, Validation Accuracy: 0.1930\n",
      "Epoch [167/250], Loss: 1.3668, Accuracy: 0.2719\n",
      "Validation Loss: 1.8956, Validation Accuracy: 0.1930\n",
      "Epoch [168/250], Loss: 1.3130, Accuracy: 0.3596\n",
      "Validation Loss: 2.1736, Validation Accuracy: 0.1930\n",
      "Epoch [169/250], Loss: 1.3870, Accuracy: 0.3421\n",
      "Validation Loss: 1.8627, Validation Accuracy: 0.1930\n",
      "Epoch [170/250], Loss: 1.3232, Accuracy: 0.3596\n",
      "Validation Loss: 1.4958, Validation Accuracy: 0.1930\n",
      "Epoch [171/250], Loss: 1.3244, Accuracy: 0.3158\n",
      "Validation Loss: 1.5402, Validation Accuracy: 0.1930\n",
      "Epoch [172/250], Loss: 1.3537, Accuracy: 0.3333\n",
      "Validation Loss: 1.8556, Validation Accuracy: 0.1930\n",
      "Epoch [173/250], Loss: 1.3416, Accuracy: 0.2982\n",
      "Validation Loss: 2.2369, Validation Accuracy: 0.1930\n",
      "Epoch [174/250], Loss: 1.3077, Accuracy: 0.3509\n",
      "Validation Loss: 1.7815, Validation Accuracy: 0.1930\n",
      "Epoch [175/250], Loss: 1.3359, Accuracy: 0.3684\n",
      "Validation Loss: 1.6803, Validation Accuracy: 0.1930\n",
      "Epoch [176/250], Loss: 1.3657, Accuracy: 0.3158\n",
      "Validation Loss: 1.7383, Validation Accuracy: 0.1930\n",
      "Epoch [177/250], Loss: 1.3417, Accuracy: 0.3333\n",
      "Validation Loss: 1.6536, Validation Accuracy: 0.1930\n",
      "Epoch [178/250], Loss: 1.2984, Accuracy: 0.3772\n",
      "Validation Loss: 1.5947, Validation Accuracy: 0.1930\n",
      "Epoch [179/250], Loss: 1.3042, Accuracy: 0.3421\n",
      "Validation Loss: 1.5123, Validation Accuracy: 0.2281\n",
      "Epoch [180/250], Loss: 1.3083, Accuracy: 0.3772\n",
      "Validation Loss: 1.4709, Validation Accuracy: 0.2281\n",
      "Epoch [181/250], Loss: 1.3258, Accuracy: 0.3684\n",
      "Validation Loss: 1.4624, Validation Accuracy: 0.2105\n",
      "Epoch [182/250], Loss: 1.3504, Accuracy: 0.2982\n",
      "Validation Loss: 1.4754, Validation Accuracy: 0.1754\n",
      "Epoch [183/250], Loss: 1.3116, Accuracy: 0.3860\n",
      "Validation Loss: 1.4803, Validation Accuracy: 0.1930\n",
      "Epoch [184/250], Loss: 1.3628, Accuracy: 0.3421\n",
      "Validation Loss: 1.4289, Validation Accuracy: 0.2982\n",
      "Epoch [185/250], Loss: 1.3307, Accuracy: 0.3421\n",
      "Validation Loss: 1.6969, Validation Accuracy: 0.1930\n",
      "Epoch [186/250], Loss: 1.3253, Accuracy: 0.3772\n",
      "Validation Loss: 1.6525, Validation Accuracy: 0.1930\n",
      "Epoch [187/250], Loss: 1.3229, Accuracy: 0.3421\n",
      "Validation Loss: 1.5480, Validation Accuracy: 0.1930\n",
      "Epoch [188/250], Loss: 1.2831, Accuracy: 0.4035\n",
      "Validation Loss: 1.6116, Validation Accuracy: 0.1930\n",
      "Epoch [189/250], Loss: 1.2967, Accuracy: 0.3509\n",
      "Validation Loss: 1.6039, Validation Accuracy: 0.1930\n",
      "Epoch [190/250], Loss: 1.3144, Accuracy: 0.2982\n",
      "Validation Loss: 1.6052, Validation Accuracy: 0.1930\n",
      "Epoch [191/250], Loss: 1.3081, Accuracy: 0.3596\n",
      "Validation Loss: 1.5909, Validation Accuracy: 0.1930\n",
      "Epoch [192/250], Loss: 1.3623, Accuracy: 0.3333\n",
      "Validation Loss: 1.5600, Validation Accuracy: 0.2456\n",
      "Epoch [193/250], Loss: 1.3343, Accuracy: 0.3421\n",
      "Validation Loss: 1.5010, Validation Accuracy: 0.2632\n",
      "Epoch [194/250], Loss: 1.3080, Accuracy: 0.3421\n",
      "Validation Loss: 1.6879, Validation Accuracy: 0.1930\n",
      "Epoch [195/250], Loss: 1.2942, Accuracy: 0.3421\n",
      "Validation Loss: 1.9009, Validation Accuracy: 0.1930\n",
      "Epoch [196/250], Loss: 1.3531, Accuracy: 0.3158\n",
      "Validation Loss: 1.8048, Validation Accuracy: 0.1930\n",
      "Epoch [197/250], Loss: 1.3140, Accuracy: 0.3509\n",
      "Validation Loss: 2.3198, Validation Accuracy: 0.1930\n",
      "Epoch [198/250], Loss: 1.3130, Accuracy: 0.3772\n",
      "Validation Loss: 2.5493, Validation Accuracy: 0.1930\n",
      "Epoch [199/250], Loss: 1.2923, Accuracy: 0.3860\n",
      "Validation Loss: 2.2462, Validation Accuracy: 0.1930\n",
      "Epoch [200/250], Loss: 1.3378, Accuracy: 0.3246\n",
      "Validation Loss: 1.9872, Validation Accuracy: 0.1930\n",
      "Epoch [201/250], Loss: 1.3113, Accuracy: 0.3158\n",
      "Validation Loss: 1.7052, Validation Accuracy: 0.1930\n",
      "Epoch [202/250], Loss: 1.3458, Accuracy: 0.3246\n",
      "Validation Loss: 1.6699, Validation Accuracy: 0.1930\n",
      "Epoch [203/250], Loss: 1.3466, Accuracy: 0.3246\n",
      "Validation Loss: 1.6220, Validation Accuracy: 0.1930\n",
      "Epoch [204/250], Loss: 1.2916, Accuracy: 0.3772\n",
      "Validation Loss: 1.6426, Validation Accuracy: 0.1930\n",
      "Epoch [205/250], Loss: 1.3642, Accuracy: 0.3246\n",
      "Validation Loss: 1.8381, Validation Accuracy: 0.1930\n",
      "Epoch [206/250], Loss: 1.3637, Accuracy: 0.2982\n",
      "Validation Loss: 2.1168, Validation Accuracy: 0.1930\n",
      "Epoch [207/250], Loss: 1.2835, Accuracy: 0.4035\n",
      "Validation Loss: 2.0981, Validation Accuracy: 0.1930\n",
      "Epoch [208/250], Loss: 1.3498, Accuracy: 0.3421\n",
      "Validation Loss: 1.9658, Validation Accuracy: 0.1930\n",
      "Epoch [209/250], Loss: 1.3610, Accuracy: 0.2719\n",
      "Validation Loss: 2.0523, Validation Accuracy: 0.1930\n",
      "Epoch [210/250], Loss: 1.3083, Accuracy: 0.3947\n",
      "Validation Loss: 2.0480, Validation Accuracy: 0.1930\n",
      "Epoch [211/250], Loss: 1.2985, Accuracy: 0.3684\n",
      "Validation Loss: 1.4510, Validation Accuracy: 0.3158\n",
      "Epoch [212/250], Loss: 1.2999, Accuracy: 0.3684\n",
      "Validation Loss: 1.5156, Validation Accuracy: 0.1930\n",
      "Epoch [213/250], Loss: 1.3048, Accuracy: 0.3860\n",
      "Validation Loss: 1.4339, Validation Accuracy: 0.2281\n",
      "Epoch [214/250], Loss: 1.2959, Accuracy: 0.3333\n",
      "Validation Loss: 1.4594, Validation Accuracy: 0.2456\n",
      "Epoch [215/250], Loss: 1.3578, Accuracy: 0.3070\n",
      "Validation Loss: 1.6077, Validation Accuracy: 0.2456\n",
      "Epoch [216/250], Loss: 1.3207, Accuracy: 0.3333\n",
      "Validation Loss: 1.6256, Validation Accuracy: 0.1930\n",
      "Epoch [217/250], Loss: 1.3507, Accuracy: 0.3070\n",
      "Validation Loss: 1.6195, Validation Accuracy: 0.1930\n",
      "Epoch [218/250], Loss: 1.2855, Accuracy: 0.4123\n",
      "Validation Loss: 1.7724, Validation Accuracy: 0.1930\n",
      "Epoch [219/250], Loss: 1.3074, Accuracy: 0.3333\n",
      "Validation Loss: 1.9278, Validation Accuracy: 0.1930\n",
      "Epoch [220/250], Loss: 1.3079, Accuracy: 0.2982\n",
      "Validation Loss: 1.5669, Validation Accuracy: 0.2105\n",
      "Epoch [221/250], Loss: 1.3172, Accuracy: 0.3421\n",
      "Validation Loss: 1.5681, Validation Accuracy: 0.1930\n",
      "Epoch [222/250], Loss: 1.3225, Accuracy: 0.3860\n",
      "Validation Loss: 1.8477, Validation Accuracy: 0.1930\n",
      "Epoch [223/250], Loss: 1.3151, Accuracy: 0.3860\n",
      "Validation Loss: 1.7855, Validation Accuracy: 0.1930\n",
      "Epoch [224/250], Loss: 1.3582, Accuracy: 0.3333\n",
      "Validation Loss: 1.6420, Validation Accuracy: 0.1930\n",
      "Epoch [225/250], Loss: 1.3597, Accuracy: 0.3860\n",
      "Validation Loss: 1.5153, Validation Accuracy: 0.1930\n",
      "Epoch [226/250], Loss: 1.3455, Accuracy: 0.3246\n",
      "Validation Loss: 1.4838, Validation Accuracy: 0.1930\n",
      "Epoch [227/250], Loss: 1.3086, Accuracy: 0.3246\n",
      "Validation Loss: 1.5034, Validation Accuracy: 0.1930\n",
      "Epoch [228/250], Loss: 1.2852, Accuracy: 0.3860\n",
      "Validation Loss: 1.7788, Validation Accuracy: 0.1930\n",
      "Epoch [229/250], Loss: 1.3063, Accuracy: 0.3070\n",
      "Validation Loss: 2.2278, Validation Accuracy: 0.1930\n",
      "Epoch [230/250], Loss: 1.3262, Accuracy: 0.3070\n",
      "Validation Loss: 2.0470, Validation Accuracy: 0.1930\n",
      "Epoch [231/250], Loss: 1.3437, Accuracy: 0.3333\n",
      "Validation Loss: 1.5134, Validation Accuracy: 0.2281\n",
      "Epoch [232/250], Loss: 1.3588, Accuracy: 0.2544\n",
      "Validation Loss: 1.6101, Validation Accuracy: 0.2105\n",
      "Epoch [233/250], Loss: 1.3297, Accuracy: 0.3509\n",
      "Validation Loss: 1.9161, Validation Accuracy: 0.1930\n",
      "Epoch [234/250], Loss: 1.3178, Accuracy: 0.3246\n",
      "Validation Loss: 2.1573, Validation Accuracy: 0.1930\n",
      "Epoch [235/250], Loss: 1.3197, Accuracy: 0.3509\n",
      "Validation Loss: 1.8563, Validation Accuracy: 0.1930\n",
      "Epoch [236/250], Loss: 1.2922, Accuracy: 0.4474\n",
      "Validation Loss: 1.9728, Validation Accuracy: 0.1930\n",
      "Epoch [237/250], Loss: 1.3153, Accuracy: 0.3421\n",
      "Validation Loss: 1.8970, Validation Accuracy: 0.1930\n",
      "Epoch [238/250], Loss: 1.3182, Accuracy: 0.3246\n",
      "Validation Loss: 1.6913, Validation Accuracy: 0.1930\n",
      "Epoch [239/250], Loss: 1.3611, Accuracy: 0.3158\n",
      "Validation Loss: 1.9675, Validation Accuracy: 0.1930\n",
      "Epoch [240/250], Loss: 1.3165, Accuracy: 0.3333\n",
      "Validation Loss: 2.1726, Validation Accuracy: 0.1930\n",
      "Epoch [241/250], Loss: 1.3314, Accuracy: 0.2632\n",
      "Validation Loss: 2.3020, Validation Accuracy: 0.1930\n",
      "Epoch [242/250], Loss: 1.3333, Accuracy: 0.3246\n",
      "Validation Loss: 2.3690, Validation Accuracy: 0.1930\n",
      "Epoch [243/250], Loss: 1.2916, Accuracy: 0.3860\n",
      "Validation Loss: 2.5776, Validation Accuracy: 0.1930\n",
      "Epoch [244/250], Loss: 1.3103, Accuracy: 0.3333\n",
      "Validation Loss: 2.5160, Validation Accuracy: 0.1930\n",
      "Epoch [245/250], Loss: 1.3727, Accuracy: 0.2632\n",
      "Validation Loss: 2.1149, Validation Accuracy: 0.1930\n",
      "Epoch [246/250], Loss: 1.3474, Accuracy: 0.2807\n",
      "Validation Loss: 1.9788, Validation Accuracy: 0.1930\n",
      "Epoch [247/250], Loss: 1.3656, Accuracy: 0.2982\n",
      "Validation Loss: 1.9166, Validation Accuracy: 0.1930\n",
      "Epoch [248/250], Loss: 1.3461, Accuracy: 0.3070\n",
      "Validation Loss: 1.5236, Validation Accuracy: 0.2105\n",
      "Epoch [249/250], Loss: 1.3329, Accuracy: 0.3333\n",
      "Validation Loss: 1.5001, Validation Accuracy: 0.1404\n",
      "Epoch [250/250], Loss: 1.3174, Accuracy: 0.3684\n",
      "Validation Loss: 1.5491, Validation Accuracy: 0.2456\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 250\n",
    "## TRAIN\n",
    "for epoch in range(num_epochs):\n",
    "    conformer.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = conformer(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == y_batch).sum().item()\n",
    "        total_predictions += y_batch.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "## Validation\n",
    "    conformer.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            outputs = conformer(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == y_batch).sum().item()\n",
    "            total_predictions += y_batch.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d568117a-3c9d-48b1-a90b-8ed2df89fe96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T15:50:47.251751700Z",
     "start_time": "2024-10-16T15:50:47.236747300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.7100\n",
      "Test Accuracy: 0.1930\n"
     ]
    }
   ],
   "source": [
    "## TEST\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        outputs = conformer(X_batch)\n",
    "        \n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest score\n",
    "        correct_predictions += (predicted == y_batch).sum().item()\n",
    "        total_predictions += y_batch.size(0)\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f0565c3c4101da64"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
