{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667cbb0e-b42e-4ea6-a195-b296702614ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:16.800602100Z",
     "start_time": "2024-09-21T17:32:16.790091100Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'conformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c504eba-a256-4ddb-bc17-55b59d27a609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:27.474963300Z",
     "start_time": "2024-09-21T17:32:16.797601600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\moabb\\pipelines\\__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from braindecode.models import EEGConformer\n",
    "\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae83aafa-2a37-42f7-9ace-d937ca00c107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:27.538045400Z",
     "start_time": "2024-09-21T17:32:27.474963300Z"
    }
   },
   "outputs": [],
   "source": [
    "from processing_eeg_methods.data_utils import (\n",
    "    convert_into_independent_channels,\n",
    "    get_dataset_basic_info,\n",
    "    get_input_data_path,\n",
    "    standard_saving_path,\n",
    "    write_model_info,\n",
    ")\n",
    "from processing_eeg_methods.data_loaders import load_data_labels_based_on_dataset\n",
    "from processing_eeg_methods.share import datasets_basic_infos\n",
    "\n",
    "subject_id = 8  # Only two things I should be able to change\n",
    "dataset_name = \"braincommand\"  # Only two things I should be able to change\n",
    "\n",
    "dataset_info = get_dataset_basic_info(datasets_basic_infos, dataset_name)\n",
    "\n",
    "data_path = r\"C:\\Users\\rosit\\Documents\\workprojects\\bci_complete\\EEG-Classifiers-Ensemble\\Datasets\\braincommand_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load calibration and singleplayer with labels 0 and 1, respectively."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b02cfc902e0443e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0 is 85\n",
      "label 1 is 102\n",
      "label 2 is 65\n",
      "label 3 is 23\n",
      "Not setting metadata\n",
      "275 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "epochs_calibration, X_calibration, y_calibration_original = load_data_labels_based_on_dataset(\n",
    "    dataset_info,\n",
    "    subject_id,\n",
    "    data_path,\n",
    "    game_mode=\"calibration3\",\n",
    ")\n",
    "\n",
    "epochs_singleplayer, X_singleplayer, y_singleplayer_original = load_data_labels_based_on_dataset(\n",
    "    dataset_info,\n",
    "    subject_id,\n",
    "    data_path,\n",
    "    game_mode=\"singleplayer\",\n",
    ")\n",
    "y_calibration = [0] * len(y_calibration_original)\n",
    "y_singleplayer = [1] * len(y_singleplayer_original)\n",
    "\n",
    "X = np.concatenate((X_calibration, X_singleplayer), axis=0)\n",
    "y = y_calibration + y_singleplayer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-20T20:46:44.317751Z",
     "start_time": "2024-09-20T20:46:39.047144300Z"
    }
   },
   "id": "2295ef4877e545bd",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load calibration from the clean .set file after EEGLAB manual rejection."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1527695aa317824d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from C:\\Users\\rosit\\Documents\\MATLAB\\clean EEG BrainCommand\\datasets_edited\\8_calibration3_cleaned.set...\n",
      "Not setting metadata\n",
      "166 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "filepath = r\"C:\\Users\\rosit\\Documents\\MATLAB\\clean EEG BrainCommand\\datasets_edited/8_calibration3_cleaned.set\"\n",
    "epochs = mne.io.read_epochs_eeglab(filepath, verbose=True)\n",
    "X = epochs.get_data()\n",
    "y = epochs.events[:, 2].astype(np.int64)\n",
    "y = y - 1\n",
    "dataset_info[\"#_channels\"] = 7"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:27.585533400Z",
     "start_time": "2024-09-21T17:32:27.540045100Z"
    }
   },
   "id": "34e833b36917c8bc",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84caa094-f91e-45cd-bb84-e4b502230981",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:27.603646Z",
     "start_time": "2024-09-21T17:32:27.584541900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 3 2 1 0 0 3 2 1 1 1 3 3 0 1 1 3 2 1 1 1 0 2 0 3 3 3 3 1 0 3 1 0 3 3\n",
      " 0 2 1 2 3 3 3 3 2 2 2 2 3 3 0 1 2 1 1 0 0 2 0 2 2 0 0 3 1 2 0 0 0 1 1 1 0\n",
      " 1 1 3 3 1 0 1 1 3]\n",
      "There are 4 unique classes in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Split the data into 50% training and 50% temp (which will later be split into test and validation)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# Split the temp data into 50% test and 50% validation, resulting in 25% of the original data each\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print(y_train)\n",
    "num_classess = len(set(y_train))\n",
    "print(f'There are {num_classess} unique classes in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c53d556-affe-4b90-a202-237624ae2400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:27.634312600Z",
     "start_time": "2024-09-21T17:32:27.600512400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (83, 7, 325)\n",
      "83 train samples\n",
      "41 test samples\n"
     ]
    }
   ],
   "source": [
    "kernels, chans, samples = 1, dataset_info[\"#_channels\"], dataset_info[\"samples\"]\n",
    "\n",
    "# y_train = y_train - 1\n",
    "# y_val = y_val - 1\n",
    "# y_test = y_test - 1\n",
    "\n",
    "# X_train      = X_train.reshape(X_train.shape[0], chans, samples)\n",
    "# X_val   = X_val.reshape(X_val.shape[0], chans, samples)\n",
    "# X_test       = X_test.reshape(X_test.shape[0], chans, samples)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Keep as integers\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303908e7-1ac7-4491-8ac4-a83aa51c49bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:27.657943700Z",
     "start_time": "2024-09-21T17:32:27.630804800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in train_loader: 2\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of batches in train_loader\n",
    "train_loader_size = len(train_loader)\n",
    "print(f\"Number of batches in train_loader: {train_loader_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84bd7fd7-e279-4068-9e75-5aa6321f1870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:27.663891200Z",
     "start_time": "2024-09-21T17:32:27.647820300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-1: 0.9651162790697675, 0: 0.9431818181818182, 1: 1.0921052631578947, 2: 1.0121951219512195}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(y)\n",
    "\n",
    "total_samples = sum(counts.values())\n",
    "\n",
    "num_classes = len(counts)\n",
    "\n",
    "class_weights = {class_label-1: total_samples / (num_classes * count) for class_label, count in counts.items()}\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "094b6a7c-ec20-44c0-a3e2-99cee2a60f9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:27.690469700Z",
     "start_time": "2024-09-21T17:32:27.662887300Z"
    }
   },
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1664cc4c-f8e6-40d3-9389-0a9a8732b5c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:28.376105300Z",
     "start_time": "2024-09-21T17:32:27.680411Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 7, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 7, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 7, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 7, 325]            [1, 40, 7, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 7, 301]           [1, 40, 1, 301]           11,240                    [7, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 304,772\n",
      "Trainable params: 304,772\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 5.89\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.21\n",
      "Params size (MB): 1.22\n",
      "Estimated Total Size (MB): 2.44\n",
      "================================================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "n_classes = dataset_info[\"#_class\"]\n",
    "classes = list(range(n_classes))\n",
    "\n",
    "n_outputs = dataset_info[\"#_class\"]\n",
    "n_chans = dataset_info[\"#_channels\"]\n",
    "n_filters_time = 40\n",
    "filter_time_length = 25\n",
    "pool_time_length = 75\n",
    "pool_time_stride = 15\n",
    "drop_prob = 0.5\n",
    "att_depth = 6\n",
    "att_heads = 10\n",
    "att_drop_prob = 0.5\n",
    "final_fc_length = 640\n",
    "return_features = False\n",
    "n_times = dataset_info[\"samples\"]\n",
    "chs_info = None\n",
    "input_window_seconds = None\n",
    "sfreq = dataset_info[\"sample_rate\"]\n",
    "add_log_softmax = True\n",
    "\n",
    "# Initialize the EEGConformer model\n",
    "conformer = EEGConformer(\n",
    "    n_outputs=n_outputs,\n",
    "    n_chans=n_chans,\n",
    "    n_filters_time=n_filters_time,\n",
    "    filter_time_length=filter_time_length,\n",
    "    pool_time_length=pool_time_length,\n",
    "    pool_time_stride=pool_time_stride,\n",
    "    drop_prob=drop_prob,\n",
    "    att_depth=att_depth,\n",
    "    att_heads=att_heads,\n",
    "    att_drop_prob=att_drop_prob,\n",
    "    final_fc_length=final_fc_length,\n",
    "    return_features=return_features,\n",
    "    n_times=n_times,\n",
    "    chs_info=chs_info,\n",
    "    input_window_seconds=input_window_seconds,\n",
    "    sfreq=sfreq,\n",
    "    add_log_softmax=add_log_softmax\n",
    ")\n",
    "conformer = conformer.to(device)\n",
    "\n",
    "print(conformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f5f63-82a0-4fe3-94fe-d48aac560d54",
   "metadata": {},
   "source": [
    "Do this to find the right final_fc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba38c99-5812-4e07-8566-5b50d2abd7ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:28.399127900Z",
     "start_time": "2024-09-21T17:32:28.378104900Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(conformer.parameters(), lr =  0.0002,betas  = [0.5, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e52920c-c26b-4d99-8636-7fb75e0c4b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:32:28.438868400Z",
     "start_time": "2024-09-21T17:32:28.393116500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "conformer.to(device)\n",
    "\n",
    "# Create a dummy input with the correct shape and move it to the same device\n",
    "dummy_input = torch.randn(kernels, chans, samples).to(device)  # Batch size\n",
    "\n",
    "# Pass the dummy input through the model up to the transformer encoder\n",
    "try:\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        x = torch.unsqueeze(dummy_input, dim=1)  # Add an extra dimension to match input shape\n",
    "        x = conformer.patch_embedding(x)  # Pass through Patch Embedding\n",
    "        x = conformer.transformer(x)  # Pass through Transformer Encoder\n",
    "        \n",
    "        # Get the shape after the transformer and calculate the new `final_fc_length`\n",
    "        print(f\"Output shape after transformer: {x.shape}\")\n",
    "        final_fc_length_calculated = x.shape[1] * x.shape[2]\n",
    "        print(f\"Calculated `final_fc_length`: {final_fc_length_calculated}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error during partial forward pass:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40d5e274-df80-4d85-a648-9535b0b270ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:33:13.459471700Z",
     "start_time": "2024-09-21T17:32:28.441869100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.4134, Accuracy: 0.2651\n",
      "Validation Loss: 1.3785, Validation Accuracy: 0.2619\n",
      "Epoch [2/250], Loss: 1.4161, Accuracy: 0.3012\n",
      "Validation Loss: 1.3840, Validation Accuracy: 0.2619\n",
      "Epoch [3/250], Loss: 1.3856, Accuracy: 0.2410\n",
      "Validation Loss: 1.3902, Validation Accuracy: 0.2619\n",
      "Epoch [4/250], Loss: 1.4091, Accuracy: 0.3133\n",
      "Validation Loss: 1.4083, Validation Accuracy: 0.2619\n",
      "Epoch [5/250], Loss: 1.4225, Accuracy: 0.3253\n",
      "Validation Loss: 1.4182, Validation Accuracy: 0.2143\n",
      "Epoch [6/250], Loss: 1.4275, Accuracy: 0.2410\n",
      "Validation Loss: 1.4240, Validation Accuracy: 0.2143\n",
      "Epoch [7/250], Loss: 1.4030, Accuracy: 0.2530\n",
      "Validation Loss: 1.4214, Validation Accuracy: 0.2143\n",
      "Epoch [8/250], Loss: 1.3788, Accuracy: 0.3373\n",
      "Validation Loss: 1.4189, Validation Accuracy: 0.2619\n",
      "Epoch [9/250], Loss: 1.4038, Accuracy: 0.2892\n",
      "Validation Loss: 1.4357, Validation Accuracy: 0.2619\n",
      "Epoch [10/250], Loss: 1.4064, Accuracy: 0.3373\n",
      "Validation Loss: 1.4384, Validation Accuracy: 0.2619\n",
      "Epoch [11/250], Loss: 1.4199, Accuracy: 0.2410\n",
      "Validation Loss: 1.4203, Validation Accuracy: 0.2619\n",
      "Epoch [12/250], Loss: 1.4606, Accuracy: 0.2651\n",
      "Validation Loss: 1.4087, Validation Accuracy: 0.2619\n",
      "Epoch [13/250], Loss: 1.3746, Accuracy: 0.2892\n",
      "Validation Loss: 1.4153, Validation Accuracy: 0.2143\n",
      "Epoch [14/250], Loss: 1.4242, Accuracy: 0.2771\n",
      "Validation Loss: 1.4127, Validation Accuracy: 0.2619\n",
      "Epoch [15/250], Loss: 1.4464, Accuracy: 0.2169\n",
      "Validation Loss: 1.4141, Validation Accuracy: 0.2619\n",
      "Epoch [16/250], Loss: 1.4131, Accuracy: 0.3133\n",
      "Validation Loss: 1.4282, Validation Accuracy: 0.2619\n",
      "Epoch [17/250], Loss: 1.4465, Accuracy: 0.3494\n",
      "Validation Loss: 1.4441, Validation Accuracy: 0.2619\n",
      "Epoch [18/250], Loss: 1.3807, Accuracy: 0.2289\n",
      "Validation Loss: 1.4489, Validation Accuracy: 0.2619\n",
      "Epoch [19/250], Loss: 1.3598, Accuracy: 0.2771\n",
      "Validation Loss: 1.4449, Validation Accuracy: 0.2619\n",
      "Epoch [20/250], Loss: 1.4458, Accuracy: 0.2771\n",
      "Validation Loss: 1.4405, Validation Accuracy: 0.2619\n",
      "Epoch [21/250], Loss: 1.3803, Accuracy: 0.2892\n",
      "Validation Loss: 1.4372, Validation Accuracy: 0.2619\n",
      "Epoch [22/250], Loss: 1.4380, Accuracy: 0.2530\n",
      "Validation Loss: 1.4319, Validation Accuracy: 0.2619\n",
      "Epoch [23/250], Loss: 1.4228, Accuracy: 0.2169\n",
      "Validation Loss: 1.4314, Validation Accuracy: 0.2619\n",
      "Epoch [24/250], Loss: 1.4142, Accuracy: 0.1687\n",
      "Validation Loss: 1.4410, Validation Accuracy: 0.2619\n",
      "Epoch [25/250], Loss: 1.3715, Accuracy: 0.2892\n",
      "Validation Loss: 1.4506, Validation Accuracy: 0.2619\n",
      "Epoch [26/250], Loss: 1.3916, Accuracy: 0.2771\n",
      "Validation Loss: 1.4534, Validation Accuracy: 0.2619\n",
      "Epoch [27/250], Loss: 1.4032, Accuracy: 0.3133\n",
      "Validation Loss: 1.4490, Validation Accuracy: 0.2619\n",
      "Epoch [28/250], Loss: 1.4308, Accuracy: 0.1928\n",
      "Validation Loss: 1.4400, Validation Accuracy: 0.2619\n",
      "Epoch [29/250], Loss: 1.4449, Accuracy: 0.1807\n",
      "Validation Loss: 1.4417, Validation Accuracy: 0.2619\n",
      "Epoch [30/250], Loss: 1.4175, Accuracy: 0.2530\n",
      "Validation Loss: 1.4489, Validation Accuracy: 0.2619\n",
      "Epoch [31/250], Loss: 1.3311, Accuracy: 0.3494\n",
      "Validation Loss: 1.4518, Validation Accuracy: 0.2619\n",
      "Epoch [32/250], Loss: 1.3710, Accuracy: 0.3133\n",
      "Validation Loss: 1.4578, Validation Accuracy: 0.2619\n",
      "Epoch [33/250], Loss: 1.4472, Accuracy: 0.2410\n",
      "Validation Loss: 1.4581, Validation Accuracy: 0.2619\n",
      "Epoch [34/250], Loss: 1.4288, Accuracy: 0.3494\n",
      "Validation Loss: 1.4401, Validation Accuracy: 0.2619\n",
      "Epoch [35/250], Loss: 1.3879, Accuracy: 0.2892\n",
      "Validation Loss: 1.4272, Validation Accuracy: 0.2619\n",
      "Epoch [36/250], Loss: 1.4369, Accuracy: 0.2651\n",
      "Validation Loss: 1.4201, Validation Accuracy: 0.2619\n",
      "Epoch [37/250], Loss: 1.3936, Accuracy: 0.3133\n",
      "Validation Loss: 1.4117, Validation Accuracy: 0.2619\n",
      "Epoch [38/250], Loss: 1.4163, Accuracy: 0.2530\n",
      "Validation Loss: 1.4063, Validation Accuracy: 0.2619\n",
      "Epoch [39/250], Loss: 1.4594, Accuracy: 0.2410\n",
      "Validation Loss: 1.4094, Validation Accuracy: 0.2619\n",
      "Epoch [40/250], Loss: 1.3990, Accuracy: 0.2651\n",
      "Validation Loss: 1.4067, Validation Accuracy: 0.2619\n",
      "Epoch [41/250], Loss: 1.4553, Accuracy: 0.2048\n",
      "Validation Loss: 1.4031, Validation Accuracy: 0.2619\n",
      "Epoch [42/250], Loss: 1.4059, Accuracy: 0.3253\n",
      "Validation Loss: 1.4015, Validation Accuracy: 0.2619\n",
      "Epoch [43/250], Loss: 1.3750, Accuracy: 0.3253\n",
      "Validation Loss: 1.4018, Validation Accuracy: 0.2619\n",
      "Epoch [44/250], Loss: 1.4087, Accuracy: 0.2771\n",
      "Validation Loss: 1.3868, Validation Accuracy: 0.2619\n",
      "Epoch [45/250], Loss: 1.3913, Accuracy: 0.2651\n",
      "Validation Loss: 1.3870, Validation Accuracy: 0.2619\n",
      "Epoch [46/250], Loss: 1.3534, Accuracy: 0.2892\n",
      "Validation Loss: 1.3976, Validation Accuracy: 0.2619\n",
      "Epoch [47/250], Loss: 1.4576, Accuracy: 0.1928\n",
      "Validation Loss: 1.3931, Validation Accuracy: 0.2619\n",
      "Epoch [48/250], Loss: 1.4114, Accuracy: 0.2771\n",
      "Validation Loss: 1.4037, Validation Accuracy: 0.2619\n",
      "Epoch [49/250], Loss: 1.4116, Accuracy: 0.3012\n",
      "Validation Loss: 1.3923, Validation Accuracy: 0.2619\n",
      "Epoch [50/250], Loss: 1.4037, Accuracy: 0.2651\n",
      "Validation Loss: 1.3974, Validation Accuracy: 0.2619\n",
      "Epoch [51/250], Loss: 1.3798, Accuracy: 0.2289\n",
      "Validation Loss: 1.3857, Validation Accuracy: 0.2619\n",
      "Epoch [52/250], Loss: 1.3897, Accuracy: 0.2651\n",
      "Validation Loss: 1.3919, Validation Accuracy: 0.2619\n",
      "Epoch [53/250], Loss: 1.4243, Accuracy: 0.2289\n",
      "Validation Loss: 1.3887, Validation Accuracy: 0.2619\n",
      "Epoch [54/250], Loss: 1.4354, Accuracy: 0.1687\n",
      "Validation Loss: 1.3977, Validation Accuracy: 0.2619\n",
      "Epoch [55/250], Loss: 1.3968, Accuracy: 0.3253\n",
      "Validation Loss: 1.4005, Validation Accuracy: 0.2619\n",
      "Epoch [56/250], Loss: 1.3957, Accuracy: 0.2410\n",
      "Validation Loss: 1.3996, Validation Accuracy: 0.2619\n",
      "Epoch [57/250], Loss: 1.4237, Accuracy: 0.2048\n",
      "Validation Loss: 1.3945, Validation Accuracy: 0.2619\n",
      "Epoch [58/250], Loss: 1.3494, Accuracy: 0.3012\n",
      "Validation Loss: 1.3922, Validation Accuracy: 0.2619\n",
      "Epoch [59/250], Loss: 1.4212, Accuracy: 0.3133\n",
      "Validation Loss: 1.3935, Validation Accuracy: 0.2619\n",
      "Epoch [60/250], Loss: 1.3836, Accuracy: 0.2410\n",
      "Validation Loss: 1.3918, Validation Accuracy: 0.2619\n",
      "Epoch [61/250], Loss: 1.3861, Accuracy: 0.3133\n",
      "Validation Loss: 1.3923, Validation Accuracy: 0.2619\n",
      "Epoch [62/250], Loss: 1.4848, Accuracy: 0.2048\n",
      "Validation Loss: 1.4002, Validation Accuracy: 0.2619\n",
      "Epoch [63/250], Loss: 1.4234, Accuracy: 0.2410\n",
      "Validation Loss: 1.3914, Validation Accuracy: 0.2143\n",
      "Epoch [64/250], Loss: 1.4056, Accuracy: 0.2530\n",
      "Validation Loss: 1.3931, Validation Accuracy: 0.2143\n",
      "Epoch [65/250], Loss: 1.4134, Accuracy: 0.2771\n",
      "Validation Loss: 1.3971, Validation Accuracy: 0.2143\n",
      "Epoch [66/250], Loss: 1.4369, Accuracy: 0.1928\n",
      "Validation Loss: 1.3914, Validation Accuracy: 0.2143\n",
      "Epoch [67/250], Loss: 1.4290, Accuracy: 0.2651\n",
      "Validation Loss: 1.3864, Validation Accuracy: 0.2143\n",
      "Epoch [68/250], Loss: 1.3678, Accuracy: 0.3012\n",
      "Validation Loss: 1.3831, Validation Accuracy: 0.3095\n",
      "Epoch [69/250], Loss: 1.4375, Accuracy: 0.2530\n",
      "Validation Loss: 1.3812, Validation Accuracy: 0.3095\n",
      "Epoch [70/250], Loss: 1.3994, Accuracy: 0.2651\n",
      "Validation Loss: 1.3802, Validation Accuracy: 0.3095\n",
      "Epoch [71/250], Loss: 1.3661, Accuracy: 0.3494\n",
      "Validation Loss: 1.3795, Validation Accuracy: 0.3095\n",
      "Epoch [72/250], Loss: 1.3864, Accuracy: 0.2651\n",
      "Validation Loss: 1.3811, Validation Accuracy: 0.2619\n",
      "Epoch [73/250], Loss: 1.4347, Accuracy: 0.2410\n",
      "Validation Loss: 1.3937, Validation Accuracy: 0.2619\n",
      "Epoch [74/250], Loss: 1.3899, Accuracy: 0.2289\n",
      "Validation Loss: 1.4040, Validation Accuracy: 0.2619\n",
      "Epoch [75/250], Loss: 1.4122, Accuracy: 0.1928\n",
      "Validation Loss: 1.4188, Validation Accuracy: 0.2619\n",
      "Epoch [76/250], Loss: 1.3581, Accuracy: 0.3494\n",
      "Validation Loss: 1.4310, Validation Accuracy: 0.2619\n",
      "Epoch [77/250], Loss: 1.3926, Accuracy: 0.3373\n",
      "Validation Loss: 1.4225, Validation Accuracy: 0.2619\n",
      "Epoch [78/250], Loss: 1.4282, Accuracy: 0.2048\n",
      "Validation Loss: 1.4182, Validation Accuracy: 0.2619\n",
      "Epoch [79/250], Loss: 1.3932, Accuracy: 0.2651\n",
      "Validation Loss: 1.4238, Validation Accuracy: 0.2619\n",
      "Epoch [80/250], Loss: 1.4058, Accuracy: 0.2289\n",
      "Validation Loss: 1.4258, Validation Accuracy: 0.2619\n",
      "Epoch [81/250], Loss: 1.3790, Accuracy: 0.3133\n",
      "Validation Loss: 1.4225, Validation Accuracy: 0.2619\n",
      "Epoch [82/250], Loss: 1.3958, Accuracy: 0.2892\n",
      "Validation Loss: 1.4135, Validation Accuracy: 0.2619\n",
      "Epoch [83/250], Loss: 1.4547, Accuracy: 0.2289\n",
      "Validation Loss: 1.4007, Validation Accuracy: 0.2619\n",
      "Epoch [84/250], Loss: 1.4506, Accuracy: 0.2771\n",
      "Validation Loss: 1.3945, Validation Accuracy: 0.2619\n",
      "Epoch [85/250], Loss: 1.4217, Accuracy: 0.2410\n",
      "Validation Loss: 1.3924, Validation Accuracy: 0.2143\n",
      "Epoch [86/250], Loss: 1.3701, Accuracy: 0.2651\n",
      "Validation Loss: 1.3990, Validation Accuracy: 0.2143\n",
      "Epoch [87/250], Loss: 1.4223, Accuracy: 0.2651\n",
      "Validation Loss: 1.3889, Validation Accuracy: 0.2143\n",
      "Epoch [88/250], Loss: 1.4038, Accuracy: 0.2530\n",
      "Validation Loss: 1.3844, Validation Accuracy: 0.2143\n",
      "Epoch [89/250], Loss: 1.3631, Accuracy: 0.2892\n",
      "Validation Loss: 1.3792, Validation Accuracy: 0.3095\n",
      "Epoch [90/250], Loss: 1.3549, Accuracy: 0.3253\n",
      "Validation Loss: 1.3889, Validation Accuracy: 0.2143\n",
      "Epoch [91/250], Loss: 1.4006, Accuracy: 0.3253\n",
      "Validation Loss: 1.4000, Validation Accuracy: 0.2143\n",
      "Epoch [92/250], Loss: 1.4220, Accuracy: 0.2530\n",
      "Validation Loss: 1.3973, Validation Accuracy: 0.2619\n",
      "Epoch [93/250], Loss: 1.3707, Accuracy: 0.2892\n",
      "Validation Loss: 1.3793, Validation Accuracy: 0.3095\n",
      "Epoch [94/250], Loss: 1.4261, Accuracy: 0.1928\n",
      "Validation Loss: 1.3827, Validation Accuracy: 0.3095\n",
      "Epoch [95/250], Loss: 1.4256, Accuracy: 0.2410\n",
      "Validation Loss: 1.3905, Validation Accuracy: 0.2143\n",
      "Epoch [96/250], Loss: 1.4027, Accuracy: 0.2651\n",
      "Validation Loss: 1.3914, Validation Accuracy: 0.2143\n",
      "Epoch [97/250], Loss: 1.3657, Accuracy: 0.3133\n",
      "Validation Loss: 1.3928, Validation Accuracy: 0.2619\n",
      "Epoch [98/250], Loss: 1.3376, Accuracy: 0.3253\n",
      "Validation Loss: 1.3818, Validation Accuracy: 0.2619\n",
      "Epoch [99/250], Loss: 1.4124, Accuracy: 0.2892\n",
      "Validation Loss: 1.3803, Validation Accuracy: 0.3095\n",
      "Epoch [100/250], Loss: 1.3919, Accuracy: 0.3976\n",
      "Validation Loss: 1.3834, Validation Accuracy: 0.3095\n",
      "Epoch [101/250], Loss: 1.4052, Accuracy: 0.2892\n",
      "Validation Loss: 1.3833, Validation Accuracy: 0.3095\n",
      "Epoch [102/250], Loss: 1.4060, Accuracy: 0.2169\n",
      "Validation Loss: 1.3768, Validation Accuracy: 0.3095\n",
      "Epoch [103/250], Loss: 1.4000, Accuracy: 0.2289\n",
      "Validation Loss: 1.3813, Validation Accuracy: 0.3095\n",
      "Epoch [104/250], Loss: 1.3593, Accuracy: 0.3494\n",
      "Validation Loss: 1.3828, Validation Accuracy: 0.3095\n",
      "Epoch [105/250], Loss: 1.3160, Accuracy: 0.3614\n",
      "Validation Loss: 1.3851, Validation Accuracy: 0.3095\n",
      "Epoch [106/250], Loss: 1.3856, Accuracy: 0.3373\n",
      "Validation Loss: 1.3855, Validation Accuracy: 0.3095\n",
      "Epoch [107/250], Loss: 1.4614, Accuracy: 0.2530\n",
      "Validation Loss: 1.4036, Validation Accuracy: 0.2619\n",
      "Epoch [108/250], Loss: 1.3727, Accuracy: 0.3373\n",
      "Validation Loss: 1.4199, Validation Accuracy: 0.2619\n",
      "Epoch [109/250], Loss: 1.3820, Accuracy: 0.3253\n",
      "Validation Loss: 1.4210, Validation Accuracy: 0.2619\n",
      "Epoch [110/250], Loss: 1.4043, Accuracy: 0.2169\n",
      "Validation Loss: 1.4046, Validation Accuracy: 0.2619\n",
      "Epoch [111/250], Loss: 1.4075, Accuracy: 0.2169\n",
      "Validation Loss: 1.4183, Validation Accuracy: 0.2619\n",
      "Epoch [112/250], Loss: 1.4101, Accuracy: 0.2892\n",
      "Validation Loss: 1.4336, Validation Accuracy: 0.2619\n",
      "Epoch [113/250], Loss: 1.4222, Accuracy: 0.2410\n",
      "Validation Loss: 1.4248, Validation Accuracy: 0.2619\n",
      "Epoch [114/250], Loss: 1.3786, Accuracy: 0.2530\n",
      "Validation Loss: 1.4182, Validation Accuracy: 0.2619\n",
      "Epoch [115/250], Loss: 1.3987, Accuracy: 0.2169\n",
      "Validation Loss: 1.4208, Validation Accuracy: 0.2619\n",
      "Epoch [116/250], Loss: 1.4429, Accuracy: 0.2892\n",
      "Validation Loss: 1.4168, Validation Accuracy: 0.2619\n",
      "Epoch [117/250], Loss: 1.4248, Accuracy: 0.3373\n",
      "Validation Loss: 1.4077, Validation Accuracy: 0.2619\n",
      "Epoch [118/250], Loss: 1.3906, Accuracy: 0.2530\n",
      "Validation Loss: 1.4158, Validation Accuracy: 0.2619\n",
      "Epoch [119/250], Loss: 1.4340, Accuracy: 0.2651\n",
      "Validation Loss: 1.4115, Validation Accuracy: 0.2619\n",
      "Epoch [120/250], Loss: 1.3709, Accuracy: 0.2289\n",
      "Validation Loss: 1.4135, Validation Accuracy: 0.2619\n",
      "Epoch [121/250], Loss: 1.3696, Accuracy: 0.3494\n",
      "Validation Loss: 1.4191, Validation Accuracy: 0.2619\n",
      "Epoch [122/250], Loss: 1.4314, Accuracy: 0.3614\n",
      "Validation Loss: 1.4095, Validation Accuracy: 0.2619\n",
      "Epoch [123/250], Loss: 1.3558, Accuracy: 0.2892\n",
      "Validation Loss: 1.4072, Validation Accuracy: 0.2619\n",
      "Epoch [124/250], Loss: 1.4056, Accuracy: 0.2048\n",
      "Validation Loss: 1.4058, Validation Accuracy: 0.2619\n",
      "Epoch [125/250], Loss: 1.4328, Accuracy: 0.2289\n",
      "Validation Loss: 1.4109, Validation Accuracy: 0.2619\n",
      "Epoch [126/250], Loss: 1.3712, Accuracy: 0.3253\n",
      "Validation Loss: 1.4106, Validation Accuracy: 0.2619\n",
      "Epoch [127/250], Loss: 1.4011, Accuracy: 0.1928\n",
      "Validation Loss: 1.4023, Validation Accuracy: 0.2619\n",
      "Epoch [128/250], Loss: 1.3929, Accuracy: 0.3133\n",
      "Validation Loss: 1.4028, Validation Accuracy: 0.2619\n",
      "Epoch [129/250], Loss: 1.4050, Accuracy: 0.2530\n",
      "Validation Loss: 1.4107, Validation Accuracy: 0.2619\n",
      "Epoch [130/250], Loss: 1.3852, Accuracy: 0.2771\n",
      "Validation Loss: 1.4017, Validation Accuracy: 0.2619\n",
      "Epoch [131/250], Loss: 1.4079, Accuracy: 0.2651\n",
      "Validation Loss: 1.3981, Validation Accuracy: 0.2619\n",
      "Epoch [132/250], Loss: 1.4222, Accuracy: 0.2892\n",
      "Validation Loss: 1.3946, Validation Accuracy: 0.2619\n",
      "Epoch [133/250], Loss: 1.3696, Accuracy: 0.3133\n",
      "Validation Loss: 1.4014, Validation Accuracy: 0.2619\n",
      "Epoch [134/250], Loss: 1.3594, Accuracy: 0.3012\n",
      "Validation Loss: 1.4013, Validation Accuracy: 0.2619\n",
      "Epoch [135/250], Loss: 1.3902, Accuracy: 0.3373\n",
      "Validation Loss: 1.4072, Validation Accuracy: 0.2619\n",
      "Epoch [136/250], Loss: 1.4167, Accuracy: 0.2530\n",
      "Validation Loss: 1.4068, Validation Accuracy: 0.2619\n",
      "Epoch [137/250], Loss: 1.3724, Accuracy: 0.3012\n",
      "Validation Loss: 1.4033, Validation Accuracy: 0.2619\n",
      "Epoch [138/250], Loss: 1.3640, Accuracy: 0.3373\n",
      "Validation Loss: 1.4012, Validation Accuracy: 0.2619\n",
      "Epoch [139/250], Loss: 1.3736, Accuracy: 0.2771\n",
      "Validation Loss: 1.3968, Validation Accuracy: 0.2143\n",
      "Epoch [140/250], Loss: 1.3676, Accuracy: 0.3494\n",
      "Validation Loss: 1.3941, Validation Accuracy: 0.2143\n",
      "Epoch [141/250], Loss: 1.4139, Accuracy: 0.2410\n",
      "Validation Loss: 1.3977, Validation Accuracy: 0.2143\n",
      "Epoch [142/250], Loss: 1.3831, Accuracy: 0.2771\n",
      "Validation Loss: 1.3923, Validation Accuracy: 0.2143\n",
      "Epoch [143/250], Loss: 1.3682, Accuracy: 0.3253\n",
      "Validation Loss: 1.3854, Validation Accuracy: 0.2143\n",
      "Epoch [144/250], Loss: 1.3641, Accuracy: 0.3012\n",
      "Validation Loss: 1.3850, Validation Accuracy: 0.3095\n",
      "Epoch [145/250], Loss: 1.3671, Accuracy: 0.3253\n",
      "Validation Loss: 1.3840, Validation Accuracy: 0.2143\n",
      "Epoch [146/250], Loss: 1.3901, Accuracy: 0.2771\n",
      "Validation Loss: 1.3895, Validation Accuracy: 0.2143\n",
      "Epoch [147/250], Loss: 1.3982, Accuracy: 0.3253\n",
      "Validation Loss: 1.3890, Validation Accuracy: 0.2619\n",
      "Epoch [148/250], Loss: 1.3802, Accuracy: 0.2410\n",
      "Validation Loss: 1.3967, Validation Accuracy: 0.2619\n",
      "Epoch [149/250], Loss: 1.3667, Accuracy: 0.2892\n",
      "Validation Loss: 1.4011, Validation Accuracy: 0.2619\n",
      "Epoch [150/250], Loss: 1.3928, Accuracy: 0.2771\n",
      "Validation Loss: 1.3953, Validation Accuracy: 0.2143\n",
      "Epoch [151/250], Loss: 1.4512, Accuracy: 0.2771\n",
      "Validation Loss: 1.3962, Validation Accuracy: 0.2143\n",
      "Epoch [152/250], Loss: 1.4284, Accuracy: 0.2651\n",
      "Validation Loss: 1.3954, Validation Accuracy: 0.2619\n",
      "Epoch [153/250], Loss: 1.4472, Accuracy: 0.3133\n",
      "Validation Loss: 1.3926, Validation Accuracy: 0.2619\n",
      "Epoch [154/250], Loss: 1.4255, Accuracy: 0.2771\n",
      "Validation Loss: 1.3947, Validation Accuracy: 0.2619\n",
      "Epoch [155/250], Loss: 1.3927, Accuracy: 0.2289\n",
      "Validation Loss: 1.4005, Validation Accuracy: 0.2619\n",
      "Epoch [156/250], Loss: 1.3578, Accuracy: 0.3373\n",
      "Validation Loss: 1.4024, Validation Accuracy: 0.2619\n",
      "Epoch [157/250], Loss: 1.3872, Accuracy: 0.2892\n",
      "Validation Loss: 1.4056, Validation Accuracy: 0.2619\n",
      "Epoch [158/250], Loss: 1.3939, Accuracy: 0.3133\n",
      "Validation Loss: 1.4087, Validation Accuracy: 0.2619\n",
      "Epoch [159/250], Loss: 1.3926, Accuracy: 0.2289\n",
      "Validation Loss: 1.4152, Validation Accuracy: 0.2619\n",
      "Epoch [160/250], Loss: 1.3830, Accuracy: 0.3253\n",
      "Validation Loss: 1.4121, Validation Accuracy: 0.2619\n",
      "Epoch [161/250], Loss: 1.4276, Accuracy: 0.2410\n",
      "Validation Loss: 1.4127, Validation Accuracy: 0.2619\n",
      "Epoch [162/250], Loss: 1.3703, Accuracy: 0.3373\n",
      "Validation Loss: 1.4015, Validation Accuracy: 0.2619\n",
      "Epoch [163/250], Loss: 1.3780, Accuracy: 0.3373\n",
      "Validation Loss: 1.4063, Validation Accuracy: 0.2619\n",
      "Epoch [164/250], Loss: 1.3939, Accuracy: 0.3133\n",
      "Validation Loss: 1.4030, Validation Accuracy: 0.2619\n",
      "Epoch [165/250], Loss: 1.4097, Accuracy: 0.3012\n",
      "Validation Loss: 1.4034, Validation Accuracy: 0.2619\n",
      "Epoch [166/250], Loss: 1.4227, Accuracy: 0.2530\n",
      "Validation Loss: 1.4067, Validation Accuracy: 0.2619\n",
      "Epoch [167/250], Loss: 1.3622, Accuracy: 0.3253\n",
      "Validation Loss: 1.4038, Validation Accuracy: 0.2619\n",
      "Epoch [168/250], Loss: 1.4101, Accuracy: 0.2651\n",
      "Validation Loss: 1.3948, Validation Accuracy: 0.2619\n",
      "Epoch [169/250], Loss: 1.4035, Accuracy: 0.2892\n",
      "Validation Loss: 1.3842, Validation Accuracy: 0.2619\n",
      "Epoch [170/250], Loss: 1.3783, Accuracy: 0.2651\n",
      "Validation Loss: 1.3846, Validation Accuracy: 0.2619\n",
      "Epoch [171/250], Loss: 1.3930, Accuracy: 0.3253\n",
      "Validation Loss: 1.3815, Validation Accuracy: 0.2619\n",
      "Epoch [172/250], Loss: 1.4131, Accuracy: 0.2289\n",
      "Validation Loss: 1.3877, Validation Accuracy: 0.2619\n",
      "Epoch [173/250], Loss: 1.3621, Accuracy: 0.3494\n",
      "Validation Loss: 1.4060, Validation Accuracy: 0.2619\n",
      "Epoch [174/250], Loss: 1.4047, Accuracy: 0.2530\n",
      "Validation Loss: 1.4081, Validation Accuracy: 0.2619\n",
      "Epoch [175/250], Loss: 1.4298, Accuracy: 0.2289\n",
      "Validation Loss: 1.4034, Validation Accuracy: 0.2619\n",
      "Epoch [176/250], Loss: 1.4058, Accuracy: 0.2771\n",
      "Validation Loss: 1.4041, Validation Accuracy: 0.2619\n",
      "Epoch [177/250], Loss: 1.4153, Accuracy: 0.2651\n",
      "Validation Loss: 1.4002, Validation Accuracy: 0.2619\n",
      "Epoch [178/250], Loss: 1.4203, Accuracy: 0.3133\n",
      "Validation Loss: 1.3982, Validation Accuracy: 0.2619\n",
      "Epoch [179/250], Loss: 1.3971, Accuracy: 0.2410\n",
      "Validation Loss: 1.4027, Validation Accuracy: 0.2619\n",
      "Epoch [180/250], Loss: 1.4205, Accuracy: 0.2651\n",
      "Validation Loss: 1.3942, Validation Accuracy: 0.2619\n",
      "Epoch [181/250], Loss: 1.3555, Accuracy: 0.3494\n",
      "Validation Loss: 1.3881, Validation Accuracy: 0.2619\n",
      "Epoch [182/250], Loss: 1.4212, Accuracy: 0.2771\n",
      "Validation Loss: 1.3873, Validation Accuracy: 0.2619\n",
      "Epoch [183/250], Loss: 1.3800, Accuracy: 0.3133\n",
      "Validation Loss: 1.3893, Validation Accuracy: 0.2619\n",
      "Epoch [184/250], Loss: 1.3527, Accuracy: 0.2771\n",
      "Validation Loss: 1.3936, Validation Accuracy: 0.2619\n",
      "Epoch [185/250], Loss: 1.3584, Accuracy: 0.3494\n",
      "Validation Loss: 1.3955, Validation Accuracy: 0.2619\n",
      "Epoch [186/250], Loss: 1.4231, Accuracy: 0.2651\n",
      "Validation Loss: 1.3911, Validation Accuracy: 0.2619\n",
      "Epoch [187/250], Loss: 1.4155, Accuracy: 0.2771\n",
      "Validation Loss: 1.3958, Validation Accuracy: 0.2619\n",
      "Epoch [188/250], Loss: 1.4051, Accuracy: 0.2651\n",
      "Validation Loss: 1.3978, Validation Accuracy: 0.2619\n",
      "Epoch [189/250], Loss: 1.3847, Accuracy: 0.3012\n",
      "Validation Loss: 1.3913, Validation Accuracy: 0.2619\n",
      "Epoch [190/250], Loss: 1.3550, Accuracy: 0.2169\n",
      "Validation Loss: 1.3881, Validation Accuracy: 0.2619\n",
      "Epoch [191/250], Loss: 1.4262, Accuracy: 0.2651\n",
      "Validation Loss: 1.3941, Validation Accuracy: 0.2619\n",
      "Epoch [192/250], Loss: 1.4077, Accuracy: 0.3012\n",
      "Validation Loss: 1.4022, Validation Accuracy: 0.2619\n",
      "Epoch [193/250], Loss: 1.3600, Accuracy: 0.3253\n",
      "Validation Loss: 1.3866, Validation Accuracy: 0.2619\n",
      "Epoch [194/250], Loss: 1.4273, Accuracy: 0.2410\n",
      "Validation Loss: 1.3828, Validation Accuracy: 0.3095\n",
      "Epoch [195/250], Loss: 1.4160, Accuracy: 0.2410\n",
      "Validation Loss: 1.3816, Validation Accuracy: 0.3095\n",
      "Epoch [196/250], Loss: 1.4394, Accuracy: 0.2169\n",
      "Validation Loss: 1.3817, Validation Accuracy: 0.3095\n",
      "Epoch [197/250], Loss: 1.4232, Accuracy: 0.3133\n",
      "Validation Loss: 1.3800, Validation Accuracy: 0.3095\n",
      "Epoch [198/250], Loss: 1.3929, Accuracy: 0.2651\n",
      "Validation Loss: 1.3798, Validation Accuracy: 0.3095\n",
      "Epoch [199/250], Loss: 1.3977, Accuracy: 0.2289\n",
      "Validation Loss: 1.3826, Validation Accuracy: 0.3095\n",
      "Epoch [200/250], Loss: 1.3266, Accuracy: 0.3735\n",
      "Validation Loss: 1.3816, Validation Accuracy: 0.3095\n",
      "Epoch [201/250], Loss: 1.3631, Accuracy: 0.2530\n",
      "Validation Loss: 1.3850, Validation Accuracy: 0.2619\n",
      "Epoch [202/250], Loss: 1.3960, Accuracy: 0.3373\n",
      "Validation Loss: 1.3851, Validation Accuracy: 0.2619\n",
      "Epoch [203/250], Loss: 1.3990, Accuracy: 0.3253\n",
      "Validation Loss: 1.3978, Validation Accuracy: 0.2619\n",
      "Epoch [204/250], Loss: 1.3691, Accuracy: 0.3133\n",
      "Validation Loss: 1.3930, Validation Accuracy: 0.2619\n",
      "Epoch [205/250], Loss: 1.4021, Accuracy: 0.2771\n",
      "Validation Loss: 1.3911, Validation Accuracy: 0.2619\n",
      "Epoch [206/250], Loss: 1.3917, Accuracy: 0.3494\n",
      "Validation Loss: 1.3940, Validation Accuracy: 0.2619\n",
      "Epoch [207/250], Loss: 1.3479, Accuracy: 0.3735\n",
      "Validation Loss: 1.4014, Validation Accuracy: 0.2619\n",
      "Epoch [208/250], Loss: 1.4168, Accuracy: 0.2410\n",
      "Validation Loss: 1.3936, Validation Accuracy: 0.2619\n",
      "Epoch [209/250], Loss: 1.3833, Accuracy: 0.3133\n",
      "Validation Loss: 1.3935, Validation Accuracy: 0.2619\n",
      "Epoch [210/250], Loss: 1.3908, Accuracy: 0.3133\n",
      "Validation Loss: 1.3885, Validation Accuracy: 0.2619\n",
      "Epoch [211/250], Loss: 1.4085, Accuracy: 0.3133\n",
      "Validation Loss: 1.3885, Validation Accuracy: 0.2619\n",
      "Epoch [212/250], Loss: 1.3810, Accuracy: 0.3012\n",
      "Validation Loss: 1.3933, Validation Accuracy: 0.2619\n",
      "Epoch [213/250], Loss: 1.3466, Accuracy: 0.3494\n",
      "Validation Loss: 1.3948, Validation Accuracy: 0.2619\n",
      "Epoch [214/250], Loss: 1.3784, Accuracy: 0.2530\n",
      "Validation Loss: 1.3935, Validation Accuracy: 0.2619\n",
      "Epoch [215/250], Loss: 1.3570, Accuracy: 0.3494\n",
      "Validation Loss: 1.3916, Validation Accuracy: 0.2619\n",
      "Epoch [216/250], Loss: 1.3541, Accuracy: 0.2892\n",
      "Validation Loss: 1.3910, Validation Accuracy: 0.2619\n",
      "Epoch [217/250], Loss: 1.3712, Accuracy: 0.2651\n",
      "Validation Loss: 1.3924, Validation Accuracy: 0.2619\n",
      "Epoch [218/250], Loss: 1.3714, Accuracy: 0.3133\n",
      "Validation Loss: 1.3875, Validation Accuracy: 0.2619\n",
      "Epoch [219/250], Loss: 1.4058, Accuracy: 0.2530\n",
      "Validation Loss: 1.3783, Validation Accuracy: 0.2619\n",
      "Epoch [220/250], Loss: 1.4457, Accuracy: 0.1807\n",
      "Validation Loss: 1.3820, Validation Accuracy: 0.2619\n",
      "Epoch [221/250], Loss: 1.4094, Accuracy: 0.2410\n",
      "Validation Loss: 1.3793, Validation Accuracy: 0.3095\n",
      "Epoch [222/250], Loss: 1.4519, Accuracy: 0.2530\n",
      "Validation Loss: 1.3856, Validation Accuracy: 0.2619\n",
      "Epoch [223/250], Loss: 1.3986, Accuracy: 0.3133\n",
      "Validation Loss: 1.3789, Validation Accuracy: 0.3095\n",
      "Epoch [224/250], Loss: 1.3552, Accuracy: 0.3494\n",
      "Validation Loss: 1.3792, Validation Accuracy: 0.3095\n",
      "Epoch [225/250], Loss: 1.4324, Accuracy: 0.2530\n",
      "Validation Loss: 1.3782, Validation Accuracy: 0.3095\n",
      "Epoch [226/250], Loss: 1.3752, Accuracy: 0.2530\n",
      "Validation Loss: 1.3797, Validation Accuracy: 0.2619\n",
      "Epoch [227/250], Loss: 1.3796, Accuracy: 0.2530\n",
      "Validation Loss: 1.3822, Validation Accuracy: 0.2619\n",
      "Epoch [228/250], Loss: 1.3787, Accuracy: 0.3133\n",
      "Validation Loss: 1.3823, Validation Accuracy: 0.2619\n",
      "Epoch [229/250], Loss: 1.3992, Accuracy: 0.3012\n",
      "Validation Loss: 1.3787, Validation Accuracy: 0.2619\n",
      "Epoch [230/250], Loss: 1.4160, Accuracy: 0.2410\n",
      "Validation Loss: 1.3833, Validation Accuracy: 0.2619\n",
      "Epoch [231/250], Loss: 1.3724, Accuracy: 0.3494\n",
      "Validation Loss: 1.3901, Validation Accuracy: 0.2619\n",
      "Epoch [232/250], Loss: 1.3738, Accuracy: 0.2651\n",
      "Validation Loss: 1.4044, Validation Accuracy: 0.2619\n",
      "Epoch [233/250], Loss: 1.3848, Accuracy: 0.3012\n",
      "Validation Loss: 1.4071, Validation Accuracy: 0.2619\n",
      "Epoch [234/250], Loss: 1.3706, Accuracy: 0.3494\n",
      "Validation Loss: 1.3947, Validation Accuracy: 0.2619\n",
      "Epoch [235/250], Loss: 1.4547, Accuracy: 0.2651\n",
      "Validation Loss: 1.3816, Validation Accuracy: 0.2619\n",
      "Epoch [236/250], Loss: 1.3893, Accuracy: 0.2892\n",
      "Validation Loss: 1.3803, Validation Accuracy: 0.3095\n",
      "Epoch [237/250], Loss: 1.3727, Accuracy: 0.3373\n",
      "Validation Loss: 1.3810, Validation Accuracy: 0.2619\n",
      "Epoch [238/250], Loss: 1.3614, Accuracy: 0.2410\n",
      "Validation Loss: 1.3825, Validation Accuracy: 0.2619\n",
      "Epoch [239/250], Loss: 1.4066, Accuracy: 0.2048\n",
      "Validation Loss: 1.3799, Validation Accuracy: 0.3095\n",
      "Epoch [240/250], Loss: 1.4002, Accuracy: 0.2771\n",
      "Validation Loss: 1.3796, Validation Accuracy: 0.3095\n",
      "Epoch [241/250], Loss: 1.3987, Accuracy: 0.2169\n",
      "Validation Loss: 1.3808, Validation Accuracy: 0.3095\n",
      "Epoch [242/250], Loss: 1.4060, Accuracy: 0.2771\n",
      "Validation Loss: 1.3787, Validation Accuracy: 0.3095\n",
      "Epoch [243/250], Loss: 1.3574, Accuracy: 0.3012\n",
      "Validation Loss: 1.3772, Validation Accuracy: 0.3095\n",
      "Epoch [244/250], Loss: 1.3578, Accuracy: 0.3494\n",
      "Validation Loss: 1.3785, Validation Accuracy: 0.3095\n",
      "Epoch [245/250], Loss: 1.3689, Accuracy: 0.2651\n",
      "Validation Loss: 1.3839, Validation Accuracy: 0.3095\n",
      "Epoch [246/250], Loss: 1.3679, Accuracy: 0.2530\n",
      "Validation Loss: 1.3842, Validation Accuracy: 0.3095\n",
      "Epoch [247/250], Loss: 1.3891, Accuracy: 0.2410\n",
      "Validation Loss: 1.3889, Validation Accuracy: 0.2143\n",
      "Epoch [248/250], Loss: 1.3780, Accuracy: 0.2410\n",
      "Validation Loss: 1.3898, Validation Accuracy: 0.2143\n",
      "Epoch [249/250], Loss: 1.3824, Accuracy: 0.3253\n",
      "Validation Loss: 1.3890, Validation Accuracy: 0.2143\n",
      "Epoch [250/250], Loss: 1.3846, Accuracy: 0.2530\n",
      "Validation Loss: 1.3898, Validation Accuracy: 0.2143\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 250\n",
    "## TRAIN\n",
    "for epoch in range(num_epochs):\n",
    "    conformer.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = conformer(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == y_batch).sum().item()\n",
    "        total_predictions += y_batch.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "## Validation\n",
    "    conformer.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            outputs = conformer(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == y_batch).sum().item()\n",
    "            total_predictions += y_batch.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d568117a-3c9d-48b1-a90b-8ed2df89fe96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T17:33:13.505769800Z",
     "start_time": "2024-09-21T17:33:13.461472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.3997\n",
      "Test Accuracy: 0.2439\n"
     ]
    }
   ],
   "source": [
    "## TEST\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        outputs = conformer(X_batch)\n",
    "        \n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest score\n",
    "        correct_predictions += (predicted == y_batch).sum().item()\n",
    "        total_predictions += y_batch.size(0)\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f0565c3c4101da64"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
