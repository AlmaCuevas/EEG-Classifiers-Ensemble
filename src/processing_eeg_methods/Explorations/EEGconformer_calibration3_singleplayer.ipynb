{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667cbb0e-b42e-4ea6-a195-b296702614ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:55:42.532806200Z",
     "start_time": "2025-01-23T21:55:42.518028700Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'conformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c504eba-a256-4ddb-bc17-55b59d27a609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T21:55:51.648533Z",
     "start_time": "2025-01-23T21:55:42.534028100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\moabb\\pipelines\\__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from braindecode.models import EEGConformer\n",
    "\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae83aafa-2a37-42f7-9ace-d937ca00c107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T22:12:41.232842100Z",
     "start_time": "2025-01-23T22:12:41.215740600Z"
    }
   },
   "outputs": [],
   "source": [
    "from processing_eeg_methods.data_utils import (\n",
    "    get_dataset_basic_info,\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from processing_eeg_methods.data_loaders import load_data_labels_based_on_dataset\n",
    "from processing_eeg_methods.share import datasets_basic_infos\n",
    "from collections import Counter\n",
    "\n",
    "dataset_name = \"braincommand\"  # Only two things I should be able to change\n",
    "\n",
    "dataset_info = get_dataset_basic_info(datasets_basic_infos, dataset_name)\n",
    "\n",
    "data_path = r\"C:\\Users\\rosit\\Documents\\workprojects\\bci_complete\\EEG-Classifiers-Ensemble\\Datasets\\braincommand_dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load calibration and singleplayer with labels 0 and 1, respectively."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b02cfc902e0443e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load calibration from the clean .set file after EEGLAB manual rejection."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1527695aa317824d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import mne\n",
    "# import numpy as np\n",
    "# \n",
    "# _, X, y = load_data_labels_based_on_dataset(\n",
    "#     dataset_info,\n",
    "#     subject_id,\n",
    "#     data_path,\n",
    "#     game_mode=\"calibration3\",\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T22:12:44.858744100Z",
     "start_time": "2025-01-23T22:12:44.842531900Z"
    }
   },
   "id": "34e833b36917c8bc",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bd7fd7-e279-4068-9e75-5aa6321f1870",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-01-23T22:12:45.335345600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 100\n",
      "label 1 is 103\n",
      "label 2 is 51\n",
      "label 3 is 22\n",
      "Not setting metadata\n",
      "276 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (252, 8, 325)\n",
      "252 train samples\n",
      "126 test samples\n",
      "Number of batches in train_loader: 4\n",
      "{-1: 1.105263157894737, 0: 0.9130434782608695}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.2652, Accuracy: 0.4524\n",
      "Validation Loss: 1.1219, Validation Accuracy: 0.5556\n",
      "Epoch [2/250], Loss: 0.8110, Accuracy: 0.7857\n",
      "Validation Loss: 1.5107, Validation Accuracy: 0.5556\n",
      "Epoch [3/250], Loss: 0.4551, Accuracy: 0.9325\n",
      "Validation Loss: 2.0413, Validation Accuracy: 0.5556\n",
      "Epoch [4/250], Loss: 0.2215, Accuracy: 1.0000\n",
      "Validation Loss: 2.8818, Validation Accuracy: 0.5556\n",
      "Epoch [5/250], Loss: 0.1215, Accuracy: 0.9960\n",
      "Validation Loss: 3.5250, Validation Accuracy: 0.5556\n",
      "Epoch [6/250], Loss: 0.0664, Accuracy: 0.9960\n",
      "Validation Loss: 3.9598, Validation Accuracy: 0.5556\n",
      "Epoch [7/250], Loss: 0.0481, Accuracy: 1.0000\n",
      "Validation Loss: 4.2868, Validation Accuracy: 0.5556\n",
      "Epoch [8/250], Loss: 0.0355, Accuracy: 1.0000\n",
      "Validation Loss: 4.5537, Validation Accuracy: 0.5556\n",
      "Epoch [9/250], Loss: 0.0306, Accuracy: 1.0000\n",
      "Validation Loss: 4.8452, Validation Accuracy: 0.5556\n",
      "Epoch [10/250], Loss: 0.0199, Accuracy: 1.0000\n",
      "Validation Loss: 4.9812, Validation Accuracy: 0.5556\n",
      "Epoch [11/250], Loss: 0.0190, Accuracy: 1.0000\n",
      "Validation Loss: 5.0921, Validation Accuracy: 0.5556\n",
      "Epoch [12/250], Loss: 0.0169, Accuracy: 1.0000\n",
      "Validation Loss: 5.1109, Validation Accuracy: 0.5556\n",
      "Epoch [13/250], Loss: 0.0122, Accuracy: 1.0000\n",
      "Validation Loss: 5.0012, Validation Accuracy: 0.5556\n",
      "Epoch [14/250], Loss: 0.0097, Accuracy: 1.0000\n",
      "Validation Loss: 4.7518, Validation Accuracy: 0.5556\n",
      "Epoch [15/250], Loss: 0.0097, Accuracy: 1.0000\n",
      "Validation Loss: 4.6563, Validation Accuracy: 0.5635\n",
      "Epoch [16/250], Loss: 0.0113, Accuracy: 1.0000\n",
      "Validation Loss: 4.8223, Validation Accuracy: 0.5714\n",
      "Epoch [17/250], Loss: 0.0096, Accuracy: 1.0000\n",
      "Validation Loss: 3.8472, Validation Accuracy: 0.5794\n",
      "Epoch [18/250], Loss: 0.0078, Accuracy: 1.0000\n",
      "Validation Loss: 2.3423, Validation Accuracy: 0.6587\n",
      "Epoch [19/250], Loss: 0.0060, Accuracy: 1.0000\n",
      "Validation Loss: 0.7041, Validation Accuracy: 0.8889\n",
      "Epoch [20/250], Loss: 0.0061, Accuracy: 1.0000\n",
      "Validation Loss: 0.2179, Validation Accuracy: 0.9603\n",
      "Epoch [21/250], Loss: 0.0040, Accuracy: 1.0000\n",
      "Validation Loss: 0.1455, Validation Accuracy: 0.9841\n",
      "Epoch [22/250], Loss: 0.0060, Accuracy: 1.0000\n",
      "Validation Loss: 0.1612, Validation Accuracy: 0.9841\n",
      "Epoch [23/250], Loss: 0.0051, Accuracy: 1.0000\n",
      "Validation Loss: 0.1716, Validation Accuracy: 0.9841\n",
      "Epoch [24/250], Loss: 0.0031, Accuracy: 1.0000\n",
      "Validation Loss: 0.1772, Validation Accuracy: 0.9841\n",
      "Epoch [25/250], Loss: 0.0046, Accuracy: 1.0000\n",
      "Validation Loss: 0.1819, Validation Accuracy: 0.9841\n",
      "Epoch [26/250], Loss: 0.0040, Accuracy: 1.0000\n",
      "Validation Loss: 0.1876, Validation Accuracy: 0.9841\n",
      "Epoch [27/250], Loss: 0.0044, Accuracy: 1.0000\n",
      "Validation Loss: 0.1910, Validation Accuracy: 0.9841\n",
      "Epoch [28/250], Loss: 0.0050, Accuracy: 1.0000\n",
      "Validation Loss: 0.1972, Validation Accuracy: 0.9841\n",
      "Epoch [29/250], Loss: 0.0030, Accuracy: 1.0000\n",
      "Validation Loss: 0.2005, Validation Accuracy: 0.9841\n",
      "Epoch [30/250], Loss: 0.0032, Accuracy: 1.0000\n",
      "Validation Loss: 0.2022, Validation Accuracy: 0.9841\n",
      "Epoch [31/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.2008, Validation Accuracy: 0.9841\n",
      "Epoch [32/250], Loss: 0.0039, Accuracy: 1.0000\n",
      "Validation Loss: 0.2034, Validation Accuracy: 0.9841\n",
      "Epoch [33/250], Loss: 0.0022, Accuracy: 1.0000\n",
      "Validation Loss: 0.2056, Validation Accuracy: 0.9841\n",
      "Epoch [34/250], Loss: 0.0036, Accuracy: 1.0000\n",
      "Validation Loss: 0.2105, Validation Accuracy: 0.9841\n",
      "Epoch [35/250], Loss: 0.0031, Accuracy: 1.0000\n",
      "Validation Loss: 0.2142, Validation Accuracy: 0.9841\n",
      "Epoch [36/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.2163, Validation Accuracy: 0.9841\n",
      "Epoch [37/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.2174, Validation Accuracy: 0.9841\n",
      "Epoch [38/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.2188, Validation Accuracy: 0.9841\n",
      "Epoch [39/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.2190, Validation Accuracy: 0.9841\n",
      "Epoch [40/250], Loss: 0.0031, Accuracy: 1.0000\n",
      "Validation Loss: 0.2204, Validation Accuracy: 0.9841\n",
      "Epoch [41/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.2223, Validation Accuracy: 0.9841\n",
      "Epoch [42/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.2252, Validation Accuracy: 0.9841\n",
      "Epoch [43/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.2269, Validation Accuracy: 0.9841\n",
      "Epoch [44/250], Loss: 0.0020, Accuracy: 1.0000\n",
      "Validation Loss: 0.2272, Validation Accuracy: 0.9841\n",
      "Epoch [45/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.2282, Validation Accuracy: 0.9841\n",
      "Epoch [46/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.2319, Validation Accuracy: 0.9841\n",
      "Epoch [47/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.2331, Validation Accuracy: 0.9841\n",
      "Epoch [48/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.2331, Validation Accuracy: 0.9841\n",
      "Epoch [49/250], Loss: 0.0031, Accuracy: 1.0000\n",
      "Validation Loss: 0.2324, Validation Accuracy: 0.9841\n",
      "Epoch [50/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.2348, Validation Accuracy: 0.9841\n",
      "Epoch [51/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.2373, Validation Accuracy: 0.9841\n",
      "Epoch [52/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.2391, Validation Accuracy: 0.9841\n",
      "Epoch [53/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.2407, Validation Accuracy: 0.9841\n",
      "Epoch [54/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.2417, Validation Accuracy: 0.9841\n",
      "Epoch [55/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.2418, Validation Accuracy: 0.9841\n",
      "Epoch [56/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.2429, Validation Accuracy: 0.9841\n",
      "Epoch [57/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.2438, Validation Accuracy: 0.9841\n",
      "Epoch [58/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.2465, Validation Accuracy: 0.9841\n",
      "Epoch [59/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.2476, Validation Accuracy: 0.9841\n",
      "Epoch [60/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.2480, Validation Accuracy: 0.9841\n",
      "Epoch [61/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.2491, Validation Accuracy: 0.9841\n",
      "Epoch [62/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.2499, Validation Accuracy: 0.9841\n",
      "Epoch [63/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.2513, Validation Accuracy: 0.9841\n",
      "Epoch [64/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.2528, Validation Accuracy: 0.9841\n",
      "Epoch [65/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.2547, Validation Accuracy: 0.9841\n",
      "Epoch [66/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.2563, Validation Accuracy: 0.9841\n",
      "Epoch [67/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.2577, Validation Accuracy: 0.9841\n",
      "Epoch [68/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.2591, Validation Accuracy: 0.9841\n",
      "Epoch [69/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.2619, Validation Accuracy: 0.9841\n",
      "Epoch [70/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.2608, Validation Accuracy: 0.9841\n",
      "Epoch [71/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.2614, Validation Accuracy: 0.9841\n",
      "Epoch [72/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.2621, Validation Accuracy: 0.9841\n",
      "Epoch [73/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.2632, Validation Accuracy: 0.9841\n",
      "Epoch [74/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.2653, Validation Accuracy: 0.9841\n",
      "Epoch [75/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.2664, Validation Accuracy: 0.9841\n",
      "Epoch [76/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.2673, Validation Accuracy: 0.9841\n",
      "Epoch [77/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.2686, Validation Accuracy: 0.9841\n",
      "Epoch [78/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.2701, Validation Accuracy: 0.9841\n",
      "Epoch [79/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.2706, Validation Accuracy: 0.9841\n",
      "Epoch [80/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.2711, Validation Accuracy: 0.9841\n",
      "Epoch [81/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.2720, Validation Accuracy: 0.9841\n",
      "Epoch [82/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.2707, Validation Accuracy: 0.9841\n",
      "Epoch [83/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.2704, Validation Accuracy: 0.9841\n",
      "Epoch [84/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.2718, Validation Accuracy: 0.9841\n",
      "Epoch [85/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.2745, Validation Accuracy: 0.9841\n",
      "Epoch [86/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.2752, Validation Accuracy: 0.9841\n",
      "Epoch [87/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.2758, Validation Accuracy: 0.9841\n",
      "Epoch [88/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.2770, Validation Accuracy: 0.9841\n",
      "Epoch [89/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.2780, Validation Accuracy: 0.9841\n",
      "Epoch [90/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.2793, Validation Accuracy: 0.9841\n",
      "Epoch [91/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.2794, Validation Accuracy: 0.9841\n",
      "Epoch [92/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.2799, Validation Accuracy: 0.9841\n",
      "Epoch [93/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.2809, Validation Accuracy: 0.9841\n",
      "Epoch [94/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.2820, Validation Accuracy: 0.9841\n",
      "Epoch [95/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.2832, Validation Accuracy: 0.9841\n",
      "Epoch [96/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.2841, Validation Accuracy: 0.9841\n",
      "Epoch [97/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.2856, Validation Accuracy: 0.9841\n",
      "Epoch [98/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.2869, Validation Accuracy: 0.9841\n",
      "Epoch [99/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.2873, Validation Accuracy: 0.9841\n",
      "Epoch [100/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.2886, Validation Accuracy: 0.9841\n",
      "Epoch [101/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.2895, Validation Accuracy: 0.9841\n",
      "Epoch [102/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.2902, Validation Accuracy: 0.9841\n",
      "Epoch [103/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.2912, Validation Accuracy: 0.9841\n",
      "Epoch [104/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.2920, Validation Accuracy: 0.9841\n",
      "Epoch [105/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.2929, Validation Accuracy: 0.9841\n",
      "Epoch [106/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.2931, Validation Accuracy: 0.9841\n",
      "Epoch [107/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.2935, Validation Accuracy: 0.9841\n",
      "Epoch [108/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.2941, Validation Accuracy: 0.9841\n",
      "Epoch [109/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.2951, Validation Accuracy: 0.9841\n",
      "Epoch [110/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.2967, Validation Accuracy: 0.9841\n",
      "Epoch [111/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.2967, Validation Accuracy: 0.9841\n",
      "Epoch [112/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.2969, Validation Accuracy: 0.9841\n",
      "Epoch [113/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.2985, Validation Accuracy: 0.9841\n",
      "Epoch [114/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.2986, Validation Accuracy: 0.9841\n",
      "Epoch [115/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.2996, Validation Accuracy: 0.9841\n",
      "Epoch [116/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3003, Validation Accuracy: 0.9841\n",
      "Epoch [117/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3010, Validation Accuracy: 0.9841\n",
      "Epoch [118/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3013, Validation Accuracy: 0.9841\n",
      "Epoch [119/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3018, Validation Accuracy: 0.9841\n",
      "Epoch [120/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3024, Validation Accuracy: 0.9841\n",
      "Epoch [121/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.3027, Validation Accuracy: 0.9841\n",
      "Epoch [122/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.3031, Validation Accuracy: 0.9841\n",
      "Epoch [123/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3032, Validation Accuracy: 0.9841\n",
      "Epoch [124/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.3039, Validation Accuracy: 0.9841\n",
      "Epoch [125/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.3052, Validation Accuracy: 0.9841\n",
      "Epoch [126/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3063, Validation Accuracy: 0.9841\n",
      "Epoch [127/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.3080, Validation Accuracy: 0.9841\n",
      "Epoch [128/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3084, Validation Accuracy: 0.9841\n",
      "Epoch [129/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3086, Validation Accuracy: 0.9841\n",
      "Epoch [130/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3092, Validation Accuracy: 0.9841\n",
      "Epoch [131/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3098, Validation Accuracy: 0.9841\n",
      "Epoch [132/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3105, Validation Accuracy: 0.9841\n",
      "Epoch [133/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3110, Validation Accuracy: 0.9841\n",
      "Epoch [134/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3114, Validation Accuracy: 0.9841\n",
      "Epoch [135/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.3126, Validation Accuracy: 0.9841\n",
      "Epoch [136/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3136, Validation Accuracy: 0.9841\n",
      "Epoch [137/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3148, Validation Accuracy: 0.9841\n",
      "Epoch [138/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3135, Validation Accuracy: 0.9841\n",
      "Epoch [139/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3129, Validation Accuracy: 0.9841\n",
      "Epoch [140/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3137, Validation Accuracy: 0.9841\n",
      "Epoch [141/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3158, Validation Accuracy: 0.9841\n",
      "Epoch [142/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3167, Validation Accuracy: 0.9841\n",
      "Epoch [143/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3178, Validation Accuracy: 0.9841\n",
      "Epoch [144/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3184, Validation Accuracy: 0.9841\n",
      "Epoch [145/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3189, Validation Accuracy: 0.9841\n",
      "Epoch [146/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3195, Validation Accuracy: 0.9841\n",
      "Epoch [147/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3197, Validation Accuracy: 0.9841\n",
      "Epoch [148/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3204, Validation Accuracy: 0.9841\n",
      "Epoch [149/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3208, Validation Accuracy: 0.9841\n",
      "Epoch [150/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3211, Validation Accuracy: 0.9841\n",
      "Epoch [151/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3218, Validation Accuracy: 0.9841\n",
      "Epoch [152/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3219, Validation Accuracy: 0.9841\n",
      "Epoch [153/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3222, Validation Accuracy: 0.9841\n",
      "Epoch [154/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3226, Validation Accuracy: 0.9841\n",
      "Epoch [155/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3227, Validation Accuracy: 0.9841\n",
      "Epoch [156/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3230, Validation Accuracy: 0.9841\n",
      "Epoch [157/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3232, Validation Accuracy: 0.9841\n",
      "Epoch [158/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3258, Validation Accuracy: 0.9841\n",
      "Epoch [159/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3265, Validation Accuracy: 0.9841\n",
      "Epoch [160/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3263, Validation Accuracy: 0.9841\n",
      "Epoch [161/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3271, Validation Accuracy: 0.9841\n",
      "Epoch [162/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3274, Validation Accuracy: 0.9841\n",
      "Epoch [163/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3276, Validation Accuracy: 0.9841\n",
      "Epoch [164/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3277, Validation Accuracy: 0.9841\n",
      "Epoch [165/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3281, Validation Accuracy: 0.9841\n",
      "Epoch [166/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3289, Validation Accuracy: 0.9841\n",
      "Epoch [167/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3296, Validation Accuracy: 0.9841\n",
      "Epoch [168/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3304, Validation Accuracy: 0.9841\n",
      "Epoch [169/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3306, Validation Accuracy: 0.9841\n",
      "Epoch [170/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3310, Validation Accuracy: 0.9841\n",
      "Epoch [171/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.3308, Validation Accuracy: 0.9841\n",
      "Epoch [172/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3318, Validation Accuracy: 0.9841\n",
      "Epoch [173/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3320, Validation Accuracy: 0.9841\n",
      "Epoch [174/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3325, Validation Accuracy: 0.9841\n",
      "Epoch [175/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.3340, Validation Accuracy: 0.9841\n",
      "Epoch [176/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3343, Validation Accuracy: 0.9841\n",
      "Epoch [177/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3347, Validation Accuracy: 0.9841\n",
      "Epoch [178/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3353, Validation Accuracy: 0.9841\n",
      "Epoch [179/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3362, Validation Accuracy: 0.9841\n",
      "Epoch [180/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3366, Validation Accuracy: 0.9841\n",
      "Epoch [181/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3372, Validation Accuracy: 0.9841\n",
      "Epoch [182/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3374, Validation Accuracy: 0.9841\n",
      "Epoch [183/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3379, Validation Accuracy: 0.9841\n",
      "Epoch [184/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3377, Validation Accuracy: 0.9841\n",
      "Epoch [185/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3379, Validation Accuracy: 0.9841\n",
      "Epoch [186/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3387, Validation Accuracy: 0.9841\n",
      "Epoch [187/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3394, Validation Accuracy: 0.9841\n",
      "Epoch [188/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3399, Validation Accuracy: 0.9841\n",
      "Epoch [189/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3401, Validation Accuracy: 0.9841\n",
      "Epoch [190/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.3439, Validation Accuracy: 0.9841\n",
      "Epoch [191/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3438, Validation Accuracy: 0.9841\n",
      "Epoch [192/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3449, Validation Accuracy: 0.9841\n",
      "Epoch [193/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3462, Validation Accuracy: 0.9841\n",
      "Epoch [194/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3471, Validation Accuracy: 0.9841\n",
      "Epoch [195/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3480, Validation Accuracy: 0.9841\n",
      "Epoch [196/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3484, Validation Accuracy: 0.9841\n",
      "Epoch [197/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3502, Validation Accuracy: 0.9841\n",
      "Epoch [198/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3507, Validation Accuracy: 0.9841\n",
      "Epoch [199/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3506, Validation Accuracy: 0.9841\n",
      "Epoch [200/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3511, Validation Accuracy: 0.9841\n",
      "Epoch [201/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3515, Validation Accuracy: 0.9841\n",
      "Epoch [202/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3522, Validation Accuracy: 0.9841\n",
      "Epoch [203/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3532, Validation Accuracy: 0.9841\n",
      "Epoch [204/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3540, Validation Accuracy: 0.9841\n",
      "Epoch [205/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3543, Validation Accuracy: 0.9841\n",
      "Epoch [206/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3543, Validation Accuracy: 0.9841\n",
      "Epoch [207/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3543, Validation Accuracy: 0.9841\n",
      "Epoch [208/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3544, Validation Accuracy: 0.9841\n",
      "Epoch [209/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3554, Validation Accuracy: 0.9841\n",
      "Epoch [210/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3558, Validation Accuracy: 0.9841\n",
      "Epoch [211/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3559, Validation Accuracy: 0.9841\n",
      "Epoch [212/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3563, Validation Accuracy: 0.9841\n",
      "Epoch [213/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3568, Validation Accuracy: 0.9841\n",
      "Epoch [214/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3569, Validation Accuracy: 0.9841\n",
      "Epoch [215/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3582, Validation Accuracy: 0.9841\n",
      "Epoch [216/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3582, Validation Accuracy: 0.9841\n",
      "Epoch [217/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3580, Validation Accuracy: 0.9841\n",
      "Epoch [218/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3589, Validation Accuracy: 0.9841\n",
      "Epoch [219/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3593, Validation Accuracy: 0.9841\n",
      "Epoch [220/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3595, Validation Accuracy: 0.9841\n",
      "Epoch [221/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3605, Validation Accuracy: 0.9841\n",
      "Epoch [222/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3612, Validation Accuracy: 0.9841\n",
      "Epoch [223/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3619, Validation Accuracy: 0.9841\n",
      "Epoch [224/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3627, Validation Accuracy: 0.9841\n",
      "Epoch [225/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3627, Validation Accuracy: 0.9841\n",
      "Epoch [226/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3632, Validation Accuracy: 0.9841\n",
      "Epoch [227/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3633, Validation Accuracy: 0.9841\n",
      "Epoch [228/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3634, Validation Accuracy: 0.9841\n",
      "Epoch [229/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3636, Validation Accuracy: 0.9841\n",
      "Epoch [230/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3640, Validation Accuracy: 0.9841\n",
      "Epoch [231/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3644, Validation Accuracy: 0.9841\n",
      "Epoch [232/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3649, Validation Accuracy: 0.9841\n",
      "Epoch [233/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3662, Validation Accuracy: 0.9841\n",
      "Epoch [234/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3663, Validation Accuracy: 0.9841\n",
      "Epoch [235/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3662, Validation Accuracy: 0.9841\n",
      "Epoch [236/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3663, Validation Accuracy: 0.9841\n",
      "Epoch [237/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3668, Validation Accuracy: 0.9841\n",
      "Epoch [238/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3678, Validation Accuracy: 0.9841\n",
      "Epoch [239/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.3679, Validation Accuracy: 0.9841\n",
      "Epoch [240/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3681, Validation Accuracy: 0.9841\n",
      "Epoch [241/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3684, Validation Accuracy: 0.9841\n",
      "Epoch [242/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.3696, Validation Accuracy: 0.9841\n",
      "Epoch [243/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3693, Validation Accuracy: 0.9841\n",
      "Epoch [244/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3691, Validation Accuracy: 0.9841\n",
      "Epoch [245/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3695, Validation Accuracy: 0.9841\n",
      "Epoch [246/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3702, Validation Accuracy: 0.9841\n",
      "Epoch [247/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.3702, Validation Accuracy: 0.9841\n",
      "Epoch [248/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3706, Validation Accuracy: 0.9841\n",
      "Epoch [249/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.3735, Validation Accuracy: 0.9841\n",
      "Epoch [250/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.3738, Validation Accuracy: 0.9841\n",
      "Test Loss: 0.1952\n",
      "Test Accuracy: 0.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Temp\\ipykernel_20448\\673908621.py:239: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, temp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 85\n",
      "label 1 is 102\n",
      "label 2 is 65\n",
      "label 3 is 23\n",
      "Not setting metadata\n",
      "275 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (251, 8, 325)\n",
      "251 train samples\n",
      "126 test samples\n",
      "Number of batches in train_loader: 4\n",
      "{-1: 1.1030701754385965, 0: 0.9145454545454546}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.2233, Accuracy: 0.4263\n",
      "Validation Loss: 0.9335, Validation Accuracy: 0.3889\n",
      "Epoch [2/250], Loss: 0.9597, Accuracy: 0.5618\n",
      "Validation Loss: 0.8157, Validation Accuracy: 0.3889\n",
      "Epoch [3/250], Loss: 0.7902, Accuracy: 0.5697\n",
      "Validation Loss: 0.8053, Validation Accuracy: 0.3889\n",
      "Epoch [4/250], Loss: 0.6998, Accuracy: 0.6853\n",
      "Validation Loss: 1.2392, Validation Accuracy: 0.3889\n",
      "Epoch [5/250], Loss: 0.5929, Accuracy: 0.7131\n",
      "Validation Loss: 1.5709, Validation Accuracy: 0.3889\n",
      "Epoch [6/250], Loss: 0.4479, Accuracy: 0.8088\n",
      "Validation Loss: 2.8103, Validation Accuracy: 0.3889\n",
      "Epoch [7/250], Loss: 0.2800, Accuracy: 0.8924\n",
      "Validation Loss: 4.2379, Validation Accuracy: 0.3889\n",
      "Epoch [8/250], Loss: 0.2020, Accuracy: 0.9522\n",
      "Validation Loss: 5.0967, Validation Accuracy: 0.3889\n",
      "Epoch [9/250], Loss: 0.1278, Accuracy: 0.9562\n",
      "Validation Loss: 5.4627, Validation Accuracy: 0.3889\n",
      "Epoch [10/250], Loss: 0.0879, Accuracy: 0.9761\n",
      "Validation Loss: 5.9563, Validation Accuracy: 0.3889\n",
      "Epoch [11/250], Loss: 0.1133, Accuracy: 0.9761\n",
      "Validation Loss: 6.0709, Validation Accuracy: 0.3889\n",
      "Epoch [12/250], Loss: 0.0927, Accuracy: 0.9681\n",
      "Validation Loss: 6.2694, Validation Accuracy: 0.3889\n",
      "Epoch [13/250], Loss: 0.0684, Accuracy: 0.9721\n",
      "Validation Loss: 6.6173, Validation Accuracy: 0.3889\n",
      "Epoch [14/250], Loss: 0.0395, Accuracy: 0.9920\n",
      "Validation Loss: 6.5715, Validation Accuracy: 0.3889\n",
      "Epoch [15/250], Loss: 0.0428, Accuracy: 0.9841\n",
      "Validation Loss: 6.7731, Validation Accuracy: 0.3889\n",
      "Epoch [16/250], Loss: 0.0216, Accuracy: 0.9920\n",
      "Validation Loss: 6.2491, Validation Accuracy: 0.3889\n",
      "Epoch [17/250], Loss: 0.1261, Accuracy: 0.9562\n",
      "Validation Loss: 6.2822, Validation Accuracy: 0.3889\n",
      "Epoch [18/250], Loss: 0.0871, Accuracy: 0.9681\n",
      "Validation Loss: 6.6014, Validation Accuracy: 0.3889\n",
      "Epoch [19/250], Loss: 0.0378, Accuracy: 0.9880\n",
      "Validation Loss: 2.9963, Validation Accuracy: 0.6032\n",
      "Epoch [20/250], Loss: 0.0475, Accuracy: 0.9761\n",
      "Validation Loss: 2.1649, Validation Accuracy: 0.6984\n",
      "Epoch [21/250], Loss: 0.0309, Accuracy: 0.9880\n",
      "Validation Loss: 0.0439, Validation Accuracy: 0.9841\n",
      "Epoch [22/250], Loss: 0.0314, Accuracy: 0.9880\n",
      "Validation Loss: 0.0225, Validation Accuracy: 0.9841\n",
      "Epoch [23/250], Loss: 0.1076, Accuracy: 0.9721\n",
      "Validation Loss: 0.1597, Validation Accuracy: 0.9762\n",
      "Epoch [24/250], Loss: 0.0198, Accuracy: 0.9960\n",
      "Validation Loss: 0.3930, Validation Accuracy: 0.9365\n",
      "Epoch [25/250], Loss: 0.0377, Accuracy: 0.9880\n",
      "Validation Loss: 0.5247, Validation Accuracy: 0.9206\n",
      "Epoch [26/250], Loss: 0.0578, Accuracy: 0.9801\n",
      "Validation Loss: 0.1482, Validation Accuracy: 0.9762\n",
      "Epoch [27/250], Loss: 0.0354, Accuracy: 0.9920\n",
      "Validation Loss: 0.4383, Validation Accuracy: 0.9206\n",
      "Epoch [28/250], Loss: 0.0315, Accuracy: 0.9920\n",
      "Validation Loss: 0.2390, Validation Accuracy: 0.9444\n",
      "Epoch [29/250], Loss: 0.0416, Accuracy: 0.9880\n",
      "Validation Loss: 1.7448, Validation Accuracy: 0.7619\n",
      "Epoch [30/250], Loss: 0.0490, Accuracy: 0.9880\n",
      "Validation Loss: 0.2245, Validation Accuracy: 0.9683\n",
      "Epoch [31/250], Loss: 0.0365, Accuracy: 0.9920\n",
      "Validation Loss: 0.2356, Validation Accuracy: 0.9524\n",
      "Epoch [32/250], Loss: 0.0114, Accuracy: 0.9960\n",
      "Validation Loss: 2.3932, Validation Accuracy: 0.6825\n",
      "Epoch [33/250], Loss: 0.0170, Accuracy: 0.9920\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [34/250], Loss: 0.0074, Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [35/250], Loss: 0.0265, Accuracy: 0.9880\n",
      "Validation Loss: 2.2194, Validation Accuracy: 0.7302\n",
      "Epoch [36/250], Loss: 0.0492, Accuracy: 0.9920\n",
      "Validation Loss: 4.3140, Validation Accuracy: 0.5794\n",
      "Epoch [37/250], Loss: 0.0439, Accuracy: 0.9841\n",
      "Validation Loss: 0.2175, Validation Accuracy: 0.9683\n",
      "Epoch [38/250], Loss: 0.0079, Accuracy: 1.0000\n",
      "Validation Loss: 0.1018, Validation Accuracy: 0.9841\n",
      "Epoch [39/250], Loss: 0.0069, Accuracy: 1.0000\n",
      "Validation Loss: 0.1148, Validation Accuracy: 0.9841\n",
      "Epoch [40/250], Loss: 0.0443, Accuracy: 0.9920\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [41/250], Loss: 0.0046, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [42/250], Loss: 0.0363, Accuracy: 0.9960\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [43/250], Loss: 0.0026, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [44/250], Loss: 0.0048, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [45/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [46/250], Loss: 0.0095, Accuracy: 0.9960\n",
      "Validation Loss: 0.5557, Validation Accuracy: 0.9286\n",
      "Epoch [47/250], Loss: 0.0378, Accuracy: 0.9880\n",
      "Validation Loss: 0.0239, Validation Accuracy: 0.9841\n",
      "Epoch [48/250], Loss: 0.0038, Accuracy: 1.0000\n",
      "Validation Loss: 0.8881, Validation Accuracy: 0.9048\n",
      "Epoch [49/250], Loss: 0.0082, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [50/250], Loss: 0.0131, Accuracy: 0.9920\n",
      "Validation Loss: 0.4770, Validation Accuracy: 0.9286\n",
      "Epoch [51/250], Loss: 0.0089, Accuracy: 0.9960\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [52/250], Loss: 0.0516, Accuracy: 0.9880\n",
      "Validation Loss: 3.8929, Validation Accuracy: 0.6111\n",
      "Epoch [53/250], Loss: 0.0123, Accuracy: 0.9960\n",
      "Validation Loss: 0.6926, Validation Accuracy: 0.9048\n",
      "Epoch [54/250], Loss: 0.0110, Accuracy: 0.9960\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [55/250], Loss: 0.0039, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [56/250], Loss: 0.0038, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [57/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [58/250], Loss: 0.0176, Accuracy: 0.9920\n",
      "Validation Loss: 0.1826, Validation Accuracy: 0.9841\n",
      "Epoch [59/250], Loss: 0.0049, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [60/250], Loss: 0.0140, Accuracy: 0.9960\n",
      "Validation Loss: 2.0772, Validation Accuracy: 0.7698\n",
      "Epoch [61/250], Loss: 0.0204, Accuracy: 0.9960\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [62/250], Loss: 0.0196, Accuracy: 0.9960\n",
      "Validation Loss: 3.5575, Validation Accuracy: 0.6429\n",
      "Epoch [63/250], Loss: 0.0277, Accuracy: 0.9880\n",
      "Validation Loss: 0.8208, Validation Accuracy: 0.9048\n",
      "Epoch [64/250], Loss: 0.0316, Accuracy: 0.9880\n",
      "Validation Loss: 0.0947, Validation Accuracy: 0.9841\n",
      "Epoch [65/250], Loss: 0.0260, Accuracy: 0.9960\n",
      "Validation Loss: 0.0092, Validation Accuracy: 1.0000\n",
      "Epoch [66/250], Loss: 0.0394, Accuracy: 0.9920\n",
      "Validation Loss: 0.9259, Validation Accuracy: 0.8810\n",
      "Epoch [67/250], Loss: 0.0234, Accuracy: 0.9920\n",
      "Validation Loss: 0.0006, Validation Accuracy: 1.0000\n",
      "Epoch [68/250], Loss: 0.0044, Accuracy: 1.0000\n",
      "Validation Loss: 0.0676, Validation Accuracy: 0.9841\n",
      "Epoch [69/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.1235, Validation Accuracy: 0.9841\n",
      "Epoch [70/250], Loss: 0.0026, Accuracy: 1.0000\n",
      "Validation Loss: 0.0167, Validation Accuracy: 0.9921\n",
      "Epoch [71/250], Loss: 0.0029, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [72/250], Loss: 0.0062, Accuracy: 1.0000\n",
      "Validation Loss: 1.0381, Validation Accuracy: 0.8651\n",
      "Epoch [73/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 2.3836, Validation Accuracy: 0.7460\n",
      "Epoch [74/250], Loss: 0.0219, Accuracy: 0.9960\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [75/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [76/250], Loss: 0.0037, Accuracy: 1.0000\n",
      "Validation Loss: 0.0417, Validation Accuracy: 0.9921\n",
      "Epoch [77/250], Loss: 0.0055, Accuracy: 1.0000\n",
      "Validation Loss: 0.0004, Validation Accuracy: 1.0000\n",
      "Epoch [78/250], Loss: 0.0320, Accuracy: 0.9920\n",
      "Validation Loss: 0.3276, Validation Accuracy: 0.9603\n",
      "Epoch [79/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0506, Validation Accuracy: 0.9841\n",
      "Epoch [80/250], Loss: 0.0051, Accuracy: 0.9960\n",
      "Validation Loss: 4.3446, Validation Accuracy: 0.6270\n",
      "Epoch [81/250], Loss: 0.0046, Accuracy: 1.0000\n",
      "Validation Loss: 0.0467, Validation Accuracy: 0.9762\n",
      "Epoch [82/250], Loss: 0.0348, Accuracy: 0.9920\n",
      "Validation Loss: 0.0951, Validation Accuracy: 0.9762\n",
      "Epoch [83/250], Loss: 0.0116, Accuracy: 0.9960\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [84/250], Loss: 0.0067, Accuracy: 0.9960\n",
      "Validation Loss: 0.3560, Validation Accuracy: 0.9524\n",
      "Epoch [85/250], Loss: 0.0101, Accuracy: 0.9960\n",
      "Validation Loss: 0.8441, Validation Accuracy: 0.9048\n",
      "Epoch [86/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.4196, Validation Accuracy: 0.9444\n",
      "Epoch [87/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0072, Validation Accuracy: 0.9921\n",
      "Epoch [88/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [89/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [90/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [91/250], Loss: 0.0232, Accuracy: 0.9960\n",
      "Validation Loss: 0.4860, Validation Accuracy: 0.9444\n",
      "Epoch [92/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.2105, Validation Accuracy: 0.9524\n",
      "Epoch [93/250], Loss: 0.0064, Accuracy: 0.9960\n",
      "Validation Loss: 0.2055, Validation Accuracy: 0.9841\n",
      "Epoch [94/250], Loss: 0.0164, Accuracy: 0.9960\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [95/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [96/250], Loss: 0.0127, Accuracy: 0.9960\n",
      "Validation Loss: 0.2577, Validation Accuracy: 0.9524\n",
      "Epoch [97/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [98/250], Loss: 0.0041, Accuracy: 1.0000\n",
      "Validation Loss: 0.6358, Validation Accuracy: 0.9365\n",
      "Epoch [99/250], Loss: 0.0361, Accuracy: 0.9920\n",
      "Validation Loss: 0.3635, Validation Accuracy: 0.9603\n",
      "Epoch [100/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.7200, Validation Accuracy: 0.9127\n",
      "Epoch [101/250], Loss: 0.0041, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [102/250], Loss: 0.0363, Accuracy: 0.9920\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [103/250], Loss: 0.0178, Accuracy: 0.9880\n",
      "Validation Loss: 0.0007, Validation Accuracy: 1.0000\n",
      "Epoch [104/250], Loss: 0.0052, Accuracy: 0.9960\n",
      "Validation Loss: 0.5437, Validation Accuracy: 0.9286\n",
      "Epoch [105/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0940, Validation Accuracy: 0.9841\n",
      "Epoch [106/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.0710, Validation Accuracy: 0.9841\n",
      "Epoch [107/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0055, Validation Accuracy: 0.9921\n",
      "Epoch [108/250], Loss: 0.0024, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [109/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.4480, Validation Accuracy: 0.9444\n",
      "Epoch [110/250], Loss: 0.0066, Accuracy: 0.9960\n",
      "Validation Loss: 0.1547, Validation Accuracy: 0.9841\n",
      "Epoch [111/250], Loss: 0.0047, Accuracy: 1.0000\n",
      "Validation Loss: 5.9957, Validation Accuracy: 0.6111\n",
      "Epoch [112/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 5.8020, Validation Accuracy: 0.6111\n",
      "Epoch [113/250], Loss: 0.0074, Accuracy: 0.9960\n",
      "Validation Loss: 0.1354, Validation Accuracy: 0.9841\n",
      "Epoch [114/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0939, Validation Accuracy: 0.9841\n",
      "Epoch [115/250], Loss: 0.0083, Accuracy: 0.9960\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [116/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [117/250], Loss: 0.0471, Accuracy: 0.9880\n",
      "Validation Loss: 1.2428, Validation Accuracy: 0.8651\n",
      "Epoch [118/250], Loss: 0.0127, Accuracy: 0.9960\n",
      "Validation Loss: 3.2412, Validation Accuracy: 0.6429\n",
      "Epoch [119/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.6045, Validation Accuracy: 0.9286\n",
      "Epoch [120/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0503, Validation Accuracy: 0.9841\n",
      "Epoch [121/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [122/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [123/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [124/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [125/250], Loss: 0.0081, Accuracy: 0.9960\n",
      "Validation Loss: 0.0204, Validation Accuracy: 0.9921\n",
      "Epoch [126/250], Loss: 0.0342, Accuracy: 0.9920\n",
      "Validation Loss: 5.6031, Validation Accuracy: 0.6111\n",
      "Epoch [127/250], Loss: 0.0128, Accuracy: 0.9960\n",
      "Validation Loss: 0.3643, Validation Accuracy: 0.9524\n",
      "Epoch [128/250], Loss: 0.0263, Accuracy: 0.9920\n",
      "Validation Loss: 4.6248, Validation Accuracy: 0.6190\n",
      "Epoch [129/250], Loss: 0.0238, Accuracy: 0.9960\n",
      "Validation Loss: 5.0161, Validation Accuracy: 0.6111\n",
      "Epoch [130/250], Loss: 0.0139, Accuracy: 0.9960\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [131/250], Loss: 0.0036, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [132/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [133/250], Loss: 0.0029, Accuracy: 1.0000\n",
      "Validation Loss: 0.0014, Validation Accuracy: 1.0000\n",
      "Epoch [134/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.1135, Validation Accuracy: 0.9841\n",
      "Epoch [135/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.0344, Validation Accuracy: 0.9921\n",
      "Epoch [136/250], Loss: 0.0053, Accuracy: 0.9960\n",
      "Validation Loss: 0.9201, Validation Accuracy: 0.9127\n",
      "Epoch [137/250], Loss: 0.0119, Accuracy: 0.9960\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [138/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [139/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [140/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.0509, Validation Accuracy: 0.9921\n",
      "Epoch [141/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0493, Validation Accuracy: 0.9921\n",
      "Epoch [142/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [143/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [144/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [145/250], Loss: 0.0038, Accuracy: 1.0000\n",
      "Validation Loss: 0.1324, Validation Accuracy: 0.9762\n",
      "Epoch [146/250], Loss: 0.0419, Accuracy: 0.9880\n",
      "Validation Loss: 0.1228, Validation Accuracy: 0.9841\n",
      "Epoch [147/250], Loss: 0.2816, Accuracy: 0.9442\n",
      "Validation Loss: 3.8350, Validation Accuracy: 0.6190\n",
      "Epoch [148/250], Loss: 0.0928, Accuracy: 0.9801\n",
      "Validation Loss: 0.0292, Validation Accuracy: 0.9841\n",
      "Epoch [149/250], Loss: 0.0079, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [150/250], Loss: 0.0126, Accuracy: 0.9920\n",
      "Validation Loss: 0.0757, Validation Accuracy: 0.9841\n",
      "Epoch [151/250], Loss: 0.0051, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [152/250], Loss: 0.0153, Accuracy: 0.9960\n",
      "Validation Loss: 0.0105, Validation Accuracy: 0.9921\n",
      "Epoch [153/250], Loss: 0.0067, Accuracy: 0.9960\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [154/250], Loss: 0.0040, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [155/250], Loss: 0.0058, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [156/250], Loss: 0.0031, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [157/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [158/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [159/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [160/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [161/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [162/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [163/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [164/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [165/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [166/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [167/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [168/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [169/250], Loss: 0.0032, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [170/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [171/250], Loss: 0.0135, Accuracy: 0.9920\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [172/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [173/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [174/250], Loss: 0.0317, Accuracy: 0.9960\n",
      "Validation Loss: 1.7028, Validation Accuracy: 0.8175\n",
      "Epoch [175/250], Loss: 0.0637, Accuracy: 0.9880\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [176/250], Loss: 0.0032, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [177/250], Loss: 0.0033, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [178/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [179/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [180/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [181/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [182/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [183/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.2490, Validation Accuracy: 0.9603\n",
      "Epoch [184/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.5627, Validation Accuracy: 0.9365\n",
      "Epoch [185/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.2240, Validation Accuracy: 0.9683\n",
      "Epoch [186/250], Loss: 0.0024, Accuracy: 1.0000\n",
      "Validation Loss: 0.1570, Validation Accuracy: 0.9762\n",
      "Epoch [187/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [188/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [189/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [190/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [191/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [192/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [193/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [194/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [195/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [196/250], Loss: 0.0038, Accuracy: 0.9960\n",
      "Validation Loss: 0.1192, Validation Accuracy: 0.9762\n",
      "Epoch [197/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0402, Validation Accuracy: 0.9921\n",
      "Epoch [198/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [199/250], Loss: 0.0122, Accuracy: 0.9920\n",
      "Validation Loss: 3.6942, Validation Accuracy: 0.6667\n",
      "Epoch [200/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.3495, Validation Accuracy: 0.9524\n",
      "Epoch [201/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0301, Validation Accuracy: 0.9921\n",
      "Epoch [202/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [203/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [204/250], Loss: 0.0428, Accuracy: 0.9960\n",
      "Validation Loss: 0.2584, Validation Accuracy: 0.9762\n",
      "Epoch [205/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.3948, Validation Accuracy: 0.9524\n",
      "Epoch [206/250], Loss: 0.0055, Accuracy: 0.9960\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [207/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [208/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [209/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [210/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [211/250], Loss: 0.0107, Accuracy: 0.9960\n",
      "Validation Loss: 0.1691, Validation Accuracy: 0.9841\n",
      "Epoch [212/250], Loss: 0.0368, Accuracy: 0.9960\n",
      "Validation Loss: 0.3089, Validation Accuracy: 0.9683\n",
      "Epoch [213/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.1913, Validation Accuracy: 0.9841\n",
      "Epoch [214/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0848, Validation Accuracy: 0.9841\n",
      "Epoch [215/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0054, Validation Accuracy: 1.0000\n",
      "Epoch [216/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [217/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [218/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [219/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [220/250], Loss: 0.0020, Accuracy: 1.0000\n",
      "Validation Loss: 2.6243, Validation Accuracy: 0.7619\n",
      "Epoch [221/250], Loss: 0.0058, Accuracy: 0.9960\n",
      "Validation Loss: 0.1688, Validation Accuracy: 0.9841\n",
      "Epoch [222/250], Loss: 0.0301, Accuracy: 0.9920\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [223/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [224/250], Loss: 0.0050, Accuracy: 0.9960\n",
      "Validation Loss: 0.7127, Validation Accuracy: 0.9127\n",
      "Epoch [225/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.5392, Validation Accuracy: 0.9444\n",
      "Epoch [226/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.1335, Validation Accuracy: 0.9841\n",
      "Epoch [227/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0006, Validation Accuracy: 1.0000\n",
      "Epoch [228/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [229/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [230/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [231/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [232/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [233/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [234/250], Loss: 0.0336, Accuracy: 0.9880\n",
      "Validation Loss: 0.0017, Validation Accuracy: 1.0000\n",
      "Epoch [235/250], Loss: 0.0108, Accuracy: 0.9960\n",
      "Validation Loss: 1.6968, Validation Accuracy: 0.8254\n",
      "Epoch [236/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 5.0690, Validation Accuracy: 0.6111\n",
      "Epoch [237/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 1.4933, Validation Accuracy: 0.8492\n",
      "Epoch [238/250], Loss: 0.0060, Accuracy: 0.9960\n",
      "Validation Loss: 0.0831, Validation Accuracy: 0.9921\n",
      "Epoch [239/250], Loss: 0.0213, Accuracy: 0.9960\n",
      "Validation Loss: 0.0222, Validation Accuracy: 0.9841\n",
      "Epoch [240/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.1970, Validation Accuracy: 0.9841\n",
      "Epoch [241/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.1481, Validation Accuracy: 0.9841\n",
      "Epoch [242/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0699, Validation Accuracy: 0.9841\n",
      "Epoch [243/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0118, Validation Accuracy: 0.9921\n",
      "Epoch [244/250], Loss: 0.0091, Accuracy: 0.9960\n",
      "Validation Loss: 4.9557, Validation Accuracy: 0.6190\n",
      "Epoch [245/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 2.6173, Validation Accuracy: 0.7778\n",
      "Epoch [246/250], Loss: 0.0333, Accuracy: 0.9960\n",
      "Validation Loss: 0.2132, Validation Accuracy: 0.9841\n",
      "Epoch [247/250], Loss: 0.0062, Accuracy: 0.9960\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [248/250], Loss: 0.0022, Accuracy: 1.0000\n",
      "Validation Loss: 0.0936, Validation Accuracy: 0.9841\n",
      "Epoch [249/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0164, Validation Accuracy: 0.9921\n",
      "Epoch [250/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Test Loss: 0.0948\n",
      "Test Accuracy: 0.9841\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 81\n",
      "label 1 is 102\n",
      "label 2 is 24\n",
      "label 3 is 48\n",
      "Not setting metadata\n",
      "255 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (241, 8, 325)\n",
      "241 train samples\n",
      "121 test samples\n",
      "Number of batches in train_loader: 4\n",
      "{-1: 1.0592105263157894, 0: 0.9470588235294117}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.3109, Accuracy: 0.3485\n",
      "Validation Loss: 1.0624, Validation Accuracy: 0.4876\n",
      "Epoch [2/250], Loss: 1.0430, Accuracy: 0.5187\n",
      "Validation Loss: 0.8303, Validation Accuracy: 0.4876\n",
      "Epoch [3/250], Loss: 0.8117, Accuracy: 0.6141\n",
      "Validation Loss: 0.8922, Validation Accuracy: 0.4876\n",
      "Epoch [4/250], Loss: 0.6646, Accuracy: 0.6888\n",
      "Validation Loss: 1.0636, Validation Accuracy: 0.4876\n",
      "Epoch [5/250], Loss: 0.4721, Accuracy: 0.8631\n",
      "Validation Loss: 1.7289, Validation Accuracy: 0.4876\n",
      "Epoch [6/250], Loss: 0.2757, Accuracy: 0.9544\n",
      "Validation Loss: 2.4353, Validation Accuracy: 0.4876\n",
      "Epoch [7/250], Loss: 0.1205, Accuracy: 0.9959\n",
      "Validation Loss: 3.1060, Validation Accuracy: 0.4876\n",
      "Epoch [8/250], Loss: 0.0658, Accuracy: 1.0000\n",
      "Validation Loss: 3.5458, Validation Accuracy: 0.4876\n",
      "Epoch [9/250], Loss: 0.0434, Accuracy: 1.0000\n",
      "Validation Loss: 3.8763, Validation Accuracy: 0.4876\n",
      "Epoch [10/250], Loss: 0.0288, Accuracy: 1.0000\n",
      "Validation Loss: 4.2002, Validation Accuracy: 0.4876\n",
      "Epoch [11/250], Loss: 0.0287, Accuracy: 0.9959\n",
      "Validation Loss: 4.4610, Validation Accuracy: 0.4876\n",
      "Epoch [12/250], Loss: 0.0158, Accuracy: 1.0000\n",
      "Validation Loss: 4.6304, Validation Accuracy: 0.4876\n",
      "Epoch [13/250], Loss: 0.0174, Accuracy: 1.0000\n",
      "Validation Loss: 4.7314, Validation Accuracy: 0.4876\n",
      "Epoch [14/250], Loss: 0.0154, Accuracy: 1.0000\n",
      "Validation Loss: 4.8463, Validation Accuracy: 0.4876\n",
      "Epoch [15/250], Loss: 0.0126, Accuracy: 1.0000\n",
      "Validation Loss: 5.0022, Validation Accuracy: 0.4876\n",
      "Epoch [16/250], Loss: 0.0104, Accuracy: 1.0000\n",
      "Validation Loss: 4.9966, Validation Accuracy: 0.4876\n",
      "Epoch [17/250], Loss: 0.0147, Accuracy: 0.9959\n",
      "Validation Loss: 4.2770, Validation Accuracy: 0.5041\n",
      "Epoch [18/250], Loss: 0.0062, Accuracy: 1.0000\n",
      "Validation Loss: 2.8290, Validation Accuracy: 0.5785\n",
      "Epoch [19/250], Loss: 0.0072, Accuracy: 1.0000\n",
      "Validation Loss: 1.2886, Validation Accuracy: 0.7603\n",
      "Epoch [20/250], Loss: 0.0046, Accuracy: 1.0000\n",
      "Validation Loss: 0.3826, Validation Accuracy: 0.9174\n",
      "Epoch [21/250], Loss: 0.0062, Accuracy: 1.0000\n",
      "Validation Loss: 0.0683, Validation Accuracy: 0.9917\n",
      "Epoch [22/250], Loss: 0.0045, Accuracy: 1.0000\n",
      "Validation Loss: 0.0315, Validation Accuracy: 0.9917\n",
      "Epoch [23/250], Loss: 0.0043, Accuracy: 1.0000\n",
      "Validation Loss: 0.0075, Validation Accuracy: 0.9917\n",
      "Epoch [24/250], Loss: 0.0037, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [25/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.0063, Validation Accuracy: 0.9917\n",
      "Epoch [26/250], Loss: 0.0055, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [27/250], Loss: 0.0029, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [28/250], Loss: 0.0030, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [29/250], Loss: 0.0033, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [30/250], Loss: 0.0030, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [31/250], Loss: 0.0038, Accuracy: 1.0000\n",
      "Validation Loss: 0.0018, Validation Accuracy: 1.0000\n",
      "Epoch [32/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [33/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [34/250], Loss: 0.0030, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [35/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [36/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [37/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [38/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [39/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [40/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [41/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [42/250], Loss: 0.0029, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [43/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [44/250], Loss: 0.0020, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [45/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [46/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [47/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [48/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [49/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [50/250], Loss: 0.0022, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [51/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [52/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [53/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [54/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0815, Validation Accuracy: 0.9917\n",
      "Epoch [55/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0575, Validation Accuracy: 0.9917\n",
      "Epoch [56/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0232, Validation Accuracy: 0.9917\n",
      "Epoch [57/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [58/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [59/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [60/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [61/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [62/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [63/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [64/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [65/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [66/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [67/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [68/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [69/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [70/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [71/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [72/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [73/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [74/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [75/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [76/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [77/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [78/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [79/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [80/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [81/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [82/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [83/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [84/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [85/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [86/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [87/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [88/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [89/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [90/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [91/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [92/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [93/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [94/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [95/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [96/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [97/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [98/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [99/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [100/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [101/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [102/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [103/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [104/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [105/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [106/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [107/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [108/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [109/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [110/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [111/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [112/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [113/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [114/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [115/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [116/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [117/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [118/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [119/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [120/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [121/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [122/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [123/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [124/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [125/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [126/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 7.9245, Validation Accuracy: 0.5124\n",
      "Epoch [127/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 2.2425, Validation Accuracy: 0.7107\n",
      "Epoch [128/250], Loss: 0.3808, Accuracy: 0.9544\n",
      "Validation Loss: 0.0668, Validation Accuracy: 0.9917\n",
      "Epoch [129/250], Loss: 0.1572, Accuracy: 0.9710\n",
      "Validation Loss: 5.3484, Validation Accuracy: 0.5124\n",
      "Epoch [130/250], Loss: 0.0210, Accuracy: 0.9959\n",
      "Validation Loss: 4.7840, Validation Accuracy: 0.5124\n",
      "Epoch [131/250], Loss: 0.0030, Accuracy: 1.0000\n",
      "Validation Loss: 4.5933, Validation Accuracy: 0.5124\n",
      "Epoch [132/250], Loss: 0.0068, Accuracy: 0.9959\n",
      "Validation Loss: 2.7746, Validation Accuracy: 0.5289\n",
      "Epoch [133/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0902, Validation Accuracy: 0.9835\n",
      "Epoch [134/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0287, Validation Accuracy: 0.9917\n",
      "Epoch [135/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0006, Validation Accuracy: 1.0000\n",
      "Epoch [136/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [137/250], Loss: 0.0024, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [138/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [139/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [140/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [141/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [142/250], Loss: 0.0020, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [143/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [144/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [145/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [146/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [147/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [148/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [149/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [150/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [151/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [152/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [153/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [154/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [155/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [156/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [157/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [158/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [159/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [160/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [161/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [162/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [163/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [164/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [165/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [166/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [167/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [168/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [169/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [170/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [171/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [172/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [173/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [174/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [175/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [176/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [177/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [178/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [179/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [180/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [181/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [182/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [183/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [184/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [185/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [186/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [187/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [188/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [189/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [190/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [191/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [192/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [193/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [194/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [195/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [196/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [197/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [198/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [199/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [200/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [201/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [202/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [203/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [204/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [205/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [206/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [207/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [208/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [209/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [210/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [211/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [212/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [213/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [214/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [215/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [216/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [217/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [218/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [219/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [220/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [221/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [222/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [223/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [224/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [225/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [226/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [227/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [228/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [229/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [230/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [231/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [232/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [233/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [234/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [235/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [236/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [237/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [238/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [239/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [240/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [241/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [242/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [243/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [244/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [245/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [246/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [247/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [248/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [249/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [250/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Test Loss: 0.0000\n",
      "Test Accuracy: 1.0000\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 121\n",
      "label 1 is 202\n",
      "label 2 is 22\n",
      "label 3 is 103\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (338, 8, 325)\n",
      "338 train samples\n",
      "169 test samples\n",
      "Number of batches in train_loader: 6\n",
      "{-1: 1.4824561403508771, 0: 0.7544642857142857}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.2498, Accuracy: 0.3994\n",
      "Validation Loss: 0.9561, Validation Accuracy: 0.6154\n",
      "Epoch [2/250], Loss: 0.8946, Accuracy: 0.6775\n",
      "Validation Loss: 0.7816, Validation Accuracy: 0.6154\n",
      "Epoch [3/250], Loss: 0.7477, Accuracy: 0.6716\n",
      "Validation Loss: 0.7171, Validation Accuracy: 0.6154\n",
      "Epoch [4/250], Loss: 0.7295, Accuracy: 0.6361\n",
      "Validation Loss: 0.6893, Validation Accuracy: 0.6154\n",
      "Epoch [5/250], Loss: 0.7043, Accuracy: 0.6450\n",
      "Validation Loss: 0.7239, Validation Accuracy: 0.6154\n",
      "Epoch [6/250], Loss: 0.7316, Accuracy: 0.6420\n",
      "Validation Loss: 0.6918, Validation Accuracy: 0.6154\n",
      "Epoch [7/250], Loss: 0.7098, Accuracy: 0.6183\n",
      "Validation Loss: 0.6767, Validation Accuracy: 0.6154\n",
      "Epoch [8/250], Loss: 0.6586, Accuracy: 0.6538\n",
      "Validation Loss: 0.7410, Validation Accuracy: 0.6154\n",
      "Epoch [9/250], Loss: 0.7045, Accuracy: 0.6598\n",
      "Validation Loss: 0.6822, Validation Accuracy: 0.6154\n",
      "Epoch [10/250], Loss: 0.6913, Accuracy: 0.6479\n",
      "Validation Loss: 0.6820, Validation Accuracy: 0.6154\n",
      "Epoch [11/250], Loss: 0.6776, Accuracy: 0.6331\n",
      "Validation Loss: 0.7062, Validation Accuracy: 0.6154\n",
      "Epoch [12/250], Loss: 0.6464, Accuracy: 0.7012\n",
      "Validation Loss: 0.7051, Validation Accuracy: 0.6154\n",
      "Epoch [13/250], Loss: 0.6930, Accuracy: 0.6538\n",
      "Validation Loss: 0.6972, Validation Accuracy: 0.6154\n",
      "Epoch [14/250], Loss: 0.7193, Accuracy: 0.6154\n",
      "Validation Loss: 0.7071, Validation Accuracy: 0.6154\n",
      "Epoch [15/250], Loss: 0.6834, Accuracy: 0.6686\n",
      "Validation Loss: 0.6806, Validation Accuracy: 0.6154\n",
      "Epoch [16/250], Loss: 0.6972, Accuracy: 0.6509\n",
      "Validation Loss: 0.6650, Validation Accuracy: 0.6154\n",
      "Epoch [17/250], Loss: 0.6779, Accuracy: 0.6302\n",
      "Validation Loss: 0.7086, Validation Accuracy: 0.6154\n",
      "Epoch [18/250], Loss: 0.6633, Accuracy: 0.6686\n",
      "Validation Loss: 0.7092, Validation Accuracy: 0.6154\n",
      "Epoch [19/250], Loss: 0.6697, Accuracy: 0.6923\n",
      "Validation Loss: 0.6908, Validation Accuracy: 0.6154\n",
      "Epoch [20/250], Loss: 0.6818, Accuracy: 0.6627\n",
      "Validation Loss: 0.7047, Validation Accuracy: 0.6154\n",
      "Epoch [21/250], Loss: 0.6643, Accuracy: 0.6834\n",
      "Validation Loss: 0.6909, Validation Accuracy: 0.6154\n",
      "Epoch [22/250], Loss: 0.6697, Accuracy: 0.6568\n",
      "Validation Loss: 0.6865, Validation Accuracy: 0.6154\n",
      "Epoch [23/250], Loss: 0.6236, Accuracy: 0.6775\n",
      "Validation Loss: 0.7015, Validation Accuracy: 0.6154\n",
      "Epoch [24/250], Loss: 0.6389, Accuracy: 0.6982\n",
      "Validation Loss: 0.6952, Validation Accuracy: 0.6154\n",
      "Epoch [25/250], Loss: 0.6508, Accuracy: 0.6834\n",
      "Validation Loss: 0.6790, Validation Accuracy: 0.6154\n",
      "Epoch [26/250], Loss: 0.6545, Accuracy: 0.6716\n",
      "Validation Loss: 0.6841, Validation Accuracy: 0.6154\n",
      "Epoch [27/250], Loss: 0.6127, Accuracy: 0.6775\n",
      "Validation Loss: 0.7158, Validation Accuracy: 0.6154\n",
      "Epoch [28/250], Loss: 0.6617, Accuracy: 0.6893\n",
      "Validation Loss: 0.7077, Validation Accuracy: 0.6154\n",
      "Epoch [29/250], Loss: 0.6555, Accuracy: 0.6598\n",
      "Validation Loss: 0.6833, Validation Accuracy: 0.6154\n",
      "Epoch [30/250], Loss: 0.6338, Accuracy: 0.6775\n",
      "Validation Loss: 0.6915, Validation Accuracy: 0.6154\n",
      "Epoch [31/250], Loss: 0.6393, Accuracy: 0.6657\n",
      "Validation Loss: 0.7255, Validation Accuracy: 0.6154\n",
      "Epoch [32/250], Loss: 0.6755, Accuracy: 0.6716\n",
      "Validation Loss: 0.6884, Validation Accuracy: 0.6154\n",
      "Epoch [33/250], Loss: 0.6597, Accuracy: 0.6657\n",
      "Validation Loss: 0.6805, Validation Accuracy: 0.6154\n",
      "Epoch [34/250], Loss: 0.6346, Accuracy: 0.6746\n",
      "Validation Loss: 0.6943, Validation Accuracy: 0.6154\n",
      "Epoch [35/250], Loss: 0.6277, Accuracy: 0.6864\n",
      "Validation Loss: 0.6894, Validation Accuracy: 0.6213\n",
      "Epoch [36/250], Loss: 0.6652, Accuracy: 0.6716\n",
      "Validation Loss: 0.6794, Validation Accuracy: 0.6213\n",
      "Epoch [37/250], Loss: 0.6324, Accuracy: 0.6775\n",
      "Validation Loss: 0.7121, Validation Accuracy: 0.6154\n",
      "Epoch [38/250], Loss: 0.6342, Accuracy: 0.6775\n",
      "Validation Loss: 0.6955, Validation Accuracy: 0.6154\n",
      "Epoch [39/250], Loss: 0.6438, Accuracy: 0.6834\n",
      "Validation Loss: 0.7072, Validation Accuracy: 0.6213\n",
      "Epoch [40/250], Loss: 0.6546, Accuracy: 0.7041\n",
      "Validation Loss: 0.6804, Validation Accuracy: 0.6154\n",
      "Epoch [41/250], Loss: 0.6692, Accuracy: 0.6834\n",
      "Validation Loss: 0.6705, Validation Accuracy: 0.6154\n",
      "Epoch [42/250], Loss: 0.6422, Accuracy: 0.6657\n",
      "Validation Loss: 0.6713, Validation Accuracy: 0.6154\n",
      "Epoch [43/250], Loss: 0.6324, Accuracy: 0.6805\n",
      "Validation Loss: 0.6959, Validation Accuracy: 0.6154\n",
      "Epoch [44/250], Loss: 0.6383, Accuracy: 0.6923\n",
      "Validation Loss: 0.7252, Validation Accuracy: 0.6154\n",
      "Epoch [45/250], Loss: 0.6537, Accuracy: 0.6834\n",
      "Validation Loss: 0.6961, Validation Accuracy: 0.6154\n",
      "Epoch [46/250], Loss: 0.6505, Accuracy: 0.6864\n",
      "Validation Loss: 0.6791, Validation Accuracy: 0.6154\n",
      "Epoch [47/250], Loss: 0.6391, Accuracy: 0.6805\n",
      "Validation Loss: 0.6843, Validation Accuracy: 0.6154\n",
      "Epoch [48/250], Loss: 0.6045, Accuracy: 0.6923\n",
      "Validation Loss: 0.7018, Validation Accuracy: 0.6154\n",
      "Epoch [49/250], Loss: 0.6409, Accuracy: 0.7012\n",
      "Validation Loss: 0.7054, Validation Accuracy: 0.6154\n",
      "Epoch [50/250], Loss: 0.6465, Accuracy: 0.6923\n",
      "Validation Loss: 0.6981, Validation Accuracy: 0.6154\n",
      "Epoch [51/250], Loss: 0.6773, Accuracy: 0.6893\n",
      "Validation Loss: 0.6755, Validation Accuracy: 0.6154\n",
      "Epoch [52/250], Loss: 0.6301, Accuracy: 0.6716\n",
      "Validation Loss: 0.6824, Validation Accuracy: 0.6154\n",
      "Epoch [53/250], Loss: 0.6508, Accuracy: 0.6834\n",
      "Validation Loss: 0.6904, Validation Accuracy: 0.6154\n",
      "Epoch [54/250], Loss: 0.6497, Accuracy: 0.6864\n",
      "Validation Loss: 0.6888, Validation Accuracy: 0.6154\n",
      "Epoch [55/250], Loss: 0.6398, Accuracy: 0.6982\n",
      "Validation Loss: 0.6830, Validation Accuracy: 0.6154\n",
      "Epoch [56/250], Loss: 0.6085, Accuracy: 0.6953\n",
      "Validation Loss: 0.6801, Validation Accuracy: 0.6154\n",
      "Epoch [57/250], Loss: 0.6221, Accuracy: 0.7071\n",
      "Validation Loss: 0.6795, Validation Accuracy: 0.6154\n",
      "Epoch [58/250], Loss: 0.6123, Accuracy: 0.6893\n",
      "Validation Loss: 0.6811, Validation Accuracy: 0.6213\n",
      "Epoch [59/250], Loss: 0.6480, Accuracy: 0.6686\n",
      "Validation Loss: 0.6878, Validation Accuracy: 0.6213\n",
      "Epoch [60/250], Loss: 0.6333, Accuracy: 0.6923\n",
      "Validation Loss: 0.6848, Validation Accuracy: 0.6213\n",
      "Epoch [61/250], Loss: 0.6061, Accuracy: 0.6923\n",
      "Validation Loss: 0.6970, Validation Accuracy: 0.6213\n",
      "Epoch [62/250], Loss: 0.6232, Accuracy: 0.6864\n",
      "Validation Loss: 0.6946, Validation Accuracy: 0.6213\n",
      "Epoch [63/250], Loss: 0.6291, Accuracy: 0.6982\n",
      "Validation Loss: 0.6733, Validation Accuracy: 0.6213\n",
      "Epoch [64/250], Loss: 0.6361, Accuracy: 0.6805\n",
      "Validation Loss: 0.6686, Validation Accuracy: 0.6272\n",
      "Epoch [65/250], Loss: 0.6423, Accuracy: 0.6864\n",
      "Validation Loss: 0.6689, Validation Accuracy: 0.6272\n",
      "Epoch [66/250], Loss: 0.6536, Accuracy: 0.6746\n",
      "Validation Loss: 0.6817, Validation Accuracy: 0.6213\n",
      "Epoch [67/250], Loss: 0.6121, Accuracy: 0.6775\n",
      "Validation Loss: 0.6990, Validation Accuracy: 0.6213\n",
      "Epoch [68/250], Loss: 0.6215, Accuracy: 0.6893\n",
      "Validation Loss: 0.7184, Validation Accuracy: 0.6154\n",
      "Epoch [69/250], Loss: 0.6722, Accuracy: 0.7041\n",
      "Validation Loss: 0.6802, Validation Accuracy: 0.6272\n",
      "Epoch [70/250], Loss: 0.6393, Accuracy: 0.6834\n",
      "Validation Loss: 0.6765, Validation Accuracy: 0.6213\n",
      "Epoch [71/250], Loss: 0.6661, Accuracy: 0.6834\n",
      "Validation Loss: 0.6902, Validation Accuracy: 0.6213\n",
      "Epoch [72/250], Loss: 0.6285, Accuracy: 0.6953\n",
      "Validation Loss: 0.7018, Validation Accuracy: 0.6213\n",
      "Epoch [73/250], Loss: 0.6310, Accuracy: 0.6716\n",
      "Validation Loss: 0.6980, Validation Accuracy: 0.6154\n",
      "Epoch [74/250], Loss: 0.6817, Accuracy: 0.6805\n",
      "Validation Loss: 0.6815, Validation Accuracy: 0.6154\n",
      "Epoch [75/250], Loss: 0.6290, Accuracy: 0.6775\n",
      "Validation Loss: 0.6816, Validation Accuracy: 0.6213\n",
      "Epoch [76/250], Loss: 0.6074, Accuracy: 0.7012\n",
      "Validation Loss: 0.6959, Validation Accuracy: 0.6213\n",
      "Epoch [77/250], Loss: 0.6388, Accuracy: 0.6893\n",
      "Validation Loss: 0.6751, Validation Accuracy: 0.6213\n",
      "Epoch [78/250], Loss: 0.6026, Accuracy: 0.7041\n",
      "Validation Loss: 0.6877, Validation Accuracy: 0.6213\n",
      "Epoch [79/250], Loss: 0.6289, Accuracy: 0.6923\n",
      "Validation Loss: 0.6825, Validation Accuracy: 0.6213\n",
      "Epoch [80/250], Loss: 0.6396, Accuracy: 0.6775\n",
      "Validation Loss: 0.6895, Validation Accuracy: 0.6213\n",
      "Epoch [81/250], Loss: 0.6194, Accuracy: 0.7041\n",
      "Validation Loss: 0.7115, Validation Accuracy: 0.6213\n",
      "Epoch [82/250], Loss: 0.6082, Accuracy: 0.6953\n",
      "Validation Loss: 0.7135, Validation Accuracy: 0.6272\n",
      "Epoch [83/250], Loss: 0.6551, Accuracy: 0.6982\n",
      "Validation Loss: 0.7193, Validation Accuracy: 0.6272\n",
      "Epoch [84/250], Loss: 0.6122, Accuracy: 0.7130\n",
      "Validation Loss: 0.7128, Validation Accuracy: 0.6213\n",
      "Epoch [85/250], Loss: 0.6324, Accuracy: 0.6893\n",
      "Validation Loss: 0.7138, Validation Accuracy: 0.6213\n",
      "Epoch [86/250], Loss: 0.6336, Accuracy: 0.6893\n",
      "Validation Loss: 0.7005, Validation Accuracy: 0.6213\n",
      "Epoch [87/250], Loss: 0.6356, Accuracy: 0.6953\n",
      "Validation Loss: 0.6736, Validation Accuracy: 0.6213\n",
      "Epoch [88/250], Loss: 0.6096, Accuracy: 0.6982\n",
      "Validation Loss: 0.6855, Validation Accuracy: 0.6213\n",
      "Epoch [89/250], Loss: 0.5928, Accuracy: 0.6923\n",
      "Validation Loss: 0.7319, Validation Accuracy: 0.6213\n",
      "Epoch [90/250], Loss: 0.6417, Accuracy: 0.6893\n",
      "Validation Loss: 0.7091, Validation Accuracy: 0.6213\n",
      "Epoch [91/250], Loss: 0.6446, Accuracy: 0.6834\n",
      "Validation Loss: 0.7422, Validation Accuracy: 0.6213\n",
      "Epoch [92/250], Loss: 0.6282, Accuracy: 0.6953\n",
      "Validation Loss: 0.7789, Validation Accuracy: 0.6213\n",
      "Epoch [93/250], Loss: 0.6510, Accuracy: 0.6923\n",
      "Validation Loss: 0.8080, Validation Accuracy: 0.6213\n",
      "Epoch [94/250], Loss: 0.6216, Accuracy: 0.6953\n",
      "Validation Loss: 0.7228, Validation Accuracy: 0.6213\n",
      "Epoch [95/250], Loss: 0.6391, Accuracy: 0.6953\n",
      "Validation Loss: 0.7469, Validation Accuracy: 0.6272\n",
      "Epoch [96/250], Loss: 0.6180, Accuracy: 0.6923\n",
      "Validation Loss: 0.7220, Validation Accuracy: 0.6213\n",
      "Epoch [97/250], Loss: 0.6235, Accuracy: 0.6893\n",
      "Validation Loss: 0.7022, Validation Accuracy: 0.6213\n",
      "Epoch [98/250], Loss: 0.6336, Accuracy: 0.7071\n",
      "Validation Loss: 0.6837, Validation Accuracy: 0.6272\n",
      "Epoch [99/250], Loss: 0.6117, Accuracy: 0.6657\n",
      "Validation Loss: 0.6911, Validation Accuracy: 0.6272\n",
      "Epoch [100/250], Loss: 0.5954, Accuracy: 0.7071\n",
      "Validation Loss: 0.7078, Validation Accuracy: 0.6213\n",
      "Epoch [101/250], Loss: 0.6360, Accuracy: 0.6805\n",
      "Validation Loss: 0.6969, Validation Accuracy: 0.6213\n",
      "Epoch [102/250], Loss: 0.6352, Accuracy: 0.6953\n",
      "Validation Loss: 0.6893, Validation Accuracy: 0.6213\n",
      "Epoch [103/250], Loss: 0.6377, Accuracy: 0.6686\n",
      "Validation Loss: 0.7114, Validation Accuracy: 0.6213\n",
      "Epoch [104/250], Loss: 0.6124, Accuracy: 0.6923\n",
      "Validation Loss: 0.7068, Validation Accuracy: 0.6213\n",
      "Epoch [105/250], Loss: 0.6134, Accuracy: 0.6982\n",
      "Validation Loss: 0.6936, Validation Accuracy: 0.6213\n",
      "Epoch [106/250], Loss: 0.6332, Accuracy: 0.6982\n",
      "Validation Loss: 0.6841, Validation Accuracy: 0.6154\n",
      "Epoch [107/250], Loss: 0.6120, Accuracy: 0.6893\n",
      "Validation Loss: 0.6632, Validation Accuracy: 0.6213\n",
      "Epoch [108/250], Loss: 0.6121, Accuracy: 0.6923\n",
      "Validation Loss: 0.6688, Validation Accuracy: 0.6154\n",
      "Epoch [109/250], Loss: 0.6310, Accuracy: 0.7041\n",
      "Validation Loss: 0.6653, Validation Accuracy: 0.6154\n",
      "Epoch [110/250], Loss: 0.6312, Accuracy: 0.6864\n",
      "Validation Loss: 0.6630, Validation Accuracy: 0.6213\n",
      "Epoch [111/250], Loss: 0.6186, Accuracy: 0.6982\n",
      "Validation Loss: 0.6687, Validation Accuracy: 0.6213\n",
      "Epoch [112/250], Loss: 0.6609, Accuracy: 0.7041\n",
      "Validation Loss: 0.6597, Validation Accuracy: 0.6213\n",
      "Epoch [113/250], Loss: 0.6353, Accuracy: 0.6805\n",
      "Validation Loss: 0.7390, Validation Accuracy: 0.6213\n",
      "Epoch [114/250], Loss: 0.5895, Accuracy: 0.7160\n",
      "Validation Loss: 0.6943, Validation Accuracy: 0.6213\n",
      "Epoch [115/250], Loss: 0.6286, Accuracy: 0.6982\n",
      "Validation Loss: 0.6810, Validation Accuracy: 0.6154\n",
      "Epoch [116/250], Loss: 0.6136, Accuracy: 0.7012\n",
      "Validation Loss: 0.6722, Validation Accuracy: 0.6154\n",
      "Epoch [117/250], Loss: 0.6238, Accuracy: 0.6893\n",
      "Validation Loss: 0.6719, Validation Accuracy: 0.6154\n",
      "Epoch [118/250], Loss: 0.6097, Accuracy: 0.6923\n",
      "Validation Loss: 0.6683, Validation Accuracy: 0.6213\n",
      "Epoch [119/250], Loss: 0.6387, Accuracy: 0.6953\n",
      "Validation Loss: 0.6617, Validation Accuracy: 0.6213\n",
      "Epoch [120/250], Loss: 0.5867, Accuracy: 0.6982\n",
      "Validation Loss: 0.6874, Validation Accuracy: 0.6213\n",
      "Epoch [121/250], Loss: 0.6296, Accuracy: 0.7012\n",
      "Validation Loss: 0.6747, Validation Accuracy: 0.6213\n",
      "Epoch [122/250], Loss: 0.6087, Accuracy: 0.7012\n",
      "Validation Loss: 0.6749, Validation Accuracy: 0.6213\n",
      "Epoch [123/250], Loss: 0.6129, Accuracy: 0.6982\n",
      "Validation Loss: 0.6902, Validation Accuracy: 0.6213\n",
      "Epoch [124/250], Loss: 0.6296, Accuracy: 0.7041\n",
      "Validation Loss: 0.6797, Validation Accuracy: 0.6213\n",
      "Epoch [125/250], Loss: 0.6393, Accuracy: 0.6864\n",
      "Validation Loss: 0.6715, Validation Accuracy: 0.6213\n",
      "Epoch [126/250], Loss: 0.6218, Accuracy: 0.6923\n",
      "Validation Loss: 0.6858, Validation Accuracy: 0.6213\n",
      "Epoch [127/250], Loss: 0.6281, Accuracy: 0.6982\n",
      "Validation Loss: 0.6656, Validation Accuracy: 0.6213\n",
      "Epoch [128/250], Loss: 0.6481, Accuracy: 0.6923\n",
      "Validation Loss: 0.6616, Validation Accuracy: 0.6213\n",
      "Epoch [129/250], Loss: 0.6208, Accuracy: 0.6953\n",
      "Validation Loss: 0.7060, Validation Accuracy: 0.6213\n",
      "Epoch [130/250], Loss: 0.6631, Accuracy: 0.6834\n",
      "Validation Loss: 0.6924, Validation Accuracy: 0.6213\n",
      "Epoch [131/250], Loss: 0.6240, Accuracy: 0.6893\n",
      "Validation Loss: 0.7642, Validation Accuracy: 0.6213\n",
      "Epoch [132/250], Loss: 0.6159, Accuracy: 0.6923\n",
      "Validation Loss: 0.7947, Validation Accuracy: 0.6213\n",
      "Epoch [133/250], Loss: 0.6112, Accuracy: 0.6982\n",
      "Validation Loss: 0.7032, Validation Accuracy: 0.6213\n",
      "Epoch [134/250], Loss: 0.6108, Accuracy: 0.7041\n",
      "Validation Loss: 0.6762, Validation Accuracy: 0.6213\n",
      "Epoch [135/250], Loss: 0.6239, Accuracy: 0.6923\n",
      "Validation Loss: 0.6651, Validation Accuracy: 0.6213\n",
      "Epoch [136/250], Loss: 0.6247, Accuracy: 0.6923\n",
      "Validation Loss: 0.7527, Validation Accuracy: 0.6213\n",
      "Epoch [137/250], Loss: 0.6297, Accuracy: 0.6982\n",
      "Validation Loss: 0.9257, Validation Accuracy: 0.6213\n",
      "Epoch [138/250], Loss: 0.6014, Accuracy: 0.7012\n",
      "Validation Loss: 0.8332, Validation Accuracy: 0.6213\n",
      "Epoch [139/250], Loss: 0.6239, Accuracy: 0.6953\n",
      "Validation Loss: 0.6931, Validation Accuracy: 0.6213\n",
      "Epoch [140/250], Loss: 0.6187, Accuracy: 0.6953\n",
      "Validation Loss: 0.8300, Validation Accuracy: 0.6213\n",
      "Epoch [141/250], Loss: 0.5869, Accuracy: 0.6893\n",
      "Validation Loss: 0.7307, Validation Accuracy: 0.6213\n",
      "Epoch [142/250], Loss: 0.6084, Accuracy: 0.6982\n",
      "Validation Loss: 0.8147, Validation Accuracy: 0.6213\n",
      "Epoch [143/250], Loss: 0.6108, Accuracy: 0.7012\n",
      "Validation Loss: 0.6987, Validation Accuracy: 0.6213\n",
      "Epoch [144/250], Loss: 0.6298, Accuracy: 0.6923\n",
      "Validation Loss: 0.6573, Validation Accuracy: 0.6213\n",
      "Epoch [145/250], Loss: 0.6075, Accuracy: 0.6982\n",
      "Validation Loss: 0.6662, Validation Accuracy: 0.6213\n",
      "Epoch [146/250], Loss: 0.6178, Accuracy: 0.6953\n",
      "Validation Loss: 0.7475, Validation Accuracy: 0.6213\n",
      "Epoch [147/250], Loss: 0.6528, Accuracy: 0.6982\n",
      "Validation Loss: 0.7056, Validation Accuracy: 0.6213\n",
      "Epoch [148/250], Loss: 0.6189, Accuracy: 0.6686\n",
      "Validation Loss: 0.6618, Validation Accuracy: 0.6213\n",
      "Epoch [149/250], Loss: 0.6095, Accuracy: 0.7012\n",
      "Validation Loss: 0.6609, Validation Accuracy: 0.6213\n",
      "Epoch [150/250], Loss: 0.6101, Accuracy: 0.6893\n",
      "Validation Loss: 0.6672, Validation Accuracy: 0.6213\n",
      "Epoch [151/250], Loss: 0.6103, Accuracy: 0.7012\n",
      "Validation Loss: 0.6592, Validation Accuracy: 0.6213\n",
      "Epoch [152/250], Loss: 0.5950, Accuracy: 0.7071\n",
      "Validation Loss: 0.6708, Validation Accuracy: 0.6213\n",
      "Epoch [153/250], Loss: 0.6277, Accuracy: 0.7012\n",
      "Validation Loss: 0.8061, Validation Accuracy: 0.6213\n",
      "Epoch [154/250], Loss: 0.5853, Accuracy: 0.7041\n",
      "Validation Loss: 0.8965, Validation Accuracy: 0.6154\n",
      "Epoch [155/250], Loss: 0.6176, Accuracy: 0.7041\n",
      "Validation Loss: 0.7089, Validation Accuracy: 0.6213\n",
      "Epoch [156/250], Loss: 0.6255, Accuracy: 0.6746\n",
      "Validation Loss: 0.6670, Validation Accuracy: 0.6213\n",
      "Epoch [157/250], Loss: 0.5844, Accuracy: 0.6834\n",
      "Validation Loss: 0.7106, Validation Accuracy: 0.6154\n",
      "Epoch [158/250], Loss: 0.6014, Accuracy: 0.7041\n",
      "Validation Loss: 0.6911, Validation Accuracy: 0.6213\n",
      "Epoch [159/250], Loss: 0.5851, Accuracy: 0.6982\n",
      "Validation Loss: 0.6705, Validation Accuracy: 0.6213\n",
      "Epoch [160/250], Loss: 0.6056, Accuracy: 0.6953\n",
      "Validation Loss: 0.6622, Validation Accuracy: 0.6154\n",
      "Epoch [161/250], Loss: 0.6113, Accuracy: 0.6923\n",
      "Validation Loss: 0.6620, Validation Accuracy: 0.6213\n",
      "Epoch [162/250], Loss: 0.5980, Accuracy: 0.7012\n",
      "Validation Loss: 0.6576, Validation Accuracy: 0.6213\n",
      "Epoch [163/250], Loss: 0.6093, Accuracy: 0.6953\n",
      "Validation Loss: 1.1856, Validation Accuracy: 0.6213\n",
      "Epoch [164/250], Loss: 0.6078, Accuracy: 0.7012\n",
      "Validation Loss: 1.2020, Validation Accuracy: 0.6213\n",
      "Epoch [165/250], Loss: 0.6174, Accuracy: 0.6893\n",
      "Validation Loss: 0.9226, Validation Accuracy: 0.6213\n",
      "Epoch [166/250], Loss: 0.6162, Accuracy: 0.6982\n",
      "Validation Loss: 0.7682, Validation Accuracy: 0.6213\n",
      "Epoch [167/250], Loss: 0.5998, Accuracy: 0.7071\n",
      "Validation Loss: 0.9090, Validation Accuracy: 0.6213\n",
      "Epoch [168/250], Loss: 0.6017, Accuracy: 0.6893\n",
      "Validation Loss: 0.6716, Validation Accuracy: 0.6213\n",
      "Epoch [169/250], Loss: 0.6127, Accuracy: 0.6982\n",
      "Validation Loss: 0.6632, Validation Accuracy: 0.6213\n",
      "Epoch [170/250], Loss: 0.6126, Accuracy: 0.7041\n",
      "Validation Loss: 0.6646, Validation Accuracy: 0.6213\n",
      "Epoch [171/250], Loss: 0.5922, Accuracy: 0.6953\n",
      "Validation Loss: 0.6581, Validation Accuracy: 0.6213\n",
      "Epoch [172/250], Loss: 0.6077, Accuracy: 0.6923\n",
      "Validation Loss: 0.6543, Validation Accuracy: 0.6213\n",
      "Epoch [173/250], Loss: 0.6357, Accuracy: 0.6982\n",
      "Validation Loss: 0.6562, Validation Accuracy: 0.6213\n",
      "Epoch [174/250], Loss: 0.6244, Accuracy: 0.6893\n",
      "Validation Loss: 0.6555, Validation Accuracy: 0.6154\n",
      "Epoch [175/250], Loss: 0.5984, Accuracy: 0.7041\n",
      "Validation Loss: 0.6748, Validation Accuracy: 0.6213\n",
      "Epoch [176/250], Loss: 0.6041, Accuracy: 0.6982\n",
      "Validation Loss: 0.6732, Validation Accuracy: 0.6213\n",
      "Epoch [177/250], Loss: 0.5935, Accuracy: 0.6953\n",
      "Validation Loss: 0.6610, Validation Accuracy: 0.6213\n",
      "Epoch [178/250], Loss: 0.6231, Accuracy: 0.7012\n",
      "Validation Loss: 0.6688, Validation Accuracy: 0.6213\n",
      "Epoch [179/250], Loss: 0.6130, Accuracy: 0.6746\n",
      "Validation Loss: 1.1033, Validation Accuracy: 0.6213\n",
      "Epoch [180/250], Loss: 0.6035, Accuracy: 0.7041\n",
      "Validation Loss: 0.7328, Validation Accuracy: 0.6213\n",
      "Epoch [181/250], Loss: 0.6062, Accuracy: 0.7012\n",
      "Validation Loss: 0.6727, Validation Accuracy: 0.6213\n",
      "Epoch [182/250], Loss: 0.6058, Accuracy: 0.6982\n",
      "Validation Loss: 0.6571, Validation Accuracy: 0.6213\n",
      "Epoch [183/250], Loss: 0.5892, Accuracy: 0.6893\n",
      "Validation Loss: 0.6600, Validation Accuracy: 0.6213\n",
      "Epoch [184/250], Loss: 0.6128, Accuracy: 0.6864\n",
      "Validation Loss: 1.1350, Validation Accuracy: 0.6213\n",
      "Epoch [185/250], Loss: 0.5788, Accuracy: 0.7041\n",
      "Validation Loss: 1.1978, Validation Accuracy: 0.6213\n",
      "Epoch [186/250], Loss: 0.5892, Accuracy: 0.7071\n",
      "Validation Loss: 1.2547, Validation Accuracy: 0.6213\n",
      "Epoch [187/250], Loss: 0.6043, Accuracy: 0.6923\n",
      "Validation Loss: 0.6609, Validation Accuracy: 0.6213\n",
      "Epoch [188/250], Loss: 0.5957, Accuracy: 0.7012\n",
      "Validation Loss: 0.6537, Validation Accuracy: 0.6213\n",
      "Epoch [189/250], Loss: 0.5699, Accuracy: 0.7101\n",
      "Validation Loss: 1.0747, Validation Accuracy: 0.6213\n",
      "Epoch [190/250], Loss: 0.5986, Accuracy: 0.6953\n",
      "Validation Loss: 1.5127, Validation Accuracy: 0.6213\n",
      "Epoch [194/250], Loss: 0.2383, Accuracy: 0.9254\n",
      "Validation Loss: 1.0866, Validation Accuracy: 0.7193\n",
      "Epoch [195/250], Loss: 0.2266, Accuracy: 0.9167\n",
      "Validation Loss: 1.8203, Validation Accuracy: 0.6316\n",
      "Epoch [196/250], Loss: 0.2227, Accuracy: 0.9254\n",
      "Validation Loss: 1.7891, Validation Accuracy: 0.6404\n",
      "Epoch [197/250], Loss: 0.1910, Accuracy: 0.9342\n",
      "Validation Loss: 1.7759, Validation Accuracy: 0.6140\n",
      "Epoch [198/250], Loss: 0.2896, Accuracy: 0.8640\n",
      "Validation Loss: 2.3005, Validation Accuracy: 0.5000\n",
      "Epoch [199/250], Loss: 0.2491, Accuracy: 0.9123\n",
      "Validation Loss: 1.5149, Validation Accuracy: 0.6404\n",
      "Epoch [200/250], Loss: 0.1419, Accuracy: 0.9693\n",
      "Validation Loss: 1.5642, Validation Accuracy: 0.6404\n",
      "Epoch [201/250], Loss: 0.2769, Accuracy: 0.9079\n",
      "Validation Loss: 2.1949, Validation Accuracy: 0.5000\n",
      "Epoch [202/250], Loss: 0.3107, Accuracy: 0.8816\n",
      "Validation Loss: 2.1268, Validation Accuracy: 0.5000\n",
      "Epoch [203/250], Loss: 0.1937, Accuracy: 0.9035\n",
      "Validation Loss: 2.9568, Validation Accuracy: 0.5000\n",
      "Epoch [204/250], Loss: 0.2319, Accuracy: 0.9123\n",
      "Validation Loss: 2.4698, Validation Accuracy: 0.5000\n",
      "Epoch [205/250], Loss: 0.1456, Accuracy: 0.9693\n",
      "Validation Loss: 2.8578, Validation Accuracy: 0.5000\n",
      "Epoch [206/250], Loss: 0.1874, Accuracy: 0.9167\n",
      "Validation Loss: 0.4979, Validation Accuracy: 0.8333\n",
      "Epoch [207/250], Loss: 0.1607, Accuracy: 0.9386\n",
      "Validation Loss: 1.1680, Validation Accuracy: 0.6404\n",
      "Epoch [208/250], Loss: 0.2082, Accuracy: 0.9167\n",
      "Validation Loss: 1.3918, Validation Accuracy: 0.5614\n",
      "Epoch [209/250], Loss: 0.2165, Accuracy: 0.9211\n",
      "Validation Loss: 2.3817, Validation Accuracy: 0.5000\n",
      "Epoch [210/250], Loss: 0.1674, Accuracy: 0.9342\n",
      "Validation Loss: 2.7407, Validation Accuracy: 0.5000\n",
      "Epoch [211/250], Loss: 0.2605, Accuracy: 0.9035\n",
      "Validation Loss: 2.9885, Validation Accuracy: 0.5000\n",
      "Epoch [212/250], Loss: 0.2215, Accuracy: 0.9254\n",
      "Validation Loss: 0.5845, Validation Accuracy: 0.8421\n",
      "Epoch [213/250], Loss: 0.1959, Accuracy: 0.9298\n",
      "Validation Loss: 3.1285, Validation Accuracy: 0.5000\n",
      "Epoch [214/250], Loss: 0.2142, Accuracy: 0.8816\n",
      "Validation Loss: 1.4709, Validation Accuracy: 0.6491\n",
      "Epoch [215/250], Loss: 0.1520, Accuracy: 0.9430\n",
      "Validation Loss: 3.0607, Validation Accuracy: 0.5000\n",
      "Epoch [216/250], Loss: 0.1683, Accuracy: 0.9254\n",
      "Validation Loss: 0.5030, Validation Accuracy: 0.8684\n",
      "Epoch [217/250], Loss: 0.1831, Accuracy: 0.9254\n",
      "Validation Loss: 1.4931, Validation Accuracy: 0.6404\n",
      "Epoch [218/250], Loss: 0.1746, Accuracy: 0.9254\n",
      "Validation Loss: 0.6084, Validation Accuracy: 0.8333\n",
      "Epoch [219/250], Loss: 0.2077, Accuracy: 0.9254\n",
      "Validation Loss: 3.4480, Validation Accuracy: 0.5000\n",
      "Epoch [220/250], Loss: 0.2163, Accuracy: 0.9167\n",
      "Validation Loss: 0.5099, Validation Accuracy: 0.8596\n",
      "Epoch [221/250], Loss: 0.2250, Accuracy: 0.9123\n",
      "Validation Loss: 1.3420, Validation Accuracy: 0.7544\n",
      "Epoch [222/250], Loss: 0.1715, Accuracy: 0.9342\n",
      "Validation Loss: 1.3955, Validation Accuracy: 0.7456\n",
      "Epoch [223/250], Loss: 0.1729, Accuracy: 0.9298\n",
      "Validation Loss: 2.4704, Validation Accuracy: 0.6140\n",
      "Epoch [224/250], Loss: 0.1774, Accuracy: 0.9342\n",
      "Validation Loss: 0.9494, Validation Accuracy: 0.8070\n",
      "Epoch [225/250], Loss: 0.1474, Accuracy: 0.9386\n",
      "Validation Loss: 1.0352, Validation Accuracy: 0.7807\n",
      "Epoch [226/250], Loss: 0.1251, Accuracy: 0.9474\n",
      "Validation Loss: 0.6603, Validation Accuracy: 0.8421\n",
      "Epoch [227/250], Loss: 0.1931, Accuracy: 0.9254\n",
      "Validation Loss: 2.0810, Validation Accuracy: 0.6667\n",
      "Epoch [228/250], Loss: 0.2124, Accuracy: 0.9474\n",
      "Validation Loss: 0.4456, Validation Accuracy: 0.8596\n",
      "Epoch [229/250], Loss: 0.2063, Accuracy: 0.9298\n",
      "Validation Loss: 1.2104, Validation Accuracy: 0.7456\n",
      "Epoch [230/250], Loss: 0.1688, Accuracy: 0.9386\n",
      "Validation Loss: 3.1845, Validation Accuracy: 0.5789\n",
      "Epoch [231/250], Loss: 0.1749, Accuracy: 0.9254\n",
      "Validation Loss: 2.7392, Validation Accuracy: 0.5614\n",
      "Epoch [232/250], Loss: 0.2045, Accuracy: 0.9079\n",
      "Validation Loss: 1.4956, Validation Accuracy: 0.6579\n",
      "Epoch [233/250], Loss: 0.1396, Accuracy: 0.9430\n",
      "Validation Loss: 1.5395, Validation Accuracy: 0.6842\n",
      "Epoch [234/250], Loss: 0.1533, Accuracy: 0.9518\n",
      "Validation Loss: 0.5190, Validation Accuracy: 0.8596\n",
      "Epoch [235/250], Loss: 0.2054, Accuracy: 0.9254\n",
      "Validation Loss: 0.8262, Validation Accuracy: 0.8860\n",
      "Epoch [236/250], Loss: 0.1771, Accuracy: 0.9123\n",
      "Validation Loss: 0.8693, Validation Accuracy: 0.8246\n",
      "Epoch [237/250], Loss: 0.1128, Accuracy: 0.9518\n",
      "Validation Loss: 0.6796, Validation Accuracy: 0.8684\n",
      "Epoch [238/250], Loss: 0.2104, Accuracy: 0.9342\n",
      "Validation Loss: 0.6572, Validation Accuracy: 0.8596\n",
      "Epoch [239/250], Loss: 0.2386, Accuracy: 0.9079\n",
      "Validation Loss: 1.3378, Validation Accuracy: 0.7456\n",
      "Epoch [240/250], Loss: 0.1520, Accuracy: 0.9298\n",
      "Validation Loss: 0.6298, Validation Accuracy: 0.8596\n",
      "Epoch [241/250], Loss: 0.1494, Accuracy: 0.9254\n",
      "Validation Loss: 3.6857, Validation Accuracy: 0.5175\n",
      "Epoch [242/250], Loss: 0.1477, Accuracy: 0.9386\n",
      "Validation Loss: 1.2961, Validation Accuracy: 0.7456\n",
      "Epoch [243/250], Loss: 0.1672, Accuracy: 0.9474\n",
      "Validation Loss: 0.6430, Validation Accuracy: 0.8772\n",
      "Epoch [244/250], Loss: 0.1061, Accuracy: 0.9518\n",
      "Validation Loss: 2.8780, Validation Accuracy: 0.5877\n",
      "Epoch [245/250], Loss: 0.1711, Accuracy: 0.9386\n",
      "Validation Loss: 1.5771, Validation Accuracy: 0.7544\n",
      "Epoch [246/250], Loss: 0.2509, Accuracy: 0.8991\n",
      "Validation Loss: 1.0503, Validation Accuracy: 0.7368\n",
      "Epoch [247/250], Loss: 0.3039, Accuracy: 0.8816\n",
      "Validation Loss: 3.1922, Validation Accuracy: 0.5175\n",
      "Epoch [248/250], Loss: 0.1974, Accuracy: 0.9211\n",
      "Validation Loss: 0.7562, Validation Accuracy: 0.8509\n",
      "Epoch [249/250], Loss: 0.1540, Accuracy: 0.9386\n",
      "Validation Loss: 0.4189, Validation Accuracy: 0.8860\n",
      "Epoch [250/250], Loss: 0.1747, Accuracy: 0.9167\n",
      "Validation Loss: 2.4006, Validation Accuracy: 0.6316\n",
      "Test Loss: 2.1632\n",
      "Test Accuracy: 0.6930\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 112\n",
      "label 1 is 23\n",
      "label 2 is 121\n",
      "label 3 is 86\n",
      "Not setting metadata\n",
      "342 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (285, 8, 325)\n",
      "285 train samples\n",
      "142 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.25, 0: 0.8333333333333334}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.2575, Accuracy: 0.3825\n",
      "Validation Loss: 0.8677, Validation Accuracy: 0.5594\n",
      "Epoch [2/250], Loss: 0.8830, Accuracy: 0.6070\n",
      "Validation Loss: 0.7802, Validation Accuracy: 0.5594\n",
      "Epoch [3/250], Loss: 0.8079, Accuracy: 0.5684\n",
      "Validation Loss: 0.7650, Validation Accuracy: 0.5594\n",
      "Epoch [4/250], Loss: 0.7734, Accuracy: 0.5404\n",
      "Validation Loss: 0.7524, Validation Accuracy: 0.5594\n",
      "Epoch [5/250], Loss: 0.7036, Accuracy: 0.6105\n",
      "Validation Loss: 0.7376, Validation Accuracy: 0.5594\n",
      "Epoch [6/250], Loss: 0.7333, Accuracy: 0.5579\n",
      "Validation Loss: 0.7417, Validation Accuracy: 0.5594\n",
      "Epoch [7/250], Loss: 0.7050, Accuracy: 0.6000\n",
      "Validation Loss: 0.7664, Validation Accuracy: 0.5594\n",
      "Epoch [8/250], Loss: 0.7328, Accuracy: 0.5965\n",
      "Validation Loss: 0.7328, Validation Accuracy: 0.5594\n",
      "Epoch [9/250], Loss: 0.6968, Accuracy: 0.5860\n",
      "Validation Loss: 0.8033, Validation Accuracy: 0.5594\n",
      "Epoch [10/250], Loss: 0.7069, Accuracy: 0.5789\n",
      "Validation Loss: 0.7819, Validation Accuracy: 0.5594\n",
      "Epoch [11/250], Loss: 0.7044, Accuracy: 0.6105\n",
      "Validation Loss: 0.7031, Validation Accuracy: 0.5594\n",
      "Epoch [12/250], Loss: 0.6725, Accuracy: 0.6105\n",
      "Validation Loss: 1.0400, Validation Accuracy: 0.5594\n",
      "Epoch [13/250], Loss: 0.6812, Accuracy: 0.6316\n",
      "Validation Loss: 1.1309, Validation Accuracy: 0.5594\n",
      "Epoch [14/250], Loss: 0.5792, Accuracy: 0.7018\n",
      "Validation Loss: 1.0416, Validation Accuracy: 0.4476\n",
      "Epoch [15/250], Loss: 0.4922, Accuracy: 0.7895\n",
      "Validation Loss: 2.3232, Validation Accuracy: 0.4406\n",
      "Epoch [16/250], Loss: 0.5001, Accuracy: 0.7614\n",
      "Validation Loss: 0.8467, Validation Accuracy: 0.5664\n",
      "Epoch [17/250], Loss: 0.5146, Accuracy: 0.7719\n",
      "Validation Loss: 2.3223, Validation Accuracy: 0.4406\n",
      "Epoch [18/250], Loss: 0.5065, Accuracy: 0.8000\n",
      "Validation Loss: 2.4212, Validation Accuracy: 0.4406\n",
      "Epoch [19/250], Loss: 0.4392, Accuracy: 0.8070\n",
      "Validation Loss: 1.6142, Validation Accuracy: 0.5594\n",
      "Epoch [20/250], Loss: 0.3560, Accuracy: 0.8421\n",
      "Validation Loss: 2.0933, Validation Accuracy: 0.4406\n",
      "Epoch [21/250], Loss: 0.4003, Accuracy: 0.8175\n",
      "Validation Loss: 1.1276, Validation Accuracy: 0.4965\n",
      "Epoch [22/250], Loss: 0.3607, Accuracy: 0.8632\n",
      "Validation Loss: 3.3614, Validation Accuracy: 0.5594\n",
      "Epoch [23/250], Loss: 0.3597, Accuracy: 0.8596\n",
      "Validation Loss: 1.7676, Validation Accuracy: 0.5594\n",
      "Epoch [24/250], Loss: 0.3373, Accuracy: 0.8667\n",
      "Validation Loss: 0.4101, Validation Accuracy: 0.8531\n",
      "Epoch [25/250], Loss: 0.4117, Accuracy: 0.8386\n",
      "Validation Loss: 1.7562, Validation Accuracy: 0.5594\n",
      "Epoch [26/250], Loss: 0.3597, Accuracy: 0.8386\n",
      "Validation Loss: 1.0226, Validation Accuracy: 0.6154\n",
      "Epoch [27/250], Loss: 0.3485, Accuracy: 0.8456\n",
      "Validation Loss: 0.4657, Validation Accuracy: 0.7483\n",
      "Epoch [28/250], Loss: 0.3815, Accuracy: 0.8632\n",
      "Validation Loss: 1.6658, Validation Accuracy: 0.4406\n",
      "Epoch [29/250], Loss: 0.3089, Accuracy: 0.8877\n",
      "Validation Loss: 1.8817, Validation Accuracy: 0.4406\n",
      "Epoch [30/250], Loss: 0.3581, Accuracy: 0.8421\n",
      "Validation Loss: 0.4351, Validation Accuracy: 0.7343\n",
      "Epoch [31/250], Loss: 0.3195, Accuracy: 0.8737\n",
      "Validation Loss: 0.3695, Validation Accuracy: 0.8042\n",
      "Epoch [32/250], Loss: 0.4097, Accuracy: 0.8421\n",
      "Validation Loss: 2.0404, Validation Accuracy: 0.4406\n",
      "Epoch [33/250], Loss: 0.3149, Accuracy: 0.8982\n",
      "Validation Loss: 1.4711, Validation Accuracy: 0.4406\n",
      "Epoch [34/250], Loss: 0.2928, Accuracy: 0.8702\n",
      "Validation Loss: 0.3704, Validation Accuracy: 0.8252\n",
      "Epoch [35/250], Loss: 0.2931, Accuracy: 0.8842\n",
      "Validation Loss: 3.3601, Validation Accuracy: 0.5594\n",
      "Epoch [36/250], Loss: 0.3149, Accuracy: 0.8737\n",
      "Validation Loss: 2.6255, Validation Accuracy: 0.5594\n",
      "Epoch [37/250], Loss: 0.3324, Accuracy: 0.8351\n",
      "Validation Loss: 0.4375, Validation Accuracy: 0.7343\n",
      "Epoch [38/250], Loss: 0.3387, Accuracy: 0.8737\n",
      "Validation Loss: 3.5577, Validation Accuracy: 0.5594\n",
      "Epoch [39/250], Loss: 0.3443, Accuracy: 0.8772\n",
      "Validation Loss: 2.6882, Validation Accuracy: 0.4406\n",
      "Epoch [40/250], Loss: 0.3197, Accuracy: 0.8667\n",
      "Validation Loss: 3.1342, Validation Accuracy: 0.5594\n",
      "Epoch [41/250], Loss: 0.3124, Accuracy: 0.8561\n",
      "Validation Loss: 2.4374, Validation Accuracy: 0.4406\n",
      "Epoch [42/250], Loss: 0.2693, Accuracy: 0.8947\n",
      "Validation Loss: 2.1932, Validation Accuracy: 0.5664\n",
      "Epoch [43/250], Loss: 0.3021, Accuracy: 0.8877\n",
      "Validation Loss: 0.3008, Validation Accuracy: 0.9231\n",
      "Epoch [44/250], Loss: 0.2935, Accuracy: 0.8667\n",
      "Validation Loss: 2.8098, Validation Accuracy: 0.5594\n",
      "Epoch [45/250], Loss: 0.3087, Accuracy: 0.8982\n",
      "Validation Loss: 2.3373, Validation Accuracy: 0.4406\n",
      "Epoch [46/250], Loss: 0.2986, Accuracy: 0.8702\n",
      "Validation Loss: 0.8355, Validation Accuracy: 0.6993\n",
      "Epoch [47/250], Loss: 0.3382, Accuracy: 0.8912\n",
      "Validation Loss: 3.0182, Validation Accuracy: 0.5594\n",
      "Epoch [48/250], Loss: 0.2993, Accuracy: 0.8596\n",
      "Validation Loss: 2.6717, Validation Accuracy: 0.4406\n",
      "Epoch [49/250], Loss: 0.2834, Accuracy: 0.8912\n",
      "Validation Loss: 2.8180, Validation Accuracy: 0.5594\n",
      "Epoch [50/250], Loss: 0.2564, Accuracy: 0.8877\n",
      "Validation Loss: 1.2829, Validation Accuracy: 0.6573\n",
      "Epoch [51/250], Loss: 0.3223, Accuracy: 0.8702\n",
      "Validation Loss: 3.3089, Validation Accuracy: 0.4406\n",
      "Epoch [52/250], Loss: 0.2479, Accuracy: 0.8947\n",
      "Validation Loss: 3.1591, Validation Accuracy: 0.5594\n",
      "Epoch [53/250], Loss: 0.3531, Accuracy: 0.8947\n",
      "Validation Loss: 2.9993, Validation Accuracy: 0.4406\n",
      "Epoch [54/250], Loss: 0.2932, Accuracy: 0.8772\n",
      "Validation Loss: 2.5744, Validation Accuracy: 0.4406\n",
      "Epoch [55/250], Loss: 0.3021, Accuracy: 0.8702\n",
      "Validation Loss: 0.3354, Validation Accuracy: 0.8601\n",
      "Epoch [56/250], Loss: 0.2666, Accuracy: 0.8982\n",
      "Validation Loss: 0.3541, Validation Accuracy: 0.8182\n",
      "Epoch [57/250], Loss: 0.2753, Accuracy: 0.8807\n",
      "Validation Loss: 1.4731, Validation Accuracy: 0.5315\n",
      "Epoch [58/250], Loss: 0.1989, Accuracy: 0.9053\n",
      "Validation Loss: 3.6954, Validation Accuracy: 0.5594\n",
      "Epoch [59/250], Loss: 0.2660, Accuracy: 0.8982\n",
      "Validation Loss: 2.6903, Validation Accuracy: 0.4406\n",
      "Epoch [60/250], Loss: 0.2339, Accuracy: 0.8982\n",
      "Validation Loss: 3.6705, Validation Accuracy: 0.5594\n",
      "Epoch [61/250], Loss: 0.2150, Accuracy: 0.9123\n",
      "Validation Loss: 0.3733, Validation Accuracy: 0.8392\n",
      "Epoch [62/250], Loss: 0.3560, Accuracy: 0.8632\n",
      "Validation Loss: 3.0852, Validation Accuracy: 0.4406\n",
      "Epoch [63/250], Loss: 0.2425, Accuracy: 0.8877\n",
      "Validation Loss: 2.2187, Validation Accuracy: 0.5594\n",
      "Epoch [64/250], Loss: 0.2313, Accuracy: 0.8947\n",
      "Validation Loss: 4.1812, Validation Accuracy: 0.5594\n",
      "Epoch [65/250], Loss: 0.2475, Accuracy: 0.8912\n",
      "Validation Loss: 3.4392, Validation Accuracy: 0.4406\n",
      "Epoch [66/250], Loss: 0.2611, Accuracy: 0.8982\n",
      "Validation Loss: 3.3336, Validation Accuracy: 0.5594\n",
      "Epoch [67/250], Loss: 0.2599, Accuracy: 0.8877\n",
      "Validation Loss: 2.2852, Validation Accuracy: 0.4336\n",
      "Epoch [68/250], Loss: 0.2002, Accuracy: 0.9228\n",
      "Validation Loss: 0.6288, Validation Accuracy: 0.6434\n",
      "Epoch [69/250], Loss: 0.2999, Accuracy: 0.8842\n",
      "Validation Loss: 1.2102, Validation Accuracy: 0.6294\n",
      "Epoch [70/250], Loss: 0.2733, Accuracy: 0.8912\n",
      "Validation Loss: 3.3911, Validation Accuracy: 0.4406\n",
      "Epoch [71/250], Loss: 0.2113, Accuracy: 0.9193\n",
      "Validation Loss: 2.7007, Validation Accuracy: 0.5944\n",
      "Epoch [72/250], Loss: 0.2113, Accuracy: 0.9053\n",
      "Validation Loss: 0.9996, Validation Accuracy: 0.5315\n",
      "Epoch [73/250], Loss: 0.2545, Accuracy: 0.9018\n",
      "Validation Loss: 0.3058, Validation Accuracy: 0.8741\n",
      "Epoch [74/250], Loss: 0.1840, Accuracy: 0.9193\n",
      "Validation Loss: 2.9453, Validation Accuracy: 0.4406\n",
      "Epoch [75/250], Loss: 0.2165, Accuracy: 0.8912\n",
      "Validation Loss: 2.0266, Validation Accuracy: 0.5594\n",
      "Epoch [76/250], Loss: 0.3198, Accuracy: 0.8772\n",
      "Validation Loss: 1.3620, Validation Accuracy: 0.5594\n",
      "Epoch [77/250], Loss: 0.2043, Accuracy: 0.9123\n",
      "Validation Loss: 0.6153, Validation Accuracy: 0.7133\n",
      "Epoch [78/250], Loss: 0.2631, Accuracy: 0.9193\n",
      "Validation Loss: 1.3620, Validation Accuracy: 0.4545\n",
      "Epoch [79/250], Loss: 0.2294, Accuracy: 0.8877\n",
      "Validation Loss: 2.6308, Validation Accuracy: 0.4406\n",
      "Epoch [80/250], Loss: 0.1918, Accuracy: 0.9298\n",
      "Validation Loss: 3.8851, Validation Accuracy: 0.4406\n",
      "Epoch [81/250], Loss: 0.2003, Accuracy: 0.9193\n",
      "Validation Loss: 4.2455, Validation Accuracy: 0.5594\n",
      "Epoch [82/250], Loss: 0.1765, Accuracy: 0.9053\n",
      "Validation Loss: 2.3938, Validation Accuracy: 0.6643\n",
      "Epoch [83/250], Loss: 0.2068, Accuracy: 0.9088\n",
      "Validation Loss: 3.8823, Validation Accuracy: 0.4406\n",
      "Epoch [84/250], Loss: 0.2050, Accuracy: 0.9193\n",
      "Validation Loss: 4.8011, Validation Accuracy: 0.5594\n",
      "Epoch [85/250], Loss: 0.2532, Accuracy: 0.9018\n",
      "Validation Loss: 3.5144, Validation Accuracy: 0.5594\n",
      "Epoch [86/250], Loss: 0.2322, Accuracy: 0.9053\n",
      "Validation Loss: 0.7644, Validation Accuracy: 0.6014\n",
      "Epoch [87/250], Loss: 0.2689, Accuracy: 0.8947\n",
      "Validation Loss: 2.9562, Validation Accuracy: 0.4406\n",
      "Epoch [88/250], Loss: 0.1885, Accuracy: 0.9193\n",
      "Validation Loss: 2.3940, Validation Accuracy: 0.6224\n",
      "Epoch [89/250], Loss: 0.2239, Accuracy: 0.9158\n",
      "Validation Loss: 0.7027, Validation Accuracy: 0.8531\n",
      "Epoch [90/250], Loss: 0.2070, Accuracy: 0.9053\n",
      "Validation Loss: 0.7266, Validation Accuracy: 0.7203\n",
      "Epoch [91/250], Loss: 0.2616, Accuracy: 0.9158\n",
      "Validation Loss: 0.3140, Validation Accuracy: 0.8741\n",
      "Epoch [92/250], Loss: 0.2448, Accuracy: 0.9018\n",
      "Validation Loss: 0.5097, Validation Accuracy: 0.6713\n",
      "Epoch [93/250], Loss: 0.2168, Accuracy: 0.9088\n",
      "Validation Loss: 0.5896, Validation Accuracy: 0.7133\n",
      "Epoch [94/250], Loss: 0.2164, Accuracy: 0.9158\n",
      "Validation Loss: 3.0008, Validation Accuracy: 0.5594\n",
      "Epoch [95/250], Loss: 0.2074, Accuracy: 0.9088\n",
      "Validation Loss: 0.8528, Validation Accuracy: 0.7273\n",
      "Epoch [96/250], Loss: 0.2325, Accuracy: 0.8947\n",
      "Validation Loss: 1.9094, Validation Accuracy: 0.5594\n",
      "Epoch [97/250], Loss: 0.2041, Accuracy: 0.9018\n",
      "Validation Loss: 0.8613, Validation Accuracy: 0.6364\n",
      "Epoch [98/250], Loss: 0.1649, Accuracy: 0.9404\n",
      "Validation Loss: 0.6320, Validation Accuracy: 0.8112\n",
      "Epoch [99/250], Loss: 0.1653, Accuracy: 0.9368\n",
      "Validation Loss: 0.9219, Validation Accuracy: 0.7133\n",
      "Epoch [100/250], Loss: 0.1625, Accuracy: 0.9228\n",
      "Validation Loss: 3.8818, Validation Accuracy: 0.5664\n",
      "Epoch [101/250], Loss: 0.3430, Accuracy: 0.8772\n",
      "Validation Loss: 0.6870, Validation Accuracy: 0.4825\n",
      "Epoch [102/250], Loss: 0.3459, Accuracy: 0.8526\n",
      "Validation Loss: 0.5872, Validation Accuracy: 0.6084\n",
      "Epoch [103/250], Loss: 0.1866, Accuracy: 0.9298\n",
      "Validation Loss: 3.0638, Validation Accuracy: 0.4406\n",
      "Epoch [104/250], Loss: 0.2004, Accuracy: 0.9088\n",
      "Validation Loss: 4.1723, Validation Accuracy: 0.5594\n",
      "Epoch [105/250], Loss: 0.2120, Accuracy: 0.9193\n",
      "Validation Loss: 3.7431, Validation Accuracy: 0.4196\n",
      "Epoch [106/250], Loss: 0.1745, Accuracy: 0.9263\n",
      "Validation Loss: 3.9732, Validation Accuracy: 0.5594\n",
      "Epoch [107/250], Loss: 0.2327, Accuracy: 0.9088\n",
      "Validation Loss: 4.5944, Validation Accuracy: 0.4406\n",
      "Epoch [108/250], Loss: 0.1785, Accuracy: 0.9193\n",
      "Validation Loss: 1.9225, Validation Accuracy: 0.5594\n",
      "Epoch [109/250], Loss: 0.1794, Accuracy: 0.9333\n",
      "Validation Loss: 3.7809, Validation Accuracy: 0.4476\n",
      "Epoch [110/250], Loss: 0.1615, Accuracy: 0.9333\n",
      "Validation Loss: 1.7759, Validation Accuracy: 0.4336\n",
      "Epoch [111/250], Loss: 0.2727, Accuracy: 0.8877\n",
      "Validation Loss: 2.4914, Validation Accuracy: 0.5804\n",
      "Epoch [112/250], Loss: 0.2247, Accuracy: 0.9298\n",
      "Validation Loss: 2.3526, Validation Accuracy: 0.5594\n",
      "Epoch [113/250], Loss: 0.1867, Accuracy: 0.9263\n",
      "Validation Loss: 0.5377, Validation Accuracy: 0.6573\n",
      "Epoch [114/250], Loss: 0.1825, Accuracy: 0.9368\n",
      "Validation Loss: 4.2626, Validation Accuracy: 0.4406\n",
      "Epoch [115/250], Loss: 0.2177, Accuracy: 0.9193\n",
      "Validation Loss: 4.4479, Validation Accuracy: 0.5594\n",
      "Epoch [116/250], Loss: 0.1723, Accuracy: 0.9263\n",
      "Validation Loss: 4.4219, Validation Accuracy: 0.4406\n",
      "Epoch [117/250], Loss: 0.1449, Accuracy: 0.9333\n",
      "Validation Loss: 1.1157, Validation Accuracy: 0.6364\n",
      "Epoch [118/250], Loss: 0.1806, Accuracy: 0.9088\n",
      "Validation Loss: 0.9165, Validation Accuracy: 0.5734\n",
      "Epoch [119/250], Loss: 0.1414, Accuracy: 0.9404\n",
      "Validation Loss: 2.9427, Validation Accuracy: 0.5175\n",
      "Epoch [120/250], Loss: 0.2071, Accuracy: 0.9298\n",
      "Validation Loss: 4.3458, Validation Accuracy: 0.4406\n",
      "Epoch [121/250], Loss: 0.2041, Accuracy: 0.9158\n",
      "Validation Loss: 0.7717, Validation Accuracy: 0.6014\n",
      "Epoch [122/250], Loss: 0.1981, Accuracy: 0.9158\n",
      "Validation Loss: 4.6064, Validation Accuracy: 0.5594\n",
      "Epoch [123/250], Loss: 0.1767, Accuracy: 0.9193\n",
      "Validation Loss: 4.6628, Validation Accuracy: 0.4406\n",
      "Epoch [124/250], Loss: 0.1590, Accuracy: 0.9333\n",
      "Validation Loss: 2.9432, Validation Accuracy: 0.6014\n",
      "Epoch [125/250], Loss: 0.1780, Accuracy: 0.9158\n",
      "Validation Loss: 1.5613, Validation Accuracy: 0.7203\n",
      "Epoch [126/250], Loss: 0.1469, Accuracy: 0.9474\n",
      "Validation Loss: 5.2479, Validation Accuracy: 0.4406\n",
      "Epoch [127/250], Loss: 0.1663, Accuracy: 0.9404\n",
      "Validation Loss: 3.7284, Validation Accuracy: 0.5594\n",
      "Epoch [128/250], Loss: 0.1483, Accuracy: 0.9228\n",
      "Validation Loss: 5.0433, Validation Accuracy: 0.4406\n",
      "Epoch [129/250], Loss: 0.1869, Accuracy: 0.9263\n",
      "Validation Loss: 5.1970, Validation Accuracy: 0.5594\n",
      "Epoch [130/250], Loss: 0.1821, Accuracy: 0.9123\n",
      "Validation Loss: 4.7402, Validation Accuracy: 0.4406\n",
      "Epoch [131/250], Loss: 0.1344, Accuracy: 0.9544\n",
      "Validation Loss: 0.7358, Validation Accuracy: 0.6853\n",
      "Epoch [132/250], Loss: 0.1602, Accuracy: 0.9368\n",
      "Validation Loss: 5.0002, Validation Accuracy: 0.5594\n",
      "Epoch [133/250], Loss: 0.1499, Accuracy: 0.9404\n",
      "Validation Loss: 1.1896, Validation Accuracy: 0.7343\n",
      "Epoch [134/250], Loss: 0.1811, Accuracy: 0.9158\n",
      "Validation Loss: 5.0153, Validation Accuracy: 0.4406\n",
      "Epoch [135/250], Loss: 0.1778, Accuracy: 0.9368\n",
      "Validation Loss: 0.4296, Validation Accuracy: 0.7413\n",
      "Epoch [136/250], Loss: 0.1655, Accuracy: 0.9088\n",
      "Validation Loss: 0.2565, Validation Accuracy: 0.8671\n",
      "Epoch [137/250], Loss: 0.1817, Accuracy: 0.9158\n",
      "Validation Loss: 1.2841, Validation Accuracy: 0.5594\n",
      "Epoch [138/250], Loss: 0.1488, Accuracy: 0.9439\n",
      "Validation Loss: 2.3610, Validation Accuracy: 0.5664\n",
      "Epoch [139/250], Loss: 0.1459, Accuracy: 0.9404\n",
      "Validation Loss: 0.5999, Validation Accuracy: 0.8601\n",
      "Epoch [140/250], Loss: 0.1491, Accuracy: 0.9298\n",
      "Validation Loss: 4.2797, Validation Accuracy: 0.5594\n",
      "Epoch [141/250], Loss: 0.1748, Accuracy: 0.9263\n",
      "Validation Loss: 0.7091, Validation Accuracy: 0.8322\n",
      "Epoch [142/250], Loss: 0.1569, Accuracy: 0.9298\n",
      "Validation Loss: 2.5566, Validation Accuracy: 0.4336\n",
      "Epoch [143/250], Loss: 0.1684, Accuracy: 0.9228\n",
      "Validation Loss: 1.4200, Validation Accuracy: 0.5594\n",
      "Epoch [144/250], Loss: 0.1059, Accuracy: 0.9719\n",
      "Validation Loss: 0.5859, Validation Accuracy: 0.6783\n",
      "Epoch [145/250], Loss: 0.1880, Accuracy: 0.9404\n",
      "Validation Loss: 5.3632, Validation Accuracy: 0.5594\n",
      "Epoch [146/250], Loss: 0.1425, Accuracy: 0.9474\n",
      "Validation Loss: 0.3712, Validation Accuracy: 0.8671\n",
      "Epoch [147/250], Loss: 0.1882, Accuracy: 0.9158\n",
      "Validation Loss: 0.2958, Validation Accuracy: 0.8601\n",
      "Epoch [148/250], Loss: 0.1273, Accuracy: 0.9333\n",
      "Validation Loss: 4.0676, Validation Accuracy: 0.5874\n",
      "Epoch [149/250], Loss: 0.1482, Accuracy: 0.9193\n",
      "Validation Loss: 2.7269, Validation Accuracy: 0.5594\n",
      "Epoch [150/250], Loss: 0.2025, Accuracy: 0.9123\n",
      "Validation Loss: 0.5919, Validation Accuracy: 0.6923\n",
      "Epoch [151/250], Loss: 0.1634, Accuracy: 0.9439\n",
      "Validation Loss: 5.8881, Validation Accuracy: 0.5594\n",
      "Epoch [152/250], Loss: 0.2247, Accuracy: 0.8807\n",
      "Validation Loss: 5.4292, Validation Accuracy: 0.4406\n",
      "Epoch [153/250], Loss: 0.1640, Accuracy: 0.9298\n",
      "Validation Loss: 5.4045, Validation Accuracy: 0.4406\n",
      "Epoch [154/250], Loss: 0.1633, Accuracy: 0.9404\n",
      "Validation Loss: 3.0013, Validation Accuracy: 0.4336\n",
      "Epoch [155/250], Loss: 0.1513, Accuracy: 0.9404\n",
      "Validation Loss: 0.7027, Validation Accuracy: 0.7552\n",
      "Epoch [156/250], Loss: 0.1208, Accuracy: 0.9474\n",
      "Validation Loss: 0.8620, Validation Accuracy: 0.7622\n",
      "Epoch [157/250], Loss: 0.1609, Accuracy: 0.9298\n",
      "Validation Loss: 5.6056, Validation Accuracy: 0.5594\n",
      "Epoch [158/250], Loss: 0.1644, Accuracy: 0.9404\n",
      "Validation Loss: 3.1017, Validation Accuracy: 0.6154\n",
      "Epoch [159/250], Loss: 0.1410, Accuracy: 0.9333\n",
      "Validation Loss: 4.9427, Validation Accuracy: 0.4406\n",
      "Epoch [160/250], Loss: 0.1176, Accuracy: 0.9474\n",
      "Validation Loss: 1.1943, Validation Accuracy: 0.7343\n",
      "Epoch [161/250], Loss: 0.1782, Accuracy: 0.9263\n",
      "Validation Loss: 0.3504, Validation Accuracy: 0.9091\n",
      "Epoch [162/250], Loss: 0.1587, Accuracy: 0.9263\n",
      "Validation Loss: 0.6844, Validation Accuracy: 0.8671\n",
      "Epoch [163/250], Loss: 0.1381, Accuracy: 0.9509\n",
      "Validation Loss: 0.9209, Validation Accuracy: 0.4406\n",
      "Epoch [164/250], Loss: 0.1973, Accuracy: 0.9263\n",
      "Validation Loss: 3.0027, Validation Accuracy: 0.5594\n",
      "Epoch [165/250], Loss: 0.1530, Accuracy: 0.9439\n",
      "Validation Loss: 0.3530, Validation Accuracy: 0.8531\n",
      "Epoch [166/250], Loss: 0.1267, Accuracy: 0.9439\n",
      "Validation Loss: 5.6360, Validation Accuracy: 0.5594\n",
      "Epoch [167/250], Loss: 0.1109, Accuracy: 0.9509\n",
      "Validation Loss: 4.6507, Validation Accuracy: 0.5594\n",
      "Epoch [168/250], Loss: 0.1224, Accuracy: 0.9404\n",
      "Validation Loss: 1.8792, Validation Accuracy: 0.4545\n",
      "Epoch [169/250], Loss: 0.2284, Accuracy: 0.9193\n",
      "Validation Loss: 3.8800, Validation Accuracy: 0.5594\n",
      "Epoch [170/250], Loss: 0.1085, Accuracy: 0.9404\n",
      "Validation Loss: 2.9278, Validation Accuracy: 0.5664\n",
      "Epoch [171/250], Loss: 0.1955, Accuracy: 0.9404\n",
      "Validation Loss: 2.6255, Validation Accuracy: 0.5105\n",
      "Epoch [172/250], Loss: 0.1432, Accuracy: 0.9579\n",
      "Validation Loss: 1.7577, Validation Accuracy: 0.6573\n",
      "Epoch [173/250], Loss: 0.1374, Accuracy: 0.9404\n",
      "Validation Loss: 5.5526, Validation Accuracy: 0.5594\n",
      "Epoch [174/250], Loss: 0.1158, Accuracy: 0.9404\n",
      "Validation Loss: 2.7405, Validation Accuracy: 0.5804\n",
      "Epoch [175/250], Loss: 0.1110, Accuracy: 0.9614\n",
      "Validation Loss: 5.3702, Validation Accuracy: 0.5594\n",
      "Epoch [176/250], Loss: 0.1170, Accuracy: 0.9509\n",
      "Validation Loss: 1.0982, Validation Accuracy: 0.7622\n",
      "Epoch [177/250], Loss: 0.1291, Accuracy: 0.9579\n",
      "Validation Loss: 5.3830, Validation Accuracy: 0.5594\n",
      "Epoch [178/250], Loss: 0.1728, Accuracy: 0.9404\n",
      "Validation Loss: 5.2804, Validation Accuracy: 0.4406\n",
      "Epoch [179/250], Loss: 0.0985, Accuracy: 0.9649\n",
      "Validation Loss: 6.1561, Validation Accuracy: 0.4406\n",
      "Epoch [180/250], Loss: 0.0896, Accuracy: 0.9684\n",
      "Validation Loss: 5.2160, Validation Accuracy: 0.5594\n",
      "Epoch [181/250], Loss: 0.1609, Accuracy: 0.9404\n",
      "Validation Loss: 1.2436, Validation Accuracy: 0.5734\n",
      "Epoch [182/250], Loss: 0.1277, Accuracy: 0.9649\n",
      "Validation Loss: 3.6740, Validation Accuracy: 0.5594\n",
      "Epoch [183/250], Loss: 0.1009, Accuracy: 0.9684\n",
      "Validation Loss: 2.1395, Validation Accuracy: 0.5385\n",
      "Epoch [184/250], Loss: 0.0855, Accuracy: 0.9544\n",
      "Validation Loss: 2.2183, Validation Accuracy: 0.5175\n",
      "Epoch [185/250], Loss: 0.1107, Accuracy: 0.9474\n",
      "Validation Loss: 3.3395, Validation Accuracy: 0.6014\n",
      "Epoch [186/250], Loss: 0.1061, Accuracy: 0.9439\n",
      "Validation Loss: 1.7344, Validation Accuracy: 0.5594\n",
      "Epoch [187/250], Loss: 0.1275, Accuracy: 0.9579\n",
      "Validation Loss: 3.0958, Validation Accuracy: 0.5594\n",
      "Epoch [188/250], Loss: 0.0838, Accuracy: 0.9614\n",
      "Validation Loss: 2.5532, Validation Accuracy: 0.5594\n",
      "Epoch [189/250], Loss: 0.1329, Accuracy: 0.9474\n",
      "Validation Loss: 2.3579, Validation Accuracy: 0.4895\n",
      "Epoch [190/250], Loss: 0.1011, Accuracy: 0.9614\n",
      "Validation Loss: 6.0962, Validation Accuracy: 0.4406\n",
      "Epoch [191/250], Loss: 0.1227, Accuracy: 0.9404\n",
      "Validation Loss: 1.5034, Validation Accuracy: 0.6014\n",
      "Epoch [192/250], Loss: 0.1353, Accuracy: 0.9474\n",
      "Validation Loss: 6.7573, Validation Accuracy: 0.4406\n",
      "Epoch [193/250], Loss: 0.1112, Accuracy: 0.9404\n",
      "Validation Loss: 5.8739, Validation Accuracy: 0.5594\n",
      "Epoch [194/250], Loss: 0.1694, Accuracy: 0.9368\n",
      "Validation Loss: 1.6426, Validation Accuracy: 0.5594\n",
      "Epoch [195/250], Loss: 0.0924, Accuracy: 0.9789\n",
      "Validation Loss: 3.3871, Validation Accuracy: 0.5594\n",
      "Epoch [196/250], Loss: 0.1171, Accuracy: 0.9509\n",
      "Validation Loss: 2.9794, Validation Accuracy: 0.4336\n",
      "Epoch [197/250], Loss: 0.1115, Accuracy: 0.9579\n",
      "Validation Loss: 2.1737, Validation Accuracy: 0.7133\n",
      "Epoch [198/250], Loss: 0.1148, Accuracy: 0.9544\n",
      "Validation Loss: 1.9071, Validation Accuracy: 0.7063\n",
      "Epoch [199/250], Loss: 0.1054, Accuracy: 0.9544\n",
      "Validation Loss: 3.8387, Validation Accuracy: 0.5315\n",
      "Epoch [200/250], Loss: 0.1202, Accuracy: 0.9544\n",
      "Validation Loss: 2.5513, Validation Accuracy: 0.4615\n",
      "Epoch [201/250], Loss: 0.1777, Accuracy: 0.9333\n",
      "Validation Loss: 0.8369, Validation Accuracy: 0.6993\n",
      "Epoch [202/250], Loss: 0.0995, Accuracy: 0.9474\n",
      "Validation Loss: 2.4441, Validation Accuracy: 0.6014\n",
      "Epoch [203/250], Loss: 0.1351, Accuracy: 0.9439\n",
      "Validation Loss: 5.6524, Validation Accuracy: 0.4336\n",
      "Epoch [204/250], Loss: 0.1420, Accuracy: 0.9439\n",
      "Validation Loss: 0.4003, Validation Accuracy: 0.7972\n",
      "Epoch [205/250], Loss: 0.0821, Accuracy: 0.9684\n",
      "Validation Loss: 0.9606, Validation Accuracy: 0.7762\n",
      "Epoch [206/250], Loss: 0.1045, Accuracy: 0.9614\n",
      "Validation Loss: 0.6673, Validation Accuracy: 0.8392\n",
      "Epoch [207/250], Loss: 0.1127, Accuracy: 0.9474\n",
      "Validation Loss: 0.4150, Validation Accuracy: 0.8881\n",
      "Epoch [208/250], Loss: 0.1372, Accuracy: 0.9544\n",
      "Validation Loss: 0.3855, Validation Accuracy: 0.8601\n",
      "Epoch [209/250], Loss: 0.1288, Accuracy: 0.9579\n",
      "Validation Loss: 1.7534, Validation Accuracy: 0.5245\n",
      "Epoch [210/250], Loss: 0.1360, Accuracy: 0.9474\n",
      "Validation Loss: 0.2950, Validation Accuracy: 0.8671\n",
      "Epoch [211/250], Loss: 0.1226, Accuracy: 0.9333\n",
      "Validation Loss: 0.5788, Validation Accuracy: 0.6853\n",
      "Epoch [212/250], Loss: 0.1329, Accuracy: 0.9579\n",
      "Validation Loss: 5.3458, Validation Accuracy: 0.5594\n",
      "Epoch [213/250], Loss: 0.1269, Accuracy: 0.9404\n",
      "Validation Loss: 1.4280, Validation Accuracy: 0.7273\n",
      "Epoch [214/250], Loss: 0.1257, Accuracy: 0.9614\n",
      "Validation Loss: 1.1488, Validation Accuracy: 0.5944\n",
      "Epoch [215/250], Loss: 0.0995, Accuracy: 0.9544\n",
      "Validation Loss: 0.8347, Validation Accuracy: 0.6573\n",
      "Epoch [216/250], Loss: 0.1162, Accuracy: 0.9474\n",
      "Validation Loss: 2.6908, Validation Accuracy: 0.5594\n",
      "Epoch [217/250], Loss: 0.0939, Accuracy: 0.9649\n",
      "Validation Loss: 0.8325, Validation Accuracy: 0.8322\n",
      "Epoch [218/250], Loss: 0.2203, Accuracy: 0.9368\n",
      "Validation Loss: 6.2534, Validation Accuracy: 0.4406\n",
      "Epoch [219/250], Loss: 0.1223, Accuracy: 0.9614\n",
      "Validation Loss: 4.1516, Validation Accuracy: 0.5594\n",
      "Epoch [220/250], Loss: 0.0895, Accuracy: 0.9684\n",
      "Validation Loss: 0.5675, Validation Accuracy: 0.8601\n",
      "Epoch [221/250], Loss: 0.1518, Accuracy: 0.9439\n",
      "Validation Loss: 6.2494, Validation Accuracy: 0.4406\n",
      "Epoch [222/250], Loss: 0.2269, Accuracy: 0.9263\n",
      "Validation Loss: 3.1899, Validation Accuracy: 0.4476\n",
      "Epoch [223/250], Loss: 0.1133, Accuracy: 0.9439\n",
      "Validation Loss: 3.8056, Validation Accuracy: 0.5594\n",
      "Epoch [224/250], Loss: 0.0794, Accuracy: 0.9649\n",
      "Validation Loss: 3.1358, Validation Accuracy: 0.6154\n",
      "Epoch [225/250], Loss: 0.0767, Accuracy: 0.9719\n",
      "Validation Loss: 4.2329, Validation Accuracy: 0.5734\n",
      "Epoch [226/250], Loss: 0.1427, Accuracy: 0.9368\n",
      "Validation Loss: 4.7241, Validation Accuracy: 0.5594\n",
      "Epoch [227/250], Loss: 0.0799, Accuracy: 0.9684\n",
      "Validation Loss: 1.8893, Validation Accuracy: 0.6643\n",
      "Epoch [228/250], Loss: 0.1060, Accuracy: 0.9614\n",
      "Validation Loss: 5.9373, Validation Accuracy: 0.4406\n",
      "Epoch [229/250], Loss: 0.1294, Accuracy: 0.9579\n",
      "Validation Loss: 4.1288, Validation Accuracy: 0.5594\n",
      "Epoch [230/250], Loss: 0.1134, Accuracy: 0.9509\n",
      "Validation Loss: 1.3963, Validation Accuracy: 0.5315\n",
      "Epoch [231/250], Loss: 0.1169, Accuracy: 0.9579\n",
      "Validation Loss: 2.1658, Validation Accuracy: 0.6014\n",
      "Epoch [232/250], Loss: 0.1231, Accuracy: 0.9579\n",
      "Validation Loss: 1.4079, Validation Accuracy: 0.7552\n",
      "Epoch [233/250], Loss: 0.0983, Accuracy: 0.9614\n",
      "Validation Loss: 4.4938, Validation Accuracy: 0.4476\n",
      "Epoch [234/250], Loss: 0.1515, Accuracy: 0.9509\n",
      "Validation Loss: 1.7997, Validation Accuracy: 0.7203\n",
      "Epoch [235/250], Loss: 0.1443, Accuracy: 0.9649\n",
      "Validation Loss: 5.0206, Validation Accuracy: 0.5594\n",
      "Epoch [236/250], Loss: 0.1138, Accuracy: 0.9684\n",
      "Validation Loss: 0.8954, Validation Accuracy: 0.7273\n",
      "Epoch [237/250], Loss: 0.0906, Accuracy: 0.9684\n",
      "Validation Loss: 2.2190, Validation Accuracy: 0.6154\n",
      "Epoch [238/250], Loss: 0.0906, Accuracy: 0.9579\n",
      "Validation Loss: 2.3575, Validation Accuracy: 0.6154\n",
      "Epoch [239/250], Loss: 0.0999, Accuracy: 0.9509\n",
      "Validation Loss: 3.7175, Validation Accuracy: 0.4615\n",
      "Epoch [240/250], Loss: 0.1119, Accuracy: 0.9754\n",
      "Validation Loss: 2.7329, Validation Accuracy: 0.5594\n",
      "Epoch [241/250], Loss: 0.1074, Accuracy: 0.9579\n",
      "Validation Loss: 3.8090, Validation Accuracy: 0.5594\n",
      "Epoch [242/250], Loss: 0.0869, Accuracy: 0.9579\n",
      "Validation Loss: 2.2735, Validation Accuracy: 0.6434\n",
      "Epoch [243/250], Loss: 0.0640, Accuracy: 0.9684\n",
      "Validation Loss: 1.2178, Validation Accuracy: 0.7762\n",
      "Epoch [244/250], Loss: 0.0923, Accuracy: 0.9649\n",
      "Validation Loss: 1.5883, Validation Accuracy: 0.7483\n",
      "Epoch [245/250], Loss: 0.1602, Accuracy: 0.9544\n",
      "Validation Loss: 2.8280, Validation Accuracy: 0.6014\n",
      "Epoch [246/250], Loss: 0.1660, Accuracy: 0.9298\n",
      "Validation Loss: 5.0668, Validation Accuracy: 0.4406\n",
      "Epoch [247/250], Loss: 0.1483, Accuracy: 0.9614\n",
      "Validation Loss: 5.2408, Validation Accuracy: 0.4336\n",
      "Epoch [248/250], Loss: 0.0757, Accuracy: 0.9719\n",
      "Validation Loss: 1.8080, Validation Accuracy: 0.6503\n",
      "Epoch [249/250], Loss: 0.0767, Accuracy: 0.9754\n",
      "Validation Loss: 3.2738, Validation Accuracy: 0.5734\n",
      "Epoch [250/250], Loss: 0.0669, Accuracy: 0.9719\n",
      "Validation Loss: 0.4682, Validation Accuracy: 0.8601\n",
      "Test Loss: 0.8090\n",
      "Test Accuracy: 0.8521\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 122\n",
      "label 1 is 35\n",
      "label 2 is 43\n",
      "label 3 is 102\n",
      "Not setting metadata\n",
      "302 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (265, 8, 325)\n",
      "265 train samples\n",
      "132 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.162280701754386, 0: 0.8774834437086093}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.2438, Accuracy: 0.3925\n",
      "Validation Loss: 1.0049, Validation Accuracy: 0.5113\n",
      "Epoch [2/250], Loss: 0.9723, Accuracy: 0.5698\n",
      "Validation Loss: 0.8771, Validation Accuracy: 0.5113\n",
      "Epoch [3/250], Loss: 0.8117, Accuracy: 0.6113\n",
      "Validation Loss: 0.8558, Validation Accuracy: 0.5113\n",
      "Epoch [4/250], Loss: 0.8309, Accuracy: 0.5509\n",
      "Validation Loss: 0.7426, Validation Accuracy: 0.5113\n",
      "Epoch [5/250], Loss: 0.8512, Accuracy: 0.4943\n",
      "Validation Loss: 0.8524, Validation Accuracy: 0.5113\n",
      "Epoch [6/250], Loss: 0.7422, Accuracy: 0.6226\n",
      "Validation Loss: 0.7795, Validation Accuracy: 0.5113\n",
      "Epoch [7/250], Loss: 0.7845, Accuracy: 0.5434\n",
      "Validation Loss: 0.7801, Validation Accuracy: 0.5113\n",
      "Epoch [8/250], Loss: 0.7880, Accuracy: 0.5509\n",
      "Validation Loss: 0.7881, Validation Accuracy: 0.5113\n",
      "Epoch [9/250], Loss: 0.7732, Accuracy: 0.5623\n",
      "Validation Loss: 0.8008, Validation Accuracy: 0.5113\n",
      "Epoch [10/250], Loss: 0.7430, Accuracy: 0.5585\n",
      "Validation Loss: 0.7709, Validation Accuracy: 0.5113\n",
      "Epoch [11/250], Loss: 0.7434, Accuracy: 0.5811\n",
      "Validation Loss: 0.7363, Validation Accuracy: 0.5113\n",
      "Epoch [12/250], Loss: 0.8181, Accuracy: 0.5434\n",
      "Validation Loss: 0.7982, Validation Accuracy: 0.5113\n",
      "Epoch [13/250], Loss: 0.7982, Accuracy: 0.5472\n",
      "Validation Loss: 0.8483, Validation Accuracy: 0.5113\n",
      "Epoch [14/250], Loss: 0.7104, Accuracy: 0.5660\n",
      "Validation Loss: 0.8064, Validation Accuracy: 0.5113\n",
      "Epoch [15/250], Loss: 0.7498, Accuracy: 0.5849\n",
      "Validation Loss: 0.7452, Validation Accuracy: 0.5188\n",
      "Epoch [16/250], Loss: 0.7404, Accuracy: 0.5811\n",
      "Validation Loss: 0.7448, Validation Accuracy: 0.5188\n",
      "Epoch [17/250], Loss: 0.7099, Accuracy: 0.5962\n",
      "Validation Loss: 0.7955, Validation Accuracy: 0.5188\n",
      "Epoch [18/250], Loss: 0.7047, Accuracy: 0.6302\n",
      "Validation Loss: 0.6888, Validation Accuracy: 0.5789\n",
      "Epoch [19/250], Loss: 0.7022, Accuracy: 0.6000\n",
      "Validation Loss: 0.7965, Validation Accuracy: 0.5188\n",
      "Epoch [20/250], Loss: 0.7663, Accuracy: 0.5774\n",
      "Validation Loss: 0.6951, Validation Accuracy: 0.6165\n",
      "Epoch [21/250], Loss: 0.7542, Accuracy: 0.5585\n",
      "Validation Loss: 0.7020, Validation Accuracy: 0.5414\n",
      "Epoch [22/250], Loss: 0.7398, Accuracy: 0.6000\n",
      "Validation Loss: 0.6942, Validation Accuracy: 0.6090\n",
      "Epoch [23/250], Loss: 0.7382, Accuracy: 0.6340\n",
      "Validation Loss: 0.7548, Validation Accuracy: 0.5188\n",
      "Epoch [24/250], Loss: 0.7055, Accuracy: 0.6000\n",
      "Validation Loss: 0.7670, Validation Accuracy: 0.5263\n",
      "Epoch [25/250], Loss: 0.6525, Accuracy: 0.6189\n",
      "Validation Loss: 0.8832, Validation Accuracy: 0.5188\n",
      "Epoch [26/250], Loss: 0.7525, Accuracy: 0.6038\n",
      "Validation Loss: 0.6981, Validation Accuracy: 0.6541\n",
      "Epoch [27/250], Loss: 0.6880, Accuracy: 0.6340\n",
      "Validation Loss: 0.7484, Validation Accuracy: 0.6241\n",
      "Epoch [28/250], Loss: 0.7774, Accuracy: 0.6340\n",
      "Validation Loss: 0.7261, Validation Accuracy: 0.6767\n",
      "Epoch [29/250], Loss: 0.6765, Accuracy: 0.6226\n",
      "Validation Loss: 1.0582, Validation Accuracy: 0.4812\n",
      "Epoch [30/250], Loss: 0.6024, Accuracy: 0.6717\n",
      "Validation Loss: 0.9874, Validation Accuracy: 0.5865\n",
      "Epoch [31/250], Loss: 0.6454, Accuracy: 0.6151\n",
      "Validation Loss: 1.5095, Validation Accuracy: 0.5188\n",
      "Epoch [32/250], Loss: 0.6286, Accuracy: 0.6491\n",
      "Validation Loss: 1.0246, Validation Accuracy: 0.5789\n",
      "Epoch [33/250], Loss: 0.7107, Accuracy: 0.6679\n",
      "Validation Loss: 1.3763, Validation Accuracy: 0.5188\n",
      "Epoch [34/250], Loss: 0.6927, Accuracy: 0.6755\n",
      "Validation Loss: 1.3228, Validation Accuracy: 0.5338\n",
      "Epoch [35/250], Loss: 0.6448, Accuracy: 0.6717\n",
      "Validation Loss: 1.1820, Validation Accuracy: 0.5338\n",
      "Epoch [36/250], Loss: 0.5524, Accuracy: 0.7019\n",
      "Validation Loss: 1.5311, Validation Accuracy: 0.5188\n",
      "Epoch [37/250], Loss: 0.5225, Accuracy: 0.7170\n",
      "Validation Loss: 1.1865, Validation Accuracy: 0.5639\n",
      "Epoch [38/250], Loss: 0.6207, Accuracy: 0.7208\n",
      "Validation Loss: 0.9438, Validation Accuracy: 0.6090\n",
      "Epoch [39/250], Loss: 0.5277, Accuracy: 0.7170\n",
      "Validation Loss: 0.8420, Validation Accuracy: 0.6992\n",
      "Epoch [40/250], Loss: 0.5951, Accuracy: 0.7245\n",
      "Validation Loss: 0.9093, Validation Accuracy: 0.6842\n",
      "Epoch [41/250], Loss: 0.5234, Accuracy: 0.7509\n",
      "Validation Loss: 1.9194, Validation Accuracy: 0.4887\n",
      "Epoch [42/250], Loss: 0.5639, Accuracy: 0.7057\n",
      "Validation Loss: 2.1570, Validation Accuracy: 0.4887\n",
      "Epoch [43/250], Loss: 0.5023, Accuracy: 0.7509\n",
      "Validation Loss: 1.5157, Validation Accuracy: 0.5188\n",
      "Epoch [44/250], Loss: 0.5643, Accuracy: 0.7132\n",
      "Validation Loss: 1.9578, Validation Accuracy: 0.4887\n",
      "Epoch [45/250], Loss: 0.5015, Accuracy: 0.7547\n",
      "Validation Loss: 1.1658, Validation Accuracy: 0.7143\n",
      "Epoch [46/250], Loss: 0.5452, Accuracy: 0.7660\n",
      "Validation Loss: 1.6679, Validation Accuracy: 0.5263\n",
      "Epoch [47/250], Loss: 0.4378, Accuracy: 0.8038\n",
      "Validation Loss: 2.1267, Validation Accuracy: 0.5113\n",
      "Epoch [48/250], Loss: 0.5819, Accuracy: 0.7283\n",
      "Validation Loss: 2.0480, Validation Accuracy: 0.5113\n",
      "Epoch [49/250], Loss: 0.5408, Accuracy: 0.7472\n",
      "Validation Loss: 1.4682, Validation Accuracy: 0.5865\n",
      "Epoch [50/250], Loss: 0.5960, Accuracy: 0.7132\n",
      "Validation Loss: 1.6299, Validation Accuracy: 0.4962\n",
      "Epoch [51/250], Loss: 0.4961, Accuracy: 0.7547\n",
      "Validation Loss: 1.2277, Validation Accuracy: 0.5639\n",
      "Epoch [52/250], Loss: 0.5122, Accuracy: 0.7208\n",
      "Validation Loss: 2.2699, Validation Accuracy: 0.4887\n",
      "Epoch [53/250], Loss: 0.5215, Accuracy: 0.7774\n",
      "Validation Loss: 1.9301, Validation Accuracy: 0.4887\n",
      "Epoch [54/250], Loss: 0.4904, Accuracy: 0.7811\n",
      "Validation Loss: 1.4518, Validation Accuracy: 0.5564\n",
      "Epoch [55/250], Loss: 0.4966, Accuracy: 0.7623\n",
      "Validation Loss: 1.1455, Validation Accuracy: 0.6842\n",
      "Epoch [56/250], Loss: 0.4768, Accuracy: 0.7887\n",
      "Validation Loss: 1.8200, Validation Accuracy: 0.4962\n",
      "Epoch [57/250], Loss: 0.5449, Accuracy: 0.7509\n",
      "Validation Loss: 2.4381, Validation Accuracy: 0.4887\n",
      "Epoch [58/250], Loss: 0.4922, Accuracy: 0.7660\n",
      "Validation Loss: 1.1884, Validation Accuracy: 0.7368\n",
      "Epoch [59/250], Loss: 0.4655, Accuracy: 0.7849\n",
      "Validation Loss: 1.1123, Validation Accuracy: 0.7444\n",
      "Epoch [60/250], Loss: 0.4778, Accuracy: 0.7849\n",
      "Validation Loss: 1.1130, Validation Accuracy: 0.7444\n",
      "Epoch [61/250], Loss: 0.4904, Accuracy: 0.7623\n",
      "Validation Loss: 1.8722, Validation Accuracy: 0.5188\n",
      "Epoch [62/250], Loss: 0.4546, Accuracy: 0.7774\n",
      "Validation Loss: 2.0062, Validation Accuracy: 0.5263\n",
      "Epoch [63/250], Loss: 0.5060, Accuracy: 0.7585\n",
      "Validation Loss: 1.1475, Validation Accuracy: 0.7293\n",
      "Epoch [64/250], Loss: 0.4989, Accuracy: 0.7962\n",
      "Validation Loss: 1.4623, Validation Accuracy: 0.5414\n",
      "Epoch [65/250], Loss: 0.4933, Accuracy: 0.8000\n",
      "Validation Loss: 1.0226, Validation Accuracy: 0.6917\n",
      "Epoch [66/250], Loss: 0.4594, Accuracy: 0.8113\n",
      "Validation Loss: 1.4701, Validation Accuracy: 0.5414\n",
      "Epoch [67/250], Loss: 0.4834, Accuracy: 0.7962\n",
      "Validation Loss: 1.3580, Validation Accuracy: 0.6316\n",
      "Epoch [68/250], Loss: 0.4925, Accuracy: 0.7887\n",
      "Validation Loss: 1.1248, Validation Accuracy: 0.7444\n",
      "Epoch [69/250], Loss: 0.4098, Accuracy: 0.7698\n",
      "Validation Loss: 1.2026, Validation Accuracy: 0.7519\n",
      "Epoch [70/250], Loss: 0.4617, Accuracy: 0.8075\n",
      "Validation Loss: 2.2509, Validation Accuracy: 0.4887\n",
      "Epoch [71/250], Loss: 0.4726, Accuracy: 0.7623\n",
      "Validation Loss: 2.3766, Validation Accuracy: 0.4887\n",
      "Epoch [72/250], Loss: 0.4857, Accuracy: 0.8000\n",
      "Validation Loss: 2.7039, Validation Accuracy: 0.4887\n",
      "Epoch [73/250], Loss: 0.5734, Accuracy: 0.7245\n",
      "Validation Loss: 2.6039, Validation Accuracy: 0.4887\n",
      "Epoch [74/250], Loss: 0.5566, Accuracy: 0.8038\n",
      "Validation Loss: 1.1358, Validation Accuracy: 0.7594\n",
      "Epoch [75/250], Loss: 0.5392, Accuracy: 0.7774\n",
      "Validation Loss: 1.4597, Validation Accuracy: 0.5489\n",
      "Epoch [76/250], Loss: 0.4520, Accuracy: 0.7698\n",
      "Validation Loss: 1.2711, Validation Accuracy: 0.6466\n",
      "Epoch [77/250], Loss: 0.4283, Accuracy: 0.8302\n",
      "Validation Loss: 1.3431, Validation Accuracy: 0.6842\n",
      "Epoch [78/250], Loss: 0.4342, Accuracy: 0.8151\n",
      "Validation Loss: 1.6892, Validation Accuracy: 0.5564\n",
      "Epoch [79/250], Loss: 0.4189, Accuracy: 0.7887\n",
      "Validation Loss: 2.5937, Validation Accuracy: 0.4887\n",
      "Epoch [80/250], Loss: 0.4194, Accuracy: 0.8226\n",
      "Validation Loss: 1.3458, Validation Accuracy: 0.6541\n",
      "Epoch [81/250], Loss: 0.5073, Accuracy: 0.8113\n",
      "Validation Loss: 2.0416, Validation Accuracy: 0.5188\n",
      "Epoch [82/250], Loss: 0.4640, Accuracy: 0.7887\n",
      "Validation Loss: 1.2964, Validation Accuracy: 0.7143\n",
      "Epoch [83/250], Loss: 0.4891, Accuracy: 0.7962\n",
      "Validation Loss: 1.1588, Validation Accuracy: 0.7368\n",
      "Epoch [84/250], Loss: 0.3810, Accuracy: 0.8415\n",
      "Validation Loss: 1.2893, Validation Accuracy: 0.7068\n",
      "Epoch [85/250], Loss: 0.3924, Accuracy: 0.8302\n",
      "Validation Loss: 1.5293, Validation Accuracy: 0.6316\n",
      "Epoch [86/250], Loss: 0.4339, Accuracy: 0.8000\n",
      "Validation Loss: 1.4133, Validation Accuracy: 0.6842\n",
      "Epoch [87/250], Loss: 0.4374, Accuracy: 0.8038\n",
      "Validation Loss: 2.6319, Validation Accuracy: 0.4887\n",
      "Epoch [88/250], Loss: 0.4515, Accuracy: 0.8038\n",
      "Validation Loss: 2.6928, Validation Accuracy: 0.4737\n",
      "Epoch [89/250], Loss: 0.3776, Accuracy: 0.8415\n",
      "Validation Loss: 1.2819, Validation Accuracy: 0.7218\n",
      "Epoch [90/250], Loss: 0.4151, Accuracy: 0.7887\n",
      "Validation Loss: 1.4727, Validation Accuracy: 0.6241\n",
      "Epoch [91/250], Loss: 0.4794, Accuracy: 0.7962\n",
      "Validation Loss: 1.1913, Validation Accuracy: 0.7068\n",
      "Epoch [92/250], Loss: 0.3849, Accuracy: 0.8226\n",
      "Validation Loss: 1.4144, Validation Accuracy: 0.6617\n",
      "Epoch [93/250], Loss: 0.3147, Accuracy: 0.8302\n",
      "Validation Loss: 1.2781, Validation Accuracy: 0.7669\n",
      "Epoch [94/250], Loss: 0.3843, Accuracy: 0.8075\n",
      "Validation Loss: 1.4051, Validation Accuracy: 0.6617\n",
      "Epoch [95/250], Loss: 0.4428, Accuracy: 0.8189\n",
      "Validation Loss: 3.0338, Validation Accuracy: 0.4887\n",
      "Epoch [96/250], Loss: 0.5987, Accuracy: 0.7849\n",
      "Validation Loss: 2.1022, Validation Accuracy: 0.4962\n",
      "Epoch [97/250], Loss: 0.4085, Accuracy: 0.7811\n",
      "Validation Loss: 1.1144, Validation Accuracy: 0.7669\n",
      "Epoch [98/250], Loss: 0.4486, Accuracy: 0.8000\n",
      "Validation Loss: 1.8193, Validation Accuracy: 0.5414\n",
      "Epoch [99/250], Loss: 0.5179, Accuracy: 0.7774\n",
      "Validation Loss: 1.1374, Validation Accuracy: 0.7519\n",
      "Epoch [100/250], Loss: 0.3809, Accuracy: 0.8226\n",
      "Validation Loss: 1.4345, Validation Accuracy: 0.6541\n",
      "Epoch [101/250], Loss: 0.4335, Accuracy: 0.8340\n",
      "Validation Loss: 1.6570, Validation Accuracy: 0.5639\n",
      "Epoch [102/250], Loss: 0.5294, Accuracy: 0.7962\n",
      "Validation Loss: 2.0430, Validation Accuracy: 0.5188\n",
      "Epoch [103/250], Loss: 0.3613, Accuracy: 0.8453\n",
      "Validation Loss: 1.2594, Validation Accuracy: 0.7519\n",
      "Epoch [104/250], Loss: 0.3464, Accuracy: 0.8415\n",
      "Validation Loss: 1.3888, Validation Accuracy: 0.7218\n",
      "Epoch [105/250], Loss: 0.3866, Accuracy: 0.8000\n",
      "Validation Loss: 1.2884, Validation Accuracy: 0.6767\n",
      "Epoch [106/250], Loss: 0.3894, Accuracy: 0.8113\n",
      "Validation Loss: 1.1657, Validation Accuracy: 0.6917\n",
      "Epoch [107/250], Loss: 0.3967, Accuracy: 0.7887\n",
      "Validation Loss: 1.1568, Validation Accuracy: 0.7519\n",
      "Epoch [108/250], Loss: 0.3952, Accuracy: 0.8491\n",
      "Validation Loss: 1.9851, Validation Accuracy: 0.5564\n",
      "Epoch [109/250], Loss: 0.4849, Accuracy: 0.8151\n",
      "Validation Loss: 1.2883, Validation Accuracy: 0.6767\n",
      "Epoch [110/250], Loss: 0.3367, Accuracy: 0.8566\n",
      "Validation Loss: 2.8282, Validation Accuracy: 0.4812\n",
      "Epoch [111/250], Loss: 0.3469, Accuracy: 0.8151\n",
      "Validation Loss: 1.8812, Validation Accuracy: 0.5564\n",
      "Epoch [112/250], Loss: 0.7043, Accuracy: 0.8377\n",
      "Validation Loss: 1.1973, Validation Accuracy: 0.7444\n",
      "Epoch [113/250], Loss: 0.4216, Accuracy: 0.8000\n",
      "Validation Loss: 1.5914, Validation Accuracy: 0.5113\n",
      "Epoch [114/250], Loss: 0.3823, Accuracy: 0.8453\n",
      "Validation Loss: 1.5513, Validation Accuracy: 0.5564\n",
      "Epoch [115/250], Loss: 0.4377, Accuracy: 0.8000\n",
      "Validation Loss: 2.7730, Validation Accuracy: 0.4812\n",
      "Epoch [116/250], Loss: 0.4615, Accuracy: 0.8528\n",
      "Validation Loss: 2.7985, Validation Accuracy: 0.4737\n",
      "Epoch [117/250], Loss: 0.4207, Accuracy: 0.8264\n",
      "Validation Loss: 1.1078, Validation Accuracy: 0.7820\n",
      "Epoch [118/250], Loss: 0.3991, Accuracy: 0.8151\n",
      "Validation Loss: 1.7650, Validation Accuracy: 0.5414\n",
      "Epoch [119/250], Loss: 0.4139, Accuracy: 0.8189\n",
      "Validation Loss: 2.4418, Validation Accuracy: 0.4962\n",
      "Epoch [120/250], Loss: 0.4578, Accuracy: 0.8189\n",
      "Validation Loss: 2.7140, Validation Accuracy: 0.4887\n",
      "Epoch [121/250], Loss: 0.3846, Accuracy: 0.8151\n",
      "Validation Loss: 2.8687, Validation Accuracy: 0.4887\n",
      "Epoch [122/250], Loss: 0.3459, Accuracy: 0.8340\n",
      "Validation Loss: 1.7363, Validation Accuracy: 0.6767\n",
      "Epoch [123/250], Loss: 0.3887, Accuracy: 0.8528\n",
      "Validation Loss: 1.6919, Validation Accuracy: 0.6241\n",
      "Epoch [124/250], Loss: 0.3640, Accuracy: 0.8226\n",
      "Validation Loss: 2.5141, Validation Accuracy: 0.5113\n",
      "Epoch [125/250], Loss: 0.3589, Accuracy: 0.8226\n",
      "Validation Loss: 2.8538, Validation Accuracy: 0.4887\n",
      "Epoch [126/250], Loss: 0.3382, Accuracy: 0.8491\n",
      "Validation Loss: 2.7626, Validation Accuracy: 0.5263\n",
      "Epoch [127/250], Loss: 0.3611, Accuracy: 0.8604\n",
      "Validation Loss: 2.2138, Validation Accuracy: 0.5414\n",
      "Epoch [128/250], Loss: 0.3991, Accuracy: 0.8264\n",
      "Validation Loss: 1.3120, Validation Accuracy: 0.7068\n",
      "Epoch [129/250], Loss: 0.3265, Accuracy: 0.8830\n",
      "Validation Loss: 2.9642, Validation Accuracy: 0.5038\n",
      "Epoch [130/250], Loss: 0.3985, Accuracy: 0.8491\n",
      "Validation Loss: 1.3901, Validation Accuracy: 0.6917\n",
      "Epoch [131/250], Loss: 0.3924, Accuracy: 0.8604\n",
      "Validation Loss: 1.2336, Validation Accuracy: 0.6992\n",
      "Epoch [132/250], Loss: 0.4637, Accuracy: 0.8113\n",
      "Validation Loss: 1.5690, Validation Accuracy: 0.6466\n",
      "Epoch [133/250], Loss: 0.3528, Accuracy: 0.8226\n",
      "Validation Loss: 1.1382, Validation Accuracy: 0.7143\n",
      "Epoch [134/250], Loss: 0.3303, Accuracy: 0.8679\n",
      "Validation Loss: 1.2649, Validation Accuracy: 0.7444\n",
      "Epoch [135/250], Loss: 0.2969, Accuracy: 0.8679\n",
      "Validation Loss: 2.1764, Validation Accuracy: 0.5714\n",
      "Epoch [136/250], Loss: 0.4958, Accuracy: 0.8415\n",
      "Validation Loss: 1.6814, Validation Accuracy: 0.5564\n",
      "Epoch [137/250], Loss: 0.4401, Accuracy: 0.7811\n",
      "Validation Loss: 1.1819, Validation Accuracy: 0.5865\n",
      "Epoch [138/250], Loss: 0.3315, Accuracy: 0.8377\n",
      "Validation Loss: 1.7756, Validation Accuracy: 0.5489\n",
      "Epoch [139/250], Loss: 0.3603, Accuracy: 0.8679\n",
      "Validation Loss: 1.8612, Validation Accuracy: 0.5414\n",
      "Epoch [140/250], Loss: 0.4006, Accuracy: 0.8302\n",
      "Validation Loss: 1.9594, Validation Accuracy: 0.5188\n",
      "Epoch [141/250], Loss: 0.4165, Accuracy: 0.8302\n",
      "Validation Loss: 1.0518, Validation Accuracy: 0.7970\n",
      "Epoch [142/250], Loss: 0.3753, Accuracy: 0.8453\n",
      "Validation Loss: 1.3108, Validation Accuracy: 0.7068\n",
      "Epoch [143/250], Loss: 0.3719, Accuracy: 0.8453\n",
      "Validation Loss: 1.6529, Validation Accuracy: 0.6316\n",
      "Epoch [144/250], Loss: 0.5411, Accuracy: 0.8189\n",
      "Validation Loss: 2.1139, Validation Accuracy: 0.5338\n",
      "Epoch [145/250], Loss: 0.4038, Accuracy: 0.8491\n",
      "Validation Loss: 2.3671, Validation Accuracy: 0.5038\n",
      "Epoch [146/250], Loss: 0.3220, Accuracy: 0.8566\n",
      "Validation Loss: 1.1441, Validation Accuracy: 0.7444\n",
      "Epoch [147/250], Loss: 0.3302, Accuracy: 0.8604\n",
      "Validation Loss: 1.2376, Validation Accuracy: 0.7218\n",
      "Epoch [148/250], Loss: 0.3547, Accuracy: 0.8377\n",
      "Validation Loss: 2.5730, Validation Accuracy: 0.4962\n",
      "Epoch [149/250], Loss: 0.3877, Accuracy: 0.8264\n",
      "Validation Loss: 2.4482, Validation Accuracy: 0.4962\n",
      "Epoch [150/250], Loss: 0.4244, Accuracy: 0.8226\n",
      "Validation Loss: 2.1471, Validation Accuracy: 0.5489\n",
      "Epoch [151/250], Loss: 0.4673, Accuracy: 0.8189\n",
      "Validation Loss: 1.2361, Validation Accuracy: 0.6917\n",
      "Epoch [152/250], Loss: 0.3801, Accuracy: 0.8226\n",
      "Validation Loss: 1.3697, Validation Accuracy: 0.6767\n",
      "Epoch [153/250], Loss: 0.2655, Accuracy: 0.8491\n",
      "Validation Loss: 1.2342, Validation Accuracy: 0.7669\n",
      "Epoch [154/250], Loss: 0.3738, Accuracy: 0.8679\n",
      "Validation Loss: 1.2953, Validation Accuracy: 0.7594\n",
      "Epoch [155/250], Loss: 0.3674, Accuracy: 0.8453\n",
      "Validation Loss: 2.4841, Validation Accuracy: 0.5113\n",
      "Epoch [156/250], Loss: 0.3597, Accuracy: 0.8415\n",
      "Validation Loss: 1.6501, Validation Accuracy: 0.6466\n",
      "Epoch [157/250], Loss: 0.3206, Accuracy: 0.8528\n",
      "Validation Loss: 1.4673, Validation Accuracy: 0.7068\n",
      "Epoch [158/250], Loss: 0.3914, Accuracy: 0.8943\n",
      "Validation Loss: 2.4505, Validation Accuracy: 0.5714\n",
      "Epoch [159/250], Loss: 0.3524, Accuracy: 0.8491\n",
      "Validation Loss: 1.2377, Validation Accuracy: 0.7068\n",
      "Epoch [160/250], Loss: 0.2998, Accuracy: 0.8792\n",
      "Validation Loss: 1.4902, Validation Accuracy: 0.7068\n",
      "Epoch [161/250], Loss: 0.2441, Accuracy: 0.8868\n",
      "Validation Loss: 1.6479, Validation Accuracy: 0.7293\n",
      "Epoch [162/250], Loss: 0.3414, Accuracy: 0.8226\n",
      "Validation Loss: 2.7533, Validation Accuracy: 0.5188\n",
      "Epoch [163/250], Loss: 0.3108, Accuracy: 0.8755\n",
      "Validation Loss: 1.8428, Validation Accuracy: 0.6466\n",
      "Epoch [164/250], Loss: 0.3555, Accuracy: 0.8604\n",
      "Validation Loss: 2.5403, Validation Accuracy: 0.5489\n",
      "Epoch [165/250], Loss: 0.3554, Accuracy: 0.8453\n",
      "Validation Loss: 1.4391, Validation Accuracy: 0.6692\n",
      "Epoch [166/250], Loss: 0.3820, Accuracy: 0.8528\n",
      "Validation Loss: 1.5942, Validation Accuracy: 0.6541\n",
      "Epoch [167/250], Loss: 0.3582, Accuracy: 0.8491\n",
      "Validation Loss: 1.6128, Validation Accuracy: 0.6541\n",
      "Epoch [168/250], Loss: 0.4041, Accuracy: 0.8717\n",
      "Validation Loss: 1.6002, Validation Accuracy: 0.6541\n",
      "Epoch [169/250], Loss: 0.4572, Accuracy: 0.8642\n",
      "Validation Loss: 2.6352, Validation Accuracy: 0.4962\n",
      "Epoch [170/250], Loss: 0.3388, Accuracy: 0.8679\n",
      "Validation Loss: 2.4619, Validation Accuracy: 0.5489\n",
      "Epoch [171/250], Loss: 0.3019, Accuracy: 0.8717\n",
      "Validation Loss: 1.4535, Validation Accuracy: 0.6466\n",
      "Epoch [172/250], Loss: 0.2895, Accuracy: 0.8755\n",
      "Validation Loss: 2.4815, Validation Accuracy: 0.5113\n",
      "Epoch [173/250], Loss: 0.2588, Accuracy: 0.8981\n",
      "Validation Loss: 1.4551, Validation Accuracy: 0.7895\n",
      "Epoch [174/250], Loss: 0.2666, Accuracy: 0.9094\n",
      "Validation Loss: 3.8972, Validation Accuracy: 0.4887\n",
      "Epoch [175/250], Loss: 0.4626, Accuracy: 0.8415\n",
      "Validation Loss: 1.4427, Validation Accuracy: 0.6917\n",
      "Epoch [176/250], Loss: 0.3849, Accuracy: 0.8340\n",
      "Validation Loss: 1.4146, Validation Accuracy: 0.6541\n",
      "Epoch [177/250], Loss: 0.2910, Accuracy: 0.8717\n",
      "Validation Loss: 1.1992, Validation Accuracy: 0.7744\n",
      "Epoch [178/250], Loss: 0.3672, Accuracy: 0.8264\n",
      "Validation Loss: 2.1302, Validation Accuracy: 0.5564\n",
      "Epoch [179/250], Loss: 0.3927, Accuracy: 0.8604\n",
      "Validation Loss: 2.7863, Validation Accuracy: 0.4887\n",
      "Epoch [180/250], Loss: 0.3111, Accuracy: 0.8755\n",
      "Validation Loss: 1.3313, Validation Accuracy: 0.6917\n",
      "Epoch [181/250], Loss: 0.3216, Accuracy: 0.8792\n",
      "Validation Loss: 1.7633, Validation Accuracy: 0.6316\n",
      "Epoch [182/250], Loss: 0.3411, Accuracy: 0.8453\n",
      "Validation Loss: 1.5291, Validation Accuracy: 0.6767\n",
      "Epoch [183/250], Loss: 0.2980, Accuracy: 0.8453\n",
      "Validation Loss: 1.3625, Validation Accuracy: 0.7218\n",
      "Epoch [184/250], Loss: 0.3829, Accuracy: 0.8642\n",
      "Validation Loss: 1.4948, Validation Accuracy: 0.7444\n",
      "Epoch [185/250], Loss: 0.3858, Accuracy: 0.8528\n",
      "Validation Loss: 1.2748, Validation Accuracy: 0.7820\n",
      "Epoch [186/250], Loss: 0.2584, Accuracy: 0.8792\n",
      "Validation Loss: 1.4012, Validation Accuracy: 0.6767\n",
      "Epoch [187/250], Loss: 0.2812, Accuracy: 0.8906\n",
      "Validation Loss: 1.5061, Validation Accuracy: 0.6842\n",
      "Epoch [188/250], Loss: 0.3441, Accuracy: 0.8717\n",
      "Validation Loss: 2.9257, Validation Accuracy: 0.5263\n",
      "Epoch [189/250], Loss: 0.3175, Accuracy: 0.8453\n",
      "Validation Loss: 1.2272, Validation Accuracy: 0.7218\n",
      "Epoch [190/250], Loss: 0.2490, Accuracy: 0.8943\n",
      "Validation Loss: 1.9910, Validation Accuracy: 0.6241\n",
      "Epoch [191/250], Loss: 0.2349, Accuracy: 0.9094\n",
      "Validation Loss: 1.4726, Validation Accuracy: 0.7594\n",
      "Epoch [192/250], Loss: 0.2803, Accuracy: 0.8679\n",
      "Validation Loss: 1.4221, Validation Accuracy: 0.8045\n",
      "Epoch [193/250], Loss: 0.3174, Accuracy: 0.8830\n",
      "Validation Loss: 2.6925, Validation Accuracy: 0.5263\n",
      "Epoch [194/250], Loss: 0.4022, Accuracy: 0.8755\n",
      "Validation Loss: 2.2584, Validation Accuracy: 0.5414\n",
      "Epoch [195/250], Loss: 0.3726, Accuracy: 0.8528\n",
      "Validation Loss: 1.4117, Validation Accuracy: 0.6466\n",
      "Epoch [196/250], Loss: 0.3810, Accuracy: 0.8528\n",
      "Validation Loss: 1.1992, Validation Accuracy: 0.7368\n",
      "Epoch [197/250], Loss: 0.3498, Accuracy: 0.8453\n",
      "Validation Loss: 1.3867, Validation Accuracy: 0.8120\n",
      "Epoch [198/250], Loss: 0.3985, Accuracy: 0.8302\n",
      "Validation Loss: 2.7524, Validation Accuracy: 0.5113\n",
      "Epoch [199/250], Loss: 0.3084, Accuracy: 0.8717\n",
      "Validation Loss: 2.6118, Validation Accuracy: 0.5113\n",
      "Epoch [200/250], Loss: 0.3499, Accuracy: 0.8868\n",
      "Validation Loss: 1.8814, Validation Accuracy: 0.5940\n",
      "Epoch [201/250], Loss: 0.2988, Accuracy: 0.8717\n",
      "Validation Loss: 2.2412, Validation Accuracy: 0.5714\n",
      "Epoch [202/250], Loss: 0.2747, Accuracy: 0.8868\n",
      "Validation Loss: 2.7264, Validation Accuracy: 0.5338\n",
      "Epoch [203/250], Loss: 0.3018, Accuracy: 0.8604\n",
      "Validation Loss: 3.6339, Validation Accuracy: 0.4887\n",
      "Epoch [204/250], Loss: 0.3129, Accuracy: 0.8604\n",
      "Validation Loss: 1.4453, Validation Accuracy: 0.7820\n",
      "Epoch [205/250], Loss: 0.2772, Accuracy: 0.8755\n",
      "Validation Loss: 2.1786, Validation Accuracy: 0.5338\n",
      "Epoch [206/250], Loss: 0.2660, Accuracy: 0.8981\n",
      "Validation Loss: 1.3284, Validation Accuracy: 0.7519\n",
      "Epoch [207/250], Loss: 0.3450, Accuracy: 0.8604\n",
      "Validation Loss: 1.4670, Validation Accuracy: 0.7519\n",
      "Epoch [208/250], Loss: 0.3289, Accuracy: 0.8566\n",
      "Validation Loss: 1.3338, Validation Accuracy: 0.7444\n",
      "Epoch [209/250], Loss: 0.2843, Accuracy: 0.8830\n",
      "Validation Loss: 1.8589, Validation Accuracy: 0.5940\n",
      "Epoch [210/250], Loss: 0.3476, Accuracy: 0.8830\n",
      "Validation Loss: 1.3859, Validation Accuracy: 0.7368\n",
      "Epoch [211/250], Loss: 0.3002, Accuracy: 0.8679\n",
      "Validation Loss: 3.0536, Validation Accuracy: 0.5038\n",
      "Epoch [212/250], Loss: 0.2961, Accuracy: 0.8642\n",
      "Validation Loss: 2.2611, Validation Accuracy: 0.5789\n",
      "Epoch [213/250], Loss: 0.2398, Accuracy: 0.8906\n",
      "Validation Loss: 1.7341, Validation Accuracy: 0.7143\n",
      "Epoch [214/250], Loss: 0.2471, Accuracy: 0.8755\n",
      "Validation Loss: 1.6508, Validation Accuracy: 0.7293\n",
      "Epoch [215/250], Loss: 0.2204, Accuracy: 0.9057\n",
      "Validation Loss: 1.5833, Validation Accuracy: 0.7519\n",
      "Epoch [216/250], Loss: 0.2677, Accuracy: 0.9094\n",
      "Validation Loss: 3.8398, Validation Accuracy: 0.4962\n",
      "Epoch [217/250], Loss: 0.2920, Accuracy: 0.8491\n",
      "Validation Loss: 3.3731, Validation Accuracy: 0.5188\n",
      "Epoch [218/250], Loss: 0.2450, Accuracy: 0.8943\n",
      "Validation Loss: 2.1867, Validation Accuracy: 0.6692\n",
      "Epoch [219/250], Loss: 0.2175, Accuracy: 0.9094\n",
      "Validation Loss: 1.7096, Validation Accuracy: 0.7068\n",
      "Epoch [220/250], Loss: 0.2451, Accuracy: 0.8981\n",
      "Validation Loss: 1.9660, Validation Accuracy: 0.6842\n",
      "Epoch [221/250], Loss: 0.2655, Accuracy: 0.8755\n",
      "Validation Loss: 1.4390, Validation Accuracy: 0.7594\n",
      "Epoch [222/250], Loss: 0.2433, Accuracy: 0.9019\n",
      "Validation Loss: 1.6137, Validation Accuracy: 0.8195\n",
      "Epoch [223/250], Loss: 0.3001, Accuracy: 0.8566\n",
      "Validation Loss: 2.9724, Validation Accuracy: 0.5414\n",
      "Epoch [224/250], Loss: 0.2353, Accuracy: 0.8981\n",
      "Validation Loss: 3.3874, Validation Accuracy: 0.5489\n",
      "Epoch [225/250], Loss: 0.2401, Accuracy: 0.9170\n",
      "Validation Loss: 3.6602, Validation Accuracy: 0.4962\n",
      "Epoch [226/250], Loss: 0.2359, Accuracy: 0.8868\n",
      "Validation Loss: 1.2249, Validation Accuracy: 0.7895\n",
      "Epoch [227/250], Loss: 0.3068, Accuracy: 0.8868\n",
      "Validation Loss: 2.1873, Validation Accuracy: 0.6165\n",
      "Epoch [228/250], Loss: 0.3072, Accuracy: 0.8830\n",
      "Validation Loss: 3.8882, Validation Accuracy: 0.4887\n",
      "Epoch [229/250], Loss: 0.2497, Accuracy: 0.8830\n",
      "Validation Loss: 3.6328, Validation Accuracy: 0.4962\n",
      "Epoch [230/250], Loss: 0.2815, Accuracy: 0.8642\n",
      "Validation Loss: 1.6036, Validation Accuracy: 0.7895\n",
      "Epoch [231/250], Loss: 0.2016, Accuracy: 0.9321\n",
      "Validation Loss: 4.0228, Validation Accuracy: 0.4962\n",
      "Epoch [232/250], Loss: 0.2622, Accuracy: 0.8679\n",
      "Validation Loss: 3.6931, Validation Accuracy: 0.5038\n",
      "Epoch [233/250], Loss: 0.2593, Accuracy: 0.8717\n",
      "Validation Loss: 1.9889, Validation Accuracy: 0.6466\n",
      "Epoch [234/250], Loss: 0.3456, Accuracy: 0.8981\n",
      "Validation Loss: 1.8956, Validation Accuracy: 0.5263\n",
      "Epoch [235/250], Loss: 0.3221, Accuracy: 0.8830\n",
      "Validation Loss: 1.4885, Validation Accuracy: 0.5714\n",
      "Epoch [236/250], Loss: 0.2934, Accuracy: 0.8642\n",
      "Validation Loss: 1.2077, Validation Accuracy: 0.7669\n",
      "Epoch [237/250], Loss: 0.3044, Accuracy: 0.8679\n",
      "Validation Loss: 1.9249, Validation Accuracy: 0.5789\n",
      "Epoch [238/250], Loss: 0.2634, Accuracy: 0.8981\n",
      "Validation Loss: 2.8928, Validation Accuracy: 0.5113\n",
      "Epoch [239/250], Loss: 0.2560, Accuracy: 0.8755\n",
      "Validation Loss: 1.4121, Validation Accuracy: 0.7519\n",
      "Epoch [240/250], Loss: 0.3080, Accuracy: 0.8717\n",
      "Validation Loss: 1.5647, Validation Accuracy: 0.7820\n",
      "Epoch [241/250], Loss: 0.2165, Accuracy: 0.9019\n",
      "Validation Loss: 3.5297, Validation Accuracy: 0.5263\n",
      "Epoch [242/250], Loss: 0.2777, Accuracy: 0.8792\n",
      "Validation Loss: 3.9401, Validation Accuracy: 0.4887\n",
      "Epoch [243/250], Loss: 0.2927, Accuracy: 0.8755\n",
      "Validation Loss: 3.9397, Validation Accuracy: 0.4887\n",
      "Epoch [244/250], Loss: 0.2855, Accuracy: 0.8868\n",
      "Validation Loss: 2.6478, Validation Accuracy: 0.5263\n",
      "Epoch [245/250], Loss: 0.3628, Accuracy: 0.8642\n",
      "Validation Loss: 2.4881, Validation Accuracy: 0.5865\n",
      "Epoch [246/250], Loss: 0.2564, Accuracy: 0.8830\n",
      "Validation Loss: 1.8374, Validation Accuracy: 0.6316\n",
      "Epoch [247/250], Loss: 0.2031, Accuracy: 0.9283\n",
      "Validation Loss: 2.2448, Validation Accuracy: 0.5714\n",
      "Epoch [248/250], Loss: 0.2039, Accuracy: 0.9132\n",
      "Validation Loss: 2.5387, Validation Accuracy: 0.5564\n",
      "Epoch [249/250], Loss: 0.2635, Accuracy: 0.8943\n",
      "Validation Loss: 1.7975, Validation Accuracy: 0.7068\n",
      "Epoch [250/250], Loss: 0.2861, Accuracy: 0.8755\n",
      "Validation Loss: 1.3923, Validation Accuracy: 0.7293\n",
      "Test Loss: 0.9062\n",
      "Test Accuracy: 0.7576\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 113\n",
      "label 1 is 40\n",
      "label 2 is 30\n",
      "label 3 is 25\n",
      "Not setting metadata\n",
      "208 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (218, 8, 325)\n",
      "218 train samples\n",
      "109 test samples\n",
      "Number of batches in train_loader: 4\n",
      "{-1: 0.956140350877193, 0: 1.0480769230769231}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.3631, Accuracy: 0.2706\n",
      "Validation Loss: 1.1225, Validation Accuracy: 0.4037\n",
      "Epoch [2/250], Loss: 1.1396, Accuracy: 0.4954\n",
      "Validation Loss: 0.9972, Validation Accuracy: 0.4037\n",
      "Epoch [3/250], Loss: 0.9662, Accuracy: 0.5138\n",
      "Validation Loss: 0.8860, Validation Accuracy: 0.4037\n",
      "Epoch [4/250], Loss: 0.8522, Accuracy: 0.5550\n",
      "Validation Loss: 0.7683, Validation Accuracy: 0.4037\n",
      "Epoch [5/250], Loss: 0.7895, Accuracy: 0.5459\n",
      "Validation Loss: 0.7825, Validation Accuracy: 0.4037\n",
      "Epoch [6/250], Loss: 0.7854, Accuracy: 0.5229\n",
      "Validation Loss: 0.8038, Validation Accuracy: 0.4037\n",
      "Epoch [7/250], Loss: 0.8190, Accuracy: 0.5092\n",
      "Validation Loss: 0.8022, Validation Accuracy: 0.4037\n",
      "Epoch [8/250], Loss: 0.7717, Accuracy: 0.5138\n",
      "Validation Loss: 0.8271, Validation Accuracy: 0.4037\n",
      "Epoch [9/250], Loss: 0.7818, Accuracy: 0.5183\n",
      "Validation Loss: 0.8700, Validation Accuracy: 0.4037\n",
      "Epoch [10/250], Loss: 0.7643, Accuracy: 0.5413\n",
      "Validation Loss: 0.8450, Validation Accuracy: 0.4037\n",
      "Epoch [11/250], Loss: 0.7815, Accuracy: 0.5550\n",
      "Validation Loss: 0.8812, Validation Accuracy: 0.4037\n",
      "Epoch [12/250], Loss: 0.7382, Accuracy: 0.5642\n",
      "Validation Loss: 0.8937, Validation Accuracy: 0.4037\n",
      "Epoch [13/250], Loss: 0.6831, Accuracy: 0.6560\n",
      "Validation Loss: 1.0480, Validation Accuracy: 0.4037\n",
      "Epoch [14/250], Loss: 0.7155, Accuracy: 0.5917\n",
      "Validation Loss: 1.3765, Validation Accuracy: 0.4037\n",
      "Epoch [15/250], Loss: 0.6566, Accuracy: 0.6560\n",
      "Validation Loss: 1.3860, Validation Accuracy: 0.4037\n",
      "Epoch [16/250], Loss: 0.5680, Accuracy: 0.6972\n",
      "Validation Loss: 2.1381, Validation Accuracy: 0.4037\n",
      "Epoch [17/250], Loss: 0.5387, Accuracy: 0.7156\n",
      "Validation Loss: 2.3807, Validation Accuracy: 0.4037\n",
      "Epoch [18/250], Loss: 0.5299, Accuracy: 0.7798\n",
      "Validation Loss: 2.0880, Validation Accuracy: 0.4128\n",
      "Epoch [19/250], Loss: 0.4548, Accuracy: 0.8211\n",
      "Validation Loss: 1.9957, Validation Accuracy: 0.4128\n",
      "Epoch [20/250], Loss: 0.4129, Accuracy: 0.8486\n",
      "Validation Loss: 2.1387, Validation Accuracy: 0.4312\n",
      "Epoch [21/250], Loss: 0.3110, Accuracy: 0.8991\n",
      "Validation Loss: 3.1468, Validation Accuracy: 0.4128\n",
      "Epoch [22/250], Loss: 0.3267, Accuracy: 0.8945\n",
      "Validation Loss: 0.6291, Validation Accuracy: 0.7890\n",
      "Epoch [23/250], Loss: 0.2525, Accuracy: 0.9037\n",
      "Validation Loss: 2.2820, Validation Accuracy: 0.5321\n",
      "Epoch [24/250], Loss: 0.4297, Accuracy: 0.8624\n",
      "Validation Loss: 3.1917, Validation Accuracy: 0.4404\n",
      "Epoch [25/250], Loss: 0.3194, Accuracy: 0.8761\n",
      "Validation Loss: 2.3799, Validation Accuracy: 0.5229\n",
      "Epoch [26/250], Loss: 0.2678, Accuracy: 0.9037\n",
      "Validation Loss: 0.5665, Validation Accuracy: 0.8165\n",
      "Epoch [27/250], Loss: 0.1970, Accuracy: 0.9220\n",
      "Validation Loss: 3.3525, Validation Accuracy: 0.5046\n",
      "Epoch [28/250], Loss: 0.2748, Accuracy: 0.9037\n",
      "Validation Loss: 4.4710, Validation Accuracy: 0.4128\n",
      "Epoch [29/250], Loss: 0.2267, Accuracy: 0.9174\n",
      "Validation Loss: 2.9360, Validation Accuracy: 0.5413\n",
      "Epoch [30/250], Loss: 0.2089, Accuracy: 0.9450\n",
      "Validation Loss: 1.9345, Validation Accuracy: 0.6972\n",
      "Epoch [31/250], Loss: 0.2472, Accuracy: 0.9083\n",
      "Validation Loss: 3.4956, Validation Accuracy: 0.4862\n",
      "Epoch [32/250], Loss: 0.1941, Accuracy: 0.9404\n",
      "Validation Loss: 0.8070, Validation Accuracy: 0.8073\n",
      "Epoch [33/250], Loss: 0.2140, Accuracy: 0.9358\n",
      "Validation Loss: 3.0309, Validation Accuracy: 0.5780\n",
      "Epoch [34/250], Loss: 0.1810, Accuracy: 0.9358\n",
      "Validation Loss: 3.5741, Validation Accuracy: 0.5229\n",
      "Epoch [35/250], Loss: 0.2578, Accuracy: 0.9220\n",
      "Validation Loss: 2.9990, Validation Accuracy: 0.5596\n",
      "Epoch [36/250], Loss: 0.2138, Accuracy: 0.9083\n",
      "Validation Loss: 1.6417, Validation Accuracy: 0.7156\n",
      "Epoch [37/250], Loss: 0.2137, Accuracy: 0.9174\n",
      "Validation Loss: 0.4192, Validation Accuracy: 0.8807\n",
      "Epoch [38/250], Loss: 0.1894, Accuracy: 0.9450\n",
      "Validation Loss: 1.8004, Validation Accuracy: 0.6789\n",
      "Epoch [39/250], Loss: 0.2522, Accuracy: 0.8899\n",
      "Validation Loss: 0.5165, Validation Accuracy: 0.8807\n",
      "Epoch [40/250], Loss: 0.2175, Accuracy: 0.9128\n",
      "Validation Loss: 0.3114, Validation Accuracy: 0.9083\n",
      "Epoch [41/250], Loss: 0.1537, Accuracy: 0.9404\n",
      "Validation Loss: 0.4858, Validation Accuracy: 0.9083\n",
      "Epoch [42/250], Loss: 0.2233, Accuracy: 0.9174\n",
      "Validation Loss: 0.4617, Validation Accuracy: 0.9083\n",
      "Epoch [43/250], Loss: 0.2464, Accuracy: 0.8991\n",
      "Validation Loss: 1.7580, Validation Accuracy: 0.6972\n",
      "Epoch [44/250], Loss: 0.1339, Accuracy: 0.9450\n",
      "Validation Loss: 2.7670, Validation Accuracy: 0.5872\n",
      "Epoch [45/250], Loss: 0.2237, Accuracy: 0.9358\n",
      "Validation Loss: 0.3283, Validation Accuracy: 0.9266\n",
      "Epoch [46/250], Loss: 0.1954, Accuracy: 0.9312\n",
      "Validation Loss: 0.6348, Validation Accuracy: 0.8165\n",
      "Epoch [47/250], Loss: 0.2231, Accuracy: 0.9358\n",
      "Validation Loss: 1.4743, Validation Accuracy: 0.6972\n",
      "Epoch [48/250], Loss: 0.2068, Accuracy: 0.9220\n",
      "Validation Loss: 0.3386, Validation Accuracy: 0.9083\n",
      "Epoch [49/250], Loss: 0.2222, Accuracy: 0.9312\n",
      "Validation Loss: 0.4577, Validation Accuracy: 0.8899\n",
      "Epoch [50/250], Loss: 0.1369, Accuracy: 0.9358\n",
      "Validation Loss: 0.2674, Validation Accuracy: 0.9358\n",
      "Epoch [51/250], Loss: 0.1265, Accuracy: 0.9633\n",
      "Validation Loss: 0.8039, Validation Accuracy: 0.8440\n",
      "Epoch [52/250], Loss: 0.2292, Accuracy: 0.9358\n",
      "Validation Loss: 2.2873, Validation Accuracy: 0.6239\n",
      "Epoch [53/250], Loss: 0.1450, Accuracy: 0.9495\n",
      "Validation Loss: 1.3146, Validation Accuracy: 0.7523\n",
      "Epoch [54/250], Loss: 0.1860, Accuracy: 0.9404\n",
      "Validation Loss: 0.5497, Validation Accuracy: 0.8807\n",
      "Epoch [55/250], Loss: 0.2192, Accuracy: 0.9174\n",
      "Validation Loss: 2.1278, Validation Accuracy: 0.6514\n",
      "Epoch [56/250], Loss: 0.1531, Accuracy: 0.9587\n",
      "Validation Loss: 2.8512, Validation Accuracy: 0.5963\n",
      "Epoch [57/250], Loss: 0.1778, Accuracy: 0.9266\n",
      "Validation Loss: 2.2190, Validation Accuracy: 0.6789\n",
      "Epoch [58/250], Loss: 0.1210, Accuracy: 0.9541\n",
      "Validation Loss: 2.9983, Validation Accuracy: 0.5963\n",
      "Epoch [59/250], Loss: 0.1567, Accuracy: 0.9450\n",
      "Validation Loss: 2.8930, Validation Accuracy: 0.5963\n",
      "Epoch [60/250], Loss: 0.1653, Accuracy: 0.9312\n",
      "Validation Loss: 3.2315, Validation Accuracy: 0.5963\n",
      "Epoch [61/250], Loss: 0.1259, Accuracy: 0.9541\n",
      "Validation Loss: 3.2835, Validation Accuracy: 0.5963\n",
      "Epoch [62/250], Loss: 0.1207, Accuracy: 0.9450\n",
      "Validation Loss: 0.8533, Validation Accuracy: 0.8165\n",
      "Epoch [63/250], Loss: 0.1134, Accuracy: 0.9495\n",
      "Validation Loss: 0.4071, Validation Accuracy: 0.9083\n",
      "Epoch [64/250], Loss: 0.1297, Accuracy: 0.9358\n",
      "Validation Loss: 0.5366, Validation Accuracy: 0.8899\n",
      "Epoch [65/250], Loss: 0.1162, Accuracy: 0.9404\n",
      "Validation Loss: 0.3187, Validation Accuracy: 0.9266\n",
      "Epoch [66/250], Loss: 0.1291, Accuracy: 0.9450\n",
      "Validation Loss: 0.5001, Validation Accuracy: 0.9083\n",
      "Epoch [67/250], Loss: 0.1125, Accuracy: 0.9679\n",
      "Validation Loss: 0.3471, Validation Accuracy: 0.9266\n",
      "Epoch [68/250], Loss: 0.1363, Accuracy: 0.9633\n",
      "Validation Loss: 0.4152, Validation Accuracy: 0.9266\n",
      "Epoch [69/250], Loss: 0.1515, Accuracy: 0.9358\n",
      "Validation Loss: 3.2474, Validation Accuracy: 0.5596\n",
      "Epoch [70/250], Loss: 0.1024, Accuracy: 0.9633\n",
      "Validation Loss: 1.8744, Validation Accuracy: 0.6972\n",
      "Epoch [71/250], Loss: 0.0795, Accuracy: 0.9771\n",
      "Validation Loss: 0.7113, Validation Accuracy: 0.8624\n",
      "Epoch [72/250], Loss: 0.1141, Accuracy: 0.9679\n",
      "Validation Loss: 0.3808, Validation Accuracy: 0.9174\n",
      "Epoch [73/250], Loss: 0.0925, Accuracy: 0.9541\n",
      "Validation Loss: 1.0947, Validation Accuracy: 0.7706\n",
      "Epoch [74/250], Loss: 0.1101, Accuracy: 0.9633\n",
      "Validation Loss: 0.6369, Validation Accuracy: 0.8807\n",
      "Epoch [75/250], Loss: 0.1141, Accuracy: 0.9495\n",
      "Validation Loss: 3.7659, Validation Accuracy: 0.5413\n",
      "Epoch [76/250], Loss: 0.1941, Accuracy: 0.9266\n",
      "Validation Loss: 1.8627, Validation Accuracy: 0.6881\n",
      "Epoch [77/250], Loss: 0.1474, Accuracy: 0.9541\n",
      "Validation Loss: 1.7718, Validation Accuracy: 0.6789\n",
      "Epoch [78/250], Loss: 0.1093, Accuracy: 0.9771\n",
      "Validation Loss: 0.6046, Validation Accuracy: 0.8716\n",
      "Epoch [79/250], Loss: 0.1598, Accuracy: 0.9633\n",
      "Validation Loss: 1.7560, Validation Accuracy: 0.7156\n",
      "Epoch [80/250], Loss: 0.1047, Accuracy: 0.9633\n",
      "Validation Loss: 0.3359, Validation Accuracy: 0.9358\n",
      "Epoch [81/250], Loss: 0.1014, Accuracy: 0.9541\n",
      "Validation Loss: 0.4434, Validation Accuracy: 0.9174\n",
      "Epoch [82/250], Loss: 0.1680, Accuracy: 0.9679\n",
      "Validation Loss: 0.4200, Validation Accuracy: 0.9174\n",
      "Epoch [83/250], Loss: 0.1324, Accuracy: 0.9541\n",
      "Validation Loss: 1.1472, Validation Accuracy: 0.7890\n",
      "Epoch [84/250], Loss: 0.0894, Accuracy: 0.9633\n",
      "Validation Loss: 0.3657, Validation Accuracy: 0.9266\n",
      "Epoch [85/250], Loss: 0.2031, Accuracy: 0.9358\n",
      "Validation Loss: 0.6743, Validation Accuracy: 0.8440\n",
      "Epoch [86/250], Loss: 0.1414, Accuracy: 0.9358\n",
      "Validation Loss: 2.2265, Validation Accuracy: 0.6330\n",
      "Epoch [87/250], Loss: 0.1463, Accuracy: 0.9358\n",
      "Validation Loss: 2.3711, Validation Accuracy: 0.5963\n",
      "Epoch [88/250], Loss: 0.0727, Accuracy: 0.9817\n",
      "Validation Loss: 1.9033, Validation Accuracy: 0.6881\n",
      "Epoch [89/250], Loss: 0.0871, Accuracy: 0.9679\n",
      "Validation Loss: 0.7357, Validation Accuracy: 0.8440\n",
      "Epoch [90/250], Loss: 0.0892, Accuracy: 0.9817\n",
      "Validation Loss: 1.3344, Validation Accuracy: 0.7248\n",
      "Epoch [91/250], Loss: 0.1985, Accuracy: 0.9587\n",
      "Validation Loss: 0.3470, Validation Accuracy: 0.9266\n",
      "Epoch [92/250], Loss: 0.1393, Accuracy: 0.9312\n",
      "Validation Loss: 0.3511, Validation Accuracy: 0.9266\n",
      "Epoch [93/250], Loss: 0.0893, Accuracy: 0.9725\n",
      "Validation Loss: 3.1569, Validation Accuracy: 0.5596\n",
      "Epoch [94/250], Loss: 0.0866, Accuracy: 0.9771\n",
      "Validation Loss: 0.8328, Validation Accuracy: 0.8440\n",
      "Epoch [95/250], Loss: 0.0774, Accuracy: 0.9862\n",
      "Validation Loss: 0.8683, Validation Accuracy: 0.8349\n",
      "Epoch [96/250], Loss: 0.1367, Accuracy: 0.9633\n",
      "Validation Loss: 0.2484, Validation Accuracy: 0.9450\n",
      "Epoch [97/250], Loss: 0.1003, Accuracy: 0.9725\n",
      "Validation Loss: 0.2809, Validation Accuracy: 0.9450\n",
      "Epoch [98/250], Loss: 0.1165, Accuracy: 0.9633\n",
      "Validation Loss: 0.2746, Validation Accuracy: 0.9266\n",
      "Epoch [99/250], Loss: 0.0755, Accuracy: 0.9725\n",
      "Validation Loss: 1.9456, Validation Accuracy: 0.6789\n",
      "Epoch [100/250], Loss: 0.1019, Accuracy: 0.9587\n",
      "Validation Loss: 3.8357, Validation Accuracy: 0.5963\n",
      "Epoch [101/250], Loss: 0.1113, Accuracy: 0.9725\n",
      "Validation Loss: 2.6392, Validation Accuracy: 0.6330\n",
      "Epoch [102/250], Loss: 0.0903, Accuracy: 0.9771\n",
      "Validation Loss: 0.2731, Validation Accuracy: 0.9450\n",
      "Epoch [103/250], Loss: 0.1191, Accuracy: 0.9587\n",
      "Validation Loss: 0.3244, Validation Accuracy: 0.9541\n",
      "Epoch [104/250], Loss: 0.0693, Accuracy: 0.9817\n",
      "Validation Loss: 0.5881, Validation Accuracy: 0.8991\n",
      "Epoch [105/250], Loss: 0.0790, Accuracy: 0.9587\n",
      "Validation Loss: 0.3953, Validation Accuracy: 0.9266\n",
      "Epoch [106/250], Loss: 0.0726, Accuracy: 0.9679\n",
      "Validation Loss: 0.3628, Validation Accuracy: 0.9174\n",
      "Epoch [107/250], Loss: 0.0566, Accuracy: 0.9817\n",
      "Validation Loss: 0.4054, Validation Accuracy: 0.9358\n",
      "Epoch [108/250], Loss: 0.0599, Accuracy: 0.9817\n",
      "Validation Loss: 1.0062, Validation Accuracy: 0.8165\n",
      "Epoch [109/250], Loss: 0.1228, Accuracy: 0.9679\n",
      "Validation Loss: 0.8913, Validation Accuracy: 0.8440\n",
      "Epoch [110/250], Loss: 0.0863, Accuracy: 0.9587\n",
      "Validation Loss: 0.6629, Validation Accuracy: 0.8899\n",
      "Epoch [111/250], Loss: 0.0421, Accuracy: 0.9862\n",
      "Validation Loss: 3.0284, Validation Accuracy: 0.6239\n",
      "Epoch [112/250], Loss: 0.0742, Accuracy: 0.9908\n",
      "Validation Loss: 2.8766, Validation Accuracy: 0.6606\n",
      "Epoch [113/250], Loss: 0.0485, Accuracy: 0.9817\n",
      "Validation Loss: 0.6335, Validation Accuracy: 0.8991\n",
      "Epoch [114/250], Loss: 0.1016, Accuracy: 0.9541\n",
      "Validation Loss: 0.3675, Validation Accuracy: 0.9358\n",
      "Epoch [115/250], Loss: 0.1030, Accuracy: 0.9725\n",
      "Validation Loss: 0.3059, Validation Accuracy: 0.9358\n",
      "Epoch [116/250], Loss: 0.1088, Accuracy: 0.9587\n",
      "Validation Loss: 2.5728, Validation Accuracy: 0.6055\n",
      "Epoch [117/250], Loss: 0.0822, Accuracy: 0.9771\n",
      "Validation Loss: 1.9494, Validation Accuracy: 0.6789\n",
      "Epoch [118/250], Loss: 0.0790, Accuracy: 0.9817\n",
      "Validation Loss: 0.4738, Validation Accuracy: 0.9174\n",
      "Epoch [119/250], Loss: 0.0802, Accuracy: 0.9633\n",
      "Validation Loss: 3.6256, Validation Accuracy: 0.6055\n",
      "Epoch [120/250], Loss: 0.0446, Accuracy: 0.9954\n",
      "Validation Loss: 1.6666, Validation Accuracy: 0.7339\n",
      "Epoch [121/250], Loss: 0.1322, Accuracy: 0.9495\n",
      "Validation Loss: 0.8138, Validation Accuracy: 0.8349\n",
      "Epoch [122/250], Loss: 0.0699, Accuracy: 0.9725\n",
      "Validation Loss: 0.4068, Validation Accuracy: 0.9358\n",
      "Epoch [123/250], Loss: 0.0419, Accuracy: 0.9862\n",
      "Validation Loss: 0.3558, Validation Accuracy: 0.9450\n",
      "Epoch [124/250], Loss: 0.0392, Accuracy: 0.9862\n",
      "Validation Loss: 0.8019, Validation Accuracy: 0.8899\n",
      "Epoch [125/250], Loss: 0.0631, Accuracy: 0.9771\n",
      "Validation Loss: 0.9077, Validation Accuracy: 0.8716\n",
      "Epoch [126/250], Loss: 0.1387, Accuracy: 0.9587\n",
      "Validation Loss: 4.7798, Validation Accuracy: 0.4862\n",
      "Epoch [127/250], Loss: 0.0663, Accuracy: 0.9725\n",
      "Validation Loss: 1.8360, Validation Accuracy: 0.7339\n",
      "Epoch [128/250], Loss: 0.0636, Accuracy: 0.9817\n",
      "Validation Loss: 1.1173, Validation Accuracy: 0.8165\n",
      "Epoch [129/250], Loss: 0.0882, Accuracy: 0.9771\n",
      "Validation Loss: 3.4716, Validation Accuracy: 0.6055\n",
      "Epoch [130/250], Loss: 0.1068, Accuracy: 0.9541\n",
      "Validation Loss: 3.0076, Validation Accuracy: 0.6330\n",
      "Epoch [131/250], Loss: 0.0836, Accuracy: 0.9679\n",
      "Validation Loss: 2.0585, Validation Accuracy: 0.7248\n",
      "Epoch [132/250], Loss: 0.0814, Accuracy: 0.9725\n",
      "Validation Loss: 2.7839, Validation Accuracy: 0.6789\n",
      "Epoch [133/250], Loss: 0.0664, Accuracy: 0.9817\n",
      "Validation Loss: 0.2882, Validation Accuracy: 0.9541\n",
      "Epoch [134/250], Loss: 0.0620, Accuracy: 0.9771\n",
      "Validation Loss: 4.1242, Validation Accuracy: 0.6055\n",
      "Epoch [135/250], Loss: 0.0500, Accuracy: 0.9771\n",
      "Validation Loss: 0.4236, Validation Accuracy: 0.9358\n",
      "Epoch [136/250], Loss: 0.1066, Accuracy: 0.9725\n",
      "Validation Loss: 0.4208, Validation Accuracy: 0.9450\n",
      "Epoch [137/250], Loss: 0.0747, Accuracy: 0.9725\n",
      "Validation Loss: 1.1324, Validation Accuracy: 0.7248\n",
      "Epoch [138/250], Loss: 0.0322, Accuracy: 0.9862\n",
      "Validation Loss: 0.8847, Validation Accuracy: 0.8257\n",
      "Epoch [139/250], Loss: 0.0405, Accuracy: 0.9771\n",
      "Validation Loss: 1.8599, Validation Accuracy: 0.6972\n",
      "Epoch [140/250], Loss: 0.0542, Accuracy: 0.9817\n",
      "Validation Loss: 1.2081, Validation Accuracy: 0.7890\n",
      "Epoch [141/250], Loss: 0.0510, Accuracy: 0.9725\n",
      "Validation Loss: 4.2853, Validation Accuracy: 0.5963\n",
      "Epoch [142/250], Loss: 0.0659, Accuracy: 0.9725\n",
      "Validation Loss: 0.9299, Validation Accuracy: 0.8624\n",
      "Epoch [143/250], Loss: 0.0527, Accuracy: 0.9862\n",
      "Validation Loss: 0.6119, Validation Accuracy: 0.9174\n",
      "Epoch [144/250], Loss: 0.0419, Accuracy: 0.9908\n",
      "Validation Loss: 0.3254, Validation Accuracy: 0.9541\n",
      "Epoch [145/250], Loss: 0.0334, Accuracy: 0.9817\n",
      "Validation Loss: 4.6512, Validation Accuracy: 0.5963\n",
      "Epoch [146/250], Loss: 0.0780, Accuracy: 0.9725\n",
      "Validation Loss: 4.7214, Validation Accuracy: 0.5963\n",
      "Epoch [147/250], Loss: 0.0647, Accuracy: 0.9771\n",
      "Validation Loss: 4.1364, Validation Accuracy: 0.5963\n",
      "Epoch [148/250], Loss: 0.0429, Accuracy: 0.9817\n",
      "Validation Loss: 2.0087, Validation Accuracy: 0.6972\n",
      "Epoch [149/250], Loss: 0.0925, Accuracy: 0.9908\n",
      "Validation Loss: 0.3980, Validation Accuracy: 0.9450\n",
      "Epoch [150/250], Loss: 0.1108, Accuracy: 0.9862\n",
      "Validation Loss: 0.3706, Validation Accuracy: 0.9450\n",
      "Epoch [151/250], Loss: 0.0705, Accuracy: 0.9771\n",
      "Validation Loss: 0.6783, Validation Accuracy: 0.8440\n",
      "Epoch [152/250], Loss: 0.0471, Accuracy: 0.9862\n",
      "Validation Loss: 3.1646, Validation Accuracy: 0.6147\n",
      "Epoch [153/250], Loss: 0.0759, Accuracy: 0.9817\n",
      "Validation Loss: 3.4578, Validation Accuracy: 0.5872\n",
      "Epoch [154/250], Loss: 0.0554, Accuracy: 0.9817\n",
      "Validation Loss: 1.9917, Validation Accuracy: 0.7431\n",
      "Epoch [155/250], Loss: 0.0470, Accuracy: 0.9817\n",
      "Validation Loss: 4.8305, Validation Accuracy: 0.5138\n",
      "Epoch [156/250], Loss: 0.0697, Accuracy: 0.9771\n",
      "Validation Loss: 3.3667, Validation Accuracy: 0.6330\n",
      "Epoch [157/250], Loss: 0.0894, Accuracy: 0.9817\n",
      "Validation Loss: 0.7401, Validation Accuracy: 0.8899\n",
      "Epoch [158/250], Loss: 0.0957, Accuracy: 0.9633\n",
      "Validation Loss: 1.4551, Validation Accuracy: 0.7890\n",
      "Epoch [159/250], Loss: 0.0808, Accuracy: 0.9725\n",
      "Validation Loss: 1.7862, Validation Accuracy: 0.7156\n",
      "Epoch [160/250], Loss: 0.0434, Accuracy: 0.9771\n",
      "Validation Loss: 2.3799, Validation Accuracy: 0.7156\n",
      "Epoch [161/250], Loss: 0.0541, Accuracy: 0.9725\n",
      "Validation Loss: 2.8936, Validation Accuracy: 0.6606\n",
      "Epoch [162/250], Loss: 0.0572, Accuracy: 0.9817\n",
      "Validation Loss: 0.4498, Validation Accuracy: 0.9174\n",
      "Epoch [163/250], Loss: 0.0425, Accuracy: 0.9908\n",
      "Validation Loss: 0.3890, Validation Accuracy: 0.9358\n",
      "Epoch [164/250], Loss: 0.0587, Accuracy: 0.9771\n",
      "Validation Loss: 0.5311, Validation Accuracy: 0.9083\n",
      "Epoch [165/250], Loss: 0.0810, Accuracy: 0.9862\n",
      "Validation Loss: 1.5793, Validation Accuracy: 0.7706\n",
      "Epoch [166/250], Loss: 0.0547, Accuracy: 0.9679\n",
      "Validation Loss: 1.0315, Validation Accuracy: 0.8440\n",
      "Epoch [167/250], Loss: 0.0220, Accuracy: 0.9908\n",
      "Validation Loss: 0.4019, Validation Accuracy: 0.9174\n",
      "Epoch [168/250], Loss: 0.1293, Accuracy: 0.9725\n",
      "Validation Loss: 3.7053, Validation Accuracy: 0.5963\n",
      "Epoch [169/250], Loss: 0.1103, Accuracy: 0.9633\n",
      "Validation Loss: 4.6338, Validation Accuracy: 0.5963\n",
      "Epoch [170/250], Loss: 0.0424, Accuracy: 0.9908\n",
      "Validation Loss: 3.8034, Validation Accuracy: 0.5963\n",
      "Epoch [171/250], Loss: 0.0315, Accuracy: 0.9908\n",
      "Validation Loss: 1.5233, Validation Accuracy: 0.7156\n",
      "Epoch [172/250], Loss: 0.0421, Accuracy: 0.9862\n",
      "Validation Loss: 0.8448, Validation Accuracy: 0.8440\n",
      "Epoch [173/250], Loss: 0.0198, Accuracy: 0.9954\n",
      "Validation Loss: 2.8251, Validation Accuracy: 0.6789\n",
      "Epoch [174/250], Loss: 0.0835, Accuracy: 0.9862\n",
      "Validation Loss: 2.4676, Validation Accuracy: 0.6697\n",
      "Epoch [175/250], Loss: 0.0241, Accuracy: 0.9954\n",
      "Validation Loss: 2.2898, Validation Accuracy: 0.6789\n",
      "Epoch [176/250], Loss: 0.0195, Accuracy: 0.9954\n",
      "Validation Loss: 1.8054, Validation Accuracy: 0.7248\n",
      "Epoch [177/250], Loss: 0.0259, Accuracy: 0.9862\n",
      "Validation Loss: 1.5821, Validation Accuracy: 0.7982\n",
      "Epoch [178/250], Loss: 0.0372, Accuracy: 0.9862\n",
      "Validation Loss: 0.3794, Validation Accuracy: 0.9541\n",
      "Epoch [179/250], Loss: 0.0663, Accuracy: 0.9771\n",
      "Validation Loss: 0.7634, Validation Accuracy: 0.8716\n",
      "Epoch [180/250], Loss: 0.0389, Accuracy: 0.9862\n",
      "Validation Loss: 0.3540, Validation Accuracy: 0.9174\n",
      "Epoch [181/250], Loss: 0.0162, Accuracy: 0.9954\n",
      "Validation Loss: 0.4543, Validation Accuracy: 0.9174\n",
      "Epoch [182/250], Loss: 0.0290, Accuracy: 0.9862\n",
      "Validation Loss: 0.9726, Validation Accuracy: 0.8440\n",
      "Epoch [183/250], Loss: 0.0524, Accuracy: 0.9862\n",
      "Validation Loss: 1.1984, Validation Accuracy: 0.8257\n",
      "Epoch [184/250], Loss: 0.0296, Accuracy: 0.9908\n",
      "Validation Loss: 0.6507, Validation Accuracy: 0.8991\n",
      "Epoch [185/250], Loss: 0.0157, Accuracy: 0.9954\n",
      "Validation Loss: 0.4441, Validation Accuracy: 0.9450\n",
      "Epoch [186/250], Loss: 0.0286, Accuracy: 0.9908\n",
      "Validation Loss: 1.0862, Validation Accuracy: 0.8716\n",
      "Epoch [187/250], Loss: 0.0384, Accuracy: 0.9817\n",
      "Validation Loss: 7.0070, Validation Accuracy: 0.4312\n",
      "Epoch [188/250], Loss: 0.0347, Accuracy: 0.9908\n",
      "Validation Loss: 0.5346, Validation Accuracy: 0.9083\n",
      "Epoch [189/250], Loss: 0.0238, Accuracy: 0.9908\n",
      "Validation Loss: 0.5614, Validation Accuracy: 0.9083\n",
      "Epoch [190/250], Loss: 0.0645, Accuracy: 0.9908\n",
      "Validation Loss: 0.7985, Validation Accuracy: 0.8716\n",
      "Epoch [191/250], Loss: 0.0721, Accuracy: 0.9633\n",
      "Validation Loss: 2.2073, Validation Accuracy: 0.6514\n",
      "Epoch [192/250], Loss: 0.0165, Accuracy: 0.9954\n",
      "Validation Loss: 0.6628, Validation Accuracy: 0.9266\n",
      "Epoch [193/250], Loss: 0.0374, Accuracy: 0.9862\n",
      "Validation Loss: 3.6424, Validation Accuracy: 0.6514\n",
      "Epoch [194/250], Loss: 0.0159, Accuracy: 0.9908\n",
      "Validation Loss: 0.5623, Validation Accuracy: 0.9358\n",
      "Epoch [195/250], Loss: 0.0979, Accuracy: 0.9817\n",
      "Validation Loss: 6.2005, Validation Accuracy: 0.4771\n",
      "Epoch [196/250], Loss: 0.1544, Accuracy: 0.9587\n",
      "Validation Loss: 4.5242, Validation Accuracy: 0.5963\n",
      "Epoch [197/250], Loss: 0.0525, Accuracy: 0.9771\n",
      "Validation Loss: 4.7992, Validation Accuracy: 0.5963\n",
      "Epoch [198/250], Loss: 0.0232, Accuracy: 0.9908\n",
      "Validation Loss: 4.7293, Validation Accuracy: 0.5963\n",
      "Epoch [199/250], Loss: 0.0292, Accuracy: 0.9908\n",
      "Validation Loss: 4.9689, Validation Accuracy: 0.5963\n",
      "Epoch [200/250], Loss: 0.1422, Accuracy: 0.9633\n",
      "Validation Loss: 2.2167, Validation Accuracy: 0.7156\n",
      "Epoch [201/250], Loss: 0.1559, Accuracy: 0.9266\n",
      "Validation Loss: 0.4904, Validation Accuracy: 0.8716\n",
      "Epoch [202/250], Loss: 0.0301, Accuracy: 0.9908\n",
      "Validation Loss: 0.5252, Validation Accuracy: 0.8899\n",
      "Epoch [203/250], Loss: 0.0680, Accuracy: 0.9908\n",
      "Validation Loss: 0.3049, Validation Accuracy: 0.9450\n",
      "Epoch [204/250], Loss: 0.0316, Accuracy: 0.9908\n",
      "Validation Loss: 0.3401, Validation Accuracy: 0.9358\n",
      "Epoch [205/250], Loss: 0.0213, Accuracy: 0.9954\n",
      "Validation Loss: 0.3896, Validation Accuracy: 0.9266\n",
      "Epoch [206/250], Loss: 0.0354, Accuracy: 0.9908\n",
      "Validation Loss: 0.3768, Validation Accuracy: 0.9450\n",
      "Epoch [207/250], Loss: 0.0315, Accuracy: 0.9908\n",
      "Validation Loss: 0.4063, Validation Accuracy: 0.9358\n",
      "Epoch [208/250], Loss: 0.0233, Accuracy: 0.9908\n",
      "Validation Loss: 0.4254, Validation Accuracy: 0.9450\n",
      "Epoch [209/250], Loss: 0.0437, Accuracy: 0.9817\n",
      "Validation Loss: 0.6022, Validation Accuracy: 0.9174\n",
      "Epoch [210/250], Loss: 0.0286, Accuracy: 0.9954\n",
      "Validation Loss: 0.9200, Validation Accuracy: 0.8807\n",
      "Epoch [211/250], Loss: 0.0322, Accuracy: 0.9908\n",
      "Validation Loss: 0.8100, Validation Accuracy: 0.8807\n",
      "Epoch [212/250], Loss: 0.0799, Accuracy: 0.9954\n",
      "Validation Loss: 1.2290, Validation Accuracy: 0.8073\n",
      "Epoch [213/250], Loss: 0.0253, Accuracy: 0.9954\n",
      "Validation Loss: 1.5036, Validation Accuracy: 0.7982\n",
      "Epoch [214/250], Loss: 0.0273, Accuracy: 0.9862\n",
      "Validation Loss: 1.8024, Validation Accuracy: 0.7523\n",
      "Epoch [215/250], Loss: 0.0126, Accuracy: 1.0000\n",
      "Validation Loss: 1.3518, Validation Accuracy: 0.7982\n",
      "Epoch [216/250], Loss: 0.0302, Accuracy: 0.9862\n",
      "Validation Loss: 2.9742, Validation Accuracy: 0.6972\n",
      "Epoch [217/250], Loss: 0.0105, Accuracy: 0.9954\n",
      "Validation Loss: 1.4041, Validation Accuracy: 0.8257\n",
      "Epoch [218/250], Loss: 0.0113, Accuracy: 0.9954\n",
      "Validation Loss: 0.4873, Validation Accuracy: 0.9450\n",
      "Epoch [219/250], Loss: 0.0235, Accuracy: 0.9862\n",
      "Validation Loss: 0.4421, Validation Accuracy: 0.9450\n",
      "Epoch [220/250], Loss: 0.0230, Accuracy: 0.9908\n",
      "Validation Loss: 0.6120, Validation Accuracy: 0.9266\n",
      "Epoch [221/250], Loss: 0.0173, Accuracy: 0.9908\n",
      "Validation Loss: 0.9910, Validation Accuracy: 0.8991\n",
      "Epoch [222/250], Loss: 0.0290, Accuracy: 0.9954\n",
      "Validation Loss: 1.7292, Validation Accuracy: 0.8349\n",
      "Epoch [223/250], Loss: 0.0079, Accuracy: 1.0000\n",
      "Validation Loss: 2.4378, Validation Accuracy: 0.7523\n",
      "Epoch [224/250], Loss: 0.0192, Accuracy: 0.9908\n",
      "Validation Loss: 0.6314, Validation Accuracy: 0.9266\n",
      "Epoch [225/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.5867, Validation Accuracy: 0.9450\n",
      "Epoch [226/250], Loss: 0.0418, Accuracy: 0.9908\n",
      "Validation Loss: 2.0565, Validation Accuracy: 0.8257\n",
      "Epoch [227/250], Loss: 0.0361, Accuracy: 0.9908\n",
      "Validation Loss: 5.1766, Validation Accuracy: 0.6239\n",
      "Epoch [228/250], Loss: 0.0819, Accuracy: 0.9862\n",
      "Validation Loss: 0.6452, Validation Accuracy: 0.9083\n",
      "Epoch [229/250], Loss: 0.0385, Accuracy: 0.9817\n",
      "Validation Loss: 3.6070, Validation Accuracy: 0.5963\n",
      "Epoch [230/250], Loss: 0.0252, Accuracy: 0.9908\n",
      "Validation Loss: 1.9685, Validation Accuracy: 0.7706\n",
      "Epoch [231/250], Loss: 0.0215, Accuracy: 0.9954\n",
      "Validation Loss: 1.0711, Validation Accuracy: 0.8532\n",
      "Epoch [232/250], Loss: 0.0097, Accuracy: 0.9954\n",
      "Validation Loss: 1.0105, Validation Accuracy: 0.8532\n",
      "Epoch [233/250], Loss: 0.0246, Accuracy: 0.9817\n",
      "Validation Loss: 1.3708, Validation Accuracy: 0.8257\n",
      "Epoch [234/250], Loss: 0.0066, Accuracy: 1.0000\n",
      "Validation Loss: 0.6064, Validation Accuracy: 0.9174\n",
      "Epoch [235/250], Loss: 0.0246, Accuracy: 0.9908\n",
      "Validation Loss: 1.6783, Validation Accuracy: 0.8257\n",
      "Epoch [236/250], Loss: 0.0160, Accuracy: 0.9908\n",
      "Validation Loss: 0.5676, Validation Accuracy: 0.9266\n",
      "Epoch [237/250], Loss: 0.0119, Accuracy: 0.9862\n",
      "Validation Loss: 0.8970, Validation Accuracy: 0.9174\n",
      "Epoch [238/250], Loss: 0.0056, Accuracy: 1.0000\n",
      "Validation Loss: 0.6482, Validation Accuracy: 0.9083\n",
      "Epoch [239/250], Loss: 0.0161, Accuracy: 0.9954\n",
      "Validation Loss: 3.2528, Validation Accuracy: 0.7064\n",
      "Epoch [240/250], Loss: 0.0622, Accuracy: 0.9862\n",
      "Validation Loss: 1.3965, Validation Accuracy: 0.8440\n",
      "Epoch [241/250], Loss: 0.1312, Accuracy: 0.9679\n",
      "Validation Loss: 4.4378, Validation Accuracy: 0.6330\n",
      "Epoch [242/250], Loss: 0.0165, Accuracy: 0.9908\n",
      "Validation Loss: 0.7958, Validation Accuracy: 0.9174\n",
      "Epoch [243/250], Loss: 0.0133, Accuracy: 0.9954\n",
      "Validation Loss: 1.0413, Validation Accuracy: 0.8624\n",
      "Epoch [244/250], Loss: 0.0254, Accuracy: 0.9954\n",
      "Validation Loss: 0.8701, Validation Accuracy: 0.8807\n",
      "Epoch [245/250], Loss: 0.0223, Accuracy: 0.9862\n",
      "Validation Loss: 0.6429, Validation Accuracy: 0.9266\n",
      "Epoch [246/250], Loss: 0.0101, Accuracy: 1.0000\n",
      "Validation Loss: 0.7673, Validation Accuracy: 0.8991\n",
      "Epoch [247/250], Loss: 0.0283, Accuracy: 0.9908\n",
      "Validation Loss: 0.6500, Validation Accuracy: 0.9358\n",
      "Epoch [248/250], Loss: 0.0095, Accuracy: 0.9954\n",
      "Validation Loss: 0.8638, Validation Accuracy: 0.9174\n",
      "Epoch [249/250], Loss: 0.0357, Accuracy: 0.9862\n",
      "Validation Loss: 4.2769, Validation Accuracy: 0.6697\n",
      "Epoch [250/250], Loss: 0.0095, Accuracy: 0.9954\n",
      "Validation Loss: 0.7583, Validation Accuracy: 0.9083\n",
      "Test Loss: 1.0504\n",
      "Test Accuracy: 0.8807\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 25\n",
      "label 1 is 38\n",
      "label 2 is 144\n",
      "label 3 is 68\n",
      "Not setting metadata\n",
      "275 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (251, 8, 325)\n",
      "251 train samples\n",
      "126 test samples\n",
      "Number of batches in train_loader: 4\n",
      "{-1: 1.1030701754385965, 0: 0.9145454545454546}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.4070, Accuracy: 0.2311\n",
      "Validation Loss: 1.1317, Validation Accuracy: 0.6111\n",
      "Epoch [2/250], Loss: 1.1767, Accuracy: 0.5498\n",
      "Validation Loss: 0.8865, Validation Accuracy: 0.6111\n",
      "Epoch [3/250], Loss: 0.9762, Accuracy: 0.5777\n",
      "Validation Loss: 0.7729, Validation Accuracy: 0.6111\n",
      "Epoch [4/250], Loss: 0.8789, Accuracy: 0.5737\n",
      "Validation Loss: 0.7265, Validation Accuracy: 0.6111\n",
      "Epoch [5/250], Loss: 0.8244, Accuracy: 0.5139\n",
      "Validation Loss: 0.7323, Validation Accuracy: 0.6111\n",
      "Epoch [6/250], Loss: 0.8034, Accuracy: 0.5259\n",
      "Validation Loss: 0.7440, Validation Accuracy: 0.6111\n",
      "Epoch [7/250], Loss: 0.7672, Accuracy: 0.5339\n",
      "Validation Loss: 0.7177, Validation Accuracy: 0.6111\n",
      "Epoch [8/250], Loss: 0.7208, Accuracy: 0.6016\n",
      "Validation Loss: 0.7648, Validation Accuracy: 0.6111\n",
      "Epoch [9/250], Loss: 0.7463, Accuracy: 0.5498\n",
      "Validation Loss: 0.7482, Validation Accuracy: 0.6111\n",
      "Epoch [10/250], Loss: 0.7175, Accuracy: 0.5936\n",
      "Validation Loss: 0.8909, Validation Accuracy: 0.6111\n",
      "Epoch [11/250], Loss: 0.7021, Accuracy: 0.6335\n",
      "Validation Loss: 0.8639, Validation Accuracy: 0.6111\n",
      "Epoch [12/250], Loss: 0.7078, Accuracy: 0.5976\n",
      "Validation Loss: 1.0134, Validation Accuracy: 0.6111\n",
      "Epoch [13/250], Loss: 0.6873, Accuracy: 0.6335\n",
      "Validation Loss: 1.2152, Validation Accuracy: 0.6111\n",
      "Epoch [14/250], Loss: 0.6366, Accuracy: 0.6494\n",
      "Validation Loss: 1.2798, Validation Accuracy: 0.6111\n",
      "Epoch [15/250], Loss: 0.6447, Accuracy: 0.6733\n",
      "Validation Loss: 1.6459, Validation Accuracy: 0.6111\n",
      "Epoch [16/250], Loss: 0.6434, Accuracy: 0.6534\n",
      "Validation Loss: 1.5214, Validation Accuracy: 0.6111\n",
      "Epoch [17/250], Loss: 0.6405, Accuracy: 0.7052\n",
      "Validation Loss: 1.6633, Validation Accuracy: 0.6111\n",
      "Epoch [18/250], Loss: 0.5882, Accuracy: 0.7211\n",
      "Validation Loss: 1.4187, Validation Accuracy: 0.6111\n",
      "Epoch [19/250], Loss: 0.5520, Accuracy: 0.7570\n",
      "Validation Loss: 2.0678, Validation Accuracy: 0.6111\n",
      "Epoch [20/250], Loss: 0.4533, Accuracy: 0.8127\n",
      "Validation Loss: 0.5662, Validation Accuracy: 0.7381\n",
      "Epoch [21/250], Loss: 0.4677, Accuracy: 0.8008\n",
      "Validation Loss: 2.0986, Validation Accuracy: 0.3889\n",
      "Epoch [22/250], Loss: 0.4958, Accuracy: 0.8008\n",
      "Validation Loss: 1.0812, Validation Accuracy: 0.5079\n",
      "Epoch [23/250], Loss: 0.5545, Accuracy: 0.7331\n",
      "Validation Loss: 0.4342, Validation Accuracy: 0.8175\n",
      "Epoch [24/250], Loss: 0.4182, Accuracy: 0.8287\n",
      "Validation Loss: 1.4270, Validation Accuracy: 0.6746\n",
      "Epoch [25/250], Loss: 0.4638, Accuracy: 0.7888\n",
      "Validation Loss: 1.3920, Validation Accuracy: 0.7143\n",
      "Epoch [26/250], Loss: 0.4007, Accuracy: 0.8446\n",
      "Validation Loss: 0.8280, Validation Accuracy: 0.7698\n",
      "Epoch [27/250], Loss: 0.4273, Accuracy: 0.8247\n",
      "Validation Loss: 0.5103, Validation Accuracy: 0.7778\n",
      "Epoch [28/250], Loss: 0.4761, Accuracy: 0.7928\n",
      "Validation Loss: 0.4095, Validation Accuracy: 0.8095\n",
      "Epoch [29/250], Loss: 0.4317, Accuracy: 0.7849\n",
      "Validation Loss: 0.7888, Validation Accuracy: 0.7698\n",
      "Epoch [30/250], Loss: 0.4406, Accuracy: 0.8008\n",
      "Validation Loss: 1.2825, Validation Accuracy: 0.7222\n",
      "Epoch [31/250], Loss: 0.3977, Accuracy: 0.8127\n",
      "Validation Loss: 0.4677, Validation Accuracy: 0.7937\n",
      "Epoch [32/250], Loss: 0.4275, Accuracy: 0.8048\n",
      "Validation Loss: 0.7029, Validation Accuracy: 0.7302\n",
      "Epoch [33/250], Loss: 0.3662, Accuracy: 0.8327\n",
      "Validation Loss: 0.7471, Validation Accuracy: 0.6984\n",
      "Epoch [34/250], Loss: 0.3381, Accuracy: 0.8606\n",
      "Validation Loss: 0.4415, Validation Accuracy: 0.8254\n",
      "Epoch [35/250], Loss: 0.4261, Accuracy: 0.8486\n",
      "Validation Loss: 1.1071, Validation Accuracy: 0.7619\n",
      "Epoch [36/250], Loss: 0.5392, Accuracy: 0.8008\n",
      "Validation Loss: 1.9391, Validation Accuracy: 0.6587\n",
      "Epoch [37/250], Loss: 0.4497, Accuracy: 0.7968\n",
      "Validation Loss: 1.7834, Validation Accuracy: 0.6746\n",
      "Epoch [38/250], Loss: 0.3812, Accuracy: 0.8327\n",
      "Validation Loss: 0.9151, Validation Accuracy: 0.7778\n",
      "Epoch [39/250], Loss: 0.4235, Accuracy: 0.8127\n",
      "Validation Loss: 1.9052, Validation Accuracy: 0.6746\n",
      "Epoch [40/250], Loss: 0.4060, Accuracy: 0.8685\n",
      "Validation Loss: 0.5857, Validation Accuracy: 0.8095\n",
      "Epoch [41/250], Loss: 0.3519, Accuracy: 0.8845\n",
      "Validation Loss: 1.4527, Validation Accuracy: 0.6984\n",
      "Epoch [42/250], Loss: 0.3674, Accuracy: 0.8606\n",
      "Validation Loss: 0.5083, Validation Accuracy: 0.8175\n",
      "Epoch [43/250], Loss: 0.3258, Accuracy: 0.8765\n",
      "Validation Loss: 0.6555, Validation Accuracy: 0.7937\n",
      "Epoch [44/250], Loss: 0.3907, Accuracy: 0.8446\n",
      "Validation Loss: 0.8023, Validation Accuracy: 0.6508\n",
      "Epoch [45/250], Loss: 0.3744, Accuracy: 0.8247\n",
      "Validation Loss: 0.7390, Validation Accuracy: 0.6984\n",
      "Epoch [46/250], Loss: 0.3762, Accuracy: 0.8685\n",
      "Validation Loss: 1.3407, Validation Accuracy: 0.4444\n",
      "Epoch [47/250], Loss: 0.3714, Accuracy: 0.8247\n",
      "Validation Loss: 1.3774, Validation Accuracy: 0.4444\n",
      "Epoch [48/250], Loss: 0.3289, Accuracy: 0.8606\n",
      "Validation Loss: 0.5610, Validation Accuracy: 0.8095\n",
      "Epoch [49/250], Loss: 0.3624, Accuracy: 0.8765\n",
      "Validation Loss: 0.6211, Validation Accuracy: 0.7698\n",
      "Epoch [50/250], Loss: 0.3065, Accuracy: 0.8805\n",
      "Validation Loss: 0.5173, Validation Accuracy: 0.8016\n",
      "Epoch [51/250], Loss: 0.4021, Accuracy: 0.8406\n",
      "Validation Loss: 1.0778, Validation Accuracy: 0.7302\n",
      "Epoch [52/250], Loss: 0.3062, Accuracy: 0.8805\n",
      "Validation Loss: 1.1332, Validation Accuracy: 0.7222\n",
      "Epoch [53/250], Loss: 0.3705, Accuracy: 0.8446\n",
      "Validation Loss: 1.2328, Validation Accuracy: 0.7063\n",
      "Epoch [54/250], Loss: 0.3518, Accuracy: 0.8526\n",
      "Validation Loss: 2.1484, Validation Accuracy: 0.6349\n",
      "Epoch [55/250], Loss: 0.3677, Accuracy: 0.8367\n",
      "Validation Loss: 2.2957, Validation Accuracy: 0.6429\n",
      "Epoch [56/250], Loss: 0.3214, Accuracy: 0.8805\n",
      "Validation Loss: 2.1227, Validation Accuracy: 0.6667\n",
      "Epoch [57/250], Loss: 0.3179, Accuracy: 0.8805\n",
      "Validation Loss: 0.7802, Validation Accuracy: 0.8175\n",
      "Epoch [58/250], Loss: 0.3150, Accuracy: 0.8685\n",
      "Validation Loss: 1.3486, Validation Accuracy: 0.7302\n",
      "Epoch [59/250], Loss: 0.3548, Accuracy: 0.8446\n",
      "Validation Loss: 0.4757, Validation Accuracy: 0.8095\n",
      "Epoch [60/250], Loss: 0.3013, Accuracy: 0.9084\n",
      "Validation Loss: 0.4875, Validation Accuracy: 0.8333\n",
      "Epoch [61/250], Loss: 0.2690, Accuracy: 0.8924\n",
      "Validation Loss: 0.8208, Validation Accuracy: 0.8016\n",
      "Epoch [62/250], Loss: 0.3212, Accuracy: 0.8685\n",
      "Validation Loss: 1.9271, Validation Accuracy: 0.6905\n",
      "Epoch [63/250], Loss: 0.3329, Accuracy: 0.8805\n",
      "Validation Loss: 2.7039, Validation Accuracy: 0.6270\n",
      "Epoch [64/250], Loss: 0.3445, Accuracy: 0.8566\n",
      "Validation Loss: 2.9347, Validation Accuracy: 0.6190\n",
      "Epoch [65/250], Loss: 0.3012, Accuracy: 0.8884\n",
      "Validation Loss: 0.7782, Validation Accuracy: 0.8016\n",
      "Epoch [66/250], Loss: 0.3377, Accuracy: 0.8606\n",
      "Validation Loss: 1.3501, Validation Accuracy: 0.7222\n",
      "Epoch [67/250], Loss: 0.3332, Accuracy: 0.8486\n",
      "Validation Loss: 0.9642, Validation Accuracy: 0.8175\n",
      "Epoch [68/250], Loss: 0.3043, Accuracy: 0.8685\n",
      "Validation Loss: 0.8636, Validation Accuracy: 0.8254\n",
      "Epoch [69/250], Loss: 0.3176, Accuracy: 0.8765\n",
      "Validation Loss: 0.4665, Validation Accuracy: 0.8333\n",
      "Epoch [70/250], Loss: 0.3030, Accuracy: 0.8566\n",
      "Validation Loss: 2.0536, Validation Accuracy: 0.6587\n",
      "Epoch [71/250], Loss: 0.3676, Accuracy: 0.8566\n",
      "Validation Loss: 2.0361, Validation Accuracy: 0.6746\n",
      "Epoch [72/250], Loss: 0.2982, Accuracy: 0.8884\n",
      "Validation Loss: 2.2224, Validation Accuracy: 0.6587\n",
      "Epoch [73/250], Loss: 0.3196, Accuracy: 0.8765\n",
      "Validation Loss: 1.7751, Validation Accuracy: 0.6746\n",
      "Epoch [74/250], Loss: 0.2744, Accuracy: 0.8964\n",
      "Validation Loss: 2.3912, Validation Accuracy: 0.6667\n",
      "Epoch [75/250], Loss: 0.2991, Accuracy: 0.8685\n",
      "Validation Loss: 0.7184, Validation Accuracy: 0.8254\n",
      "Epoch [76/250], Loss: 0.2980, Accuracy: 0.8884\n",
      "Validation Loss: 2.0708, Validation Accuracy: 0.6587\n",
      "Epoch [77/250], Loss: 0.2666, Accuracy: 0.8884\n",
      "Validation Loss: 0.6898, Validation Accuracy: 0.8095\n",
      "Epoch [78/250], Loss: 0.2923, Accuracy: 0.8964\n",
      "Validation Loss: 2.0730, Validation Accuracy: 0.6587\n",
      "Epoch [79/250], Loss: 0.2988, Accuracy: 0.8645\n",
      "Validation Loss: 0.7329, Validation Accuracy: 0.8016\n",
      "Epoch [80/250], Loss: 0.2888, Accuracy: 0.8805\n",
      "Validation Loss: 0.4596, Validation Accuracy: 0.8095\n",
      "Epoch [81/250], Loss: 0.2911, Accuracy: 0.8725\n",
      "Validation Loss: 0.8667, Validation Accuracy: 0.6190\n",
      "Epoch [82/250], Loss: 0.2549, Accuracy: 0.9163\n",
      "Validation Loss: 0.6602, Validation Accuracy: 0.7619\n",
      "Epoch [83/250], Loss: 0.2448, Accuracy: 0.9004\n",
      "Validation Loss: 1.1431, Validation Accuracy: 0.6190\n",
      "Epoch [84/250], Loss: 0.2845, Accuracy: 0.8924\n",
      "Validation Loss: 0.5565, Validation Accuracy: 0.8095\n",
      "Epoch [85/250], Loss: 0.3457, Accuracy: 0.8606\n",
      "Validation Loss: 1.2928, Validation Accuracy: 0.7540\n",
      "Epoch [86/250], Loss: 0.2460, Accuracy: 0.8964\n",
      "Validation Loss: 1.0814, Validation Accuracy: 0.8254\n",
      "Epoch [87/250], Loss: 0.2995, Accuracy: 0.8884\n",
      "Validation Loss: 0.5819, Validation Accuracy: 0.8333\n",
      "Epoch [88/250], Loss: 0.2907, Accuracy: 0.8765\n",
      "Validation Loss: 0.6310, Validation Accuracy: 0.8016\n",
      "Epoch [89/250], Loss: 0.2194, Accuracy: 0.9084\n",
      "Validation Loss: 0.7871, Validation Accuracy: 0.7619\n",
      "Epoch [90/250], Loss: 0.2645, Accuracy: 0.8845\n",
      "Validation Loss: 0.8767, Validation Accuracy: 0.7063\n",
      "Epoch [91/250], Loss: 0.2597, Accuracy: 0.8964\n",
      "Validation Loss: 0.4441, Validation Accuracy: 0.8413\n",
      "Epoch [92/250], Loss: 0.3035, Accuracy: 0.8884\n",
      "Validation Loss: 1.3007, Validation Accuracy: 0.7460\n",
      "Epoch [93/250], Loss: 0.2215, Accuracy: 0.9203\n",
      "Validation Loss: 2.4106, Validation Accuracy: 0.6349\n",
      "Epoch [94/250], Loss: 0.2647, Accuracy: 0.8884\n",
      "Validation Loss: 1.9016, Validation Accuracy: 0.6667\n",
      "Epoch [95/250], Loss: 0.2377, Accuracy: 0.9124\n",
      "Validation Loss: 1.6288, Validation Accuracy: 0.6905\n",
      "Epoch [96/250], Loss: 0.2787, Accuracy: 0.8805\n",
      "Validation Loss: 0.6785, Validation Accuracy: 0.8492\n",
      "Epoch [97/250], Loss: 0.2715, Accuracy: 0.8725\n",
      "Validation Loss: 1.3570, Validation Accuracy: 0.6032\n",
      "Epoch [98/250], Loss: 0.2429, Accuracy: 0.8805\n",
      "Validation Loss: 0.5740, Validation Accuracy: 0.8492\n",
      "Epoch [99/250], Loss: 0.2274, Accuracy: 0.9124\n",
      "Validation Loss: 1.1291, Validation Accuracy: 0.6508\n",
      "Epoch [100/250], Loss: 0.1857, Accuracy: 0.9283\n",
      "Validation Loss: 1.9609, Validation Accuracy: 0.4683\n",
      "Epoch [101/250], Loss: 0.2584, Accuracy: 0.9084\n",
      "Validation Loss: 1.3020, Validation Accuracy: 0.5556\n",
      "Epoch [102/250], Loss: 0.2689, Accuracy: 0.9004\n",
      "Validation Loss: 0.5148, Validation Accuracy: 0.8492\n",
      "Epoch [103/250], Loss: 0.3485, Accuracy: 0.8685\n",
      "Validation Loss: 1.8623, Validation Accuracy: 0.6587\n",
      "Epoch [104/250], Loss: 0.2616, Accuracy: 0.8765\n",
      "Validation Loss: 1.9879, Validation Accuracy: 0.6746\n",
      "Epoch [105/250], Loss: 0.2782, Accuracy: 0.8884\n",
      "Validation Loss: 1.9052, Validation Accuracy: 0.6587\n",
      "Epoch [106/250], Loss: 0.2621, Accuracy: 0.9004\n",
      "Validation Loss: 2.3259, Validation Accuracy: 0.6587\n",
      "Epoch [107/250], Loss: 0.2401, Accuracy: 0.9323\n",
      "Validation Loss: 1.4866, Validation Accuracy: 0.7222\n",
      "Epoch [108/250], Loss: 0.2483, Accuracy: 0.8924\n",
      "Validation Loss: 0.4317, Validation Accuracy: 0.8571\n",
      "Epoch [109/250], Loss: 0.3006, Accuracy: 0.8964\n",
      "Validation Loss: 1.6620, Validation Accuracy: 0.7222\n",
      "Epoch [110/250], Loss: 0.2186, Accuracy: 0.9084\n",
      "Validation Loss: 1.2571, Validation Accuracy: 0.7698\n",
      "Epoch [111/250], Loss: 0.1308, Accuracy: 0.9482\n",
      "Validation Loss: 0.4732, Validation Accuracy: 0.8651\n",
      "Epoch [112/250], Loss: 0.2662, Accuracy: 0.9044\n",
      "Validation Loss: 2.4188, Validation Accuracy: 0.6349\n",
      "Epoch [113/250], Loss: 0.2313, Accuracy: 0.9203\n",
      "Validation Loss: 2.2797, Validation Accuracy: 0.6429\n",
      "Epoch [114/250], Loss: 0.2280, Accuracy: 0.9004\n",
      "Validation Loss: 0.4553, Validation Accuracy: 0.8571\n",
      "Epoch [115/250], Loss: 0.1519, Accuracy: 0.9482\n",
      "Validation Loss: 0.5125, Validation Accuracy: 0.8413\n",
      "Epoch [116/250], Loss: 0.2434, Accuracy: 0.9163\n",
      "Validation Loss: 0.5389, Validation Accuracy: 0.8333\n",
      "Epoch [117/250], Loss: 0.2107, Accuracy: 0.9203\n",
      "Validation Loss: 2.4013, Validation Accuracy: 0.6270\n",
      "Epoch [118/250], Loss: 0.1879, Accuracy: 0.9363\n",
      "Validation Loss: 1.8641, Validation Accuracy: 0.7063\n",
      "Epoch [119/250], Loss: 0.2833, Accuracy: 0.9004\n",
      "Validation Loss: 0.5856, Validation Accuracy: 0.8492\n",
      "Epoch [120/250], Loss: 0.2239, Accuracy: 0.9203\n",
      "Validation Loss: 0.6248, Validation Accuracy: 0.8492\n",
      "Epoch [121/250], Loss: 0.2298, Accuracy: 0.9203\n",
      "Validation Loss: 0.4762, Validation Accuracy: 0.8413\n",
      "Epoch [122/250], Loss: 0.1860, Accuracy: 0.9323\n",
      "Validation Loss: 0.4952, Validation Accuracy: 0.8810\n",
      "Epoch [123/250], Loss: 0.2080, Accuracy: 0.9323\n",
      "Validation Loss: 0.4089, Validation Accuracy: 0.8889\n",
      "Epoch [124/250], Loss: 0.1778, Accuracy: 0.9402\n",
      "Validation Loss: 2.0097, Validation Accuracy: 0.5000\n",
      "Epoch [125/250], Loss: 0.1933, Accuracy: 0.9323\n",
      "Validation Loss: 2.9825, Validation Accuracy: 0.3968\n",
      "Epoch [126/250], Loss: 0.2359, Accuracy: 0.8924\n",
      "Validation Loss: 0.4369, Validation Accuracy: 0.8571\n",
      "Epoch [127/250], Loss: 0.1646, Accuracy: 0.9323\n",
      "Validation Loss: 0.7882, Validation Accuracy: 0.7540\n",
      "Epoch [128/250], Loss: 0.2180, Accuracy: 0.9163\n",
      "Validation Loss: 1.3259, Validation Accuracy: 0.7619\n",
      "Epoch [129/250], Loss: 0.2183, Accuracy: 0.9243\n",
      "Validation Loss: 0.4456, Validation Accuracy: 0.8810\n",
      "Epoch [130/250], Loss: 0.1938, Accuracy: 0.9283\n",
      "Validation Loss: 0.4893, Validation Accuracy: 0.8889\n",
      "Epoch [131/250], Loss: 0.1966, Accuracy: 0.9283\n",
      "Validation Loss: 1.1678, Validation Accuracy: 0.7778\n",
      "Epoch [132/250], Loss: 0.2351, Accuracy: 0.9163\n",
      "Validation Loss: 1.4856, Validation Accuracy: 0.7381\n",
      "Epoch [133/250], Loss: 0.3762, Accuracy: 0.8924\n",
      "Validation Loss: 1.7832, Validation Accuracy: 0.4603\n",
      "Epoch [134/250], Loss: 0.2888, Accuracy: 0.8924\n",
      "Validation Loss: 0.4502, Validation Accuracy: 0.8492\n",
      "Epoch [135/250], Loss: 0.2485, Accuracy: 0.8964\n",
      "Validation Loss: 0.8076, Validation Accuracy: 0.7778\n",
      "Epoch [136/250], Loss: 0.2229, Accuracy: 0.9163\n",
      "Validation Loss: 0.5433, Validation Accuracy: 0.8413\n",
      "Epoch [137/250], Loss: 0.2460, Accuracy: 0.8964\n",
      "Validation Loss: 0.5825, Validation Accuracy: 0.8333\n",
      "Epoch [138/250], Loss: 0.2027, Accuracy: 0.9084\n",
      "Validation Loss: 0.7712, Validation Accuracy: 0.8730\n",
      "Epoch [139/250], Loss: 0.1806, Accuracy: 0.9203\n",
      "Validation Loss: 0.5941, Validation Accuracy: 0.8413\n",
      "Epoch [140/250], Loss: 0.1888, Accuracy: 0.9323\n",
      "Validation Loss: 0.5656, Validation Accuracy: 0.8810\n",
      "Epoch [141/250], Loss: 0.2888, Accuracy: 0.9004\n",
      "Validation Loss: 0.7774, Validation Accuracy: 0.8254\n",
      "Epoch [142/250], Loss: 0.1866, Accuracy: 0.9442\n",
      "Validation Loss: 0.6636, Validation Accuracy: 0.8254\n",
      "Epoch [143/250], Loss: 0.2386, Accuracy: 0.9044\n",
      "Validation Loss: 1.0678, Validation Accuracy: 0.7937\n",
      "Epoch [144/250], Loss: 0.2943, Accuracy: 0.8884\n",
      "Validation Loss: 1.3080, Validation Accuracy: 0.7143\n",
      "Epoch [145/250], Loss: 0.2033, Accuracy: 0.9363\n",
      "Validation Loss: 0.7218, Validation Accuracy: 0.8333\n",
      "Epoch [146/250], Loss: 0.1901, Accuracy: 0.9203\n",
      "Validation Loss: 0.9516, Validation Accuracy: 0.7381\n",
      "Epoch [147/250], Loss: 0.2583, Accuracy: 0.9084\n",
      "Validation Loss: 0.7805, Validation Accuracy: 0.7302\n",
      "Epoch [148/250], Loss: 0.2045, Accuracy: 0.9243\n",
      "Validation Loss: 0.4112, Validation Accuracy: 0.8492\n",
      "Epoch [149/250], Loss: 0.1728, Accuracy: 0.9482\n",
      "Validation Loss: 1.9983, Validation Accuracy: 0.6746\n",
      "Epoch [150/250], Loss: 0.1588, Accuracy: 0.9442\n",
      "Validation Loss: 0.5784, Validation Accuracy: 0.8413\n",
      "Epoch [151/250], Loss: 0.1882, Accuracy: 0.9283\n",
      "Validation Loss: 2.8781, Validation Accuracy: 0.6190\n",
      "Epoch [152/250], Loss: 0.2149, Accuracy: 0.9163\n",
      "Validation Loss: 3.4135, Validation Accuracy: 0.6190\n",
      "Epoch [153/250], Loss: 0.1781, Accuracy: 0.9163\n",
      "Validation Loss: 2.1716, Validation Accuracy: 0.6508\n",
      "Epoch [154/250], Loss: 0.1946, Accuracy: 0.9203\n",
      "Validation Loss: 1.7284, Validation Accuracy: 0.7143\n",
      "Epoch [155/250], Loss: 0.2112, Accuracy: 0.9243\n",
      "Validation Loss: 0.5787, Validation Accuracy: 0.8492\n",
      "Epoch [156/250], Loss: 0.1279, Accuracy: 0.9681\n",
      "Validation Loss: 1.4535, Validation Accuracy: 0.7540\n",
      "Epoch [157/250], Loss: 0.2116, Accuracy: 0.9203\n",
      "Validation Loss: 0.3947, Validation Accuracy: 0.8651\n",
      "Epoch [158/250], Loss: 0.1751, Accuracy: 0.9203\n",
      "Validation Loss: 0.6086, Validation Accuracy: 0.7540\n",
      "Epoch [159/250], Loss: 0.1922, Accuracy: 0.9283\n",
      "Validation Loss: 1.3811, Validation Accuracy: 0.7302\n",
      "Epoch [160/250], Loss: 0.1404, Accuracy: 0.9522\n",
      "Validation Loss: 1.9743, Validation Accuracy: 0.6746\n",
      "Epoch [161/250], Loss: 0.1942, Accuracy: 0.9283\n",
      "Validation Loss: 2.5730, Validation Accuracy: 0.6508\n",
      "Epoch [162/250], Loss: 0.1872, Accuracy: 0.9323\n",
      "Validation Loss: 2.0529, Validation Accuracy: 0.4048\n",
      "Epoch [163/250], Loss: 0.1959, Accuracy: 0.9323\n",
      "Validation Loss: 0.4036, Validation Accuracy: 0.8492\n",
      "Epoch [164/250], Loss: 0.1799, Accuracy: 0.9243\n",
      "Validation Loss: 0.6782, Validation Accuracy: 0.8175\n",
      "Epoch [165/250], Loss: 0.1815, Accuracy: 0.9323\n",
      "Validation Loss: 0.3925, Validation Accuracy: 0.8810\n",
      "Epoch [166/250], Loss: 0.1214, Accuracy: 0.9602\n",
      "Validation Loss: 0.7761, Validation Accuracy: 0.7302\n",
      "Epoch [167/250], Loss: 0.2044, Accuracy: 0.9363\n",
      "Validation Loss: 0.7236, Validation Accuracy: 0.8254\n",
      "Epoch [168/250], Loss: 0.2092, Accuracy: 0.9203\n",
      "Validation Loss: 0.4931, Validation Accuracy: 0.8889\n",
      "Epoch [169/250], Loss: 0.2251, Accuracy: 0.9124\n",
      "Validation Loss: 0.4849, Validation Accuracy: 0.8333\n",
      "Epoch [170/250], Loss: 0.1825, Accuracy: 0.9402\n",
      "Validation Loss: 0.4869, Validation Accuracy: 0.8571\n",
      "Epoch [171/250], Loss: 0.1577, Accuracy: 0.9203\n",
      "Validation Loss: 2.1473, Validation Accuracy: 0.6905\n",
      "Epoch [172/250], Loss: 0.2338, Accuracy: 0.9203\n",
      "Validation Loss: 1.9350, Validation Accuracy: 0.6587\n",
      "Epoch [173/250], Loss: 0.2283, Accuracy: 0.8964\n",
      "Validation Loss: 2.6340, Validation Accuracy: 0.6190\n",
      "Epoch [174/250], Loss: 0.1423, Accuracy: 0.9442\n",
      "Validation Loss: 1.9301, Validation Accuracy: 0.6984\n",
      "Epoch [175/250], Loss: 0.1696, Accuracy: 0.9442\n",
      "Validation Loss: 1.2683, Validation Accuracy: 0.8333\n",
      "Epoch [176/250], Loss: 0.2237, Accuracy: 0.9243\n",
      "Validation Loss: 3.6574, Validation Accuracy: 0.4048\n",
      "Epoch [177/250], Loss: 0.1601, Accuracy: 0.9402\n",
      "Validation Loss: 1.3773, Validation Accuracy: 0.6508\n",
      "Epoch [178/250], Loss: 0.1241, Accuracy: 0.9522\n",
      "Validation Loss: 0.8193, Validation Accuracy: 0.7778\n",
      "Epoch [179/250], Loss: 0.1879, Accuracy: 0.9402\n",
      "Validation Loss: 0.5083, Validation Accuracy: 0.8254\n",
      "Epoch [180/250], Loss: 0.1342, Accuracy: 0.9482\n",
      "Validation Loss: 0.5288, Validation Accuracy: 0.8333\n",
      "Epoch [181/250], Loss: 0.1354, Accuracy: 0.9442\n",
      "Validation Loss: 0.5573, Validation Accuracy: 0.8333\n",
      "Epoch [182/250], Loss: 0.1401, Accuracy: 0.9522\n",
      "Validation Loss: 0.8425, Validation Accuracy: 0.7778\n",
      "Epoch [183/250], Loss: 0.1562, Accuracy: 0.9323\n",
      "Validation Loss: 3.3051, Validation Accuracy: 0.4286\n",
      "Epoch [184/250], Loss: 0.1362, Accuracy: 0.9482\n",
      "Validation Loss: 3.8057, Validation Accuracy: 0.4048\n",
      "Epoch [185/250], Loss: 0.1965, Accuracy: 0.9402\n",
      "Validation Loss: 1.3651, Validation Accuracy: 0.7619\n",
      "Epoch [186/250], Loss: 0.1365, Accuracy: 0.9442\n",
      "Validation Loss: 0.6148, Validation Accuracy: 0.8651\n",
      "Epoch [187/250], Loss: 0.1972, Accuracy: 0.9203\n",
      "Validation Loss: 0.6330, Validation Accuracy: 0.8492\n",
      "Epoch [188/250], Loss: 0.1286, Accuracy: 0.9721\n",
      "Validation Loss: 0.5802, Validation Accuracy: 0.8889\n",
      "Epoch [189/250], Loss: 0.1182, Accuracy: 0.9562\n",
      "Validation Loss: 1.0559, Validation Accuracy: 0.8175\n",
      "Epoch [190/250], Loss: 0.2838, Accuracy: 0.9004\n",
      "Validation Loss: 0.3906, Validation Accuracy: 0.8810\n",
      "Epoch [191/250], Loss: 0.1829, Accuracy: 0.9363\n",
      "Validation Loss: 1.3126, Validation Accuracy: 0.7302\n",
      "Epoch [192/250], Loss: 0.1773, Accuracy: 0.9402\n",
      "Validation Loss: 1.4226, Validation Accuracy: 0.7698\n",
      "Epoch [193/250], Loss: 0.1184, Accuracy: 0.9681\n",
      "Validation Loss: 2.2929, Validation Accuracy: 0.6825\n",
      "Epoch [194/250], Loss: 0.1477, Accuracy: 0.9562\n",
      "Validation Loss: 1.1563, Validation Accuracy: 0.8095\n",
      "Epoch [195/250], Loss: 0.1278, Accuracy: 0.9522\n",
      "Validation Loss: 0.9674, Validation Accuracy: 0.8175\n",
      "Epoch [196/250], Loss: 0.1511, Accuracy: 0.9562\n",
      "Validation Loss: 4.0385, Validation Accuracy: 0.4048\n",
      "Epoch [197/250], Loss: 0.1456, Accuracy: 0.9562\n",
      "Validation Loss: 4.5457, Validation Accuracy: 0.3889\n",
      "Epoch [198/250], Loss: 0.1936, Accuracy: 0.9283\n",
      "Validation Loss: 3.9565, Validation Accuracy: 0.4048\n",
      "Epoch [199/250], Loss: 0.1134, Accuracy: 0.9522\n",
      "Validation Loss: 0.7848, Validation Accuracy: 0.8254\n",
      "Epoch [200/250], Loss: 0.1378, Accuracy: 0.9482\n",
      "Validation Loss: 0.5335, Validation Accuracy: 0.8810\n",
      "Epoch [201/250], Loss: 0.1330, Accuracy: 0.9442\n",
      "Validation Loss: 1.7651, Validation Accuracy: 0.7302\n",
      "Epoch [202/250], Loss: 0.1181, Accuracy: 0.9681\n",
      "Validation Loss: 0.9816, Validation Accuracy: 0.8571\n",
      "Epoch [203/250], Loss: 0.1296, Accuracy: 0.9522\n",
      "Validation Loss: 2.5225, Validation Accuracy: 0.6825\n",
      "Epoch [204/250], Loss: 0.1277, Accuracy: 0.9681\n",
      "Validation Loss: 2.3200, Validation Accuracy: 0.6746\n",
      "Epoch [205/250], Loss: 0.1025, Accuracy: 0.9562\n",
      "Validation Loss: 1.4263, Validation Accuracy: 0.7540\n",
      "Epoch [206/250], Loss: 0.1177, Accuracy: 0.9681\n",
      "Validation Loss: 1.7523, Validation Accuracy: 0.7302\n",
      "Epoch [207/250], Loss: 0.1669, Accuracy: 0.9442\n",
      "Validation Loss: 1.0070, Validation Accuracy: 0.8095\n",
      "Epoch [208/250], Loss: 0.1900, Accuracy: 0.9283\n",
      "Validation Loss: 0.9926, Validation Accuracy: 0.8016\n",
      "Epoch [209/250], Loss: 0.0951, Accuracy: 0.9721\n",
      "Validation Loss: 0.6833, Validation Accuracy: 0.8651\n",
      "Epoch [210/250], Loss: 0.1309, Accuracy: 0.9522\n",
      "Validation Loss: 0.9198, Validation Accuracy: 0.7698\n",
      "Epoch [211/250], Loss: 0.1254, Accuracy: 0.9482\n",
      "Validation Loss: 0.4190, Validation Accuracy: 0.8651\n",
      "Epoch [212/250], Loss: 0.1305, Accuracy: 0.9482\n",
      "Validation Loss: 0.6808, Validation Accuracy: 0.8254\n",
      "Epoch [213/250], Loss: 0.1535, Accuracy: 0.9442\n",
      "Validation Loss: 2.6146, Validation Accuracy: 0.4444\n",
      "Epoch [214/250], Loss: 0.1274, Accuracy: 0.9482\n",
      "Validation Loss: 3.1369, Validation Accuracy: 0.3968\n",
      "Epoch [215/250], Loss: 0.1591, Accuracy: 0.9363\n",
      "Validation Loss: 1.0172, Validation Accuracy: 0.6111\n",
      "Epoch [216/250], Loss: 0.1361, Accuracy: 0.9442\n",
      "Validation Loss: 0.7869, Validation Accuracy: 0.8016\n",
      "Epoch [217/250], Loss: 0.1605, Accuracy: 0.9482\n",
      "Validation Loss: 1.1963, Validation Accuracy: 0.7540\n",
      "Epoch [218/250], Loss: 0.1217, Accuracy: 0.9442\n",
      "Validation Loss: 0.6970, Validation Accuracy: 0.8651\n",
      "Epoch [219/250], Loss: 0.1275, Accuracy: 0.9522\n",
      "Validation Loss: 0.4660, Validation Accuracy: 0.8810\n",
      "Epoch [220/250], Loss: 0.1720, Accuracy: 0.9363\n",
      "Validation Loss: 0.6388, Validation Accuracy: 0.8730\n",
      "Epoch [221/250], Loss: 0.1649, Accuracy: 0.9402\n",
      "Validation Loss: 1.0045, Validation Accuracy: 0.7540\n",
      "Epoch [222/250], Loss: 0.1648, Accuracy: 0.9402\n",
      "Validation Loss: 4.9068, Validation Accuracy: 0.4048\n",
      "Epoch [223/250], Loss: 0.1712, Accuracy: 0.9442\n",
      "Validation Loss: 3.5955, Validation Accuracy: 0.4683\n",
      "Epoch [224/250], Loss: 0.1263, Accuracy: 0.9602\n",
      "Validation Loss: 0.6184, Validation Accuracy: 0.8730\n",
      "Epoch [225/250], Loss: 0.0820, Accuracy: 0.9761\n",
      "Validation Loss: 0.5342, Validation Accuracy: 0.8730\n",
      "Epoch [226/250], Loss: 0.1794, Accuracy: 0.9243\n",
      "Validation Loss: 1.6440, Validation Accuracy: 0.5873\n",
      "Epoch [227/250], Loss: 0.1381, Accuracy: 0.9681\n",
      "Validation Loss: 0.5572, Validation Accuracy: 0.8333\n",
      "Epoch [228/250], Loss: 0.1603, Accuracy: 0.9641\n",
      "Validation Loss: 0.6277, Validation Accuracy: 0.8571\n",
      "Epoch [229/250], Loss: 0.1289, Accuracy: 0.9562\n",
      "Validation Loss: 0.7287, Validation Accuracy: 0.8413\n",
      "Epoch [230/250], Loss: 0.1732, Accuracy: 0.9323\n",
      "Validation Loss: 2.1758, Validation Accuracy: 0.6190\n",
      "Epoch [231/250], Loss: 0.1156, Accuracy: 0.9442\n",
      "Validation Loss: 1.0749, Validation Accuracy: 0.7063\n",
      "Epoch [232/250], Loss: 0.1118, Accuracy: 0.9602\n",
      "Validation Loss: 3.0070, Validation Accuracy: 0.6190\n",
      "Epoch [233/250], Loss: 0.1183, Accuracy: 0.9522\n",
      "Validation Loss: 3.4776, Validation Accuracy: 0.6190\n",
      "Epoch [234/250], Loss: 0.1226, Accuracy: 0.9482\n",
      "Validation Loss: 0.5228, Validation Accuracy: 0.8968\n",
      "Epoch [235/250], Loss: 0.1188, Accuracy: 0.9641\n",
      "Validation Loss: 1.0184, Validation Accuracy: 0.8095\n",
      "Epoch [236/250], Loss: 0.1120, Accuracy: 0.9522\n",
      "Validation Loss: 0.8338, Validation Accuracy: 0.8810\n",
      "Epoch [237/250], Loss: 0.1107, Accuracy: 0.9641\n",
      "Validation Loss: 1.1014, Validation Accuracy: 0.8492\n",
      "Epoch [238/250], Loss: 0.1337, Accuracy: 0.9522\n",
      "Validation Loss: 0.7516, Validation Accuracy: 0.8413\n",
      "Epoch [239/250], Loss: 0.2244, Accuracy: 0.9402\n",
      "Validation Loss: 0.9564, Validation Accuracy: 0.7937\n",
      "Epoch [240/250], Loss: 0.1173, Accuracy: 0.9602\n",
      "Validation Loss: 1.4715, Validation Accuracy: 0.6746\n",
      "Epoch [241/250], Loss: 0.0989, Accuracy: 0.9721\n",
      "Validation Loss: 1.5752, Validation Accuracy: 0.7063\n",
      "Epoch [242/250], Loss: 0.1076, Accuracy: 0.9522\n",
      "Validation Loss: 2.7097, Validation Accuracy: 0.5556\n",
      "Epoch [243/250], Loss: 0.1369, Accuracy: 0.9442\n",
      "Validation Loss: 4.2999, Validation Accuracy: 0.4206\n",
      "Epoch [244/250], Loss: 0.1553, Accuracy: 0.9442\n",
      "Validation Loss: 1.1688, Validation Accuracy: 0.7302\n",
      "Epoch [245/250], Loss: 0.1004, Accuracy: 0.9641\n",
      "Validation Loss: 2.8312, Validation Accuracy: 0.5397\n",
      "Epoch [246/250], Loss: 0.0714, Accuracy: 0.9761\n",
      "Validation Loss: 3.5170, Validation Accuracy: 0.5079\n",
      "Epoch [247/250], Loss: 0.1234, Accuracy: 0.9482\n",
      "Validation Loss: 1.2628, Validation Accuracy: 0.6825\n",
      "Epoch [248/250], Loss: 0.1077, Accuracy: 0.9641\n",
      "Validation Loss: 1.5131, Validation Accuracy: 0.6111\n",
      "Epoch [249/250], Loss: 0.1071, Accuracy: 0.9522\n",
      "Validation Loss: 0.6197, Validation Accuracy: 0.8016\n",
      "Epoch [250/250], Loss: 0.1284, Accuracy: 0.9522\n",
      "Validation Loss: 2.2495, Validation Accuracy: 0.6508\n",
      "Test Loss: 3.3338\n",
      "Test Accuracy: 0.4762\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 160\n",
      "label 1 is 70\n",
      "label 2 is 25\n",
      "label 3 is 28\n",
      "Not setting metadata\n",
      "283 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (255, 8, 325)\n",
      "255 train samples\n",
      "128 test samples\n",
      "Number of batches in train_loader: 4\n",
      "{-1: 1.1206140350877194, 0: 0.9028268551236749}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.3024, Accuracy: 0.3255\n",
      "Validation Loss: 1.0650, Validation Accuracy: 0.5312\n",
      "Epoch [2/250], Loss: 1.0504, Accuracy: 0.5373\n",
      "Validation Loss: 0.8153, Validation Accuracy: 0.5312\n",
      "Epoch [3/250], Loss: 0.8453, Accuracy: 0.5294\n",
      "Validation Loss: 0.7393, Validation Accuracy: 0.4688\n",
      "Epoch [4/250], Loss: 0.8089, Accuracy: 0.4863\n",
      "Validation Loss: 0.7444, Validation Accuracy: 0.4688\n",
      "Epoch [5/250], Loss: 0.7759, Accuracy: 0.5333\n",
      "Validation Loss: 0.7365, Validation Accuracy: 0.4688\n",
      "Epoch [6/250], Loss: 0.7301, Accuracy: 0.6039\n",
      "Validation Loss: 0.7212, Validation Accuracy: 0.4688\n",
      "Epoch [7/250], Loss: 0.7350, Accuracy: 0.5725\n",
      "Validation Loss: 0.7171, Validation Accuracy: 0.4688\n",
      "Epoch [8/250], Loss: 0.7641, Accuracy: 0.5059\n",
      "Validation Loss: 0.7056, Validation Accuracy: 0.4688\n",
      "Epoch [9/250], Loss: 0.7649, Accuracy: 0.4902\n",
      "Validation Loss: 0.7268, Validation Accuracy: 0.4688\n",
      "Epoch [10/250], Loss: 0.7406, Accuracy: 0.5725\n",
      "Validation Loss: 0.7604, Validation Accuracy: 0.4688\n",
      "Epoch [11/250], Loss: 0.7692, Accuracy: 0.5333\n",
      "Validation Loss: 0.7225, Validation Accuracy: 0.4688\n",
      "Epoch [12/250], Loss: 0.7457, Accuracy: 0.5216\n",
      "Validation Loss: 0.7177, Validation Accuracy: 0.4688\n",
      "Epoch [13/250], Loss: 0.7302, Accuracy: 0.5569\n",
      "Validation Loss: 0.7032, Validation Accuracy: 0.4688\n",
      "Epoch [14/250], Loss: 0.7482, Accuracy: 0.5020\n",
      "Validation Loss: 0.7100, Validation Accuracy: 0.4688\n",
      "Epoch [15/250], Loss: 0.7220, Accuracy: 0.5686\n",
      "Validation Loss: 0.7222, Validation Accuracy: 0.4688\n",
      "Epoch [16/250], Loss: 0.7185, Accuracy: 0.5843\n",
      "Validation Loss: 0.7118, Validation Accuracy: 0.4688\n",
      "Epoch [17/250], Loss: 0.7377, Accuracy: 0.5451\n",
      "Validation Loss: 0.7208, Validation Accuracy: 0.4688\n",
      "Epoch [18/250], Loss: 0.7194, Accuracy: 0.5529\n",
      "Validation Loss: 0.7135, Validation Accuracy: 0.4688\n",
      "Epoch [19/250], Loss: 0.7313, Accuracy: 0.5608\n",
      "Validation Loss: 0.7084, Validation Accuracy: 0.4922\n",
      "Epoch [20/250], Loss: 0.7156, Accuracy: 0.5529\n",
      "Validation Loss: 0.7083, Validation Accuracy: 0.4922\n",
      "Epoch [21/250], Loss: 0.7044, Accuracy: 0.5804\n",
      "Validation Loss: 0.7142, Validation Accuracy: 0.4844\n",
      "Epoch [22/250], Loss: 0.7192, Accuracy: 0.5529\n",
      "Validation Loss: 0.7045, Validation Accuracy: 0.5156\n",
      "Epoch [23/250], Loss: 0.7409, Accuracy: 0.4980\n",
      "Validation Loss: 0.7213, Validation Accuracy: 0.4844\n",
      "Epoch [24/250], Loss: 0.7298, Accuracy: 0.5765\n",
      "Validation Loss: 0.6975, Validation Accuracy: 0.5156\n",
      "Epoch [25/250], Loss: 0.7359, Accuracy: 0.5255\n",
      "Validation Loss: 0.6985, Validation Accuracy: 0.4922\n",
      "Epoch [26/250], Loss: 0.7102, Accuracy: 0.5765\n",
      "Validation Loss: 0.6949, Validation Accuracy: 0.5312\n",
      "Epoch [27/250], Loss: 0.7123, Accuracy: 0.5529\n",
      "Validation Loss: 0.6863, Validation Accuracy: 0.5391\n",
      "Epoch [28/250], Loss: 0.6986, Accuracy: 0.6235\n",
      "Validation Loss: 0.6869, Validation Accuracy: 0.5469\n",
      "Epoch [29/250], Loss: 0.6871, Accuracy: 0.6118\n",
      "Validation Loss: 0.6997, Validation Accuracy: 0.5391\n",
      "Epoch [30/250], Loss: 0.7048, Accuracy: 0.5647\n",
      "Validation Loss: 0.7155, Validation Accuracy: 0.4922\n",
      "Epoch [31/250], Loss: 0.6195, Accuracy: 0.6902\n",
      "Validation Loss: 0.6023, Validation Accuracy: 0.6484\n",
      "Epoch [32/250], Loss: 0.6190, Accuracy: 0.6745\n",
      "Validation Loss: 0.7222, Validation Accuracy: 0.5938\n",
      "Epoch [33/250], Loss: 0.6003, Accuracy: 0.6980\n",
      "Validation Loss: 1.5050, Validation Accuracy: 0.4766\n",
      "Epoch [34/250], Loss: 0.4821, Accuracy: 0.7765\n",
      "Validation Loss: 1.7922, Validation Accuracy: 0.4766\n",
      "Epoch [35/250], Loss: 0.5869, Accuracy: 0.7451\n",
      "Validation Loss: 1.8996, Validation Accuracy: 0.4766\n",
      "Epoch [36/250], Loss: 0.4737, Accuracy: 0.8118\n",
      "Validation Loss: 1.5889, Validation Accuracy: 0.5391\n",
      "Epoch [37/250], Loss: 0.4019, Accuracy: 0.8157\n",
      "Validation Loss: 2.0204, Validation Accuracy: 0.4844\n",
      "Epoch [38/250], Loss: 0.4333, Accuracy: 0.8353\n",
      "Validation Loss: 1.9690, Validation Accuracy: 0.5234\n",
      "Epoch [39/250], Loss: 0.3045, Accuracy: 0.8863\n",
      "Validation Loss: 1.5471, Validation Accuracy: 0.6094\n",
      "Epoch [40/250], Loss: 0.3052, Accuracy: 0.9020\n",
      "Validation Loss: 1.0353, Validation Accuracy: 0.7422\n",
      "Epoch [41/250], Loss: 0.2744, Accuracy: 0.9020\n",
      "Validation Loss: 1.7790, Validation Accuracy: 0.6328\n",
      "Epoch [42/250], Loss: 0.3563, Accuracy: 0.8588\n",
      "Validation Loss: 1.9145, Validation Accuracy: 0.6172\n",
      "Epoch [43/250], Loss: 0.3573, Accuracy: 0.8431\n",
      "Validation Loss: 1.7018, Validation Accuracy: 0.6406\n",
      "Epoch [44/250], Loss: 0.2581, Accuracy: 0.9176\n",
      "Validation Loss: 0.3035, Validation Accuracy: 0.8984\n",
      "Epoch [45/250], Loss: 0.2551, Accuracy: 0.9020\n",
      "Validation Loss: 0.2050, Validation Accuracy: 0.9453\n",
      "Epoch [46/250], Loss: 0.3097, Accuracy: 0.9020\n",
      "Validation Loss: 1.4239, Validation Accuracy: 0.7188\n",
      "Epoch [47/250], Loss: 0.2502, Accuracy: 0.9216\n",
      "Validation Loss: 1.3202, Validation Accuracy: 0.7500\n",
      "Epoch [48/250], Loss: 0.2668, Accuracy: 0.9059\n",
      "Validation Loss: 1.4574, Validation Accuracy: 0.7422\n",
      "Epoch [49/250], Loss: 0.2749, Accuracy: 0.9059\n",
      "Validation Loss: 1.4314, Validation Accuracy: 0.7422\n",
      "Epoch [50/250], Loss: 0.2721, Accuracy: 0.9294\n",
      "Validation Loss: 0.8878, Validation Accuracy: 0.8281\n",
      "Epoch [51/250], Loss: 0.2256, Accuracy: 0.9176\n",
      "Validation Loss: 0.2653, Validation Accuracy: 0.9453\n",
      "Epoch [52/250], Loss: 0.2606, Accuracy: 0.9412\n",
      "Validation Loss: 0.6304, Validation Accuracy: 0.8672\n",
      "Epoch [53/250], Loss: 0.2072, Accuracy: 0.9373\n",
      "Validation Loss: 0.9562, Validation Accuracy: 0.8047\n",
      "Epoch [54/250], Loss: 0.2165, Accuracy: 0.9294\n",
      "Validation Loss: 0.3684, Validation Accuracy: 0.9062\n",
      "Epoch [55/250], Loss: 0.2179, Accuracy: 0.9373\n",
      "Validation Loss: 1.0393, Validation Accuracy: 0.8125\n",
      "Epoch [56/250], Loss: 0.2084, Accuracy: 0.9294\n",
      "Validation Loss: 1.4590, Validation Accuracy: 0.7656\n",
      "Epoch [57/250], Loss: 0.2256, Accuracy: 0.9333\n",
      "Validation Loss: 0.7991, Validation Accuracy: 0.8438\n",
      "Epoch [58/250], Loss: 0.2168, Accuracy: 0.9294\n",
      "Validation Loss: 0.5991, Validation Accuracy: 0.8828\n",
      "Epoch [59/250], Loss: 0.1612, Accuracy: 0.9569\n",
      "Validation Loss: 0.5413, Validation Accuracy: 0.8906\n",
      "Epoch [60/250], Loss: 0.1814, Accuracy: 0.9529\n",
      "Validation Loss: 0.0816, Validation Accuracy: 0.9766\n",
      "Epoch [61/250], Loss: 0.1609, Accuracy: 0.9490\n",
      "Validation Loss: 0.3397, Validation Accuracy: 0.8672\n",
      "Epoch [62/250], Loss: 0.1691, Accuracy: 0.9451\n",
      "Validation Loss: 0.2416, Validation Accuracy: 0.8906\n",
      "Epoch [63/250], Loss: 0.1873, Accuracy: 0.9373\n",
      "Validation Loss: 0.0134, Validation Accuracy: 1.0000\n",
      "Epoch [64/250], Loss: 0.2149, Accuracy: 0.9412\n",
      "Validation Loss: 0.0197, Validation Accuracy: 0.9922\n",
      "Epoch [65/250], Loss: 0.1901, Accuracy: 0.9412\n",
      "Validation Loss: 0.2326, Validation Accuracy: 0.9141\n",
      "Epoch [66/250], Loss: 0.2003, Accuracy: 0.9451\n",
      "Validation Loss: 0.0195, Validation Accuracy: 1.0000\n",
      "Epoch [67/250], Loss: 0.1727, Accuracy: 0.9412\n",
      "Validation Loss: 0.0273, Validation Accuracy: 0.9922\n",
      "Epoch [68/250], Loss: 0.1205, Accuracy: 0.9725\n",
      "Validation Loss: 0.1317, Validation Accuracy: 0.9609\n",
      "Epoch [69/250], Loss: 0.1822, Accuracy: 0.9608\n",
      "Validation Loss: 0.0162, Validation Accuracy: 1.0000\n",
      "Epoch [70/250], Loss: 0.1510, Accuracy: 0.9647\n",
      "Validation Loss: 0.0149, Validation Accuracy: 1.0000\n",
      "Epoch [71/250], Loss: 0.1787, Accuracy: 0.9451\n",
      "Validation Loss: 0.0155, Validation Accuracy: 1.0000\n",
      "Epoch [72/250], Loss: 0.1586, Accuracy: 0.9569\n",
      "Validation Loss: 0.3021, Validation Accuracy: 0.9453\n",
      "Epoch [73/250], Loss: 0.1711, Accuracy: 0.9451\n",
      "Validation Loss: 0.2133, Validation Accuracy: 0.9688\n",
      "Epoch [74/250], Loss: 0.1678, Accuracy: 0.9529\n",
      "Validation Loss: 0.0243, Validation Accuracy: 0.9922\n",
      "Epoch [75/250], Loss: 0.1893, Accuracy: 0.9373\n",
      "Validation Loss: 0.0273, Validation Accuracy: 0.9922\n",
      "Epoch [76/250], Loss: 0.1236, Accuracy: 0.9686\n",
      "Validation Loss: 0.9311, Validation Accuracy: 0.7188\n",
      "Epoch [77/250], Loss: 0.1880, Accuracy: 0.9333\n",
      "Validation Loss: 0.0764, Validation Accuracy: 0.9766\n",
      "Epoch [78/250], Loss: 0.1477, Accuracy: 0.9569\n",
      "Validation Loss: 0.1217, Validation Accuracy: 0.9531\n",
      "Epoch [79/250], Loss: 0.1664, Accuracy: 0.9490\n",
      "Validation Loss: 0.0187, Validation Accuracy: 0.9922\n",
      "Epoch [80/250], Loss: 0.1353, Accuracy: 0.9686\n",
      "Validation Loss: 0.0095, Validation Accuracy: 1.0000\n",
      "Epoch [81/250], Loss: 0.1378, Accuracy: 0.9608\n",
      "Validation Loss: 0.0131, Validation Accuracy: 1.0000\n",
      "Epoch [82/250], Loss: 0.1815, Accuracy: 0.9569\n",
      "Validation Loss: 0.0151, Validation Accuracy: 1.0000\n",
      "Epoch [83/250], Loss: 0.1340, Accuracy: 0.9725\n",
      "Validation Loss: 0.0153, Validation Accuracy: 1.0000\n",
      "Epoch [84/250], Loss: 0.1295, Accuracy: 0.9686\n",
      "Validation Loss: 0.0627, Validation Accuracy: 0.9844\n",
      "Epoch [85/250], Loss: 0.1615, Accuracy: 0.9569\n",
      "Validation Loss: 0.0233, Validation Accuracy: 0.9922\n",
      "Epoch [86/250], Loss: 0.1135, Accuracy: 0.9686\n",
      "Validation Loss: 0.0440, Validation Accuracy: 0.9844\n",
      "Epoch [87/250], Loss: 0.1829, Accuracy: 0.9490\n",
      "Validation Loss: 0.4627, Validation Accuracy: 0.9219\n",
      "Epoch [88/250], Loss: 0.1378, Accuracy: 0.9608\n",
      "Validation Loss: 0.6106, Validation Accuracy: 0.9141\n",
      "Epoch [89/250], Loss: 0.1105, Accuracy: 0.9686\n",
      "Validation Loss: 0.6666, Validation Accuracy: 0.9141\n",
      "Epoch [90/250], Loss: 0.1077, Accuracy: 0.9686\n",
      "Validation Loss: 0.6925, Validation Accuracy: 0.9141\n",
      "Epoch [91/250], Loss: 0.1306, Accuracy: 0.9569\n",
      "Validation Loss: 0.6637, Validation Accuracy: 0.9062\n",
      "Epoch [92/250], Loss: 0.1598, Accuracy: 0.9529\n",
      "Validation Loss: 0.0146, Validation Accuracy: 1.0000\n",
      "Epoch [93/250], Loss: 0.1127, Accuracy: 0.9647\n",
      "Validation Loss: 0.0118, Validation Accuracy: 1.0000\n",
      "Epoch [94/250], Loss: 0.1182, Accuracy: 0.9608\n",
      "Validation Loss: 0.8160, Validation Accuracy: 0.8828\n",
      "Epoch [95/250], Loss: 0.1391, Accuracy: 0.9686\n",
      "Validation Loss: 0.2993, Validation Accuracy: 0.9531\n",
      "Epoch [96/250], Loss: 0.1259, Accuracy: 0.9647\n",
      "Validation Loss: 0.5882, Validation Accuracy: 0.9219\n",
      "Epoch [97/250], Loss: 0.1528, Accuracy: 0.9686\n",
      "Validation Loss: 0.1055, Validation Accuracy: 0.9844\n",
      "Epoch [98/250], Loss: 0.1052, Accuracy: 0.9686\n",
      "Validation Loss: 0.0185, Validation Accuracy: 0.9922\n",
      "Epoch [99/250], Loss: 0.1113, Accuracy: 0.9765\n",
      "Validation Loss: 0.0337, Validation Accuracy: 0.9922\n",
      "Epoch [100/250], Loss: 0.1370, Accuracy: 0.9686\n",
      "Validation Loss: 0.2043, Validation Accuracy: 0.9688\n",
      "Epoch [101/250], Loss: 0.1477, Accuracy: 0.9647\n",
      "Validation Loss: 0.0967, Validation Accuracy: 0.9844\n",
      "Epoch [102/250], Loss: 0.1545, Accuracy: 0.9529\n",
      "Validation Loss: 0.0797, Validation Accuracy: 0.9922\n",
      "Epoch [103/250], Loss: 0.1704, Accuracy: 0.9608\n",
      "Validation Loss: 0.0175, Validation Accuracy: 1.0000\n",
      "Epoch [104/250], Loss: 0.1062, Accuracy: 0.9804\n",
      "Validation Loss: 0.0261, Validation Accuracy: 0.9922\n",
      "Epoch [105/250], Loss: 0.0782, Accuracy: 0.9804\n",
      "Validation Loss: 0.0085, Validation Accuracy: 1.0000\n",
      "Epoch [106/250], Loss: 0.0861, Accuracy: 0.9804\n",
      "Validation Loss: 0.0078, Validation Accuracy: 1.0000\n",
      "Epoch [107/250], Loss: 0.0913, Accuracy: 0.9765\n",
      "Validation Loss: 0.0066, Validation Accuracy: 1.0000\n",
      "Epoch [108/250], Loss: 0.1579, Accuracy: 0.9647\n",
      "Validation Loss: 0.0284, Validation Accuracy: 0.9922\n",
      "Epoch [109/250], Loss: 0.1247, Accuracy: 0.9725\n",
      "Validation Loss: 0.0184, Validation Accuracy: 1.0000\n",
      "Epoch [110/250], Loss: 0.1144, Accuracy: 0.9686\n",
      "Validation Loss: 0.0585, Validation Accuracy: 0.9844\n",
      "Epoch [111/250], Loss: 0.1009, Accuracy: 0.9765\n",
      "Validation Loss: 0.1595, Validation Accuracy: 0.9766\n",
      "Epoch [112/250], Loss: 0.1275, Accuracy: 0.9647\n",
      "Validation Loss: 0.1821, Validation Accuracy: 0.9766\n",
      "Epoch [113/250], Loss: 0.1316, Accuracy: 0.9608\n",
      "Validation Loss: 0.5495, Validation Accuracy: 0.9219\n",
      "Epoch [114/250], Loss: 0.1506, Accuracy: 0.9608\n",
      "Validation Loss: 0.0714, Validation Accuracy: 0.9922\n",
      "Epoch [115/250], Loss: 0.1117, Accuracy: 0.9725\n",
      "Validation Loss: 0.0257, Validation Accuracy: 0.9922\n",
      "Epoch [116/250], Loss: 0.1098, Accuracy: 0.9725\n",
      "Validation Loss: 0.0656, Validation Accuracy: 0.9922\n",
      "Epoch [117/250], Loss: 0.1112, Accuracy: 0.9725\n",
      "Validation Loss: 0.0137, Validation Accuracy: 1.0000\n",
      "Epoch [118/250], Loss: 0.0941, Accuracy: 0.9804\n",
      "Validation Loss: 0.0114, Validation Accuracy: 1.0000\n",
      "Epoch [119/250], Loss: 0.1002, Accuracy: 0.9765\n",
      "Validation Loss: 0.0140, Validation Accuracy: 1.0000\n",
      "Epoch [120/250], Loss: 0.1352, Accuracy: 0.9569\n",
      "Validation Loss: 0.0148, Validation Accuracy: 1.0000\n",
      "Epoch [121/250], Loss: 0.1217, Accuracy: 0.9647\n",
      "Validation Loss: 0.0188, Validation Accuracy: 1.0000\n",
      "Epoch [122/250], Loss: 0.1473, Accuracy: 0.9569\n",
      "Validation Loss: 0.1567, Validation Accuracy: 0.9531\n",
      "Epoch [123/250], Loss: 0.1098, Accuracy: 0.9647\n",
      "Validation Loss: 0.1473, Validation Accuracy: 0.9453\n",
      "Epoch [124/250], Loss: 0.0899, Accuracy: 0.9804\n",
      "Validation Loss: 0.0766, Validation Accuracy: 0.9766\n",
      "Epoch [125/250], Loss: 0.1514, Accuracy: 0.9608\n",
      "Validation Loss: 0.1476, Validation Accuracy: 0.9688\n",
      "Epoch [126/250], Loss: 0.1636, Accuracy: 0.9608\n",
      "Validation Loss: 0.0278, Validation Accuracy: 0.9922\n",
      "Epoch [127/250], Loss: 0.0995, Accuracy: 0.9804\n",
      "Validation Loss: 0.0264, Validation Accuracy: 0.9922\n",
      "Epoch [128/250], Loss: 0.0808, Accuracy: 0.9804\n",
      "Validation Loss: 0.0287, Validation Accuracy: 0.9922\n",
      "Epoch [129/250], Loss: 0.0916, Accuracy: 0.9804\n",
      "Validation Loss: 0.0824, Validation Accuracy: 0.9766\n",
      "Epoch [130/250], Loss: 0.1088, Accuracy: 0.9725\n",
      "Validation Loss: 0.0197, Validation Accuracy: 0.9922\n",
      "Epoch [131/250], Loss: 0.1287, Accuracy: 0.9686\n",
      "Validation Loss: 0.0168, Validation Accuracy: 1.0000\n",
      "Epoch [132/250], Loss: 0.1053, Accuracy: 0.9725\n",
      "Validation Loss: 0.0136, Validation Accuracy: 1.0000\n",
      "Epoch [133/250], Loss: 0.1017, Accuracy: 0.9765\n",
      "Validation Loss: 0.0839, Validation Accuracy: 0.9922\n",
      "Epoch [134/250], Loss: 0.1051, Accuracy: 0.9686\n",
      "Validation Loss: 0.3931, Validation Accuracy: 0.9375\n",
      "Epoch [135/250], Loss: 0.1073, Accuracy: 0.9647\n",
      "Validation Loss: 0.6281, Validation Accuracy: 0.9297\n",
      "Epoch [136/250], Loss: 0.1040, Accuracy: 0.9765\n",
      "Validation Loss: 0.0159, Validation Accuracy: 1.0000\n",
      "Epoch [137/250], Loss: 0.1459, Accuracy: 0.9608\n",
      "Validation Loss: 1.2558, Validation Accuracy: 0.6562\n",
      "Epoch [138/250], Loss: 0.0996, Accuracy: 0.9765\n",
      "Validation Loss: 0.6537, Validation Accuracy: 0.8125\n",
      "Epoch [139/250], Loss: 0.0917, Accuracy: 0.9765\n",
      "Validation Loss: 0.2376, Validation Accuracy: 0.9375\n",
      "Epoch [140/250], Loss: 0.1313, Accuracy: 0.9725\n",
      "Validation Loss: 0.7255, Validation Accuracy: 0.7891\n",
      "Epoch [141/250], Loss: 0.0914, Accuracy: 0.9804\n",
      "Validation Loss: 0.0453, Validation Accuracy: 0.9844\n",
      "Epoch [142/250], Loss: 0.1120, Accuracy: 0.9765\n",
      "Validation Loss: 0.0634, Validation Accuracy: 0.9766\n",
      "Epoch [143/250], Loss: 0.1129, Accuracy: 0.9647\n",
      "Validation Loss: 0.0111, Validation Accuracy: 1.0000\n",
      "Epoch [144/250], Loss: 0.1192, Accuracy: 0.9647\n",
      "Validation Loss: 0.0217, Validation Accuracy: 0.9922\n",
      "Epoch [145/250], Loss: 0.1129, Accuracy: 0.9686\n",
      "Validation Loss: 0.0110, Validation Accuracy: 1.0000\n",
      "Epoch [146/250], Loss: 0.0894, Accuracy: 0.9686\n",
      "Validation Loss: 0.0096, Validation Accuracy: 1.0000\n",
      "Epoch [147/250], Loss: 0.1092, Accuracy: 0.9725\n",
      "Validation Loss: 0.0421, Validation Accuracy: 0.9922\n",
      "Epoch [148/250], Loss: 0.1072, Accuracy: 0.9765\n",
      "Validation Loss: 0.0099, Validation Accuracy: 1.0000\n",
      "Epoch [149/250], Loss: 0.1307, Accuracy: 0.9608\n",
      "Validation Loss: 0.2757, Validation Accuracy: 0.9609\n",
      "Epoch [150/250], Loss: 0.1306, Accuracy: 0.9686\n",
      "Validation Loss: 0.0106, Validation Accuracy: 1.0000\n",
      "Epoch [151/250], Loss: 0.1462, Accuracy: 0.9569\n",
      "Validation Loss: 0.0174, Validation Accuracy: 1.0000\n",
      "Epoch [152/250], Loss: 0.1292, Accuracy: 0.9686\n",
      "Validation Loss: 0.0173, Validation Accuracy: 1.0000\n",
      "Epoch [153/250], Loss: 0.1201, Accuracy: 0.9725\n",
      "Validation Loss: 0.0114, Validation Accuracy: 1.0000\n",
      "Epoch [154/250], Loss: 0.1068, Accuracy: 0.9725\n",
      "Validation Loss: 0.0092, Validation Accuracy: 1.0000\n",
      "Epoch [155/250], Loss: 0.0841, Accuracy: 0.9804\n",
      "Validation Loss: 0.0089, Validation Accuracy: 1.0000\n",
      "Epoch [156/250], Loss: 0.1094, Accuracy: 0.9765\n",
      "Validation Loss: 0.0191, Validation Accuracy: 0.9922\n",
      "Epoch [157/250], Loss: 0.1078, Accuracy: 0.9765\n",
      "Validation Loss: 0.1851, Validation Accuracy: 0.9453\n",
      "Epoch [158/250], Loss: 0.1193, Accuracy: 0.9725\n",
      "Validation Loss: 0.0971, Validation Accuracy: 0.9609\n",
      "Epoch [159/250], Loss: 0.1057, Accuracy: 0.9804\n",
      "Validation Loss: 0.0386, Validation Accuracy: 0.9844\n",
      "Epoch [160/250], Loss: 0.1097, Accuracy: 0.9686\n",
      "Validation Loss: 0.0217, Validation Accuracy: 0.9922\n",
      "Epoch [161/250], Loss: 0.0948, Accuracy: 0.9804\n",
      "Validation Loss: 0.1194, Validation Accuracy: 0.9844\n",
      "Epoch [162/250], Loss: 0.0888, Accuracy: 0.9765\n",
      "Validation Loss: 0.0130, Validation Accuracy: 1.0000\n",
      "Epoch [163/250], Loss: 0.0840, Accuracy: 0.9765\n",
      "Validation Loss: 0.0091, Validation Accuracy: 1.0000\n",
      "Epoch [164/250], Loss: 0.1071, Accuracy: 0.9725\n",
      "Validation Loss: 0.0913, Validation Accuracy: 0.9844\n",
      "Epoch [165/250], Loss: 0.1042, Accuracy: 0.9725\n",
      "Validation Loss: 0.5040, Validation Accuracy: 0.8438\n",
      "Epoch [166/250], Loss: 0.1013, Accuracy: 0.9725\n",
      "Validation Loss: 0.1364, Validation Accuracy: 0.9531\n",
      "Epoch [167/250], Loss: 0.0859, Accuracy: 0.9804\n",
      "Validation Loss: 0.0613, Validation Accuracy: 0.9766\n",
      "Epoch [168/250], Loss: 0.0965, Accuracy: 0.9804\n",
      "Validation Loss: 0.0356, Validation Accuracy: 0.9922\n",
      "Epoch [169/250], Loss: 0.1152, Accuracy: 0.9647\n",
      "Validation Loss: 1.7390, Validation Accuracy: 0.5625\n",
      "Epoch [170/250], Loss: 0.1236, Accuracy: 0.9686\n",
      "Validation Loss: 0.2516, Validation Accuracy: 0.9219\n",
      "Epoch [171/250], Loss: 0.1277, Accuracy: 0.9647\n",
      "Validation Loss: 0.0377, Validation Accuracy: 0.9922\n",
      "Epoch [172/250], Loss: 0.0997, Accuracy: 0.9765\n",
      "Validation Loss: 0.0563, Validation Accuracy: 0.9922\n",
      "Epoch [173/250], Loss: 0.1151, Accuracy: 0.9686\n",
      "Validation Loss: 0.2360, Validation Accuracy: 0.9688\n",
      "Epoch [174/250], Loss: 0.1062, Accuracy: 0.9725\n",
      "Validation Loss: 0.0089, Validation Accuracy: 1.0000\n",
      "Epoch [175/250], Loss: 0.1078, Accuracy: 0.9686\n",
      "Validation Loss: 0.0301, Validation Accuracy: 0.9922\n",
      "Epoch [176/250], Loss: 0.1006, Accuracy: 0.9725\n",
      "Validation Loss: 0.0333, Validation Accuracy: 0.9922\n",
      "Epoch [177/250], Loss: 0.0842, Accuracy: 0.9765\n",
      "Validation Loss: 0.0136, Validation Accuracy: 1.0000\n",
      "Epoch [178/250], Loss: 0.1100, Accuracy: 0.9725\n",
      "Validation Loss: 0.0368, Validation Accuracy: 0.9922\n",
      "Epoch [179/250], Loss: 0.0964, Accuracy: 0.9804\n",
      "Validation Loss: 0.0132, Validation Accuracy: 1.0000\n",
      "Epoch [180/250], Loss: 0.1050, Accuracy: 0.9765\n",
      "Validation Loss: 0.0551, Validation Accuracy: 0.9922\n",
      "Epoch [181/250], Loss: 0.0813, Accuracy: 0.9765\n",
      "Validation Loss: 0.0126, Validation Accuracy: 1.0000\n",
      "Epoch [182/250], Loss: 0.1097, Accuracy: 0.9647\n",
      "Validation Loss: 0.0270, Validation Accuracy: 0.9922\n",
      "Epoch [183/250], Loss: 0.0940, Accuracy: 0.9765\n",
      "Validation Loss: 0.2658, Validation Accuracy: 0.9609\n",
      "Epoch [184/250], Loss: 0.0881, Accuracy: 0.9765\n",
      "Validation Loss: 1.2416, Validation Accuracy: 0.8828\n",
      "Epoch [185/250], Loss: 0.1146, Accuracy: 0.9725\n",
      "Validation Loss: 0.3189, Validation Accuracy: 0.9609\n",
      "Epoch [186/250], Loss: 0.0849, Accuracy: 0.9765\n",
      "Validation Loss: 0.0828, Validation Accuracy: 0.9844\n",
      "Epoch [187/250], Loss: 0.1037, Accuracy: 0.9765\n",
      "Validation Loss: 0.2670, Validation Accuracy: 0.9688\n",
      "Epoch [188/250], Loss: 0.1123, Accuracy: 0.9725\n",
      "Validation Loss: 0.1334, Validation Accuracy: 0.9766\n",
      "Epoch [189/250], Loss: 0.0891, Accuracy: 0.9804\n",
      "Validation Loss: 0.0128, Validation Accuracy: 1.0000\n",
      "Epoch [190/250], Loss: 0.0878, Accuracy: 0.9804\n",
      "Validation Loss: 0.0369, Validation Accuracy: 0.9922\n",
      "Epoch [191/250], Loss: 0.0870, Accuracy: 0.9765\n",
      "Validation Loss: 0.0338, Validation Accuracy: 0.9922\n",
      "Epoch [192/250], Loss: 0.1020, Accuracy: 0.9765\n",
      "Validation Loss: 0.1113, Validation Accuracy: 0.9609\n",
      "Epoch [193/250], Loss: 0.0801, Accuracy: 0.9804\n",
      "Validation Loss: 0.1905, Validation Accuracy: 0.9375\n",
      "Epoch [194/250], Loss: 0.0777, Accuracy: 0.9765\n",
      "Validation Loss: 0.0299, Validation Accuracy: 0.9922\n",
      "Epoch [195/250], Loss: 0.0853, Accuracy: 0.9765\n",
      "Validation Loss: 0.0321, Validation Accuracy: 0.9922\n",
      "Epoch [196/250], Loss: 0.0921, Accuracy: 0.9765\n",
      "Validation Loss: 0.0815, Validation Accuracy: 0.9688\n",
      "Epoch [197/250], Loss: 0.0785, Accuracy: 0.9804\n",
      "Validation Loss: 0.0352, Validation Accuracy: 0.9844\n",
      "Epoch [198/250], Loss: 0.0748, Accuracy: 0.9804\n",
      "Validation Loss: 0.0171, Validation Accuracy: 0.9922\n",
      "Epoch [199/250], Loss: 0.0971, Accuracy: 0.9765\n",
      "Validation Loss: 0.0077, Validation Accuracy: 1.0000\n",
      "Epoch [200/250], Loss: 0.1389, Accuracy: 0.9686\n",
      "Validation Loss: 0.6599, Validation Accuracy: 0.9219\n",
      "Epoch [201/250], Loss: 0.0856, Accuracy: 0.9804\n",
      "Validation Loss: 0.6352, Validation Accuracy: 0.9219\n",
      "Epoch [202/250], Loss: 0.0812, Accuracy: 0.9804\n",
      "Validation Loss: 0.2978, Validation Accuracy: 0.9609\n",
      "Epoch [203/250], Loss: 0.0781, Accuracy: 0.9804\n",
      "Validation Loss: 0.1570, Validation Accuracy: 0.9766\n",
      "Epoch [204/250], Loss: 0.0756, Accuracy: 0.9804\n",
      "Validation Loss: 0.0356, Validation Accuracy: 0.9922\n",
      "Epoch [205/250], Loss: 0.0982, Accuracy: 0.9765\n",
      "Validation Loss: 0.0041, Validation Accuracy: 1.0000\n",
      "Epoch [206/250], Loss: 0.0873, Accuracy: 0.9765\n",
      "Validation Loss: 0.0090, Validation Accuracy: 1.0000\n",
      "Epoch [207/250], Loss: 0.0754, Accuracy: 0.9765\n",
      "Validation Loss: 0.0087, Validation Accuracy: 1.0000\n",
      "Epoch [208/250], Loss: 0.0853, Accuracy: 0.9765\n",
      "Validation Loss: 0.0442, Validation Accuracy: 0.9922\n",
      "Epoch [209/250], Loss: 0.0822, Accuracy: 0.9804\n",
      "Validation Loss: 0.0054, Validation Accuracy: 1.0000\n",
      "Epoch [210/250], Loss: 0.1089, Accuracy: 0.9647\n",
      "Validation Loss: 0.0819, Validation Accuracy: 0.9922\n",
      "Epoch [211/250], Loss: 0.0903, Accuracy: 0.9725\n",
      "Validation Loss: 1.8639, Validation Accuracy: 0.8203\n",
      "Epoch [212/250], Loss: 0.1024, Accuracy: 0.9686\n",
      "Validation Loss: 0.3394, Validation Accuracy: 0.9531\n",
      "Epoch [213/250], Loss: 0.1075, Accuracy: 0.9686\n",
      "Validation Loss: 0.0267, Validation Accuracy: 0.9922\n",
      "Epoch [214/250], Loss: 0.0911, Accuracy: 0.9725\n",
      "Validation Loss: 0.2493, Validation Accuracy: 0.9375\n",
      "Epoch [215/250], Loss: 0.1236, Accuracy: 0.9686\n",
      "Validation Loss: 0.2478, Validation Accuracy: 0.9453\n",
      "Epoch [216/250], Loss: 0.1195, Accuracy: 0.9686\n",
      "Validation Loss: 0.0884, Validation Accuracy: 0.9766\n",
      "Epoch [217/250], Loss: 0.1704, Accuracy: 0.9529\n",
      "Validation Loss: 1.1374, Validation Accuracy: 0.8594\n",
      "Epoch [218/250], Loss: 0.0828, Accuracy: 0.9765\n",
      "Validation Loss: 0.8496, Validation Accuracy: 0.9219\n",
      "Epoch [219/250], Loss: 0.1240, Accuracy: 0.9686\n",
      "Validation Loss: 0.5277, Validation Accuracy: 0.9375\n",
      "Epoch [220/250], Loss: 0.0864, Accuracy: 0.9765\n",
      "Validation Loss: 0.1490, Validation Accuracy: 0.9844\n",
      "Epoch [221/250], Loss: 0.0765, Accuracy: 0.9725\n",
      "Validation Loss: 0.4244, Validation Accuracy: 0.9609\n",
      "Epoch [222/250], Loss: 0.0688, Accuracy: 0.9804\n",
      "Validation Loss: 0.3639, Validation Accuracy: 0.9609\n",
      "Epoch [223/250], Loss: 0.0885, Accuracy: 0.9765\n",
      "Validation Loss: 0.1543, Validation Accuracy: 0.9844\n",
      "Epoch [224/250], Loss: 0.0691, Accuracy: 0.9765\n",
      "Validation Loss: 0.0203, Validation Accuracy: 0.9922\n",
      "Epoch [225/250], Loss: 0.0834, Accuracy: 0.9843\n",
      "Validation Loss: 0.0111, Validation Accuracy: 1.0000\n",
      "Epoch [226/250], Loss: 0.1124, Accuracy: 0.9686\n",
      "Validation Loss: 0.0127, Validation Accuracy: 1.0000\n",
      "Epoch [227/250], Loss: 0.0719, Accuracy: 0.9804\n",
      "Validation Loss: 0.0417, Validation Accuracy: 0.9844\n",
      "Epoch [228/250], Loss: 0.0583, Accuracy: 0.9804\n",
      "Validation Loss: 0.0091, Validation Accuracy: 1.0000\n",
      "Epoch [229/250], Loss: 0.0818, Accuracy: 0.9804\n",
      "Validation Loss: 0.0157, Validation Accuracy: 1.0000\n",
      "Epoch [230/250], Loss: 0.0888, Accuracy: 0.9725\n",
      "Validation Loss: 0.0393, Validation Accuracy: 0.9922\n",
      "Epoch [231/250], Loss: 0.0753, Accuracy: 0.9804\n",
      "Validation Loss: 0.0270, Validation Accuracy: 0.9922\n",
      "Epoch [232/250], Loss: 0.0566, Accuracy: 0.9804\n",
      "Validation Loss: 0.0213, Validation Accuracy: 0.9922\n",
      "Epoch [233/250], Loss: 0.0688, Accuracy: 0.9843\n",
      "Validation Loss: 0.0330, Validation Accuracy: 0.9922\n",
      "Epoch [234/250], Loss: 0.0677, Accuracy: 0.9804\n",
      "Validation Loss: 0.0612, Validation Accuracy: 0.9844\n",
      "Epoch [235/250], Loss: 0.0927, Accuracy: 0.9686\n",
      "Validation Loss: 0.0761, Validation Accuracy: 0.9922\n",
      "Epoch [236/250], Loss: 0.1010, Accuracy: 0.9725\n",
      "Validation Loss: 0.0405, Validation Accuracy: 0.9922\n",
      "Epoch [237/250], Loss: 0.0789, Accuracy: 0.9686\n",
      "Validation Loss: 0.0599, Validation Accuracy: 0.9844\n",
      "Epoch [238/250], Loss: 0.1026, Accuracy: 0.9725\n",
      "Validation Loss: 0.0746, Validation Accuracy: 0.9922\n",
      "Epoch [239/250], Loss: 0.1004, Accuracy: 0.9686\n",
      "Validation Loss: 0.0397, Validation Accuracy: 0.9922\n",
      "Epoch [240/250], Loss: 0.0554, Accuracy: 0.9804\n",
      "Validation Loss: 0.0265, Validation Accuracy: 0.9922\n",
      "Epoch [241/250], Loss: 0.0729, Accuracy: 0.9804\n",
      "Validation Loss: 0.0097, Validation Accuracy: 1.0000\n",
      "Epoch [242/250], Loss: 0.0880, Accuracy: 0.9686\n",
      "Validation Loss: 0.0259, Validation Accuracy: 0.9922\n",
      "Epoch [243/250], Loss: 0.1023, Accuracy: 0.9686\n",
      "Validation Loss: 0.3066, Validation Accuracy: 0.9375\n",
      "Epoch [244/250], Loss: 0.0668, Accuracy: 0.9765\n",
      "Validation Loss: 0.3277, Validation Accuracy: 0.9297\n",
      "Epoch [245/250], Loss: 0.0938, Accuracy: 0.9725\n",
      "Validation Loss: 0.5805, Validation Accuracy: 0.8828\n",
      "Epoch [246/250], Loss: 0.1051, Accuracy: 0.9686\n",
      "Validation Loss: 2.4307, Validation Accuracy: 0.6172\n",
      "Epoch [247/250], Loss: 0.0988, Accuracy: 0.9686\n",
      "Validation Loss: 1.4236, Validation Accuracy: 0.7656\n",
      "Epoch [248/250], Loss: 0.0693, Accuracy: 0.9804\n",
      "Validation Loss: 0.2916, Validation Accuracy: 0.9531\n",
      "Epoch [249/250], Loss: 0.0624, Accuracy: 0.9804\n",
      "Validation Loss: 0.0235, Validation Accuracy: 0.9922\n",
      "Epoch [250/250], Loss: 0.0662, Accuracy: 0.9765\n",
      "Validation Loss: 0.0387, Validation Accuracy: 0.9922\n",
      "Test Loss: 0.1813\n",
      "Test Accuracy: 0.9688\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 83\n",
      "label 1 is 28\n",
      "label 2 is 179\n",
      "label 3 is 37\n",
      "Not setting metadata\n",
      "327 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (277, 8, 325)\n",
      "277 train samples\n",
      "139 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.2171052631578947, 0: 0.8486238532110092}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.1574, Accuracy: 0.4549\n",
      "Validation Loss: 0.8687, Validation Accuracy: 0.5899\n",
      "Epoch [2/250], Loss: 0.8708, Accuracy: 0.5812\n",
      "Validation Loss: 0.7232, Validation Accuracy: 0.5899\n",
      "Epoch [3/250], Loss: 0.7537, Accuracy: 0.6209\n",
      "Validation Loss: 0.7000, Validation Accuracy: 0.5899\n",
      "Epoch [4/250], Loss: 0.7523, Accuracy: 0.5451\n",
      "Validation Loss: 0.7225, Validation Accuracy: 0.5899\n",
      "Epoch [5/250], Loss: 0.7357, Accuracy: 0.5848\n",
      "Validation Loss: 0.7530, Validation Accuracy: 0.5899\n",
      "Epoch [6/250], Loss: 0.7074, Accuracy: 0.6282\n",
      "Validation Loss: 0.7168, Validation Accuracy: 0.5899\n",
      "Epoch [7/250], Loss: 0.7259, Accuracy: 0.5560\n",
      "Validation Loss: 0.8567, Validation Accuracy: 0.5899\n",
      "Epoch [8/250], Loss: 0.6981, Accuracy: 0.6209\n",
      "Validation Loss: 0.8798, Validation Accuracy: 0.5899\n",
      "Epoch [9/250], Loss: 0.6725, Accuracy: 0.6282\n",
      "Validation Loss: 1.0163, Validation Accuracy: 0.5899\n",
      "Epoch [10/250], Loss: 0.6748, Accuracy: 0.6679\n",
      "Validation Loss: 1.2410, Validation Accuracy: 0.5899\n",
      "Epoch [11/250], Loss: 0.5930, Accuracy: 0.7256\n",
      "Validation Loss: 1.4143, Validation Accuracy: 0.5899\n",
      "Epoch [12/250], Loss: 0.5625, Accuracy: 0.7581\n",
      "Validation Loss: 1.3808, Validation Accuracy: 0.5899\n",
      "Epoch [13/250], Loss: 0.5194, Accuracy: 0.7581\n",
      "Validation Loss: 1.6224, Validation Accuracy: 0.5899\n",
      "Epoch [14/250], Loss: 0.4596, Accuracy: 0.7653\n",
      "Validation Loss: 1.3246, Validation Accuracy: 0.5899\n",
      "Epoch [15/250], Loss: 0.5026, Accuracy: 0.7834\n",
      "Validation Loss: 1.3048, Validation Accuracy: 0.6043\n",
      "Epoch [16/250], Loss: 0.5327, Accuracy: 0.7762\n",
      "Validation Loss: 1.8829, Validation Accuracy: 0.5899\n",
      "Epoch [17/250], Loss: 0.4123, Accuracy: 0.8448\n",
      "Validation Loss: 1.6287, Validation Accuracy: 0.6043\n",
      "Epoch [18/250], Loss: 0.3913, Accuracy: 0.8267\n",
      "Validation Loss: 0.2255, Validation Accuracy: 0.8849\n",
      "Epoch [19/250], Loss: 0.3729, Accuracy: 0.8412\n",
      "Validation Loss: 1.0733, Validation Accuracy: 0.6691\n",
      "Epoch [20/250], Loss: 0.3709, Accuracy: 0.8195\n",
      "Validation Loss: 2.3400, Validation Accuracy: 0.5899\n",
      "Epoch [21/250], Loss: 0.3287, Accuracy: 0.8700\n",
      "Validation Loss: 1.4727, Validation Accuracy: 0.6691\n",
      "Epoch [22/250], Loss: 0.3526, Accuracy: 0.8736\n",
      "Validation Loss: 0.2369, Validation Accuracy: 0.8777\n",
      "Epoch [23/250], Loss: 0.4283, Accuracy: 0.8628\n",
      "Validation Loss: 2.3547, Validation Accuracy: 0.4101\n",
      "Epoch [24/250], Loss: 0.2985, Accuracy: 0.8664\n",
      "Validation Loss: 1.2950, Validation Accuracy: 0.5612\n",
      "Epoch [25/250], Loss: 0.3139, Accuracy: 0.8700\n",
      "Validation Loss: 0.3891, Validation Accuracy: 0.8705\n",
      "Epoch [26/250], Loss: 0.2733, Accuracy: 0.9061\n",
      "Validation Loss: 0.1102, Validation Accuracy: 0.9353\n",
      "Epoch [27/250], Loss: 0.2972, Accuracy: 0.8773\n",
      "Validation Loss: 1.3565, Validation Accuracy: 0.7050\n",
      "Epoch [28/250], Loss: 0.2547, Accuracy: 0.9061\n",
      "Validation Loss: 0.7922, Validation Accuracy: 0.7986\n",
      "Epoch [29/250], Loss: 0.3793, Accuracy: 0.8628\n",
      "Validation Loss: 0.2508, Validation Accuracy: 0.8777\n",
      "Epoch [30/250], Loss: 0.3019, Accuracy: 0.8845\n",
      "Validation Loss: 2.5397, Validation Accuracy: 0.4101\n",
      "Epoch [31/250], Loss: 0.2878, Accuracy: 0.9025\n",
      "Validation Loss: 2.2586, Validation Accuracy: 0.4101\n",
      "Epoch [32/250], Loss: 0.4205, Accuracy: 0.8375\n",
      "Validation Loss: 2.2733, Validation Accuracy: 0.4173\n",
      "Epoch [33/250], Loss: 0.3321, Accuracy: 0.8556\n",
      "Validation Loss: 0.2595, Validation Accuracy: 0.8777\n",
      "Epoch [34/250], Loss: 0.2901, Accuracy: 0.8881\n",
      "Validation Loss: 2.0567, Validation Accuracy: 0.6259\n",
      "Epoch [35/250], Loss: 0.3501, Accuracy: 0.8628\n",
      "Validation Loss: 0.9688, Validation Accuracy: 0.7554\n",
      "Epoch [36/250], Loss: 0.3382, Accuracy: 0.8700\n",
      "Validation Loss: 0.1753, Validation Accuracy: 0.9065\n",
      "Epoch [37/250], Loss: 0.3135, Accuracy: 0.8664\n",
      "Validation Loss: 0.1447, Validation Accuracy: 0.9424\n",
      "Epoch [38/250], Loss: 0.2732, Accuracy: 0.8773\n",
      "Validation Loss: 1.3143, Validation Accuracy: 0.7266\n",
      "Epoch [39/250], Loss: 0.2881, Accuracy: 0.8809\n",
      "Validation Loss: 1.5897, Validation Accuracy: 0.6906\n",
      "Epoch [40/250], Loss: 0.2347, Accuracy: 0.8953\n",
      "Validation Loss: 1.5619, Validation Accuracy: 0.7122\n",
      "Epoch [41/250], Loss: 0.2805, Accuracy: 0.8917\n",
      "Validation Loss: 0.7165, Validation Accuracy: 0.7914\n",
      "Epoch [42/250], Loss: 0.2686, Accuracy: 0.8953\n",
      "Validation Loss: 2.2101, Validation Accuracy: 0.4532\n",
      "Epoch [43/250], Loss: 0.3146, Accuracy: 0.8917\n",
      "Validation Loss: 2.3079, Validation Accuracy: 0.4101\n",
      "Epoch [44/250], Loss: 0.2454, Accuracy: 0.8989\n",
      "Validation Loss: 3.0585, Validation Accuracy: 0.4101\n",
      "Epoch [45/250], Loss: 0.3389, Accuracy: 0.8664\n",
      "Validation Loss: 0.2714, Validation Accuracy: 0.8849\n",
      "Epoch [46/250], Loss: 0.2480, Accuracy: 0.9061\n",
      "Validation Loss: 0.2533, Validation Accuracy: 0.8993\n",
      "Epoch [47/250], Loss: 0.2566, Accuracy: 0.9061\n",
      "Validation Loss: 0.1104, Validation Accuracy: 0.9496\n",
      "Epoch [48/250], Loss: 0.2442, Accuracy: 0.9097\n",
      "Validation Loss: 0.8312, Validation Accuracy: 0.8201\n",
      "Epoch [49/250], Loss: 0.2044, Accuracy: 0.9206\n",
      "Validation Loss: 0.1166, Validation Accuracy: 0.9353\n",
      "Epoch [50/250], Loss: 0.1760, Accuracy: 0.9242\n",
      "Validation Loss: 0.1367, Validation Accuracy: 0.9209\n",
      "Epoch [51/250], Loss: 0.1721, Accuracy: 0.9458\n",
      "Validation Loss: 2.9814, Validation Accuracy: 0.4173\n",
      "Epoch [52/250], Loss: 0.2318, Accuracy: 0.9206\n",
      "Validation Loss: 0.9954, Validation Accuracy: 0.6978\n",
      "Epoch [53/250], Loss: 0.1603, Accuracy: 0.9495\n",
      "Validation Loss: 3.8753, Validation Accuracy: 0.4101\n",
      "Epoch [54/250], Loss: 0.1783, Accuracy: 0.9386\n",
      "Validation Loss: 0.4695, Validation Accuracy: 0.8777\n",
      "Epoch [55/250], Loss: 0.1858, Accuracy: 0.9350\n",
      "Validation Loss: 0.4334, Validation Accuracy: 0.8633\n",
      "Epoch [56/250], Loss: 0.1625, Accuracy: 0.9458\n",
      "Validation Loss: 0.2097, Validation Accuracy: 0.9209\n",
      "Epoch [57/250], Loss: 0.1587, Accuracy: 0.9458\n",
      "Validation Loss: 1.2554, Validation Accuracy: 0.7482\n",
      "Epoch [58/250], Loss: 0.4029, Accuracy: 0.8845\n",
      "Validation Loss: 3.7714, Validation Accuracy: 0.4101\n",
      "Epoch [59/250], Loss: 0.1831, Accuracy: 0.9314\n",
      "Validation Loss: 3.8620, Validation Accuracy: 0.4101\n",
      "Epoch [60/250], Loss: 0.1877, Accuracy: 0.9422\n",
      "Validation Loss: 4.2049, Validation Accuracy: 0.4101\n",
      "Epoch [61/250], Loss: 0.2390, Accuracy: 0.9206\n",
      "Validation Loss: 3.8712, Validation Accuracy: 0.4101\n",
      "Epoch [62/250], Loss: 0.1628, Accuracy: 0.9278\n",
      "Validation Loss: 3.0778, Validation Accuracy: 0.4317\n",
      "Epoch [63/250], Loss: 0.2185, Accuracy: 0.9170\n",
      "Validation Loss: 3.5680, Validation Accuracy: 0.4101\n",
      "Epoch [64/250], Loss: 0.1546, Accuracy: 0.9495\n",
      "Validation Loss: 1.9238, Validation Accuracy: 0.6043\n",
      "Epoch [65/250], Loss: 0.1769, Accuracy: 0.9458\n",
      "Validation Loss: 3.7040, Validation Accuracy: 0.4101\n",
      "Epoch [66/250], Loss: 0.2028, Accuracy: 0.9278\n",
      "Validation Loss: 0.4925, Validation Accuracy: 0.8633\n",
      "Epoch [67/250], Loss: 0.1470, Accuracy: 0.9350\n",
      "Validation Loss: 2.2398, Validation Accuracy: 0.6475\n",
      "Epoch [68/250], Loss: 0.1474, Accuracy: 0.9350\n",
      "Validation Loss: 0.1705, Validation Accuracy: 0.9353\n",
      "Epoch [69/250], Loss: 0.1857, Accuracy: 0.9386\n",
      "Validation Loss: 0.6460, Validation Accuracy: 0.8129\n",
      "Epoch [70/250], Loss: 0.2299, Accuracy: 0.9134\n",
      "Validation Loss: 2.3103, Validation Accuracy: 0.5468\n",
      "Epoch [71/250], Loss: 0.1353, Accuracy: 0.9567\n",
      "Validation Loss: 0.8794, Validation Accuracy: 0.7842\n",
      "Epoch [72/250], Loss: 0.1548, Accuracy: 0.9495\n",
      "Validation Loss: 0.0978, Validation Accuracy: 0.9640\n",
      "Epoch [73/250], Loss: 0.1411, Accuracy: 0.9422\n",
      "Validation Loss: 1.1713, Validation Accuracy: 0.7554\n",
      "Epoch [74/250], Loss: 0.1669, Accuracy: 0.9422\n",
      "Validation Loss: 4.1049, Validation Accuracy: 0.4101\n",
      "Epoch [75/250], Loss: 0.2386, Accuracy: 0.9061\n",
      "Validation Loss: 4.4070, Validation Accuracy: 0.4101\n",
      "Epoch [76/250], Loss: 0.1579, Accuracy: 0.9567\n",
      "Validation Loss: 0.2366, Validation Accuracy: 0.9065\n",
      "Epoch [77/250], Loss: 0.1828, Accuracy: 0.9422\n",
      "Validation Loss: 4.2765, Validation Accuracy: 0.4101\n",
      "Epoch [78/250], Loss: 0.1397, Accuracy: 0.9495\n",
      "Validation Loss: 1.6868, Validation Accuracy: 0.7050\n",
      "Epoch [79/250], Loss: 0.1616, Accuracy: 0.9458\n",
      "Validation Loss: 1.3057, Validation Accuracy: 0.7554\n",
      "Epoch [80/250], Loss: 0.2210, Accuracy: 0.9567\n",
      "Validation Loss: 0.2025, Validation Accuracy: 0.9353\n",
      "Epoch [81/250], Loss: 0.2506, Accuracy: 0.9097\n",
      "Validation Loss: 3.9324, Validation Accuracy: 0.4101\n",
      "Epoch [82/250], Loss: 0.1740, Accuracy: 0.9531\n",
      "Validation Loss: 3.9931, Validation Accuracy: 0.4101\n",
      "Epoch [83/250], Loss: 0.1788, Accuracy: 0.9350\n",
      "Validation Loss: 2.0064, Validation Accuracy: 0.5827\n",
      "Epoch [84/250], Loss: 0.1899, Accuracy: 0.9495\n",
      "Validation Loss: 0.2944, Validation Accuracy: 0.9065\n",
      "Epoch [85/250], Loss: 0.1651, Accuracy: 0.9531\n",
      "Validation Loss: 0.8390, Validation Accuracy: 0.8201\n",
      "Epoch [86/250], Loss: 0.1463, Accuracy: 0.9386\n",
      "Validation Loss: 0.1721, Validation Accuracy: 0.9424\n",
      "Epoch [87/250], Loss: 0.1259, Accuracy: 0.9603\n",
      "Validation Loss: 0.7272, Validation Accuracy: 0.8345\n",
      "Epoch [88/250], Loss: 0.1293, Accuracy: 0.9495\n",
      "Validation Loss: 1.9793, Validation Accuracy: 0.6331\n",
      "Epoch [89/250], Loss: 0.1404, Accuracy: 0.9458\n",
      "Validation Loss: 0.5902, Validation Accuracy: 0.8345\n",
      "Epoch [90/250], Loss: 0.2216, Accuracy: 0.9350\n",
      "Validation Loss: 0.2737, Validation Accuracy: 0.9137\n",
      "Epoch [91/250], Loss: 0.1246, Accuracy: 0.9458\n",
      "Validation Loss: 1.3641, Validation Accuracy: 0.7410\n",
      "Epoch [92/250], Loss: 0.1424, Accuracy: 0.9531\n",
      "Validation Loss: 0.1649, Validation Accuracy: 0.9424\n",
      "Epoch [93/250], Loss: 0.1225, Accuracy: 0.9495\n",
      "Validation Loss: 1.3662, Validation Accuracy: 0.7410\n",
      "Epoch [94/250], Loss: 0.1076, Accuracy: 0.9567\n",
      "Validation Loss: 0.1555, Validation Accuracy: 0.9424\n",
      "Epoch [95/250], Loss: 0.1661, Accuracy: 0.9567\n",
      "Validation Loss: 4.1538, Validation Accuracy: 0.4173\n",
      "Epoch [96/250], Loss: 0.1783, Accuracy: 0.9206\n",
      "Validation Loss: 4.5014, Validation Accuracy: 0.4101\n",
      "Epoch [97/250], Loss: 0.0979, Accuracy: 0.9639\n",
      "Validation Loss: 3.8410, Validation Accuracy: 0.4245\n",
      "Epoch [98/250], Loss: 0.1726, Accuracy: 0.9531\n",
      "Validation Loss: 1.0469, Validation Accuracy: 0.7698\n",
      "Epoch [99/250], Loss: 0.1355, Accuracy: 0.9711\n",
      "Validation Loss: 1.0213, Validation Accuracy: 0.7914\n",
      "Epoch [100/250], Loss: 0.0886, Accuracy: 0.9639\n",
      "Validation Loss: 2.3437, Validation Accuracy: 0.6043\n",
      "Epoch [101/250], Loss: 0.1515, Accuracy: 0.9567\n",
      "Validation Loss: 2.5819, Validation Accuracy: 0.5683\n",
      "Epoch [102/250], Loss: 0.1460, Accuracy: 0.9206\n",
      "Validation Loss: 4.2473, Validation Accuracy: 0.4101\n",
      "Epoch [103/250], Loss: 0.1138, Accuracy: 0.9567\n",
      "Validation Loss: 1.2247, Validation Accuracy: 0.7410\n",
      "Epoch [104/250], Loss: 0.1212, Accuracy: 0.9458\n",
      "Validation Loss: 0.0915, Validation Accuracy: 0.9568\n",
      "Epoch [105/250], Loss: 0.1296, Accuracy: 0.9531\n",
      "Validation Loss: 1.8874, Validation Accuracy: 0.6187\n",
      "Epoch [106/250], Loss: 0.1655, Accuracy: 0.9639\n",
      "Validation Loss: 1.2925, Validation Accuracy: 0.7338\n",
      "Epoch [107/250], Loss: 0.0925, Accuracy: 0.9639\n",
      "Validation Loss: 1.3981, Validation Accuracy: 0.7338\n",
      "Epoch [108/250], Loss: 0.0903, Accuracy: 0.9675\n",
      "Validation Loss: 0.9193, Validation Accuracy: 0.8201\n",
      "Epoch [109/250], Loss: 0.1108, Accuracy: 0.9639\n",
      "Validation Loss: 0.0803, Validation Accuracy: 0.9640\n",
      "Epoch [110/250], Loss: 0.1180, Accuracy: 0.9603\n",
      "Validation Loss: 0.2741, Validation Accuracy: 0.9137\n",
      "Epoch [111/250], Loss: 0.1523, Accuracy: 0.9350\n",
      "Validation Loss: 0.0883, Validation Accuracy: 0.9712\n",
      "Epoch [112/250], Loss: 0.1167, Accuracy: 0.9495\n",
      "Validation Loss: 5.0211, Validation Accuracy: 0.4101\n",
      "Epoch [113/250], Loss: 0.1213, Accuracy: 0.9495\n",
      "Validation Loss: 4.1158, Validation Accuracy: 0.4245\n",
      "Epoch [114/250], Loss: 0.1127, Accuracy: 0.9639\n",
      "Validation Loss: 0.6606, Validation Accuracy: 0.8345\n",
      "Epoch [115/250], Loss: 0.1328, Accuracy: 0.9495\n",
      "Validation Loss: 0.1701, Validation Accuracy: 0.9424\n",
      "Epoch [116/250], Loss: 0.1424, Accuracy: 0.9531\n",
      "Validation Loss: 0.1747, Validation Accuracy: 0.9353\n",
      "Epoch [117/250], Loss: 0.0989, Accuracy: 0.9639\n",
      "Validation Loss: 0.9160, Validation Accuracy: 0.7986\n",
      "Epoch [118/250], Loss: 0.1213, Accuracy: 0.9603\n",
      "Validation Loss: 0.0713, Validation Accuracy: 0.9712\n",
      "Epoch [119/250], Loss: 0.0774, Accuracy: 0.9856\n",
      "Validation Loss: 4.3981, Validation Accuracy: 0.4173\n",
      "Epoch [120/250], Loss: 0.0968, Accuracy: 0.9495\n",
      "Validation Loss: 5.7386, Validation Accuracy: 0.4101\n",
      "Epoch [121/250], Loss: 0.0765, Accuracy: 0.9639\n",
      "Validation Loss: 5.7191, Validation Accuracy: 0.4101\n",
      "Epoch [122/250], Loss: 0.1233, Accuracy: 0.9495\n",
      "Validation Loss: 5.4954, Validation Accuracy: 0.4101\n",
      "Epoch [123/250], Loss: 0.0862, Accuracy: 0.9567\n",
      "Validation Loss: 0.2006, Validation Accuracy: 0.9424\n",
      "Epoch [124/250], Loss: 0.0878, Accuracy: 0.9603\n",
      "Validation Loss: 0.4595, Validation Accuracy: 0.8921\n",
      "Epoch [125/250], Loss: 0.0968, Accuracy: 0.9783\n",
      "Validation Loss: 5.9762, Validation Accuracy: 0.4101\n",
      "Epoch [126/250], Loss: 0.0984, Accuracy: 0.9639\n",
      "Validation Loss: 0.0346, Validation Accuracy: 0.9856\n",
      "Epoch [127/250], Loss: 0.1120, Accuracy: 0.9567\n",
      "Validation Loss: 2.9023, Validation Accuracy: 0.5971\n",
      "Epoch [128/250], Loss: 0.1456, Accuracy: 0.9458\n",
      "Validation Loss: 0.0928, Validation Accuracy: 0.9496\n",
      "Epoch [129/250], Loss: 0.0792, Accuracy: 0.9675\n",
      "Validation Loss: 2.3030, Validation Accuracy: 0.6475\n",
      "Epoch [130/250], Loss: 0.1240, Accuracy: 0.9531\n",
      "Validation Loss: 0.0594, Validation Accuracy: 0.9640\n",
      "Epoch [131/250], Loss: 0.0719, Accuracy: 0.9747\n",
      "Validation Loss: 0.0742, Validation Accuracy: 0.9640\n",
      "Epoch [132/250], Loss: 0.0880, Accuracy: 0.9675\n",
      "Validation Loss: 0.0979, Validation Accuracy: 0.9640\n",
      "Epoch [133/250], Loss: 0.0778, Accuracy: 0.9711\n",
      "Validation Loss: 0.8390, Validation Accuracy: 0.8273\n",
      "Epoch [134/250], Loss: 0.1115, Accuracy: 0.9639\n",
      "Validation Loss: 3.1686, Validation Accuracy: 0.5899\n",
      "Epoch [135/250], Loss: 0.0806, Accuracy: 0.9711\n",
      "Validation Loss: 3.1159, Validation Accuracy: 0.5899\n",
      "Epoch [136/250], Loss: 0.0931, Accuracy: 0.9567\n",
      "Validation Loss: 0.9964, Validation Accuracy: 0.7986\n",
      "Epoch [137/250], Loss: 0.1027, Accuracy: 0.9747\n",
      "Validation Loss: 0.0668, Validation Accuracy: 0.9640\n",
      "Epoch [138/250], Loss: 0.1093, Accuracy: 0.9531\n",
      "Validation Loss: 6.8660, Validation Accuracy: 0.4101\n",
      "Epoch [139/250], Loss: 0.0826, Accuracy: 0.9747\n",
      "Validation Loss: 4.1241, Validation Accuracy: 0.4532\n",
      "Epoch [140/250], Loss: 0.0688, Accuracy: 0.9747\n",
      "Validation Loss: 5.8061, Validation Accuracy: 0.4173\n",
      "Epoch [141/250], Loss: 0.0687, Accuracy: 0.9639\n",
      "Validation Loss: 2.7413, Validation Accuracy: 0.6475\n",
      "Epoch [142/250], Loss: 0.0664, Accuracy: 0.9747\n",
      "Validation Loss: 0.0982, Validation Accuracy: 0.9712\n",
      "Epoch [143/250], Loss: 0.1036, Accuracy: 0.9639\n",
      "Validation Loss: 6.4492, Validation Accuracy: 0.4101\n",
      "Epoch [144/250], Loss: 0.0729, Accuracy: 0.9711\n",
      "Validation Loss: 0.7804, Validation Accuracy: 0.8417\n",
      "Epoch [145/250], Loss: 0.0610, Accuracy: 0.9711\n",
      "Validation Loss: 1.7303, Validation Accuracy: 0.7194\n",
      "Epoch [146/250], Loss: 0.0603, Accuracy: 0.9783\n",
      "Validation Loss: 0.1173, Validation Accuracy: 0.9568\n",
      "Epoch [147/250], Loss: 0.0742, Accuracy: 0.9783\n",
      "Validation Loss: 1.5175, Validation Accuracy: 0.7482\n",
      "Epoch [148/250], Loss: 0.1660, Accuracy: 0.9531\n",
      "Validation Loss: 6.0241, Validation Accuracy: 0.4101\n",
      "Epoch [149/250], Loss: 0.1424, Accuracy: 0.9458\n",
      "Validation Loss: 0.1199, Validation Accuracy: 0.9568\n",
      "Epoch [150/250], Loss: 0.1391, Accuracy: 0.9567\n",
      "Validation Loss: 0.1065, Validation Accuracy: 0.9496\n",
      "Epoch [151/250], Loss: 0.0941, Accuracy: 0.9567\n",
      "Validation Loss: 0.1035, Validation Accuracy: 0.9640\n",
      "Epoch [152/250], Loss: 0.0733, Accuracy: 0.9747\n",
      "Validation Loss: 0.7809, Validation Accuracy: 0.8345\n",
      "Epoch [153/250], Loss: 0.0921, Accuracy: 0.9567\n",
      "Validation Loss: 0.1958, Validation Accuracy: 0.9281\n",
      "Epoch [154/250], Loss: 0.1049, Accuracy: 0.9567\n",
      "Validation Loss: 0.9447, Validation Accuracy: 0.8058\n",
      "Epoch [155/250], Loss: 0.0628, Accuracy: 0.9675\n",
      "Validation Loss: 4.0882, Validation Accuracy: 0.4460\n",
      "Epoch [156/250], Loss: 0.0461, Accuracy: 0.9856\n",
      "Validation Loss: 1.2848, Validation Accuracy: 0.8129\n",
      "Epoch [157/250], Loss: 0.0788, Accuracy: 0.9675\n",
      "Validation Loss: 1.6847, Validation Accuracy: 0.7914\n",
      "Epoch [158/250], Loss: 0.0650, Accuracy: 0.9783\n",
      "Validation Loss: 3.2109, Validation Accuracy: 0.5899\n",
      "Epoch [159/250], Loss: 0.1143, Accuracy: 0.9711\n",
      "Validation Loss: 7.3030, Validation Accuracy: 0.4101\n",
      "Epoch [160/250], Loss: 0.0631, Accuracy: 0.9747\n",
      "Validation Loss: 0.1208, Validation Accuracy: 0.9568\n",
      "Epoch [161/250], Loss: 0.1098, Accuracy: 0.9603\n",
      "Validation Loss: 3.5390, Validation Accuracy: 0.5899\n",
      "Epoch [162/250], Loss: 0.1021, Accuracy: 0.9531\n",
      "Validation Loss: 1.5331, Validation Accuracy: 0.7482\n",
      "Epoch [163/250], Loss: 0.0646, Accuracy: 0.9675\n",
      "Validation Loss: 4.4452, Validation Accuracy: 0.4604\n",
      "Epoch [164/250], Loss: 0.1029, Accuracy: 0.9567\n",
      "Validation Loss: 5.4953, Validation Accuracy: 0.4173\n",
      "Epoch [165/250], Loss: 0.0367, Accuracy: 0.9892\n",
      "Validation Loss: 6.2347, Validation Accuracy: 0.4101\n",
      "Epoch [166/250], Loss: 0.1444, Accuracy: 0.9711\n",
      "Validation Loss: 0.0821, Validation Accuracy: 0.9640\n",
      "Epoch [167/250], Loss: 0.0682, Accuracy: 0.9856\n",
      "Validation Loss: 2.0787, Validation Accuracy: 0.6763\n",
      "Epoch [168/250], Loss: 0.0720, Accuracy: 0.9639\n",
      "Validation Loss: 3.3624, Validation Accuracy: 0.5899\n",
      "Epoch [169/250], Loss: 0.0797, Accuracy: 0.9675\n",
      "Validation Loss: 1.9763, Validation Accuracy: 0.7050\n",
      "Epoch [170/250], Loss: 0.0924, Accuracy: 0.9711\n",
      "Validation Loss: 1.0226, Validation Accuracy: 0.8561\n",
      "Epoch [171/250], Loss: 0.0632, Accuracy: 0.9639\n",
      "Validation Loss: 0.8937, Validation Accuracy: 0.8345\n",
      "Epoch [172/250], Loss: 0.0472, Accuracy: 0.9747\n",
      "Validation Loss: 0.0856, Validation Accuracy: 0.9784\n",
      "Epoch [173/250], Loss: 0.0992, Accuracy: 0.9567\n",
      "Validation Loss: 6.4498, Validation Accuracy: 0.4173\n",
      "Epoch [174/250], Loss: 0.0409, Accuracy: 0.9819\n",
      "Validation Loss: 2.7006, Validation Accuracy: 0.6619\n",
      "Epoch [175/250], Loss: 0.0308, Accuracy: 0.9892\n",
      "Validation Loss: 0.2078, Validation Accuracy: 0.9568\n",
      "Epoch [176/250], Loss: 0.0803, Accuracy: 0.9711\n",
      "Validation Loss: 0.2591, Validation Accuracy: 0.9353\n",
      "Epoch [177/250], Loss: 0.1571, Accuracy: 0.9495\n",
      "Validation Loss: 0.6900, Validation Accuracy: 0.8633\n",
      "Epoch [178/250], Loss: 0.1190, Accuracy: 0.9711\n",
      "Validation Loss: 0.0781, Validation Accuracy: 0.9640\n",
      "Epoch [179/250], Loss: 0.0921, Accuracy: 0.9603\n",
      "Validation Loss: 0.4490, Validation Accuracy: 0.8777\n",
      "Epoch [180/250], Loss: 0.0636, Accuracy: 0.9819\n",
      "Validation Loss: 0.1659, Validation Accuracy: 0.9496\n",
      "Epoch [181/250], Loss: 0.1303, Accuracy: 0.9603\n",
      "Validation Loss: 3.1014, Validation Accuracy: 0.5468\n",
      "Epoch [182/250], Loss: 0.0635, Accuracy: 0.9819\n",
      "Validation Loss: 6.9300, Validation Accuracy: 0.4101\n",
      "Epoch [183/250], Loss: 0.0800, Accuracy: 0.9639\n",
      "Validation Loss: 2.5592, Validation Accuracy: 0.6187\n",
      "Epoch [184/250], Loss: 0.0539, Accuracy: 0.9783\n",
      "Validation Loss: 2.2998, Validation Accuracy: 0.6906\n",
      "Epoch [185/250], Loss: 0.0475, Accuracy: 0.9783\n",
      "Validation Loss: 2.8694, Validation Accuracy: 0.6691\n",
      "Epoch [186/250], Loss: 0.0454, Accuracy: 0.9856\n",
      "Validation Loss: 0.0575, Validation Accuracy: 0.9712\n",
      "Epoch [187/250], Loss: 0.0949, Accuracy: 0.9747\n",
      "Validation Loss: 0.0977, Validation Accuracy: 0.9496\n",
      "Epoch [188/250], Loss: 0.0542, Accuracy: 0.9819\n",
      "Validation Loss: 0.1322, Validation Accuracy: 0.9640\n",
      "Epoch [189/250], Loss: 0.0734, Accuracy: 0.9711\n",
      "Validation Loss: 0.0883, Validation Accuracy: 0.9496\n",
      "Epoch [190/250], Loss: 0.0436, Accuracy: 0.9819\n",
      "Validation Loss: 3.3720, Validation Accuracy: 0.5036\n",
      "Epoch [191/250], Loss: 0.0544, Accuracy: 0.9819\n",
      "Validation Loss: 2.6969, Validation Accuracy: 0.6619\n",
      "Epoch [192/250], Loss: 0.0413, Accuracy: 0.9819\n",
      "Validation Loss: 5.1114, Validation Accuracy: 0.4532\n",
      "Epoch [193/250], Loss: 0.0458, Accuracy: 0.9783\n",
      "Validation Loss: 0.1175, Validation Accuracy: 0.9568\n",
      "Epoch [194/250], Loss: 0.0584, Accuracy: 0.9675\n",
      "Validation Loss: 2.2575, Validation Accuracy: 0.6978\n",
      "Epoch [195/250], Loss: 0.0529, Accuracy: 0.9747\n",
      "Validation Loss: 0.1418, Validation Accuracy: 0.9640\n",
      "Epoch [196/250], Loss: 0.0426, Accuracy: 0.9747\n",
      "Validation Loss: 3.4001, Validation Accuracy: 0.6331\n",
      "Epoch [197/250], Loss: 0.0935, Accuracy: 0.9783\n",
      "Validation Loss: 1.4590, Validation Accuracy: 0.7914\n",
      "Epoch [198/250], Loss: 0.1199, Accuracy: 0.9567\n",
      "Validation Loss: 0.2127, Validation Accuracy: 0.9424\n",
      "Epoch [199/250], Loss: 0.0376, Accuracy: 0.9928\n",
      "Validation Loss: 0.0921, Validation Accuracy: 0.9712\n",
      "Epoch [200/250], Loss: 0.0395, Accuracy: 0.9819\n",
      "Validation Loss: 0.1488, Validation Accuracy: 0.9496\n",
      "Epoch [201/250], Loss: 0.0690, Accuracy: 0.9819\n",
      "Validation Loss: 0.0808, Validation Accuracy: 0.9568\n",
      "Epoch [202/250], Loss: 0.0394, Accuracy: 0.9783\n",
      "Validation Loss: 1.0464, Validation Accuracy: 0.8345\n",
      "Epoch [203/250], Loss: 0.0257, Accuracy: 0.9928\n",
      "Validation Loss: 0.5212, Validation Accuracy: 0.8921\n",
      "Epoch [204/250], Loss: 0.0809, Accuracy: 0.9747\n",
      "Validation Loss: 0.0658, Validation Accuracy: 0.9784\n",
      "Epoch [205/250], Loss: 0.1702, Accuracy: 0.9639\n",
      "Validation Loss: 1.4621, Validation Accuracy: 0.7698\n",
      "Epoch [206/250], Loss: 0.0530, Accuracy: 0.9711\n",
      "Validation Loss: 0.0481, Validation Accuracy: 0.9856\n",
      "Epoch [207/250], Loss: 0.0623, Accuracy: 0.9675\n",
      "Validation Loss: 0.3790, Validation Accuracy: 0.9137\n",
      "Epoch [208/250], Loss: 0.0557, Accuracy: 0.9892\n",
      "Validation Loss: 1.5247, Validation Accuracy: 0.7554\n",
      "Epoch [209/250], Loss: 0.0648, Accuracy: 0.9819\n",
      "Validation Loss: 4.0924, Validation Accuracy: 0.4173\n",
      "Epoch [210/250], Loss: 0.0304, Accuracy: 0.9819\n",
      "Validation Loss: 0.0709, Validation Accuracy: 0.9712\n",
      "Epoch [211/250], Loss: 0.0490, Accuracy: 0.9856\n",
      "Validation Loss: 0.4606, Validation Accuracy: 0.8561\n",
      "Epoch [212/250], Loss: 0.0246, Accuracy: 0.9964\n",
      "Validation Loss: 1.4469, Validation Accuracy: 0.8129\n",
      "Epoch [213/250], Loss: 0.0438, Accuracy: 0.9747\n",
      "Validation Loss: 0.2608, Validation Accuracy: 0.9568\n",
      "Epoch [214/250], Loss: 0.0706, Accuracy: 0.9711\n",
      "Validation Loss: 0.1001, Validation Accuracy: 0.9568\n",
      "Epoch [215/250], Loss: 0.0333, Accuracy: 0.9892\n",
      "Validation Loss: 2.1122, Validation Accuracy: 0.7482\n",
      "Epoch [216/250], Loss: 0.0176, Accuracy: 0.9964\n",
      "Validation Loss: 1.6411, Validation Accuracy: 0.8058\n",
      "Epoch [217/250], Loss: 0.0466, Accuracy: 0.9856\n",
      "Validation Loss: 4.9677, Validation Accuracy: 0.4388\n",
      "Epoch [218/250], Loss: 0.0421, Accuracy: 0.9783\n",
      "Validation Loss: 6.1066, Validation Accuracy: 0.4173\n",
      "Epoch [219/250], Loss: 0.0397, Accuracy: 0.9928\n",
      "Validation Loss: 0.3926, Validation Accuracy: 0.9209\n",
      "Epoch [220/250], Loss: 0.0449, Accuracy: 0.9783\n",
      "Validation Loss: 2.3424, Validation Accuracy: 0.7338\n",
      "Epoch [221/250], Loss: 0.0198, Accuracy: 0.9928\n",
      "Validation Loss: 0.9835, Validation Accuracy: 0.8705\n",
      "Epoch [222/250], Loss: 0.0312, Accuracy: 0.9856\n",
      "Validation Loss: 1.5840, Validation Accuracy: 0.8129\n",
      "Epoch [223/250], Loss: 0.1087, Accuracy: 0.9711\n",
      "Validation Loss: 7.5680, Validation Accuracy: 0.4101\n",
      "Epoch [224/250], Loss: 0.0530, Accuracy: 0.9783\n",
      "Validation Loss: 0.3223, Validation Accuracy: 0.9137\n",
      "Epoch [225/250], Loss: 0.0697, Accuracy: 0.9856\n",
      "Validation Loss: 0.3245, Validation Accuracy: 0.9353\n",
      "Epoch [226/250], Loss: 0.0713, Accuracy: 0.9783\n",
      "Validation Loss: 0.1152, Validation Accuracy: 0.9712\n",
      "Epoch [227/250], Loss: 0.0795, Accuracy: 0.9747\n",
      "Validation Loss: 0.8903, Validation Accuracy: 0.8561\n",
      "Epoch [228/250], Loss: 0.0346, Accuracy: 0.9892\n",
      "Validation Loss: 0.0666, Validation Accuracy: 0.9784\n",
      "Epoch [229/250], Loss: 0.0672, Accuracy: 0.9783\n",
      "Validation Loss: 0.1451, Validation Accuracy: 0.9568\n",
      "Epoch [230/250], Loss: 0.0360, Accuracy: 0.9892\n",
      "Validation Loss: 1.7076, Validation Accuracy: 0.7194\n",
      "Epoch [231/250], Loss: 0.0820, Accuracy: 0.9603\n",
      "Validation Loss: 6.5005, Validation Accuracy: 0.4101\n",
      "Epoch [232/250], Loss: 0.0531, Accuracy: 0.9711\n",
      "Validation Loss: 0.5032, Validation Accuracy: 0.8849\n",
      "Epoch [233/250], Loss: 0.0571, Accuracy: 0.9819\n",
      "Validation Loss: 3.4566, Validation Accuracy: 0.6115\n",
      "Epoch [234/250], Loss: 0.0355, Accuracy: 0.9892\n",
      "Validation Loss: 6.2750, Validation Accuracy: 0.4245\n",
      "Epoch [235/250], Loss: 0.0719, Accuracy: 0.9747\n",
      "Validation Loss: 0.7986, Validation Accuracy: 0.8705\n",
      "Epoch [236/250], Loss: 0.0467, Accuracy: 0.9783\n",
      "Validation Loss: 0.1137, Validation Accuracy: 0.9568\n",
      "Epoch [237/250], Loss: 0.1218, Accuracy: 0.9711\n",
      "Validation Loss: 0.7964, Validation Accuracy: 0.8273\n",
      "Epoch [238/250], Loss: 0.0546, Accuracy: 0.9856\n",
      "Validation Loss: 0.0982, Validation Accuracy: 0.9784\n",
      "Epoch [239/250], Loss: 0.0611, Accuracy: 0.9892\n",
      "Validation Loss: 1.6530, Validation Accuracy: 0.7410\n",
      "Epoch [240/250], Loss: 0.0327, Accuracy: 0.9819\n",
      "Validation Loss: 1.3974, Validation Accuracy: 0.7770\n",
      "Epoch [241/250], Loss: 0.1088, Accuracy: 0.9783\n",
      "Validation Loss: 1.1243, Validation Accuracy: 0.8201\n",
      "Epoch [242/250], Loss: 0.0831, Accuracy: 0.9783\n",
      "Validation Loss: 1.0527, Validation Accuracy: 0.8345\n",
      "Epoch [243/250], Loss: 0.0886, Accuracy: 0.9711\n",
      "Validation Loss: 0.1037, Validation Accuracy: 0.9568\n",
      "Epoch [244/250], Loss: 0.0539, Accuracy: 0.9747\n",
      "Validation Loss: 0.0836, Validation Accuracy: 0.9640\n",
      "Epoch [245/250], Loss: 0.1179, Accuracy: 0.9783\n",
      "Validation Loss: 5.0625, Validation Accuracy: 0.4245\n",
      "Epoch [246/250], Loss: 0.0472, Accuracy: 0.9819\n",
      "Validation Loss: 3.3055, Validation Accuracy: 0.5540\n",
      "Epoch [247/250], Loss: 0.0571, Accuracy: 0.9783\n",
      "Validation Loss: 0.0637, Validation Accuracy: 0.9712\n",
      "Epoch [248/250], Loss: 0.0530, Accuracy: 0.9783\n",
      "Validation Loss: 0.7853, Validation Accuracy: 0.8633\n",
      "Epoch [249/250], Loss: 0.0821, Accuracy: 0.9856\n",
      "Validation Loss: 4.2317, Validation Accuracy: 0.5899\n",
      "Epoch [250/250], Loss: 0.0678, Accuracy: 0.9783\n",
      "Validation Loss: 3.6281, Validation Accuracy: 0.6043\n",
      "Test Loss: 5.6043\n",
      "Test Accuracy: 0.5324\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 202\n",
      "label 1 is 151\n",
      "label 2 is 22\n",
      "label 3 is 26\n",
      "Not setting metadata\n",
      "401 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (314, 8, 325)\n",
      "314 train samples\n",
      "157 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.3793859649122806, 0: 0.78428927680798}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.2118, Accuracy: 0.4331\n",
      "Validation Loss: 0.9225, Validation Accuracy: 0.5949\n",
      "Epoch [2/250], Loss: 0.9243, Accuracy: 0.6497\n",
      "Validation Loss: 0.7713, Validation Accuracy: 0.5949\n",
      "Epoch [3/250], Loss: 0.7553, Accuracy: 0.6656\n",
      "Validation Loss: 0.8070, Validation Accuracy: 0.4051\n",
      "Epoch [4/250], Loss: 0.6302, Accuracy: 0.7293\n",
      "Validation Loss: 1.4702, Validation Accuracy: 0.4051\n",
      "Epoch [5/250], Loss: 0.4584, Accuracy: 0.8599\n",
      "Validation Loss: 2.4705, Validation Accuracy: 0.4051\n",
      "Epoch [6/250], Loss: 0.3028, Accuracy: 0.9045\n",
      "Validation Loss: 3.3896, Validation Accuracy: 0.4051\n",
      "Epoch [7/250], Loss: 0.1963, Accuracy: 0.9395\n",
      "Validation Loss: 4.0602, Validation Accuracy: 0.4051\n",
      "Epoch [8/250], Loss: 0.1664, Accuracy: 0.9522\n",
      "Validation Loss: 4.4189, Validation Accuracy: 0.4051\n",
      "Epoch [9/250], Loss: 0.1124, Accuracy: 0.9777\n",
      "Validation Loss: 4.8605, Validation Accuracy: 0.4051\n",
      "Epoch [10/250], Loss: 0.1485, Accuracy: 0.9522\n",
      "Validation Loss: 5.1428, Validation Accuracy: 0.4051\n",
      "Epoch [11/250], Loss: 0.1074, Accuracy: 0.9713\n",
      "Validation Loss: 5.1009, Validation Accuracy: 0.4051\n",
      "Epoch [12/250], Loss: 0.1316, Accuracy: 0.9522\n",
      "Validation Loss: 4.9816, Validation Accuracy: 0.4051\n",
      "Epoch [13/250], Loss: 0.1182, Accuracy: 0.9618\n",
      "Validation Loss: 4.6044, Validation Accuracy: 0.4177\n",
      "Epoch [14/250], Loss: 0.0653, Accuracy: 0.9745\n",
      "Validation Loss: 3.8498, Validation Accuracy: 0.4747\n",
      "Epoch [15/250], Loss: 0.0395, Accuracy: 0.9936\n",
      "Validation Loss: 3.8608, Validation Accuracy: 0.4873\n",
      "Epoch [16/250], Loss: 0.0503, Accuracy: 0.9809\n",
      "Validation Loss: 4.4219, Validation Accuracy: 0.4873\n",
      "Epoch [17/250], Loss: 0.0517, Accuracy: 0.9841\n",
      "Validation Loss: 3.0960, Validation Accuracy: 0.5886\n",
      "Epoch [18/250], Loss: 0.0200, Accuracy: 0.9968\n",
      "Validation Loss: 0.8174, Validation Accuracy: 0.8734\n",
      "Epoch [19/250], Loss: 0.0415, Accuracy: 0.9904\n",
      "Validation Loss: 1.6179, Validation Accuracy: 0.7532\n",
      "Epoch [20/250], Loss: 0.0366, Accuracy: 0.9873\n",
      "Validation Loss: 0.1320, Validation Accuracy: 0.9684\n",
      "Epoch [21/250], Loss: 0.0635, Accuracy: 0.9809\n",
      "Validation Loss: 0.1267, Validation Accuracy: 0.9747\n",
      "Epoch [22/250], Loss: 0.0466, Accuracy: 0.9873\n",
      "Validation Loss: 1.9422, Validation Accuracy: 0.6709\n",
      "Epoch [23/250], Loss: 0.0177, Accuracy: 0.9968\n",
      "Validation Loss: 0.4714, Validation Accuracy: 0.9177\n",
      "Epoch [24/250], Loss: 0.0430, Accuracy: 0.9873\n",
      "Validation Loss: 0.4728, Validation Accuracy: 0.9114\n",
      "Epoch [25/250], Loss: 0.0294, Accuracy: 0.9936\n",
      "Validation Loss: 0.1472, Validation Accuracy: 0.9810\n",
      "Epoch [26/250], Loss: 0.0259, Accuracy: 0.9904\n",
      "Validation Loss: 3.1514, Validation Accuracy: 0.6456\n",
      "Epoch [27/250], Loss: 0.0546, Accuracy: 0.9873\n",
      "Validation Loss: 2.2280, Validation Accuracy: 0.7278\n",
      "Epoch [28/250], Loss: 0.0506, Accuracy: 0.9904\n",
      "Validation Loss: 0.1073, Validation Accuracy: 0.9873\n",
      "Epoch [29/250], Loss: 0.0187, Accuracy: 0.9968\n",
      "Validation Loss: 3.9973, Validation Accuracy: 0.5949\n",
      "Epoch [30/250], Loss: 0.0745, Accuracy: 0.9745\n",
      "Validation Loss: 1.9850, Validation Accuracy: 0.6772\n",
      "Epoch [31/250], Loss: 0.0252, Accuracy: 0.9936\n",
      "Validation Loss: 0.1833, Validation Accuracy: 0.9620\n",
      "Epoch [32/250], Loss: 0.0214, Accuracy: 0.9936\n",
      "Validation Loss: 0.5137, Validation Accuracy: 0.9177\n",
      "Epoch [33/250], Loss: 0.0266, Accuracy: 0.9968\n",
      "Validation Loss: 3.9777, Validation Accuracy: 0.6013\n",
      "Epoch [34/250], Loss: 0.0151, Accuracy: 0.9968\n",
      "Validation Loss: 0.6418, Validation Accuracy: 0.9051\n",
      "Epoch [35/250], Loss: 0.0732, Accuracy: 0.9713\n",
      "Validation Loss: 5.1018, Validation Accuracy: 0.5949\n",
      "Epoch [36/250], Loss: 0.0358, Accuracy: 0.9904\n",
      "Validation Loss: 0.1896, Validation Accuracy: 0.9620\n",
      "Epoch [37/250], Loss: 0.0188, Accuracy: 0.9968\n",
      "Validation Loss: 0.1096, Validation Accuracy: 0.9684\n",
      "Epoch [38/250], Loss: 0.0174, Accuracy: 0.9936\n",
      "Validation Loss: 1.0692, Validation Accuracy: 0.8481\n",
      "Epoch [39/250], Loss: 0.0139, Accuracy: 0.9968\n",
      "Validation Loss: 0.3938, Validation Accuracy: 0.9177\n",
      "Epoch [40/250], Loss: 0.0091, Accuracy: 0.9936\n",
      "Validation Loss: 0.4241, Validation Accuracy: 0.9430\n",
      "Epoch [41/250], Loss: 0.0309, Accuracy: 0.9873\n",
      "Validation Loss: 0.1488, Validation Accuracy: 0.9620\n",
      "Epoch [42/250], Loss: 0.0387, Accuracy: 0.9873\n",
      "Validation Loss: 0.1150, Validation Accuracy: 0.9810\n",
      "Epoch [43/250], Loss: 0.0263, Accuracy: 0.9904\n",
      "Validation Loss: 0.7443, Validation Accuracy: 0.8924\n",
      "Epoch [44/250], Loss: 0.0516, Accuracy: 0.9873\n",
      "Validation Loss: 0.1612, Validation Accuracy: 0.9747\n",
      "Epoch [45/250], Loss: 0.0649, Accuracy: 0.9873\n",
      "Validation Loss: 3.5313, Validation Accuracy: 0.5949\n",
      "Epoch [46/250], Loss: 0.0097, Accuracy: 1.0000\n",
      "Validation Loss: 4.7892, Validation Accuracy: 0.5949\n",
      "Epoch [47/250], Loss: 0.0431, Accuracy: 0.9904\n",
      "Validation Loss: 0.0795, Validation Accuracy: 0.9810\n",
      "Epoch [48/250], Loss: 0.0075, Accuracy: 1.0000\n",
      "Validation Loss: 0.6476, Validation Accuracy: 0.9051\n",
      "Epoch [49/250], Loss: 0.0086, Accuracy: 1.0000\n",
      "Validation Loss: 0.2443, Validation Accuracy: 0.9557\n",
      "Epoch [50/250], Loss: 0.0339, Accuracy: 0.9904\n",
      "Validation Loss: 0.1470, Validation Accuracy: 0.9747\n",
      "Epoch [51/250], Loss: 0.0130, Accuracy: 0.9968\n",
      "Validation Loss: 1.9595, Validation Accuracy: 0.7595\n",
      "Epoch [52/250], Loss: 0.0273, Accuracy: 0.9936\n",
      "Validation Loss: 0.0745, Validation Accuracy: 0.9873\n",
      "Epoch [53/250], Loss: 0.0622, Accuracy: 0.9873\n",
      "Validation Loss: 5.3583, Validation Accuracy: 0.5949\n",
      "Epoch [54/250], Loss: 0.0157, Accuracy: 0.9968\n",
      "Validation Loss: 3.8643, Validation Accuracy: 0.6013\n",
      "Epoch [55/250], Loss: 0.0133, Accuracy: 0.9968\n",
      "Validation Loss: 4.9403, Validation Accuracy: 0.5949\n",
      "Epoch [56/250], Loss: 0.0183, Accuracy: 0.9968\n",
      "Validation Loss: 0.2714, Validation Accuracy: 0.9557\n",
      "Epoch [57/250], Loss: 0.0057, Accuracy: 1.0000\n",
      "Validation Loss: 0.1433, Validation Accuracy: 0.9810\n",
      "Epoch [58/250], Loss: 0.0160, Accuracy: 0.9904\n",
      "Validation Loss: 2.6520, Validation Accuracy: 0.6962\n",
      "Epoch [59/250], Loss: 0.0184, Accuracy: 0.9968\n",
      "Validation Loss: 0.3060, Validation Accuracy: 0.9430\n",
      "Epoch [60/250], Loss: 0.0101, Accuracy: 0.9936\n",
      "Validation Loss: 2.1443, Validation Accuracy: 0.7658\n",
      "Epoch [61/250], Loss: 0.0065, Accuracy: 0.9968\n",
      "Validation Loss: 0.7396, Validation Accuracy: 0.9114\n",
      "Epoch [62/250], Loss: 0.0294, Accuracy: 0.9904\n",
      "Validation Loss: 0.1155, Validation Accuracy: 0.9810\n",
      "Epoch [63/250], Loss: 0.0047, Accuracy: 1.0000\n",
      "Validation Loss: 0.1363, Validation Accuracy: 0.9810\n",
      "Epoch [64/250], Loss: 0.0037, Accuracy: 1.0000\n",
      "Validation Loss: 0.1706, Validation Accuracy: 0.9810\n",
      "Epoch [65/250], Loss: 0.0053, Accuracy: 1.0000\n",
      "Validation Loss: 2.5673, Validation Accuracy: 0.7025\n",
      "Epoch [66/250], Loss: 0.0352, Accuracy: 0.9873\n",
      "Validation Loss: 0.3692, Validation Accuracy: 0.9367\n",
      "Epoch [67/250], Loss: 0.0448, Accuracy: 0.9809\n",
      "Validation Loss: 0.2610, Validation Accuracy: 0.9430\n",
      "Epoch [68/250], Loss: 0.0044, Accuracy: 1.0000\n",
      "Validation Loss: 0.1396, Validation Accuracy: 0.9810\n",
      "Epoch [69/250], Loss: 0.0051, Accuracy: 1.0000\n",
      "Validation Loss: 0.1676, Validation Accuracy: 0.9810\n",
      "Epoch [70/250], Loss: 0.0048, Accuracy: 1.0000\n",
      "Validation Loss: 0.1711, Validation Accuracy: 0.9810\n",
      "Epoch [71/250], Loss: 0.0131, Accuracy: 0.9904\n",
      "Validation Loss: 0.4807, Validation Accuracy: 0.9304\n",
      "Epoch [72/250], Loss: 0.0120, Accuracy: 0.9968\n",
      "Validation Loss: 2.6918, Validation Accuracy: 0.7025\n",
      "Epoch [73/250], Loss: 0.0243, Accuracy: 0.9936\n",
      "Validation Loss: 1.5083, Validation Accuracy: 0.7975\n",
      "Epoch [74/250], Loss: 0.0132, Accuracy: 0.9936\n",
      "Validation Loss: 1.2050, Validation Accuracy: 0.8165\n",
      "Epoch [75/250], Loss: 0.0350, Accuracy: 0.9904\n",
      "Validation Loss: 0.2084, Validation Accuracy: 0.9620\n",
      "Epoch [76/250], Loss: 0.0037, Accuracy: 1.0000\n",
      "Validation Loss: 0.1499, Validation Accuracy: 0.9810\n",
      "Epoch [77/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.1640, Validation Accuracy: 0.9810\n",
      "Epoch [78/250], Loss: 0.0212, Accuracy: 0.9904\n",
      "Validation Loss: 5.6307, Validation Accuracy: 0.5949\n",
      "Epoch [79/250], Loss: 0.0056, Accuracy: 1.0000\n",
      "Validation Loss: 5.5290, Validation Accuracy: 0.5949\n",
      "Epoch [80/250], Loss: 0.0064, Accuracy: 0.9968\n",
      "Validation Loss: 0.1608, Validation Accuracy: 0.9747\n",
      "Epoch [81/250], Loss: 0.0255, Accuracy: 0.9936\n",
      "Validation Loss: 0.2172, Validation Accuracy: 0.9620\n",
      "Epoch [82/250], Loss: 0.0176, Accuracy: 0.9936\n",
      "Validation Loss: 0.1673, Validation Accuracy: 0.9684\n",
      "Epoch [83/250], Loss: 0.0312, Accuracy: 0.9904\n",
      "Validation Loss: 2.2002, Validation Accuracy: 0.6899\n",
      "Epoch [84/250], Loss: 0.0134, Accuracy: 0.9968\n",
      "Validation Loss: 0.4994, Validation Accuracy: 0.9177\n",
      "Epoch [85/250], Loss: 0.0030, Accuracy: 1.0000\n",
      "Validation Loss: 0.5120, Validation Accuracy: 0.9114\n",
      "Epoch [86/250], Loss: 0.0036, Accuracy: 1.0000\n",
      "Validation Loss: 0.4672, Validation Accuracy: 0.9177\n",
      "Epoch [87/250], Loss: 0.0049, Accuracy: 1.0000\n",
      "Validation Loss: 0.1282, Validation Accuracy: 0.9810\n",
      "Epoch [88/250], Loss: 0.0060, Accuracy: 0.9968\n",
      "Validation Loss: 0.1924, Validation Accuracy: 0.9747\n",
      "Epoch [89/250], Loss: 0.0085, Accuracy: 0.9968\n",
      "Validation Loss: 3.6294, Validation Accuracy: 0.6519\n",
      "Epoch [90/250], Loss: 0.0159, Accuracy: 0.9904\n",
      "Validation Loss: 4.9508, Validation Accuracy: 0.6013\n",
      "Epoch [91/250], Loss: 0.0105, Accuracy: 0.9936\n",
      "Validation Loss: 0.4836, Validation Accuracy: 0.9241\n",
      "Epoch [92/250], Loss: 0.0055, Accuracy: 0.9968\n",
      "Validation Loss: 0.1942, Validation Accuracy: 0.9747\n",
      "Epoch [93/250], Loss: 0.0102, Accuracy: 0.9968\n",
      "Validation Loss: 1.4663, Validation Accuracy: 0.8608\n",
      "Epoch [94/250], Loss: 0.0184, Accuracy: 0.9904\n",
      "Validation Loss: 6.0852, Validation Accuracy: 0.5949\n",
      "Epoch [95/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 4.7628, Validation Accuracy: 0.6076\n",
      "Epoch [96/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 1.0414, Validation Accuracy: 0.8861\n",
      "Epoch [97/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.4514, Validation Accuracy: 0.9494\n",
      "Epoch [98/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.2800, Validation Accuracy: 0.9684\n",
      "Epoch [99/250], Loss: 0.0097, Accuracy: 0.9968\n",
      "Validation Loss: 0.2856, Validation Accuracy: 0.9430\n",
      "Epoch [100/250], Loss: 0.0327, Accuracy: 0.9936\n",
      "Validation Loss: 3.2912, Validation Accuracy: 0.7089\n",
      "Epoch [101/250], Loss: 0.0296, Accuracy: 0.9904\n",
      "Validation Loss: 0.5985, Validation Accuracy: 0.9177\n",
      "Epoch [102/250], Loss: 0.0051, Accuracy: 1.0000\n",
      "Validation Loss: 0.1438, Validation Accuracy: 0.9810\n",
      "Epoch [103/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.1681, Validation Accuracy: 0.9810\n",
      "Epoch [104/250], Loss: 0.0477, Accuracy: 0.9936\n",
      "Validation Loss: 0.2076, Validation Accuracy: 0.9747\n",
      "Epoch [105/250], Loss: 0.0036, Accuracy: 1.0000\n",
      "Validation Loss: 0.2000, Validation Accuracy: 0.9747\n",
      "Epoch [106/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.1768, Validation Accuracy: 0.9810\n",
      "Epoch [107/250], Loss: 0.0047, Accuracy: 0.9968\n",
      "Validation Loss: 0.1838, Validation Accuracy: 0.9810\n",
      "Epoch [108/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.4858, Validation Accuracy: 0.9367\n",
      "Epoch [109/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.3162, Validation Accuracy: 0.9684\n",
      "Epoch [110/250], Loss: 0.0144, Accuracy: 0.9968\n",
      "Validation Loss: 0.4576, Validation Accuracy: 0.9367\n",
      "Epoch [111/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.1868, Validation Accuracy: 0.9747\n",
      "Epoch [112/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.1405, Validation Accuracy: 0.9810\n",
      "Epoch [113/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.3185, Validation Accuracy: 0.9684\n",
      "Epoch [114/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.3814, Validation Accuracy: 0.9557\n",
      "Epoch [115/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.3009, Validation Accuracy: 0.9684\n",
      "Epoch [116/250], Loss: 0.0266, Accuracy: 0.9936\n",
      "Validation Loss: 4.0820, Validation Accuracy: 0.6392\n",
      "Epoch [117/250], Loss: 0.0024, Accuracy: 1.0000\n",
      "Validation Loss: 0.8404, Validation Accuracy: 0.8924\n",
      "Epoch [118/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.2520, Validation Accuracy: 0.9747\n",
      "Epoch [119/250], Loss: 0.0067, Accuracy: 0.9968\n",
      "Validation Loss: 0.2926, Validation Accuracy: 0.9684\n",
      "Epoch [120/250], Loss: 0.0138, Accuracy: 0.9968\n",
      "Validation Loss: 0.1959, Validation Accuracy: 0.9747\n",
      "Epoch [121/250], Loss: 0.0113, Accuracy: 0.9968\n",
      "Validation Loss: 0.3042, Validation Accuracy: 0.9557\n",
      "Epoch [122/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.1281, Validation Accuracy: 0.9747\n",
      "Epoch [123/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.5563, Validation Accuracy: 0.9304\n",
      "Epoch [124/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.5212, Validation Accuracy: 0.9367\n",
      "Epoch [125/250], Loss: 0.0145, Accuracy: 0.9968\n",
      "Validation Loss: 2.1183, Validation Accuracy: 0.8354\n",
      "Epoch [126/250], Loss: 0.0046, Accuracy: 0.9968\n",
      "Validation Loss: 1.9090, Validation Accuracy: 0.8354\n",
      "Epoch [127/250], Loss: 0.0051, Accuracy: 0.9968\n",
      "Validation Loss: 0.2037, Validation Accuracy: 0.9684\n",
      "Epoch [128/250], Loss: 0.0116, Accuracy: 0.9968\n",
      "Validation Loss: 0.2555, Validation Accuracy: 0.9684\n",
      "Epoch [129/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.9917, Validation Accuracy: 0.8861\n",
      "Epoch [130/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.8643, Validation Accuracy: 0.9114\n",
      "Epoch [131/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.4487, Validation Accuracy: 0.9494\n",
      "Epoch [132/250], Loss: 0.0058, Accuracy: 0.9968\n",
      "Validation Loss: 0.5215, Validation Accuracy: 0.9367\n",
      "Epoch [133/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.1176, Validation Accuracy: 0.9810\n",
      "Epoch [134/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.1765, Validation Accuracy: 0.9810\n",
      "Epoch [135/250], Loss: 0.0069, Accuracy: 0.9968\n",
      "Validation Loss: 0.5311, Validation Accuracy: 0.9367\n",
      "Epoch [136/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 3.3087, Validation Accuracy: 0.7278\n",
      "Epoch [137/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.6282, Validation Accuracy: 0.9367\n",
      "Epoch [138/250], Loss: 0.0256, Accuracy: 0.9936\n",
      "Validation Loss: 0.2166, Validation Accuracy: 0.9620\n",
      "Epoch [139/250], Loss: 0.0509, Accuracy: 0.9841\n",
      "Validation Loss: 1.2550, Validation Accuracy: 0.8544\n",
      "Epoch [140/250], Loss: 0.0072, Accuracy: 1.0000\n",
      "Validation Loss: 0.1862, Validation Accuracy: 0.9747\n",
      "Epoch [141/250], Loss: 0.0120, Accuracy: 0.9968\n",
      "Validation Loss: 0.7136, Validation Accuracy: 0.9051\n",
      "Epoch [142/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.4083, Validation Accuracy: 0.9494\n",
      "Epoch [143/250], Loss: 0.0039, Accuracy: 1.0000\n",
      "Validation Loss: 0.5610, Validation Accuracy: 0.9304\n",
      "Epoch [144/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.2795, Validation Accuracy: 0.9684\n",
      "Epoch [145/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.1984, Validation Accuracy: 0.9810\n",
      "Epoch [146/250], Loss: 0.0048, Accuracy: 0.9968\n",
      "Validation Loss: 0.2786, Validation Accuracy: 0.9620\n",
      "Epoch [147/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.1582, Validation Accuracy: 0.9747\n",
      "Epoch [148/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.4580, Validation Accuracy: 0.9494\n",
      "Epoch [149/250], Loss: 0.0074, Accuracy: 0.9968\n",
      "Validation Loss: 0.3756, Validation Accuracy: 0.9494\n",
      "Epoch [150/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.2401, Validation Accuracy: 0.9747\n",
      "Epoch [151/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.2071, Validation Accuracy: 0.9810\n",
      "Epoch [152/250], Loss: 0.0449, Accuracy: 0.9904\n",
      "Validation Loss: 0.3448, Validation Accuracy: 0.9557\n",
      "Epoch [153/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 1.0285, Validation Accuracy: 0.9051\n",
      "Epoch [154/250], Loss: 0.0046, Accuracy: 0.9968\n",
      "Validation Loss: 0.1594, Validation Accuracy: 0.9747\n",
      "Epoch [155/250], Loss: 0.0054, Accuracy: 0.9968\n",
      "Validation Loss: 0.2949, Validation Accuracy: 0.9747\n",
      "Epoch [156/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.2429, Validation Accuracy: 0.9684\n",
      "Epoch [157/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.1842, Validation Accuracy: 0.9747\n",
      "Epoch [158/250], Loss: 0.0031, Accuracy: 0.9968\n",
      "Validation Loss: 0.1810, Validation Accuracy: 0.9810\n",
      "Epoch [159/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.1776, Validation Accuracy: 0.9810\n",
      "Epoch [160/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.1764, Validation Accuracy: 0.9810\n",
      "Epoch [161/250], Loss: 0.0042, Accuracy: 0.9968\n",
      "Validation Loss: 0.1857, Validation Accuracy: 0.9810\n",
      "Epoch [162/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.1605, Validation Accuracy: 0.9810\n",
      "Epoch [163/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.1256, Validation Accuracy: 0.9810\n",
      "Epoch [164/250], Loss: 0.0190, Accuracy: 0.9904\n",
      "Validation Loss: 0.2513, Validation Accuracy: 0.9747\n",
      "Epoch [165/250], Loss: 0.0055, Accuracy: 0.9968\n",
      "Validation Loss: 0.1846, Validation Accuracy: 0.9747\n",
      "Epoch [166/250], Loss: 0.0103, Accuracy: 0.9968\n",
      "Validation Loss: 0.1756, Validation Accuracy: 0.9810\n",
      "Epoch [167/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.1771, Validation Accuracy: 0.9810\n",
      "Epoch [168/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.1782, Validation Accuracy: 0.9810\n",
      "Epoch [169/250], Loss: 0.0059, Accuracy: 0.9968\n",
      "Validation Loss: 1.2357, Validation Accuracy: 0.8418\n",
      "Epoch [170/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.5552, Validation Accuracy: 0.9367\n",
      "Epoch [171/250], Loss: 0.0282, Accuracy: 0.9873\n",
      "Validation Loss: 1.9874, Validation Accuracy: 0.7911\n",
      "Epoch [172/250], Loss: 0.0384, Accuracy: 0.9904\n",
      "Validation Loss: 5.6380, Validation Accuracy: 0.5759\n",
      "Epoch [173/250], Loss: 0.0116, Accuracy: 0.9968\n",
      "Validation Loss: 4.2015, Validation Accuracy: 0.6582\n",
      "Epoch [174/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 1.8629, Validation Accuracy: 0.8354\n",
      "Epoch [175/250], Loss: 0.0030, Accuracy: 1.0000\n",
      "Validation Loss: 0.4548, Validation Accuracy: 0.9494\n",
      "Epoch [176/250], Loss: 0.0053, Accuracy: 0.9968\n",
      "Validation Loss: 0.1541, Validation Accuracy: 0.9747\n",
      "Epoch [177/250], Loss: 0.0393, Accuracy: 0.9904\n",
      "Validation Loss: 4.7460, Validation Accuracy: 0.5949\n",
      "Epoch [178/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 4.4726, Validation Accuracy: 0.5949\n",
      "Epoch [179/250], Loss: 0.0206, Accuracy: 0.9936\n",
      "Validation Loss: 2.6131, Validation Accuracy: 0.6709\n",
      "Epoch [180/250], Loss: 0.0133, Accuracy: 0.9968\n",
      "Validation Loss: 0.6721, Validation Accuracy: 0.8987\n",
      "Epoch [181/250], Loss: 0.0112, Accuracy: 0.9968\n",
      "Validation Loss: 0.1377, Validation Accuracy: 0.9810\n",
      "Epoch [182/250], Loss: 0.0237, Accuracy: 0.9936\n",
      "Validation Loss: 0.1751, Validation Accuracy: 0.9810\n",
      "Epoch [183/250], Loss: 0.0155, Accuracy: 0.9936\n",
      "Validation Loss: 0.2666, Validation Accuracy: 0.9620\n",
      "Epoch [184/250], Loss: 0.0045, Accuracy: 0.9968\n",
      "Validation Loss: 0.1776, Validation Accuracy: 0.9810\n",
      "Epoch [185/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.1719, Validation Accuracy: 0.9810\n",
      "Epoch [186/250], Loss: 0.0072, Accuracy: 0.9968\n",
      "Validation Loss: 0.1832, Validation Accuracy: 0.9810\n",
      "Epoch [187/250], Loss: 0.0043, Accuracy: 1.0000\n",
      "Validation Loss: 0.1673, Validation Accuracy: 0.9810\n",
      "Epoch [188/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.1566, Validation Accuracy: 0.9810\n",
      "Epoch [189/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.1506, Validation Accuracy: 0.9810\n",
      "Epoch [190/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.1549, Validation Accuracy: 0.9810\n",
      "Epoch [191/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.1899, Validation Accuracy: 0.9810\n",
      "Epoch [192/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.1856, Validation Accuracy: 0.9810\n",
      "Epoch [193/250], Loss: 0.0055, Accuracy: 0.9968\n",
      "Validation Loss: 0.1736, Validation Accuracy: 0.9810\n",
      "Epoch [194/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.1672, Validation Accuracy: 0.9810\n",
      "Epoch [195/250], Loss: 0.0020, Accuracy: 1.0000\n",
      "Validation Loss: 0.1307, Validation Accuracy: 0.9873\n",
      "Epoch [196/250], Loss: 0.0028, Accuracy: 0.9968\n",
      "Validation Loss: 0.1793, Validation Accuracy: 0.9810\n",
      "Epoch [197/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.1792, Validation Accuracy: 0.9810\n",
      "Epoch [198/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.1670, Validation Accuracy: 0.9810\n",
      "Epoch [199/250], Loss: 0.0271, Accuracy: 0.9968\n",
      "Validation Loss: 4.5884, Validation Accuracy: 0.6646\n",
      "Epoch [200/250], Loss: 0.0217, Accuracy: 0.9968\n",
      "Validation Loss: 0.1012, Validation Accuracy: 0.9810\n",
      "Epoch [201/250], Loss: 0.0040, Accuracy: 0.9968\n",
      "Validation Loss: 0.4026, Validation Accuracy: 0.9557\n",
      "Epoch [202/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.2599, Validation Accuracy: 0.9684\n",
      "Epoch [203/250], Loss: 0.0046, Accuracy: 1.0000\n",
      "Validation Loss: 0.1714, Validation Accuracy: 0.9810\n",
      "Epoch [204/250], Loss: 0.0088, Accuracy: 0.9968\n",
      "Validation Loss: 0.1784, Validation Accuracy: 0.9810\n",
      "Epoch [205/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.2162, Validation Accuracy: 0.9747\n",
      "Epoch [206/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.1962, Validation Accuracy: 0.9810\n",
      "Epoch [207/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.1654, Validation Accuracy: 0.9810\n",
      "Epoch [208/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.1877, Validation Accuracy: 0.9810\n",
      "Epoch [209/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.1835, Validation Accuracy: 0.9810\n",
      "Epoch [210/250], Loss: 0.0026, Accuracy: 1.0000\n",
      "Validation Loss: 0.2343, Validation Accuracy: 0.9747\n",
      "Epoch [211/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.2067, Validation Accuracy: 0.9810\n",
      "Epoch [212/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.2570, Validation Accuracy: 0.9747\n",
      "Epoch [213/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.2130, Validation Accuracy: 0.9810\n",
      "Epoch [214/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.2133, Validation Accuracy: 0.9810\n",
      "Epoch [215/250], Loss: 0.0212, Accuracy: 0.9968\n",
      "Validation Loss: 0.1872, Validation Accuracy: 0.9810\n",
      "Epoch [216/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.1918, Validation Accuracy: 0.9810\n",
      "Epoch [217/250], Loss: 0.0111, Accuracy: 0.9968\n",
      "Validation Loss: 0.4247, Validation Accuracy: 0.9430\n",
      "Epoch [218/250], Loss: 0.0041, Accuracy: 1.0000\n",
      "Validation Loss: 0.5478, Validation Accuracy: 0.9241\n",
      "Epoch [219/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.3070, Validation Accuracy: 0.9557\n",
      "Epoch [220/250], Loss: 0.0026, Accuracy: 1.0000\n",
      "Validation Loss: 0.5326, Validation Accuracy: 0.9304\n",
      "Epoch [221/250], Loss: 0.0438, Accuracy: 0.9936\n",
      "Validation Loss: 1.4206, Validation Accuracy: 0.8165\n",
      "Epoch [222/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.1804, Validation Accuracy: 0.9810\n",
      "Epoch [223/250], Loss: 0.0032, Accuracy: 0.9968\n",
      "Validation Loss: 0.1260, Validation Accuracy: 0.9810\n",
      "Epoch [224/250], Loss: 0.0107, Accuracy: 0.9968\n",
      "Validation Loss: 0.1500, Validation Accuracy: 0.9810\n",
      "Epoch [225/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.1875, Validation Accuracy: 0.9810\n",
      "Epoch [226/250], Loss: 0.0029, Accuracy: 1.0000\n",
      "Validation Loss: 0.1941, Validation Accuracy: 0.9810\n",
      "Epoch [227/250], Loss: 0.0096, Accuracy: 0.9936\n",
      "Validation Loss: 0.3370, Validation Accuracy: 0.9620\n",
      "Epoch [228/250], Loss: 0.0055, Accuracy: 0.9968\n",
      "Validation Loss: 2.6441, Validation Accuracy: 0.7468\n",
      "Epoch [229/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 3.5579, Validation Accuracy: 0.6899\n",
      "Epoch [230/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.8588, Validation Accuracy: 0.9051\n",
      "Epoch [231/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.3581, Validation Accuracy: 0.9557\n",
      "Epoch [232/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.2278, Validation Accuracy: 0.9747\n",
      "Epoch [233/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.2140, Validation Accuracy: 0.9810\n",
      "Epoch [234/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.2094, Validation Accuracy: 0.9810\n",
      "Epoch [235/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.2066, Validation Accuracy: 0.9810\n",
      "Epoch [236/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.2029, Validation Accuracy: 0.9810\n",
      "Epoch [237/250], Loss: 0.0157, Accuracy: 0.9936\n",
      "Validation Loss: 0.2052, Validation Accuracy: 0.9684\n",
      "Epoch [238/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.1619, Validation Accuracy: 0.9810\n",
      "Epoch [239/250], Loss: 0.0156, Accuracy: 0.9968\n",
      "Validation Loss: 0.2196, Validation Accuracy: 0.9810\n",
      "Epoch [240/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.2090, Validation Accuracy: 0.9810\n",
      "Epoch [241/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.1963, Validation Accuracy: 0.9810\n",
      "Epoch [242/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.1862, Validation Accuracy: 0.9810\n",
      "Epoch [243/250], Loss: 0.0085, Accuracy: 0.9968\n",
      "Validation Loss: 0.1930, Validation Accuracy: 0.9810\n",
      "Epoch [244/250], Loss: 0.0134, Accuracy: 0.9968\n",
      "Validation Loss: 4.7593, Validation Accuracy: 0.6076\n",
      "Epoch [245/250], Loss: 0.0066, Accuracy: 0.9968\n",
      "Validation Loss: 0.2645, Validation Accuracy: 0.9620\n",
      "Epoch [246/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.1217, Validation Accuracy: 0.9810\n",
      "Epoch [247/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.1298, Validation Accuracy: 0.9810\n",
      "Epoch [248/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.1156, Validation Accuracy: 0.9810\n",
      "Epoch [249/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0854, Validation Accuracy: 0.9873\n",
      "Epoch [250/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0839, Validation Accuracy: 0.9937\n",
      "Test Loss: 0.1325\n",
      "Test Accuracy: 0.9809\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 115\n",
      "label 1 is 24\n",
      "label 2 is 126\n",
      "label 3 is 72\n",
      "Not setting metadata\n",
      "337 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (282, 8, 325)\n",
      "282 train samples\n",
      "141 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.2390350877192982, 0: 0.8382789317507419}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.3685, Accuracy: 0.2518\n",
      "Validation Loss: 1.2101, Validation Accuracy: 0.5000\n",
      "Epoch [2/250], Loss: 1.1643, Accuracy: 0.5461\n",
      "Validation Loss: 0.9619, Validation Accuracy: 0.5000\n",
      "Epoch [3/250], Loss: 0.8786, Accuracy: 0.6525\n",
      "Validation Loss: 0.7713, Validation Accuracy: 0.5000\n",
      "Epoch [4/250], Loss: 0.7302, Accuracy: 0.7128\n",
      "Validation Loss: 1.0273, Validation Accuracy: 0.5000\n",
      "Epoch [5/250], Loss: 0.5871, Accuracy: 0.7589\n",
      "Validation Loss: 2.1308, Validation Accuracy: 0.5000\n",
      "Epoch [6/250], Loss: 0.3487, Accuracy: 0.9255\n",
      "Validation Loss: 3.6137, Validation Accuracy: 0.5000\n",
      "Epoch [7/250], Loss: 0.2382, Accuracy: 0.9326\n",
      "Validation Loss: 4.5408, Validation Accuracy: 0.5000\n",
      "Epoch [8/250], Loss: 0.1566, Accuracy: 0.9504\n",
      "Validation Loss: 5.1046, Validation Accuracy: 0.5000\n",
      "Epoch [9/250], Loss: 0.1402, Accuracy: 0.9610\n",
      "Validation Loss: 5.0580, Validation Accuracy: 0.5000\n",
      "Epoch [10/250], Loss: 0.1279, Accuracy: 0.9681\n",
      "Validation Loss: 5.1398, Validation Accuracy: 0.5000\n",
      "Epoch [11/250], Loss: 0.1119, Accuracy: 0.9645\n",
      "Validation Loss: 4.2632, Validation Accuracy: 0.5000\n",
      "Epoch [12/250], Loss: 0.1038, Accuracy: 0.9787\n",
      "Validation Loss: 6.0560, Validation Accuracy: 0.5000\n",
      "Epoch [13/250], Loss: 0.0900, Accuracy: 0.9787\n",
      "Validation Loss: 2.5091, Validation Accuracy: 0.5986\n",
      "Epoch [14/250], Loss: 0.1132, Accuracy: 0.9716\n",
      "Validation Loss: 2.0488, Validation Accuracy: 0.6620\n",
      "Epoch [15/250], Loss: 0.0710, Accuracy: 0.9787\n",
      "Validation Loss: 3.1697, Validation Accuracy: 0.6338\n",
      "Epoch [16/250], Loss: 0.0869, Accuracy: 0.9823\n",
      "Validation Loss: 1.8641, Validation Accuracy: 0.5634\n",
      "Epoch [17/250], Loss: 0.0584, Accuracy: 0.9858\n",
      "Validation Loss: 0.0536, Validation Accuracy: 0.9718\n",
      "Epoch [18/250], Loss: 0.0471, Accuracy: 0.9823\n",
      "Validation Loss: 0.1056, Validation Accuracy: 0.9577\n",
      "Epoch [19/250], Loss: 0.0647, Accuracy: 0.9858\n",
      "Validation Loss: 4.4128, Validation Accuracy: 0.5070\n",
      "Epoch [20/250], Loss: 0.0343, Accuracy: 0.9894\n",
      "Validation Loss: 4.3337, Validation Accuracy: 0.5141\n",
      "Epoch [21/250], Loss: 0.0515, Accuracy: 0.9894\n",
      "Validation Loss: 5.2320, Validation Accuracy: 0.5000\n",
      "Epoch [22/250], Loss: 0.0431, Accuracy: 0.9894\n",
      "Validation Loss: 1.4941, Validation Accuracy: 0.6338\n",
      "Epoch [23/250], Loss: 0.1108, Accuracy: 0.9787\n",
      "Validation Loss: 3.0193, Validation Accuracy: 0.5423\n",
      "Epoch [24/250], Loss: 0.0401, Accuracy: 0.9894\n",
      "Validation Loss: 5.0125, Validation Accuracy: 0.5000\n",
      "Epoch [25/250], Loss: 0.0227, Accuracy: 0.9929\n",
      "Validation Loss: 5.0401, Validation Accuracy: 0.5000\n",
      "Epoch [26/250], Loss: 0.0304, Accuracy: 0.9965\n",
      "Validation Loss: 3.3428, Validation Accuracy: 0.6972\n",
      "Epoch [27/250], Loss: 0.0295, Accuracy: 0.9929\n",
      "Validation Loss: 0.2292, Validation Accuracy: 0.9718\n",
      "Epoch [28/250], Loss: 0.0297, Accuracy: 0.9929\n",
      "Validation Loss: 0.0276, Validation Accuracy: 0.9859\n",
      "Epoch [29/250], Loss: 0.0227, Accuracy: 0.9894\n",
      "Validation Loss: 5.0928, Validation Accuracy: 0.5070\n",
      "Epoch [30/250], Loss: 0.0389, Accuracy: 0.9858\n",
      "Validation Loss: 4.8159, Validation Accuracy: 0.5000\n",
      "Epoch [31/250], Loss: 0.0178, Accuracy: 1.0000\n",
      "Validation Loss: 5.0311, Validation Accuracy: 0.5070\n",
      "Epoch [32/250], Loss: 0.0221, Accuracy: 0.9929\n",
      "Validation Loss: 0.0456, Validation Accuracy: 0.9859\n",
      "Epoch [33/250], Loss: 0.0473, Accuracy: 0.9894\n",
      "Validation Loss: 4.3317, Validation Accuracy: 0.5211\n",
      "Epoch [34/250], Loss: 0.0384, Accuracy: 0.9894\n",
      "Validation Loss: 5.2964, Validation Accuracy: 0.5000\n",
      "Epoch [35/250], Loss: 0.0716, Accuracy: 0.9823\n",
      "Validation Loss: 5.5813, Validation Accuracy: 0.5000\n",
      "Epoch [36/250], Loss: 0.0305, Accuracy: 0.9823\n",
      "Validation Loss: 5.6007, Validation Accuracy: 0.5000\n",
      "Epoch [37/250], Loss: 0.0044, Accuracy: 1.0000\n",
      "Validation Loss: 4.8122, Validation Accuracy: 0.5211\n",
      "Epoch [38/250], Loss: 0.0506, Accuracy: 0.9894\n",
      "Validation Loss: 0.9499, Validation Accuracy: 0.8803\n",
      "Epoch [39/250], Loss: 0.0167, Accuracy: 0.9929\n",
      "Validation Loss: 4.7666, Validation Accuracy: 0.5141\n",
      "Epoch [40/250], Loss: 0.0139, Accuracy: 0.9965\n",
      "Validation Loss: 5.7944, Validation Accuracy: 0.5000\n",
      "Epoch [41/250], Loss: 0.0104, Accuracy: 1.0000\n",
      "Validation Loss: 5.5602, Validation Accuracy: 0.5000\n",
      "Epoch [42/250], Loss: 0.0287, Accuracy: 0.9929\n",
      "Validation Loss: 4.3948, Validation Accuracy: 0.5211\n",
      "Epoch [43/250], Loss: 0.0107, Accuracy: 0.9965\n",
      "Validation Loss: 5.3105, Validation Accuracy: 0.5070\n",
      "Epoch [44/250], Loss: 0.0105, Accuracy: 0.9965\n",
      "Validation Loss: 5.5780, Validation Accuracy: 0.5070\n",
      "Epoch [45/250], Loss: 0.0079, Accuracy: 0.9965\n",
      "Validation Loss: 1.7149, Validation Accuracy: 0.8310\n",
      "Epoch [46/250], Loss: 0.0048, Accuracy: 1.0000\n",
      "Validation Loss: 1.5022, Validation Accuracy: 0.8592\n",
      "Epoch [47/250], Loss: 0.0051, Accuracy: 1.0000\n",
      "Validation Loss: 0.5133, Validation Accuracy: 0.9296\n",
      "Epoch [48/250], Loss: 0.0081, Accuracy: 0.9965\n",
      "Validation Loss: 0.0639, Validation Accuracy: 0.9930\n",
      "Epoch [49/250], Loss: 0.0051, Accuracy: 1.0000\n",
      "Validation Loss: 0.4071, Validation Accuracy: 0.9437\n",
      "Epoch [50/250], Loss: 0.0106, Accuracy: 0.9965\n",
      "Validation Loss: 0.1224, Validation Accuracy: 0.9859\n",
      "Epoch [51/250], Loss: 0.0081, Accuracy: 0.9965\n",
      "Validation Loss: 5.9660, Validation Accuracy: 0.5000\n",
      "Epoch [52/250], Loss: 0.0299, Accuracy: 0.9929\n",
      "Validation Loss: 4.9802, Validation Accuracy: 0.6197\n",
      "Epoch [53/250], Loss: 0.1048, Accuracy: 0.9681\n",
      "Validation Loss: 6.0691, Validation Accuracy: 0.5000\n",
      "Epoch [54/250], Loss: 0.0310, Accuracy: 0.9894\n",
      "Validation Loss: 5.7214, Validation Accuracy: 0.5000\n",
      "Epoch [55/250], Loss: 0.0336, Accuracy: 0.9929\n",
      "Validation Loss: 3.6431, Validation Accuracy: 0.5423\n",
      "Epoch [56/250], Loss: 0.0059, Accuracy: 1.0000\n",
      "Validation Loss: 3.1058, Validation Accuracy: 0.5634\n",
      "Epoch [57/250], Loss: 0.0054, Accuracy: 1.0000\n",
      "Validation Loss: 0.1302, Validation Accuracy: 0.9648\n",
      "Epoch [58/250], Loss: 0.0192, Accuracy: 0.9929\n",
      "Validation Loss: 0.9277, Validation Accuracy: 0.8873\n",
      "Epoch [59/250], Loss: 0.0192, Accuracy: 0.9965\n",
      "Validation Loss: 0.0456, Validation Accuracy: 0.9930\n",
      "Epoch [60/250], Loss: 0.0092, Accuracy: 1.0000\n",
      "Validation Loss: 0.0324, Validation Accuracy: 0.9930\n",
      "Epoch [61/250], Loss: 0.0058, Accuracy: 0.9965\n",
      "Validation Loss: 0.0087, Validation Accuracy: 0.9930\n",
      "Epoch [62/250], Loss: 0.0052, Accuracy: 1.0000\n",
      "Validation Loss: 5.7935, Validation Accuracy: 0.5070\n",
      "Epoch [63/250], Loss: 0.0077, Accuracy: 0.9965\n",
      "Validation Loss: 4.5448, Validation Accuracy: 0.5423\n",
      "Epoch [64/250], Loss: 0.0050, Accuracy: 1.0000\n",
      "Validation Loss: 3.7303, Validation Accuracy: 0.5423\n",
      "Epoch [65/250], Loss: 0.0041, Accuracy: 1.0000\n",
      "Validation Loss: 0.1102, Validation Accuracy: 0.9789\n",
      "Epoch [66/250], Loss: 0.0624, Accuracy: 0.9929\n",
      "Validation Loss: 3.2787, Validation Accuracy: 0.7183\n",
      "Epoch [67/250], Loss: 0.0410, Accuracy: 0.9858\n",
      "Validation Loss: 5.5806, Validation Accuracy: 0.5070\n",
      "Epoch [68/250], Loss: 0.0239, Accuracy: 0.9929\n",
      "Validation Loss: 5.1708, Validation Accuracy: 0.5141\n",
      "Epoch [69/250], Loss: 0.0117, Accuracy: 0.9965\n",
      "Validation Loss: 5.2057, Validation Accuracy: 0.5070\n",
      "Epoch [70/250], Loss: 0.0048, Accuracy: 1.0000\n",
      "Validation Loss: 5.7196, Validation Accuracy: 0.5000\n",
      "Epoch [71/250], Loss: 0.0110, Accuracy: 0.9965\n",
      "Validation Loss: 1.5461, Validation Accuracy: 0.8239\n",
      "Epoch [72/250], Loss: 0.0126, Accuracy: 1.0000\n",
      "Validation Loss: 0.4708, Validation Accuracy: 0.9366\n",
      "Epoch [73/250], Loss: 0.0165, Accuracy: 0.9965\n",
      "Validation Loss: 5.0302, Validation Accuracy: 0.5352\n",
      "Epoch [74/250], Loss: 0.0237, Accuracy: 0.9929\n",
      "Validation Loss: 7.1757, Validation Accuracy: 0.5000\n",
      "Epoch [75/250], Loss: 0.0123, Accuracy: 0.9929\n",
      "Validation Loss: 6.6720, Validation Accuracy: 0.5000\n",
      "Epoch [76/250], Loss: 0.0049, Accuracy: 1.0000\n",
      "Validation Loss: 0.8882, Validation Accuracy: 0.8732\n",
      "Epoch [77/250], Loss: 0.0053, Accuracy: 1.0000\n",
      "Validation Loss: 0.0166, Validation Accuracy: 0.9930\n",
      "Epoch [78/250], Loss: 0.0110, Accuracy: 0.9965\n",
      "Validation Loss: 0.1846, Validation Accuracy: 0.9577\n",
      "Epoch [79/250], Loss: 0.0058, Accuracy: 0.9965\n",
      "Validation Loss: 6.4163, Validation Accuracy: 0.5000\n",
      "Epoch [80/250], Loss: 0.0143, Accuracy: 0.9929\n",
      "Validation Loss: 0.4939, Validation Accuracy: 0.9155\n",
      "Epoch [81/250], Loss: 0.0073, Accuracy: 0.9929\n",
      "Validation Loss: 1.7391, Validation Accuracy: 0.7887\n",
      "Epoch [82/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.5516, Validation Accuracy: 0.9225\n",
      "Epoch [83/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0498, Validation Accuracy: 0.9930\n",
      "Epoch [84/250], Loss: 0.0051, Accuracy: 1.0000\n",
      "Validation Loss: 5.1954, Validation Accuracy: 0.5423\n",
      "Epoch [85/250], Loss: 0.0141, Accuracy: 0.9965\n",
      "Validation Loss: 3.3644, Validation Accuracy: 0.7606\n",
      "Epoch [86/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 1.8173, Validation Accuracy: 0.8592\n",
      "Epoch [87/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.1048, Validation Accuracy: 0.9789\n",
      "Epoch [88/250], Loss: 0.0039, Accuracy: 0.9965\n",
      "Validation Loss: 0.4844, Validation Accuracy: 0.9437\n",
      "Epoch [89/250], Loss: 0.0022, Accuracy: 1.0000\n",
      "Validation Loss: 0.9581, Validation Accuracy: 0.8944\n",
      "Epoch [90/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0637, Validation Accuracy: 0.9859\n",
      "Epoch [91/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0201, Validation Accuracy: 0.9930\n",
      "Epoch [92/250], Loss: 0.0049, Accuracy: 0.9965\n",
      "Validation Loss: 5.8307, Validation Accuracy: 0.5352\n",
      "Epoch [93/250], Loss: 0.0130, Accuracy: 0.9929\n",
      "Validation Loss: 0.0286, Validation Accuracy: 0.9930\n",
      "Epoch [94/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0115, Validation Accuracy: 0.9930\n",
      "Epoch [95/250], Loss: 0.0097, Accuracy: 0.9965\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [96/250], Loss: 0.0214, Accuracy: 0.9929\n",
      "Validation Loss: 6.2287, Validation Accuracy: 0.5352\n",
      "Epoch [97/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 5.0743, Validation Accuracy: 0.5563\n",
      "Epoch [98/250], Loss: 0.0040, Accuracy: 0.9965\n",
      "Validation Loss: 1.1025, Validation Accuracy: 0.8803\n",
      "Epoch [99/250], Loss: 0.0022, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [100/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0644, Validation Accuracy: 0.9930\n",
      "Epoch [101/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0093, Validation Accuracy: 0.9930\n",
      "Epoch [102/250], Loss: 0.0137, Accuracy: 0.9965\n",
      "Validation Loss: 0.0068, Validation Accuracy: 0.9930\n",
      "Epoch [103/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0090, Validation Accuracy: 0.9930\n",
      "Epoch [104/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0787, Validation Accuracy: 0.9859\n",
      "Epoch [105/250], Loss: 0.0088, Accuracy: 0.9965\n",
      "Validation Loss: 0.2613, Validation Accuracy: 0.9577\n",
      "Epoch [106/250], Loss: 0.0282, Accuracy: 0.9929\n",
      "Validation Loss: 0.3248, Validation Accuracy: 0.9507\n",
      "Epoch [107/250], Loss: 0.0181, Accuracy: 0.9965\n",
      "Validation Loss: 0.0022, Validation Accuracy: 1.0000\n",
      "Epoch [108/250], Loss: 0.0078, Accuracy: 0.9929\n",
      "Validation Loss: 7.5887, Validation Accuracy: 0.5000\n",
      "Epoch [109/250], Loss: 0.0134, Accuracy: 0.9965\n",
      "Validation Loss: 4.4686, Validation Accuracy: 0.7042\n",
      "Epoch [110/250], Loss: 0.0033, Accuracy: 1.0000\n",
      "Validation Loss: 0.7660, Validation Accuracy: 0.9225\n",
      "Epoch [111/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.1587, Validation Accuracy: 0.9718\n",
      "Epoch [112/250], Loss: 0.0082, Accuracy: 1.0000\n",
      "Validation Loss: 7.4588, Validation Accuracy: 0.5000\n",
      "Epoch [113/250], Loss: 0.0038, Accuracy: 1.0000\n",
      "Validation Loss: 4.6855, Validation Accuracy: 0.5563\n",
      "Epoch [114/250], Loss: 0.0090, Accuracy: 0.9965\n",
      "Validation Loss: 0.1070, Validation Accuracy: 0.9859\n",
      "Epoch [115/250], Loss: 0.0158, Accuracy: 0.9965\n",
      "Validation Loss: 6.1457, Validation Accuracy: 0.5211\n",
      "Epoch [116/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 5.3624, Validation Accuracy: 0.5423\n",
      "Epoch [117/250], Loss: 0.0622, Accuracy: 0.9894\n",
      "Validation Loss: 0.2832, Validation Accuracy: 0.9437\n",
      "Epoch [118/250], Loss: 0.0389, Accuracy: 0.9894\n",
      "Validation Loss: 5.1792, Validation Accuracy: 0.5141\n",
      "Epoch [119/250], Loss: 0.0215, Accuracy: 0.9894\n",
      "Validation Loss: 0.2735, Validation Accuracy: 0.9366\n",
      "Epoch [120/250], Loss: 0.0142, Accuracy: 0.9965\n",
      "Validation Loss: 3.2720, Validation Accuracy: 0.7113\n",
      "Epoch [121/250], Loss: 0.0109, Accuracy: 0.9965\n",
      "Validation Loss: 0.3107, Validation Accuracy: 0.9296\n",
      "Epoch [122/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0511, Validation Accuracy: 0.9930\n",
      "Epoch [123/250], Loss: 0.0128, Accuracy: 0.9965\n",
      "Validation Loss: 0.0412, Validation Accuracy: 0.9930\n",
      "Epoch [124/250], Loss: 0.0116, Accuracy: 0.9929\n",
      "Validation Loss: 0.0008, Validation Accuracy: 1.0000\n",
      "Epoch [125/250], Loss: 0.0055, Accuracy: 0.9965\n",
      "Validation Loss: 0.1478, Validation Accuracy: 0.9718\n",
      "Epoch [126/250], Loss: 0.0534, Accuracy: 0.9929\n",
      "Validation Loss: 8.7696, Validation Accuracy: 0.5000\n",
      "Epoch [127/250], Loss: 0.0611, Accuracy: 0.9858\n",
      "Validation Loss: 3.0889, Validation Accuracy: 0.6549\n",
      "Epoch [128/250], Loss: 0.0109, Accuracy: 0.9894\n",
      "Validation Loss: 4.5737, Validation Accuracy: 0.5070\n",
      "Epoch [129/250], Loss: 0.0068, Accuracy: 1.0000\n",
      "Validation Loss: 4.9552, Validation Accuracy: 0.5070\n",
      "Epoch [130/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.1473, Validation Accuracy: 0.9718\n",
      "Epoch [131/250], Loss: 0.0145, Accuracy: 0.9965\n",
      "Validation Loss: 2.1683, Validation Accuracy: 0.7887\n",
      "Epoch [132/250], Loss: 0.0072, Accuracy: 0.9965\n",
      "Validation Loss: 0.0583, Validation Accuracy: 0.9930\n",
      "Epoch [133/250], Loss: 0.0033, Accuracy: 1.0000\n",
      "Validation Loss: 0.3860, Validation Accuracy: 0.9437\n",
      "Epoch [134/250], Loss: 0.0194, Accuracy: 0.9965\n",
      "Validation Loss: 6.1891, Validation Accuracy: 0.5070\n",
      "Epoch [135/250], Loss: 0.0110, Accuracy: 0.9929\n",
      "Validation Loss: 4.7472, Validation Accuracy: 0.5493\n",
      "Epoch [136/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.6092, Validation Accuracy: 0.9225\n",
      "Epoch [137/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0576, Validation Accuracy: 0.9859\n",
      "Epoch [138/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0178, Validation Accuracy: 0.9859\n",
      "Epoch [139/250], Loss: 0.0039, Accuracy: 0.9965\n",
      "Validation Loss: 0.0321, Validation Accuracy: 0.9930\n",
      "Epoch [140/250], Loss: 0.0052, Accuracy: 0.9965\n",
      "Validation Loss: 3.0242, Validation Accuracy: 0.6338\n",
      "Epoch [141/250], Loss: 0.0093, Accuracy: 0.9965\n",
      "Validation Loss: 5.3560, Validation Accuracy: 0.6127\n",
      "Epoch [142/250], Loss: 0.1178, Accuracy: 0.9787\n",
      "Validation Loss: 5.9155, Validation Accuracy: 0.5000\n",
      "Epoch [143/250], Loss: 0.0124, Accuracy: 0.9965\n",
      "Validation Loss: 6.4485, Validation Accuracy: 0.5000\n",
      "Epoch [144/250], Loss: 0.0039, Accuracy: 1.0000\n",
      "Validation Loss: 6.2588, Validation Accuracy: 0.5000\n",
      "Epoch [145/250], Loss: 0.0120, Accuracy: 0.9965\n",
      "Validation Loss: 5.8020, Validation Accuracy: 0.5070\n",
      "Epoch [146/250], Loss: 0.0164, Accuracy: 0.9965\n",
      "Validation Loss: 0.0868, Validation Accuracy: 0.9789\n",
      "Epoch [147/250], Loss: 0.0065, Accuracy: 0.9965\n",
      "Validation Loss: 0.1645, Validation Accuracy: 0.9718\n",
      "Epoch [148/250], Loss: 0.0231, Accuracy: 0.9894\n",
      "Validation Loss: 6.5701, Validation Accuracy: 0.5000\n",
      "Epoch [149/250], Loss: 0.0040, Accuracy: 1.0000\n",
      "Validation Loss: 6.0901, Validation Accuracy: 0.5141\n",
      "Epoch [150/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 1.7058, Validation Accuracy: 0.7535\n",
      "Epoch [151/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.1763, Validation Accuracy: 0.9648\n",
      "Epoch [152/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.1192, Validation Accuracy: 0.9789\n",
      "Epoch [153/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.1922, Validation Accuracy: 0.9648\n",
      "Epoch [154/250], Loss: 0.0045, Accuracy: 0.9965\n",
      "Validation Loss: 0.0596, Validation Accuracy: 0.9930\n",
      "Epoch [155/250], Loss: 0.0033, Accuracy: 0.9965\n",
      "Validation Loss: 1.5041, Validation Accuracy: 0.8239\n",
      "Epoch [156/250], Loss: 0.0026, Accuracy: 1.0000\n",
      "Validation Loss: 0.8365, Validation Accuracy: 0.9014\n",
      "Epoch [157/250], Loss: 0.0040, Accuracy: 0.9965\n",
      "Validation Loss: 0.0076, Validation Accuracy: 0.9930\n",
      "Epoch [158/250], Loss: 0.0143, Accuracy: 0.9965\n",
      "Validation Loss: 7.9549, Validation Accuracy: 0.5000\n",
      "Epoch [159/250], Loss: 0.0268, Accuracy: 0.9929\n",
      "Validation Loss: 7.2306, Validation Accuracy: 0.5000\n",
      "Epoch [160/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 6.4085, Validation Accuracy: 0.5141\n",
      "Epoch [161/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 2.5927, Validation Accuracy: 0.6901\n",
      "Epoch [162/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0732, Validation Accuracy: 0.9859\n",
      "Epoch [163/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0011, Validation Accuracy: 1.0000\n",
      "Epoch [164/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [165/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [166/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0004, Validation Accuracy: 1.0000\n",
      "Epoch [167/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0005, Validation Accuracy: 1.0000\n",
      "Epoch [168/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0006, Validation Accuracy: 1.0000\n",
      "Epoch [169/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0267, Validation Accuracy: 0.9859\n",
      "Epoch [170/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0064, Validation Accuracy: 0.9930\n",
      "Epoch [171/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0019, Validation Accuracy: 1.0000\n",
      "Epoch [172/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0021, Validation Accuracy: 1.0000\n",
      "Epoch [173/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0032, Validation Accuracy: 1.0000\n",
      "Epoch [174/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0018, Validation Accuracy: 1.0000\n",
      "Epoch [175/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0014, Validation Accuracy: 1.0000\n",
      "Epoch [176/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0010, Validation Accuracy: 1.0000\n",
      "Epoch [177/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0009, Validation Accuracy: 1.0000\n",
      "Epoch [178/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0011, Validation Accuracy: 1.0000\n",
      "Epoch [179/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0011, Validation Accuracy: 1.0000\n",
      "Epoch [180/250], Loss: 0.0062, Accuracy: 1.0000\n",
      "Validation Loss: 6.2776, Validation Accuracy: 0.5493\n",
      "Epoch [181/250], Loss: 0.0042, Accuracy: 0.9965\n",
      "Validation Loss: 6.2585, Validation Accuracy: 0.5493\n",
      "Epoch [182/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.8524, Validation Accuracy: 0.9225\n",
      "Epoch [183/250], Loss: 0.0046, Accuracy: 1.0000\n",
      "Validation Loss: 0.0522, Validation Accuracy: 0.9859\n",
      "Epoch [184/250], Loss: 0.0604, Accuracy: 0.9929\n",
      "Validation Loss: 0.1297, Validation Accuracy: 0.9789\n",
      "Epoch [185/250], Loss: 0.0061, Accuracy: 1.0000\n",
      "Validation Loss: 4.0565, Validation Accuracy: 0.5000\n",
      "Epoch [186/250], Loss: 0.0452, Accuracy: 0.9894\n",
      "Validation Loss: 1.2059, Validation Accuracy: 0.7958\n",
      "Epoch [187/250], Loss: 0.0364, Accuracy: 0.9858\n",
      "Validation Loss: 2.9026, Validation Accuracy: 0.6620\n",
      "Epoch [188/250], Loss: 0.0100, Accuracy: 0.9965\n",
      "Validation Loss: 1.5760, Validation Accuracy: 0.7817\n",
      "Epoch [189/250], Loss: 0.0042, Accuracy: 1.0000\n",
      "Validation Loss: 0.1582, Validation Accuracy: 0.9577\n",
      "Epoch [190/250], Loss: 0.0159, Accuracy: 0.9929\n",
      "Validation Loss: 0.0076, Validation Accuracy: 0.9930\n",
      "Epoch [191/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.0078, Validation Accuracy: 0.9930\n",
      "Epoch [192/250], Loss: 0.0049, Accuracy: 1.0000\n",
      "Validation Loss: 0.0580, Validation Accuracy: 0.9789\n",
      "Epoch [193/250], Loss: 0.0022, Accuracy: 1.0000\n",
      "Validation Loss: 0.0483, Validation Accuracy: 0.9789\n",
      "Epoch [194/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0400, Validation Accuracy: 0.9789\n",
      "Epoch [195/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0341, Validation Accuracy: 0.9789\n",
      "Epoch [196/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.7712, Validation Accuracy: 0.9155\n",
      "Epoch [197/250], Loss: 0.0030, Accuracy: 1.0000\n",
      "Validation Loss: 0.0863, Validation Accuracy: 0.9789\n",
      "Epoch [198/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0303, Validation Accuracy: 0.9859\n",
      "Epoch [199/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0202, Validation Accuracy: 0.9859\n",
      "Epoch [200/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0110, Validation Accuracy: 0.9859\n",
      "Epoch [201/250], Loss: 0.0198, Accuracy: 0.9894\n",
      "Validation Loss: 1.4739, Validation Accuracy: 0.8380\n",
      "Epoch [202/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.6614, Validation Accuracy: 0.9155\n",
      "Epoch [203/250], Loss: 0.0059, Accuracy: 0.9965\n",
      "Validation Loss: 0.0114, Validation Accuracy: 0.9859\n",
      "Epoch [204/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0124, Validation Accuracy: 0.9930\n",
      "Epoch [205/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0119, Validation Accuracy: 0.9930\n",
      "Epoch [206/250], Loss: 0.0267, Accuracy: 0.9965\n",
      "Validation Loss: 5.4901, Validation Accuracy: 0.5352\n",
      "Epoch [207/250], Loss: 0.0188, Accuracy: 0.9929\n",
      "Validation Loss: 5.8071, Validation Accuracy: 0.5282\n",
      "Epoch [208/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.8872, Validation Accuracy: 0.8592\n",
      "Epoch [209/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 2.2316, Validation Accuracy: 0.7042\n",
      "Epoch [210/250], Loss: 0.0067, Accuracy: 0.9965\n",
      "Validation Loss: 8.2202, Validation Accuracy: 0.5000\n",
      "Epoch [211/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 7.8650, Validation Accuracy: 0.5000\n",
      "Epoch [212/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 6.0618, Validation Accuracy: 0.5352\n",
      "Epoch [213/250], Loss: 0.0138, Accuracy: 0.9965\n",
      "Validation Loss: 7.7713, Validation Accuracy: 0.5352\n",
      "Epoch [214/250], Loss: 0.0313, Accuracy: 0.9929\n",
      "Validation Loss: 1.0665, Validation Accuracy: 0.8803\n",
      "Epoch [215/250], Loss: 0.1013, Accuracy: 0.9894\n",
      "Validation Loss: 5.8648, Validation Accuracy: 0.5070\n",
      "Epoch [216/250], Loss: 0.0097, Accuracy: 0.9965\n",
      "Validation Loss: 6.9703, Validation Accuracy: 0.5000\n",
      "Epoch [217/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 6.3131, Validation Accuracy: 0.5070\n",
      "Epoch [218/250], Loss: 0.0039, Accuracy: 1.0000\n",
      "Validation Loss: 0.0636, Validation Accuracy: 0.9789\n",
      "Epoch [219/250], Loss: 0.0050, Accuracy: 1.0000\n",
      "Validation Loss: 1.9091, Validation Accuracy: 0.7465\n",
      "Epoch [220/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 3.7054, Validation Accuracy: 0.6127\n",
      "Epoch [221/250], Loss: 0.0022, Accuracy: 1.0000\n",
      "Validation Loss: 0.1531, Validation Accuracy: 0.9718\n",
      "Epoch [222/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.0598, Validation Accuracy: 0.9789\n",
      "Epoch [223/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0162, Validation Accuracy: 0.9930\n",
      "Epoch [224/250], Loss: 0.0040, Accuracy: 1.0000\n",
      "Validation Loss: 0.6381, Validation Accuracy: 0.9014\n",
      "Epoch [225/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.5884, Validation Accuracy: 0.9155\n",
      "Epoch [226/250], Loss: 0.0020, Accuracy: 1.0000\n",
      "Validation Loss: 0.0576, Validation Accuracy: 0.9930\n",
      "Epoch [227/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0362, Validation Accuracy: 0.9930\n",
      "Epoch [228/250], Loss: 0.0047, Accuracy: 0.9965\n",
      "Validation Loss: 0.0028, Validation Accuracy: 1.0000\n",
      "Epoch [229/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0028, Validation Accuracy: 1.0000\n",
      "Epoch [230/250], Loss: 0.0036, Accuracy: 0.9965\n",
      "Validation Loss: 0.0661, Validation Accuracy: 0.9930\n",
      "Epoch [231/250], Loss: 0.0060, Accuracy: 1.0000\n",
      "Validation Loss: 0.0564, Validation Accuracy: 0.9930\n",
      "Epoch [232/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [233/250], Loss: 0.0053, Accuracy: 0.9965\n",
      "Validation Loss: 8.2488, Validation Accuracy: 0.5070\n",
      "Epoch [234/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 8.3294, Validation Accuracy: 0.5070\n",
      "Epoch [235/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 7.3595, Validation Accuracy: 0.5352\n",
      "Epoch [236/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 1.4166, Validation Accuracy: 0.8732\n",
      "Epoch [237/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0585, Validation Accuracy: 0.9859\n",
      "Epoch [238/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0028, Validation Accuracy: 1.0000\n",
      "Epoch [239/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [240/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [241/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [242/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [243/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [244/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [245/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.3819, Validation Accuracy: 0.9437\n",
      "Epoch [246/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.2677, Validation Accuracy: 0.9648\n",
      "Epoch [247/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0748, Validation Accuracy: 0.9930\n",
      "Epoch [248/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0561, Validation Accuracy: 0.9930\n",
      "Epoch [249/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0036, Validation Accuracy: 1.0000\n",
      "Epoch [250/250], Loss: 0.0055, Accuracy: 0.9965\n",
      "Validation Loss: 0.1339, Validation Accuracy: 0.9789\n",
      "Test Loss: 0.4006\n",
      "Test Accuracy: 0.9574\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 153\n",
      "label 1 is 168\n",
      "label 2 is 25\n",
      "label 3 is 22\n",
      "Not setting metadata\n",
      "368 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (298, 8, 325)\n",
      "298 train samples\n",
      "149 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.3070175438596492, 0: 0.8097826086956522}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.3925, Accuracy: 0.3121\n",
      "Validation Loss: 0.9680, Validation Accuracy: 0.6107\n",
      "Epoch [2/250], Loss: 1.0442, Accuracy: 0.5738\n",
      "Validation Loss: 0.7874, Validation Accuracy: 0.6107\n",
      "Epoch [3/250], Loss: 0.8337, Accuracy: 0.6275\n",
      "Validation Loss: 0.7073, Validation Accuracy: 0.6107\n",
      "Epoch [4/250], Loss: 0.8053, Accuracy: 0.5839\n",
      "Validation Loss: 0.6831, Validation Accuracy: 0.6107\n",
      "Epoch [5/250], Loss: 0.7470, Accuracy: 0.6443\n",
      "Validation Loss: 0.6742, Validation Accuracy: 0.6107\n",
      "Epoch [6/250], Loss: 0.7496, Accuracy: 0.6208\n",
      "Validation Loss: 0.6915, Validation Accuracy: 0.6107\n",
      "Epoch [7/250], Loss: 0.7062, Accuracy: 0.6409\n",
      "Validation Loss: 0.6676, Validation Accuracy: 0.6107\n",
      "Epoch [8/250], Loss: 0.7140, Accuracy: 0.6107\n",
      "Validation Loss: 0.6800, Validation Accuracy: 0.6107\n",
      "Epoch [9/250], Loss: 0.7125, Accuracy: 0.6107\n",
      "Validation Loss: 0.6969, Validation Accuracy: 0.5638\n",
      "Epoch [10/250], Loss: 0.7026, Accuracy: 0.6309\n",
      "Validation Loss: 0.7323, Validation Accuracy: 0.4228\n",
      "Epoch [11/250], Loss: 0.6589, Accuracy: 0.6644\n",
      "Validation Loss: 0.8153, Validation Accuracy: 0.4027\n",
      "Epoch [12/250], Loss: 0.6315, Accuracy: 0.6711\n",
      "Validation Loss: 0.8530, Validation Accuracy: 0.4228\n",
      "Epoch [13/250], Loss: 0.5832, Accuracy: 0.7483\n",
      "Validation Loss: 1.6478, Validation Accuracy: 0.4161\n",
      "Epoch [14/250], Loss: 0.5571, Accuracy: 0.7550\n",
      "Validation Loss: 2.9288, Validation Accuracy: 0.3893\n",
      "Epoch [15/250], Loss: 0.5227, Accuracy: 0.7886\n",
      "Validation Loss: 2.3885, Validation Accuracy: 0.4094\n",
      "Epoch [16/250], Loss: 0.4762, Accuracy: 0.8087\n",
      "Validation Loss: 2.7286, Validation Accuracy: 0.4295\n",
      "Epoch [17/250], Loss: 0.4818, Accuracy: 0.8087\n",
      "Validation Loss: 0.4434, Validation Accuracy: 0.7383\n",
      "Epoch [18/250], Loss: 0.4180, Accuracy: 0.8557\n",
      "Validation Loss: 1.5824, Validation Accuracy: 0.6107\n",
      "Epoch [19/250], Loss: 0.3434, Accuracy: 0.8456\n",
      "Validation Loss: 3.2843, Validation Accuracy: 0.4362\n",
      "Epoch [20/250], Loss: 0.3560, Accuracy: 0.8658\n",
      "Validation Loss: 3.3562, Validation Accuracy: 0.4497\n",
      "Epoch [21/250], Loss: 0.3563, Accuracy: 0.8725\n",
      "Validation Loss: 0.5412, Validation Accuracy: 0.7584\n",
      "Epoch [22/250], Loss: 0.3482, Accuracy: 0.8725\n",
      "Validation Loss: 1.6757, Validation Accuracy: 0.6107\n",
      "Epoch [23/250], Loss: 0.3878, Accuracy: 0.8691\n",
      "Validation Loss: 4.2523, Validation Accuracy: 0.3893\n",
      "Epoch [24/250], Loss: 0.2668, Accuracy: 0.9128\n",
      "Validation Loss: 1.8774, Validation Accuracy: 0.6107\n",
      "Epoch [25/250], Loss: 0.3284, Accuracy: 0.8826\n",
      "Validation Loss: 0.1317, Validation Accuracy: 0.9530\n",
      "Epoch [26/250], Loss: 0.3161, Accuracy: 0.8960\n",
      "Validation Loss: 1.4261, Validation Accuracy: 0.6107\n",
      "Epoch [27/250], Loss: 0.2627, Accuracy: 0.9228\n",
      "Validation Loss: 1.7738, Validation Accuracy: 0.6107\n",
      "Epoch [28/250], Loss: 0.3240, Accuracy: 0.8859\n",
      "Validation Loss: 2.1759, Validation Accuracy: 0.5503\n",
      "Epoch [29/250], Loss: 0.2792, Accuracy: 0.8960\n",
      "Validation Loss: 1.1867, Validation Accuracy: 0.6779\n",
      "Epoch [30/250], Loss: 0.2345, Accuracy: 0.9128\n",
      "Validation Loss: 0.2940, Validation Accuracy: 0.8926\n",
      "Epoch [31/250], Loss: 0.2959, Accuracy: 0.9027\n",
      "Validation Loss: 2.2701, Validation Accuracy: 0.6107\n",
      "Epoch [32/250], Loss: 0.2010, Accuracy: 0.9362\n",
      "Validation Loss: 0.3070, Validation Accuracy: 0.8993\n",
      "Epoch [33/250], Loss: 0.2166, Accuracy: 0.9430\n",
      "Validation Loss: 0.1226, Validation Accuracy: 0.9530\n",
      "Epoch [34/250], Loss: 0.2358, Accuracy: 0.9161\n",
      "Validation Loss: 2.7686, Validation Accuracy: 0.6107\n",
      "Epoch [35/250], Loss: 0.2760, Accuracy: 0.8826\n",
      "Validation Loss: 2.6348, Validation Accuracy: 0.5369\n",
      "Epoch [36/250], Loss: 0.2670, Accuracy: 0.9094\n",
      "Validation Loss: 2.1075, Validation Accuracy: 0.5705\n",
      "Epoch [37/250], Loss: 0.2127, Accuracy: 0.9228\n",
      "Validation Loss: 1.7411, Validation Accuracy: 0.6510\n",
      "Epoch [38/250], Loss: 0.2257, Accuracy: 0.9161\n",
      "Validation Loss: 1.1465, Validation Accuracy: 0.6846\n",
      "Epoch [39/250], Loss: 0.2155, Accuracy: 0.9430\n",
      "Validation Loss: 1.1655, Validation Accuracy: 0.6510\n",
      "Epoch [40/250], Loss: 0.2527, Accuracy: 0.8960\n",
      "Validation Loss: 4.0573, Validation Accuracy: 0.4161\n",
      "Epoch [41/250], Loss: 0.1706, Accuracy: 0.9463\n",
      "Validation Loss: 2.1327, Validation Accuracy: 0.6107\n",
      "Epoch [42/250], Loss: 0.2224, Accuracy: 0.9195\n",
      "Validation Loss: 1.0782, Validation Accuracy: 0.6644\n",
      "Epoch [43/250], Loss: 0.1920, Accuracy: 0.9262\n",
      "Validation Loss: 2.6371, Validation Accuracy: 0.6107\n",
      "Epoch [44/250], Loss: 0.1954, Accuracy: 0.9262\n",
      "Validation Loss: 0.7530, Validation Accuracy: 0.8188\n",
      "Epoch [45/250], Loss: 0.1832, Accuracy: 0.9094\n",
      "Validation Loss: 2.7560, Validation Accuracy: 0.6107\n",
      "Epoch [46/250], Loss: 0.1701, Accuracy: 0.9362\n",
      "Validation Loss: 0.5288, Validation Accuracy: 0.8523\n",
      "Epoch [47/250], Loss: 0.1811, Accuracy: 0.9463\n",
      "Validation Loss: 0.0661, Validation Accuracy: 0.9732\n",
      "Epoch [48/250], Loss: 0.2343, Accuracy: 0.9228\n",
      "Validation Loss: 0.1516, Validation Accuracy: 0.9396\n",
      "Epoch [49/250], Loss: 0.1714, Accuracy: 0.9262\n",
      "Validation Loss: 1.0759, Validation Accuracy: 0.7584\n",
      "Epoch [50/250], Loss: 0.1853, Accuracy: 0.9530\n",
      "Validation Loss: 3.8118, Validation Accuracy: 0.4295\n",
      "Epoch [51/250], Loss: 0.2227, Accuracy: 0.9228\n",
      "Validation Loss: 2.6184, Validation Accuracy: 0.6107\n",
      "Epoch [52/250], Loss: 0.2160, Accuracy: 0.9262\n",
      "Validation Loss: 2.5656, Validation Accuracy: 0.6107\n",
      "Epoch [53/250], Loss: 0.1872, Accuracy: 0.9396\n",
      "Validation Loss: 3.0176, Validation Accuracy: 0.6107\n",
      "Epoch [54/250], Loss: 0.1538, Accuracy: 0.9463\n",
      "Validation Loss: 0.1076, Validation Accuracy: 0.9597\n",
      "Epoch [55/250], Loss: 0.2233, Accuracy: 0.9128\n",
      "Validation Loss: 2.8472, Validation Accuracy: 0.6107\n",
      "Epoch [56/250], Loss: 0.2468, Accuracy: 0.9094\n",
      "Validation Loss: 0.0781, Validation Accuracy: 0.9597\n",
      "Epoch [57/250], Loss: 0.2032, Accuracy: 0.9396\n",
      "Validation Loss: 3.3133, Validation Accuracy: 0.6107\n",
      "Epoch [58/250], Loss: 0.1847, Accuracy: 0.9396\n",
      "Validation Loss: 1.7686, Validation Accuracy: 0.5638\n",
      "Epoch [59/250], Loss: 0.1473, Accuracy: 0.9463\n",
      "Validation Loss: 0.4462, Validation Accuracy: 0.8591\n",
      "Epoch [60/250], Loss: 0.1985, Accuracy: 0.9430\n",
      "Validation Loss: 0.0767, Validation Accuracy: 0.9664\n",
      "Epoch [61/250], Loss: 0.1501, Accuracy: 0.9530\n",
      "Validation Loss: 0.9472, Validation Accuracy: 0.7181\n",
      "Epoch [62/250], Loss: 0.1508, Accuracy: 0.9463\n",
      "Validation Loss: 2.4348, Validation Accuracy: 0.5436\n",
      "Epoch [63/250], Loss: 0.1566, Accuracy: 0.9430\n",
      "Validation Loss: 0.5097, Validation Accuracy: 0.8255\n",
      "Epoch [64/250], Loss: 0.1561, Accuracy: 0.9530\n",
      "Validation Loss: 2.1716, Validation Accuracy: 0.6107\n",
      "Epoch [65/250], Loss: 0.2001, Accuracy: 0.9228\n",
      "Validation Loss: 0.4588, Validation Accuracy: 0.8456\n",
      "Epoch [66/250], Loss: 0.2032, Accuracy: 0.9362\n",
      "Validation Loss: 1.5646, Validation Accuracy: 0.6443\n",
      "Epoch [67/250], Loss: 0.1606, Accuracy: 0.9597\n",
      "Validation Loss: 2.6058, Validation Accuracy: 0.6107\n",
      "Epoch [68/250], Loss: 0.1656, Accuracy: 0.9295\n",
      "Validation Loss: 0.9407, Validation Accuracy: 0.7987\n",
      "Epoch [69/250], Loss: 0.1622, Accuracy: 0.9396\n",
      "Validation Loss: 5.0640, Validation Accuracy: 0.3960\n",
      "Epoch [70/250], Loss: 0.1451, Accuracy: 0.9530\n",
      "Validation Loss: 1.4050, Validation Accuracy: 0.6644\n",
      "Epoch [71/250], Loss: 0.1087, Accuracy: 0.9631\n",
      "Validation Loss: 3.1751, Validation Accuracy: 0.6107\n",
      "Epoch [72/250], Loss: 0.1076, Accuracy: 0.9597\n",
      "Validation Loss: 0.0589, Validation Accuracy: 0.9799\n",
      "Epoch [73/250], Loss: 0.1606, Accuracy: 0.9430\n",
      "Validation Loss: 0.4110, Validation Accuracy: 0.8591\n",
      "Epoch [74/250], Loss: 0.1544, Accuracy: 0.9497\n",
      "Validation Loss: 3.0658, Validation Accuracy: 0.6107\n",
      "Epoch [75/250], Loss: 0.1344, Accuracy: 0.9631\n",
      "Validation Loss: 1.0206, Validation Accuracy: 0.7987\n",
      "Epoch [76/250], Loss: 0.1206, Accuracy: 0.9564\n",
      "Validation Loss: 0.2890, Validation Accuracy: 0.8993\n",
      "Epoch [77/250], Loss: 0.1208, Accuracy: 0.9631\n",
      "Validation Loss: 2.3730, Validation Accuracy: 0.6443\n",
      "Epoch [78/250], Loss: 0.1043, Accuracy: 0.9698\n",
      "Validation Loss: 1.7785, Validation Accuracy: 0.6846\n",
      "Epoch [79/250], Loss: 0.1868, Accuracy: 0.9295\n",
      "Validation Loss: 2.7403, Validation Accuracy: 0.5101\n",
      "Epoch [80/250], Loss: 0.0985, Accuracy: 0.9597\n",
      "Validation Loss: 0.4872, Validation Accuracy: 0.8322\n",
      "Epoch [81/250], Loss: 0.1480, Accuracy: 0.9564\n",
      "Validation Loss: 3.7975, Validation Accuracy: 0.6107\n",
      "Epoch [82/250], Loss: 0.1729, Accuracy: 0.9497\n",
      "Validation Loss: 3.9331, Validation Accuracy: 0.6107\n",
      "Epoch [83/250], Loss: 0.1260, Accuracy: 0.9530\n",
      "Validation Loss: 0.4276, Validation Accuracy: 0.9195\n",
      "Epoch [84/250], Loss: 0.1196, Accuracy: 0.9564\n",
      "Validation Loss: 0.3630, Validation Accuracy: 0.8993\n",
      "Epoch [85/250], Loss: 0.1604, Accuracy: 0.9564\n",
      "Validation Loss: 1.6470, Validation Accuracy: 0.6913\n",
      "Epoch [86/250], Loss: 0.1245, Accuracy: 0.9664\n",
      "Validation Loss: 4.0048, Validation Accuracy: 0.4228\n",
      "Epoch [87/250], Loss: 0.1509, Accuracy: 0.9463\n",
      "Validation Loss: 0.5717, Validation Accuracy: 0.8054\n",
      "Epoch [88/250], Loss: 0.0986, Accuracy: 0.9597\n",
      "Validation Loss: 1.9600, Validation Accuracy: 0.5906\n",
      "Epoch [89/250], Loss: 0.1382, Accuracy: 0.9530\n",
      "Validation Loss: 1.7601, Validation Accuracy: 0.5973\n",
      "Epoch [90/250], Loss: 0.1516, Accuracy: 0.9497\n",
      "Validation Loss: 0.2440, Validation Accuracy: 0.9060\n",
      "Epoch [91/250], Loss: 0.1841, Accuracy: 0.9631\n",
      "Validation Loss: 2.4757, Validation Accuracy: 0.6242\n",
      "Epoch [92/250], Loss: 0.1187, Accuracy: 0.9597\n",
      "Validation Loss: 0.8466, Validation Accuracy: 0.7315\n",
      "Epoch [93/250], Loss: 0.1023, Accuracy: 0.9497\n",
      "Validation Loss: 2.8207, Validation Accuracy: 0.5503\n",
      "Epoch [94/250], Loss: 0.0997, Accuracy: 0.9698\n",
      "Validation Loss: 0.0480, Validation Accuracy: 0.9799\n",
      "Epoch [95/250], Loss: 0.1523, Accuracy: 0.9497\n",
      "Validation Loss: 3.1594, Validation Accuracy: 0.6107\n",
      "Epoch [96/250], Loss: 0.1233, Accuracy: 0.9597\n",
      "Validation Loss: 1.4903, Validation Accuracy: 0.6577\n",
      "Epoch [97/250], Loss: 0.1030, Accuracy: 0.9631\n",
      "Validation Loss: 1.1891, Validation Accuracy: 0.6980\n",
      "Epoch [98/250], Loss: 0.1268, Accuracy: 0.9497\n",
      "Validation Loss: 4.9606, Validation Accuracy: 0.4094\n",
      "Epoch [99/250], Loss: 0.1281, Accuracy: 0.9530\n",
      "Validation Loss: 0.4259, Validation Accuracy: 0.9195\n",
      "Epoch [100/250], Loss: 0.1073, Accuracy: 0.9698\n",
      "Validation Loss: 0.7821, Validation Accuracy: 0.7987\n",
      "Epoch [101/250], Loss: 0.0610, Accuracy: 0.9732\n",
      "Validation Loss: 0.9794, Validation Accuracy: 0.7315\n",
      "Epoch [102/250], Loss: 0.0894, Accuracy: 0.9664\n",
      "Validation Loss: 3.0182, Validation Accuracy: 0.6376\n",
      "Epoch [103/250], Loss: 0.1010, Accuracy: 0.9664\n",
      "Validation Loss: 1.1085, Validation Accuracy: 0.7114\n",
      "Epoch [104/250], Loss: 0.1353, Accuracy: 0.9497\n",
      "Validation Loss: 0.1867, Validation Accuracy: 0.9463\n",
      "Epoch [105/250], Loss: 0.0937, Accuracy: 0.9631\n",
      "Validation Loss: 3.5648, Validation Accuracy: 0.6107\n",
      "Epoch [106/250], Loss: 0.0985, Accuracy: 0.9597\n",
      "Validation Loss: 4.0982, Validation Accuracy: 0.6107\n",
      "Epoch [107/250], Loss: 0.1336, Accuracy: 0.9564\n",
      "Validation Loss: 2.8286, Validation Accuracy: 0.5369\n",
      "Epoch [108/250], Loss: 0.1113, Accuracy: 0.9698\n",
      "Validation Loss: 0.1931, Validation Accuracy: 0.9329\n",
      "Epoch [109/250], Loss: 0.1080, Accuracy: 0.9564\n",
      "Validation Loss: 4.5277, Validation Accuracy: 0.4228\n",
      "Epoch [110/250], Loss: 0.0870, Accuracy: 0.9664\n",
      "Validation Loss: 4.1219, Validation Accuracy: 0.6107\n",
      "Epoch [111/250], Loss: 0.1597, Accuracy: 0.9530\n",
      "Validation Loss: 3.4739, Validation Accuracy: 0.5168\n",
      "Epoch [112/250], Loss: 0.1043, Accuracy: 0.9698\n",
      "Validation Loss: 0.0950, Validation Accuracy: 0.9732\n",
      "Epoch [113/250], Loss: 0.0951, Accuracy: 0.9631\n",
      "Validation Loss: 2.6476, Validation Accuracy: 0.6577\n",
      "Epoch [114/250], Loss: 0.1062, Accuracy: 0.9631\n",
      "Validation Loss: 2.4330, Validation Accuracy: 0.5973\n",
      "Epoch [115/250], Loss: 0.0768, Accuracy: 0.9664\n",
      "Validation Loss: 0.7371, Validation Accuracy: 0.8389\n",
      "Epoch [116/250], Loss: 0.0978, Accuracy: 0.9664\n",
      "Validation Loss: 2.1078, Validation Accuracy: 0.7047\n",
      "Epoch [117/250], Loss: 0.0868, Accuracy: 0.9765\n",
      "Validation Loss: 0.2159, Validation Accuracy: 0.9396\n",
      "Epoch [118/250], Loss: 0.0763, Accuracy: 0.9832\n",
      "Validation Loss: 2.5297, Validation Accuracy: 0.6242\n",
      "Epoch [119/250], Loss: 0.0879, Accuracy: 0.9564\n",
      "Validation Loss: 3.6969, Validation Accuracy: 0.6107\n",
      "Epoch [120/250], Loss: 0.0639, Accuracy: 0.9732\n",
      "Validation Loss: 0.0991, Validation Accuracy: 0.9597\n",
      "Epoch [121/250], Loss: 0.0807, Accuracy: 0.9664\n",
      "Validation Loss: 1.3709, Validation Accuracy: 0.7852\n",
      "Epoch [122/250], Loss: 0.0990, Accuracy: 0.9698\n",
      "Validation Loss: 2.0109, Validation Accuracy: 0.6644\n",
      "Epoch [123/250], Loss: 0.0697, Accuracy: 0.9698\n",
      "Validation Loss: 0.0473, Validation Accuracy: 0.9866\n",
      "Epoch [124/250], Loss: 0.0570, Accuracy: 0.9866\n",
      "Validation Loss: 0.0399, Validation Accuracy: 0.9866\n",
      "Epoch [125/250], Loss: 0.1032, Accuracy: 0.9832\n",
      "Validation Loss: 0.0566, Validation Accuracy: 0.9732\n",
      "Epoch [126/250], Loss: 0.1110, Accuracy: 0.9698\n",
      "Validation Loss: 0.1557, Validation Accuracy: 0.9530\n",
      "Epoch [127/250], Loss: 0.0472, Accuracy: 0.9866\n",
      "Validation Loss: 0.5707, Validation Accuracy: 0.8389\n",
      "Epoch [128/250], Loss: 0.0522, Accuracy: 0.9832\n",
      "Validation Loss: 2.4366, Validation Accuracy: 0.6174\n",
      "Epoch [129/250], Loss: 0.0997, Accuracy: 0.9631\n",
      "Validation Loss: 5.2791, Validation Accuracy: 0.4161\n",
      "Epoch [130/250], Loss: 0.0653, Accuracy: 0.9698\n",
      "Validation Loss: 3.7896, Validation Accuracy: 0.5302\n",
      "Epoch [131/250], Loss: 0.1012, Accuracy: 0.9631\n",
      "Validation Loss: 3.4703, Validation Accuracy: 0.5235\n",
      "Epoch [132/250], Loss: 0.0820, Accuracy: 0.9799\n",
      "Validation Loss: 0.0968, Validation Accuracy: 0.9664\n",
      "Epoch [133/250], Loss: 0.0917, Accuracy: 0.9631\n",
      "Validation Loss: 0.2242, Validation Accuracy: 0.9396\n",
      "Epoch [134/250], Loss: 0.1085, Accuracy: 0.9530\n",
      "Validation Loss: 0.0484, Validation Accuracy: 0.9732\n",
      "Epoch [135/250], Loss: 0.0660, Accuracy: 0.9765\n",
      "Validation Loss: 2.2872, Validation Accuracy: 0.5973\n",
      "Epoch [136/250], Loss: 0.0783, Accuracy: 0.9698\n",
      "Validation Loss: 4.7368, Validation Accuracy: 0.6107\n",
      "Epoch [137/250], Loss: 0.1034, Accuracy: 0.9564\n",
      "Validation Loss: 3.4572, Validation Accuracy: 0.5034\n",
      "Epoch [138/250], Loss: 0.1102, Accuracy: 0.9698\n",
      "Validation Loss: 0.1124, Validation Accuracy: 0.9597\n",
      "Epoch [139/250], Loss: 0.1039, Accuracy: 0.9631\n",
      "Validation Loss: 4.0176, Validation Accuracy: 0.6107\n",
      "Epoch [140/250], Loss: 0.0649, Accuracy: 0.9832\n",
      "Validation Loss: 1.1923, Validation Accuracy: 0.7450\n",
      "Epoch [141/250], Loss: 0.0789, Accuracy: 0.9799\n",
      "Validation Loss: 4.5757, Validation Accuracy: 0.6107\n",
      "Epoch [142/250], Loss: 0.0757, Accuracy: 0.9631\n",
      "Validation Loss: 3.4669, Validation Accuracy: 0.5570\n",
      "Epoch [143/250], Loss: 0.0442, Accuracy: 0.9866\n",
      "Validation Loss: 0.1990, Validation Accuracy: 0.9396\n",
      "Epoch [144/250], Loss: 0.0553, Accuracy: 0.9799\n",
      "Validation Loss: 0.1266, Validation Accuracy: 0.9664\n",
      "Epoch [145/250], Loss: 0.1129, Accuracy: 0.9463\n",
      "Validation Loss: 2.8396, Validation Accuracy: 0.6510\n",
      "Epoch [146/250], Loss: 0.0515, Accuracy: 0.9866\n",
      "Validation Loss: 0.9670, Validation Accuracy: 0.8255\n",
      "Epoch [147/250], Loss: 0.0531, Accuracy: 0.9765\n",
      "Validation Loss: 0.8006, Validation Accuracy: 0.8322\n",
      "Epoch [148/250], Loss: 0.0728, Accuracy: 0.9664\n",
      "Validation Loss: 0.9684, Validation Accuracy: 0.7651\n",
      "Epoch [149/250], Loss: 0.0554, Accuracy: 0.9765\n",
      "Validation Loss: 3.7161, Validation Accuracy: 0.5503\n",
      "Epoch [150/250], Loss: 0.0518, Accuracy: 0.9698\n",
      "Validation Loss: 4.9684, Validation Accuracy: 0.6107\n",
      "Epoch [151/250], Loss: 0.1041, Accuracy: 0.9698\n",
      "Validation Loss: 0.4566, Validation Accuracy: 0.9060\n",
      "Epoch [152/250], Loss: 0.0945, Accuracy: 0.9664\n",
      "Validation Loss: 0.8604, Validation Accuracy: 0.7785\n",
      "Epoch [153/250], Loss: 0.0618, Accuracy: 0.9799\n",
      "Validation Loss: 0.1645, Validation Accuracy: 0.9530\n",
      "Epoch [154/250], Loss: 0.0838, Accuracy: 0.9765\n",
      "Validation Loss: 0.2621, Validation Accuracy: 0.9262\n",
      "Epoch [155/250], Loss: 0.0943, Accuracy: 0.9732\n",
      "Validation Loss: 2.1003, Validation Accuracy: 0.6779\n",
      "Epoch [156/250], Loss: 0.0827, Accuracy: 0.9765\n",
      "Validation Loss: 0.1405, Validation Accuracy: 0.9530\n",
      "Epoch [157/250], Loss: 0.0550, Accuracy: 0.9799\n",
      "Validation Loss: 2.9788, Validation Accuracy: 0.5772\n",
      "Epoch [158/250], Loss: 0.0733, Accuracy: 0.9799\n",
      "Validation Loss: 0.4257, Validation Accuracy: 0.9195\n",
      "Epoch [159/250], Loss: 0.0814, Accuracy: 0.9799\n",
      "Validation Loss: 4.7714, Validation Accuracy: 0.6107\n",
      "Epoch [160/250], Loss: 0.0705, Accuracy: 0.9799\n",
      "Validation Loss: 2.6271, Validation Accuracy: 0.6040\n",
      "Epoch [161/250], Loss: 0.0706, Accuracy: 0.9631\n",
      "Validation Loss: 1.6217, Validation Accuracy: 0.7248\n",
      "Epoch [162/250], Loss: 0.0404, Accuracy: 0.9899\n",
      "Validation Loss: 0.0462, Validation Accuracy: 0.9933\n",
      "Epoch [163/250], Loss: 0.0758, Accuracy: 0.9765\n",
      "Validation Loss: 1.5522, Validation Accuracy: 0.7919\n",
      "Epoch [164/250], Loss: 0.0423, Accuracy: 0.9799\n",
      "Validation Loss: 0.1007, Validation Accuracy: 0.9664\n",
      "Epoch [165/250], Loss: 0.0741, Accuracy: 0.9799\n",
      "Validation Loss: 2.8682, Validation Accuracy: 0.6309\n",
      "Epoch [166/250], Loss: 0.0958, Accuracy: 0.9664\n",
      "Validation Loss: 0.3989, Validation Accuracy: 0.9060\n",
      "Epoch [167/250], Loss: 0.0706, Accuracy: 0.9899\n",
      "Validation Loss: 0.4570, Validation Accuracy: 0.8993\n",
      "Epoch [168/250], Loss: 0.0449, Accuracy: 0.9899\n",
      "Validation Loss: 4.8747, Validation Accuracy: 0.6107\n",
      "Epoch [169/250], Loss: 0.0494, Accuracy: 0.9765\n",
      "Validation Loss: 1.9585, Validation Accuracy: 0.6577\n",
      "Epoch [170/250], Loss: 0.0712, Accuracy: 0.9698\n",
      "Validation Loss: 0.9925, Validation Accuracy: 0.7450\n",
      "Epoch [171/250], Loss: 0.0928, Accuracy: 0.9664\n",
      "Validation Loss: 4.5387, Validation Accuracy: 0.4228\n",
      "Epoch [172/250], Loss: 0.0582, Accuracy: 0.9832\n",
      "Validation Loss: 1.1541, Validation Accuracy: 0.7517\n",
      "Epoch [173/250], Loss: 0.0598, Accuracy: 0.9799\n",
      "Validation Loss: 3.7718, Validation Accuracy: 0.6174\n",
      "Epoch [174/250], Loss: 0.0627, Accuracy: 0.9698\n",
      "Validation Loss: 1.6524, Validation Accuracy: 0.6443\n",
      "Epoch [175/250], Loss: 0.0771, Accuracy: 0.9765\n",
      "Validation Loss: 0.0421, Validation Accuracy: 0.9933\n",
      "Epoch [176/250], Loss: 0.0589, Accuracy: 0.9899\n",
      "Validation Loss: 4.4152, Validation Accuracy: 0.4899\n",
      "Epoch [177/250], Loss: 0.0904, Accuracy: 0.9698\n",
      "Validation Loss: 4.6573, Validation Accuracy: 0.6107\n",
      "Epoch [178/250], Loss: 0.1091, Accuracy: 0.9664\n",
      "Validation Loss: 2.4643, Validation Accuracy: 0.6443\n",
      "Epoch [179/250], Loss: 0.0588, Accuracy: 0.9765\n",
      "Validation Loss: 0.6899, Validation Accuracy: 0.8121\n",
      "Epoch [180/250], Loss: 0.0361, Accuracy: 0.9933\n",
      "Validation Loss: 0.1161, Validation Accuracy: 0.9597\n",
      "Epoch [181/250], Loss: 0.0621, Accuracy: 0.9799\n",
      "Validation Loss: 3.4520, Validation Accuracy: 0.5570\n",
      "Epoch [182/250], Loss: 0.0243, Accuracy: 0.9899\n",
      "Validation Loss: 2.2571, Validation Accuracy: 0.6644\n",
      "Epoch [183/250], Loss: 0.0648, Accuracy: 0.9799\n",
      "Validation Loss: 5.8032, Validation Accuracy: 0.6107\n",
      "Epoch [184/250], Loss: 0.0936, Accuracy: 0.9732\n",
      "Validation Loss: 2.2183, Validation Accuracy: 0.6107\n",
      "Epoch [185/250], Loss: 0.0893, Accuracy: 0.9765\n",
      "Validation Loss: 0.7909, Validation Accuracy: 0.8121\n",
      "Epoch [186/250], Loss: 0.0706, Accuracy: 0.9698\n",
      "Validation Loss: 0.9903, Validation Accuracy: 0.7987\n",
      "Epoch [187/250], Loss: 0.0449, Accuracy: 0.9799\n",
      "Validation Loss: 3.4671, Validation Accuracy: 0.5705\n",
      "Epoch [188/250], Loss: 0.0438, Accuracy: 0.9765\n",
      "Validation Loss: 1.2885, Validation Accuracy: 0.8188\n",
      "Epoch [189/250], Loss: 0.0802, Accuracy: 0.9866\n",
      "Validation Loss: 2.1989, Validation Accuracy: 0.7315\n",
      "Epoch [190/250], Loss: 0.1122, Accuracy: 0.9698\n",
      "Validation Loss: 0.4218, Validation Accuracy: 0.8859\n",
      "Epoch [191/250], Loss: 0.0260, Accuracy: 0.9866\n",
      "Validation Loss: 1.9341, Validation Accuracy: 0.7181\n",
      "Epoch [192/250], Loss: 0.0791, Accuracy: 0.9732\n",
      "Validation Loss: 0.0540, Validation Accuracy: 0.9933\n",
      "Epoch [193/250], Loss: 0.0724, Accuracy: 0.9799\n",
      "Validation Loss: 3.2006, Validation Accuracy: 0.5772\n",
      "Epoch [194/250], Loss: 0.0697, Accuracy: 0.9698\n",
      "Validation Loss: 0.5263, Validation Accuracy: 0.8658\n",
      "Epoch [195/250], Loss: 0.0563, Accuracy: 0.9698\n",
      "Validation Loss: 0.0931, Validation Accuracy: 0.9732\n",
      "Epoch [196/250], Loss: 0.0433, Accuracy: 0.9799\n",
      "Validation Loss: 0.0490, Validation Accuracy: 0.9799\n",
      "Epoch [197/250], Loss: 0.0176, Accuracy: 0.9966\n",
      "Validation Loss: 1.7492, Validation Accuracy: 0.6913\n",
      "Epoch [198/250], Loss: 0.0620, Accuracy: 0.9765\n",
      "Validation Loss: 4.7225, Validation Accuracy: 0.6107\n",
      "Epoch [199/250], Loss: 0.0429, Accuracy: 0.9832\n",
      "Validation Loss: 0.2810, Validation Accuracy: 0.9463\n",
      "Epoch [200/250], Loss: 0.0505, Accuracy: 0.9866\n",
      "Validation Loss: 0.1392, Validation Accuracy: 0.9597\n",
      "Epoch [201/250], Loss: 0.0335, Accuracy: 0.9899\n",
      "Validation Loss: 0.0679, Validation Accuracy: 0.9866\n",
      "Epoch [202/250], Loss: 0.0415, Accuracy: 0.9832\n",
      "Validation Loss: 5.4937, Validation Accuracy: 0.6107\n",
      "Epoch [203/250], Loss: 0.0285, Accuracy: 0.9933\n",
      "Validation Loss: 5.1568, Validation Accuracy: 0.6107\n",
      "Epoch [204/250], Loss: 0.0131, Accuracy: 0.9966\n",
      "Validation Loss: 1.5068, Validation Accuracy: 0.8054\n",
      "Epoch [205/250], Loss: 0.0485, Accuracy: 0.9866\n",
      "Validation Loss: 2.0108, Validation Accuracy: 0.7383\n",
      "Epoch [206/250], Loss: 0.0458, Accuracy: 0.9799\n",
      "Validation Loss: 3.3404, Validation Accuracy: 0.6376\n",
      "Epoch [207/250], Loss: 0.0462, Accuracy: 0.9832\n",
      "Validation Loss: 3.2176, Validation Accuracy: 0.5638\n",
      "Epoch [208/250], Loss: 0.1008, Accuracy: 0.9698\n",
      "Validation Loss: 5.5083, Validation Accuracy: 0.4497\n",
      "Epoch [209/250], Loss: 0.0588, Accuracy: 0.9799\n",
      "Validation Loss: 0.0420, Validation Accuracy: 0.9933\n",
      "Epoch [210/250], Loss: 0.0830, Accuracy: 0.9765\n",
      "Validation Loss: 4.0541, Validation Accuracy: 0.6107\n",
      "Epoch [211/250], Loss: 0.0326, Accuracy: 0.9933\n",
      "Validation Loss: 0.1142, Validation Accuracy: 0.9732\n",
      "Epoch [212/250], Loss: 0.0452, Accuracy: 0.9899\n",
      "Validation Loss: 0.5502, Validation Accuracy: 0.8792\n",
      "Epoch [213/250], Loss: 0.0593, Accuracy: 0.9765\n",
      "Validation Loss: 0.2624, Validation Accuracy: 0.9262\n",
      "Epoch [214/250], Loss: 0.0233, Accuracy: 0.9966\n",
      "Validation Loss: 0.0371, Validation Accuracy: 0.9933\n",
      "Epoch [215/250], Loss: 0.0240, Accuracy: 0.9899\n",
      "Validation Loss: 2.3711, Validation Accuracy: 0.6913\n",
      "Epoch [216/250], Loss: 0.0303, Accuracy: 0.9933\n",
      "Validation Loss: 0.2561, Validation Accuracy: 0.9329\n",
      "Epoch [217/250], Loss: 0.0444, Accuracy: 0.9866\n",
      "Validation Loss: 0.1842, Validation Accuracy: 0.9597\n",
      "Epoch [218/250], Loss: 0.1780, Accuracy: 0.9530\n",
      "Validation Loss: 0.2000, Validation Accuracy: 0.9329\n",
      "Epoch [219/250], Loss: 0.0529, Accuracy: 0.9799\n",
      "Validation Loss: 0.0546, Validation Accuracy: 0.9933\n",
      "Epoch [220/250], Loss: 0.0386, Accuracy: 0.9899\n",
      "Validation Loss: 1.4913, Validation Accuracy: 0.7181\n",
      "Epoch [221/250], Loss: 0.0191, Accuracy: 0.9966\n",
      "Validation Loss: 0.0584, Validation Accuracy: 0.9933\n",
      "Epoch [222/250], Loss: 0.0312, Accuracy: 0.9899\n",
      "Validation Loss: 4.7650, Validation Accuracy: 0.5570\n",
      "Epoch [223/250], Loss: 0.0428, Accuracy: 0.9832\n",
      "Validation Loss: 3.0972, Validation Accuracy: 0.6443\n",
      "Epoch [224/250], Loss: 0.0319, Accuracy: 0.9866\n",
      "Validation Loss: 0.1007, Validation Accuracy: 0.9732\n",
      "Epoch [225/250], Loss: 0.0958, Accuracy: 0.9664\n",
      "Validation Loss: 5.2684, Validation Accuracy: 0.6107\n",
      "Epoch [226/250], Loss: 0.1223, Accuracy: 0.9597\n",
      "Validation Loss: 0.3231, Validation Accuracy: 0.9128\n",
      "Epoch [227/250], Loss: 0.0411, Accuracy: 0.9866\n",
      "Validation Loss: 0.0393, Validation Accuracy: 0.9866\n",
      "Epoch [228/250], Loss: 0.0223, Accuracy: 0.9933\n",
      "Validation Loss: 1.6999, Validation Accuracy: 0.6846\n",
      "Epoch [229/250], Loss: 0.0219, Accuracy: 0.9933\n",
      "Validation Loss: 0.0767, Validation Accuracy: 0.9866\n",
      "Epoch [230/250], Loss: 0.0713, Accuracy: 0.9832\n",
      "Validation Loss: 0.9127, Validation Accuracy: 0.8054\n",
      "Epoch [231/250], Loss: 0.0787, Accuracy: 0.9698\n",
      "Validation Loss: 3.8273, Validation Accuracy: 0.6107\n",
      "Epoch [232/250], Loss: 0.0543, Accuracy: 0.9832\n",
      "Validation Loss: 1.0928, Validation Accuracy: 0.7852\n",
      "Epoch [233/250], Loss: 0.0724, Accuracy: 0.9799\n",
      "Validation Loss: 0.0732, Validation Accuracy: 0.9866\n",
      "Epoch [234/250], Loss: 0.0342, Accuracy: 0.9899\n",
      "Validation Loss: 0.0806, Validation Accuracy: 0.9799\n",
      "Epoch [235/250], Loss: 0.1229, Accuracy: 0.9664\n",
      "Validation Loss: 0.0980, Validation Accuracy: 0.9866\n",
      "Epoch [236/250], Loss: 0.0359, Accuracy: 0.9899\n",
      "Validation Loss: 1.3683, Validation Accuracy: 0.7852\n",
      "Epoch [237/250], Loss: 0.0247, Accuracy: 0.9899\n",
      "Validation Loss: 0.7985, Validation Accuracy: 0.8523\n",
      "Epoch [238/250], Loss: 0.0211, Accuracy: 0.9966\n",
      "Validation Loss: 2.5183, Validation Accuracy: 0.6577\n",
      "Epoch [239/250], Loss: 0.0536, Accuracy: 0.9933\n",
      "Validation Loss: 0.7747, Validation Accuracy: 0.8792\n",
      "Epoch [240/250], Loss: 0.0209, Accuracy: 0.9966\n",
      "Validation Loss: 0.0508, Validation Accuracy: 0.9866\n",
      "Epoch [241/250], Loss: 0.0777, Accuracy: 0.9765\n",
      "Validation Loss: 0.0331, Validation Accuracy: 0.9933\n",
      "Epoch [242/250], Loss: 0.0195, Accuracy: 1.0000\n",
      "Validation Loss: 0.3987, Validation Accuracy: 0.9195\n",
      "Epoch [243/250], Loss: 0.0280, Accuracy: 0.9899\n",
      "Validation Loss: 1.1997, Validation Accuracy: 0.8255\n",
      "Epoch [244/250], Loss: 0.0295, Accuracy: 0.9899\n",
      "Validation Loss: 4.0392, Validation Accuracy: 0.6242\n",
      "Epoch [245/250], Loss: 0.0397, Accuracy: 0.9832\n",
      "Validation Loss: 0.6653, Validation Accuracy: 0.8523\n",
      "Epoch [246/250], Loss: 0.0332, Accuracy: 0.9899\n",
      "Validation Loss: 0.5361, Validation Accuracy: 0.9060\n",
      "Epoch [247/250], Loss: 0.0617, Accuracy: 0.9799\n",
      "Validation Loss: 5.0591, Validation Accuracy: 0.4966\n",
      "Epoch [248/250], Loss: 0.0708, Accuracy: 0.9933\n",
      "Validation Loss: 0.2771, Validation Accuracy: 0.9329\n",
      "Epoch [249/250], Loss: 0.0356, Accuracy: 0.9866\n",
      "Validation Loss: 0.5941, Validation Accuracy: 0.8859\n",
      "Epoch [250/250], Loss: 0.0642, Accuracy: 0.9765\n",
      "Validation Loss: 0.2209, Validation Accuracy: 0.9396\n",
      "Test Loss: 0.3936\n",
      "Test Accuracy: 0.9060\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 167\n",
      "label 1 is 31\n",
      "label 2 is 73\n",
      "label 3 is 41\n",
      "Not setting metadata\n",
      "312 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (270, 8, 325)\n",
      "270 train samples\n",
      "135 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.1842105263157894, 0: 0.8653846153846154}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.2828, Accuracy: 0.3778\n",
      "Validation Loss: 0.9666, Validation Accuracy: 0.6000\n",
      "Epoch [2/250], Loss: 0.9945, Accuracy: 0.5407\n",
      "Validation Loss: 0.8088, Validation Accuracy: 0.6000\n",
      "Epoch [3/250], Loss: 0.8397, Accuracy: 0.5667\n",
      "Validation Loss: 0.7335, Validation Accuracy: 0.6000\n",
      "Epoch [4/250], Loss: 0.7778, Accuracy: 0.5556\n",
      "Validation Loss: 0.7183, Validation Accuracy: 0.6000\n",
      "Epoch [5/250], Loss: 0.7922, Accuracy: 0.5741\n",
      "Validation Loss: 0.7046, Validation Accuracy: 0.6000\n",
      "Epoch [6/250], Loss: 0.7639, Accuracy: 0.5222\n",
      "Validation Loss: 0.7114, Validation Accuracy: 0.6000\n",
      "Epoch [7/250], Loss: 0.7441, Accuracy: 0.6000\n",
      "Validation Loss: 0.7024, Validation Accuracy: 0.5926\n",
      "Epoch [8/250], Loss: 0.7416, Accuracy: 0.5741\n",
      "Validation Loss: 0.7032, Validation Accuracy: 0.6000\n",
      "Epoch [9/250], Loss: 0.7338, Accuracy: 0.5852\n",
      "Validation Loss: 0.7068, Validation Accuracy: 0.4296\n",
      "Epoch [10/250], Loss: 0.7651, Accuracy: 0.5593\n",
      "Validation Loss: 0.7513, Validation Accuracy: 0.4000\n",
      "Epoch [11/250], Loss: 0.6750, Accuracy: 0.5926\n",
      "Validation Loss: 0.7036, Validation Accuracy: 0.6000\n",
      "Epoch [12/250], Loss: 0.7521, Accuracy: 0.5741\n",
      "Validation Loss: 0.6974, Validation Accuracy: 0.5037\n",
      "Epoch [13/250], Loss: 0.7283, Accuracy: 0.5185\n",
      "Validation Loss: 0.6924, Validation Accuracy: 0.6000\n",
      "Epoch [14/250], Loss: 0.7331, Accuracy: 0.5852\n",
      "Validation Loss: 0.6939, Validation Accuracy: 0.5852\n",
      "Epoch [15/250], Loss: 0.7065, Accuracy: 0.6148\n",
      "Validation Loss: 0.7063, Validation Accuracy: 0.5556\n",
      "Epoch [16/250], Loss: 0.7235, Accuracy: 0.5963\n",
      "Validation Loss: 0.7309, Validation Accuracy: 0.6000\n",
      "Epoch [17/250], Loss: 0.6938, Accuracy: 0.6185\n",
      "Validation Loss: 0.7034, Validation Accuracy: 0.6222\n",
      "Epoch [18/250], Loss: 0.6920, Accuracy: 0.5889\n",
      "Validation Loss: 0.7449, Validation Accuracy: 0.5111\n",
      "Epoch [19/250], Loss: 0.6926, Accuracy: 0.5704\n",
      "Validation Loss: 0.7037, Validation Accuracy: 0.6000\n",
      "Epoch [20/250], Loss: 0.6902, Accuracy: 0.6148\n",
      "Validation Loss: 0.7119, Validation Accuracy: 0.6000\n",
      "Epoch [21/250], Loss: 0.6686, Accuracy: 0.6259\n",
      "Validation Loss: 0.7199, Validation Accuracy: 0.5926\n",
      "Epoch [22/250], Loss: 0.6600, Accuracy: 0.6111\n",
      "Validation Loss: 0.7351, Validation Accuracy: 0.5852\n",
      "Epoch [23/250], Loss: 0.6514, Accuracy: 0.6074\n",
      "Validation Loss: 0.9139, Validation Accuracy: 0.6074\n",
      "Epoch [24/250], Loss: 0.6492, Accuracy: 0.6481\n",
      "Validation Loss: 0.7414, Validation Accuracy: 0.5778\n",
      "Epoch [25/250], Loss: 0.6788, Accuracy: 0.6519\n",
      "Validation Loss: 0.8222, Validation Accuracy: 0.6296\n",
      "Epoch [26/250], Loss: 0.6603, Accuracy: 0.6333\n",
      "Validation Loss: 0.7795, Validation Accuracy: 0.6000\n",
      "Epoch [27/250], Loss: 0.6167, Accuracy: 0.6593\n",
      "Validation Loss: 0.7584, Validation Accuracy: 0.5852\n",
      "Epoch [28/250], Loss: 0.6895, Accuracy: 0.5963\n",
      "Validation Loss: 0.9120, Validation Accuracy: 0.6222\n",
      "Epoch [29/250], Loss: 0.6627, Accuracy: 0.6148\n",
      "Validation Loss: 0.9033, Validation Accuracy: 0.6222\n",
      "Epoch [30/250], Loss: 0.6281, Accuracy: 0.6407\n",
      "Validation Loss: 0.7890, Validation Accuracy: 0.6222\n",
      "Epoch [31/250], Loss: 0.6757, Accuracy: 0.6593\n",
      "Validation Loss: 0.8275, Validation Accuracy: 0.5852\n",
      "Epoch [32/250], Loss: 0.6772, Accuracy: 0.6037\n",
      "Validation Loss: 0.8758, Validation Accuracy: 0.5185\n",
      "Epoch [33/250], Loss: 0.6407, Accuracy: 0.6333\n",
      "Validation Loss: 0.9131, Validation Accuracy: 0.5185\n",
      "Epoch [34/250], Loss: 0.6660, Accuracy: 0.6222\n",
      "Validation Loss: 0.7501, Validation Accuracy: 0.6148\n",
      "Epoch [35/250], Loss: 0.7352, Accuracy: 0.6074\n",
      "Validation Loss: 0.7441, Validation Accuracy: 0.5852\n",
      "Epoch [36/250], Loss: 0.6420, Accuracy: 0.6667\n",
      "Validation Loss: 0.7572, Validation Accuracy: 0.6074\n",
      "Epoch [37/250], Loss: 0.6227, Accuracy: 0.6704\n",
      "Validation Loss: 0.7647, Validation Accuracy: 0.6074\n",
      "Epoch [38/250], Loss: 0.6310, Accuracy: 0.6407\n",
      "Validation Loss: 0.7625, Validation Accuracy: 0.6148\n",
      "Epoch [39/250], Loss: 0.6657, Accuracy: 0.6407\n",
      "Validation Loss: 0.9404, Validation Accuracy: 0.5407\n",
      "Epoch [40/250], Loss: 0.6598, Accuracy: 0.6704\n",
      "Validation Loss: 0.8289, Validation Accuracy: 0.6074\n",
      "Epoch [41/250], Loss: 0.6194, Accuracy: 0.6667\n",
      "Validation Loss: 0.8205, Validation Accuracy: 0.6000\n",
      "Epoch [42/250], Loss: 0.6558, Accuracy: 0.6593\n",
      "Validation Loss: 0.7729, Validation Accuracy: 0.6000\n",
      "Epoch [43/250], Loss: 0.6010, Accuracy: 0.6704\n",
      "Validation Loss: 0.7663, Validation Accuracy: 0.6593\n",
      "Epoch [44/250], Loss: 0.6148, Accuracy: 0.6778\n",
      "Validation Loss: 0.7731, Validation Accuracy: 0.6667\n",
      "Epoch [45/250], Loss: 0.5734, Accuracy: 0.6815\n",
      "Validation Loss: 0.7815, Validation Accuracy: 0.6741\n",
      "Epoch [46/250], Loss: 0.5653, Accuracy: 0.7037\n",
      "Validation Loss: 0.7205, Validation Accuracy: 0.6296\n",
      "Epoch [47/250], Loss: 0.6209, Accuracy: 0.6963\n",
      "Validation Loss: 0.7865, Validation Accuracy: 0.6444\n",
      "Epoch [48/250], Loss: 0.5834, Accuracy: 0.7074\n",
      "Validation Loss: 0.7879, Validation Accuracy: 0.6074\n",
      "Epoch [49/250], Loss: 0.6195, Accuracy: 0.6815\n",
      "Validation Loss: 0.8767, Validation Accuracy: 0.6370\n",
      "Epoch [50/250], Loss: 0.5766, Accuracy: 0.7222\n",
      "Validation Loss: 0.9433, Validation Accuracy: 0.6074\n",
      "Epoch [51/250], Loss: 0.6349, Accuracy: 0.6667\n",
      "Validation Loss: 1.0792, Validation Accuracy: 0.5778\n",
      "Epoch [52/250], Loss: 0.6173, Accuracy: 0.6852\n",
      "Validation Loss: 1.1422, Validation Accuracy: 0.4963\n",
      "Epoch [53/250], Loss: 0.5828, Accuracy: 0.7111\n",
      "Validation Loss: 0.7587, Validation Accuracy: 0.6667\n",
      "Epoch [54/250], Loss: 0.5919, Accuracy: 0.6963\n",
      "Validation Loss: 1.2254, Validation Accuracy: 0.4889\n",
      "Epoch [55/250], Loss: 0.6045, Accuracy: 0.6815\n",
      "Validation Loss: 1.2571, Validation Accuracy: 0.4889\n",
      "Epoch [56/250], Loss: 0.6619, Accuracy: 0.6778\n",
      "Validation Loss: 0.7879, Validation Accuracy: 0.6370\n",
      "Epoch [57/250], Loss: 0.5921, Accuracy: 0.6741\n",
      "Validation Loss: 0.8658, Validation Accuracy: 0.6000\n",
      "Epoch [58/250], Loss: 0.6584, Accuracy: 0.6852\n",
      "Validation Loss: 1.1340, Validation Accuracy: 0.5037\n",
      "Epoch [59/250], Loss: 0.6062, Accuracy: 0.6889\n",
      "Validation Loss: 0.6974, Validation Accuracy: 0.6222\n",
      "Epoch [60/250], Loss: 0.6626, Accuracy: 0.6815\n",
      "Validation Loss: 0.9076, Validation Accuracy: 0.6074\n",
      "Epoch [61/250], Loss: 0.6068, Accuracy: 0.6778\n",
      "Validation Loss: 0.8694, Validation Accuracy: 0.5556\n",
      "Epoch [62/250], Loss: 0.6390, Accuracy: 0.7111\n",
      "Validation Loss: 0.6737, Validation Accuracy: 0.6444\n",
      "Epoch [63/250], Loss: 0.6343, Accuracy: 0.6667\n",
      "Validation Loss: 0.6795, Validation Accuracy: 0.6593\n",
      "Epoch [64/250], Loss: 0.5943, Accuracy: 0.6815\n",
      "Validation Loss: 1.0318, Validation Accuracy: 0.6000\n",
      "Epoch [65/250], Loss: 0.5753, Accuracy: 0.6889\n",
      "Validation Loss: 0.7947, Validation Accuracy: 0.6519\n",
      "Epoch [66/250], Loss: 0.5459, Accuracy: 0.7370\n",
      "Validation Loss: 1.2206, Validation Accuracy: 0.4963\n",
      "Epoch [67/250], Loss: 0.6031, Accuracy: 0.7259\n",
      "Validation Loss: 1.2033, Validation Accuracy: 0.4741\n",
      "Epoch [68/250], Loss: 0.5606, Accuracy: 0.6778\n",
      "Validation Loss: 1.2147, Validation Accuracy: 0.4741\n",
      "Epoch [69/250], Loss: 0.5223, Accuracy: 0.7667\n",
      "Validation Loss: 0.9129, Validation Accuracy: 0.5630\n",
      "Epoch [70/250], Loss: 0.5582, Accuracy: 0.6852\n",
      "Validation Loss: 0.9676, Validation Accuracy: 0.6074\n",
      "Epoch [71/250], Loss: 0.5546, Accuracy: 0.7000\n",
      "Validation Loss: 0.7424, Validation Accuracy: 0.6741\n",
      "Epoch [72/250], Loss: 0.5109, Accuracy: 0.7593\n",
      "Validation Loss: 0.9083, Validation Accuracy: 0.6741\n",
      "Epoch [73/250], Loss: 0.5560, Accuracy: 0.7296\n",
      "Validation Loss: 1.1672, Validation Accuracy: 0.6148\n",
      "Epoch [74/250], Loss: 0.5488, Accuracy: 0.6926\n",
      "Validation Loss: 1.6345, Validation Accuracy: 0.6000\n",
      "Epoch [75/250], Loss: 0.5572, Accuracy: 0.7481\n",
      "Validation Loss: 0.9931, Validation Accuracy: 0.6815\n",
      "Epoch [76/250], Loss: 0.6303, Accuracy: 0.7444\n",
      "Validation Loss: 0.7467, Validation Accuracy: 0.6593\n",
      "Epoch [77/250], Loss: 0.5602, Accuracy: 0.7222\n",
      "Validation Loss: 0.7345, Validation Accuracy: 0.6889\n",
      "Epoch [78/250], Loss: 0.5482, Accuracy: 0.7481\n",
      "Validation Loss: 1.0133, Validation Accuracy: 0.6148\n",
      "Epoch [79/250], Loss: 0.5504, Accuracy: 0.7370\n",
      "Validation Loss: 0.9346, Validation Accuracy: 0.6593\n",
      "Epoch [80/250], Loss: 0.6070, Accuracy: 0.7148\n",
      "Validation Loss: 0.7356, Validation Accuracy: 0.6963\n",
      "Epoch [81/250], Loss: 0.5357, Accuracy: 0.7444\n",
      "Validation Loss: 1.6466, Validation Accuracy: 0.6000\n",
      "Epoch [82/250], Loss: 0.5793, Accuracy: 0.6926\n",
      "Validation Loss: 0.7473, Validation Accuracy: 0.6889\n",
      "Epoch [83/250], Loss: 0.4696, Accuracy: 0.7889\n",
      "Validation Loss: 0.9313, Validation Accuracy: 0.6889\n",
      "Epoch [84/250], Loss: 0.5961, Accuracy: 0.6778\n",
      "Validation Loss: 1.5750, Validation Accuracy: 0.6000\n",
      "Epoch [85/250], Loss: 0.5838, Accuracy: 0.7444\n",
      "Validation Loss: 1.5946, Validation Accuracy: 0.6000\n",
      "Epoch [86/250], Loss: 0.5610, Accuracy: 0.7148\n",
      "Validation Loss: 1.8986, Validation Accuracy: 0.6000\n",
      "Epoch [87/250], Loss: 0.5532, Accuracy: 0.7259\n",
      "Validation Loss: 1.1625, Validation Accuracy: 0.6222\n",
      "Epoch [88/250], Loss: 0.5226, Accuracy: 0.7407\n",
      "Validation Loss: 0.9273, Validation Accuracy: 0.7037\n",
      "Epoch [89/250], Loss: 0.5687, Accuracy: 0.7074\n",
      "Validation Loss: 0.7053, Validation Accuracy: 0.6444\n",
      "Epoch [90/250], Loss: 0.5466, Accuracy: 0.7370\n",
      "Validation Loss: 0.7145, Validation Accuracy: 0.6593\n",
      "Epoch [91/250], Loss: 0.5651, Accuracy: 0.7296\n",
      "Validation Loss: 1.5758, Validation Accuracy: 0.4815\n",
      "Epoch [92/250], Loss: 0.5280, Accuracy: 0.7519\n",
      "Validation Loss: 1.0905, Validation Accuracy: 0.5926\n",
      "Epoch [93/250], Loss: 0.5816, Accuracy: 0.7296\n",
      "Validation Loss: 1.0009, Validation Accuracy: 0.6074\n",
      "Epoch [94/250], Loss: 0.5824, Accuracy: 0.7037\n",
      "Validation Loss: 0.6400, Validation Accuracy: 0.6963\n",
      "Epoch [95/250], Loss: 0.5117, Accuracy: 0.7370\n",
      "Validation Loss: 1.1034, Validation Accuracy: 0.6222\n",
      "Epoch [96/250], Loss: 0.5564, Accuracy: 0.7407\n",
      "Validation Loss: 0.6980, Validation Accuracy: 0.7111\n",
      "Epoch [97/250], Loss: 0.5753, Accuracy: 0.7407\n",
      "Validation Loss: 0.9147, Validation Accuracy: 0.6741\n",
      "Epoch [98/250], Loss: 0.5561, Accuracy: 0.6852\n",
      "Validation Loss: 1.5479, Validation Accuracy: 0.6000\n",
      "Epoch [99/250], Loss: 0.5342, Accuracy: 0.7444\n",
      "Validation Loss: 1.8753, Validation Accuracy: 0.6000\n",
      "Epoch [100/250], Loss: 0.5135, Accuracy: 0.7481\n",
      "Validation Loss: 1.1073, Validation Accuracy: 0.6815\n",
      "Epoch [101/250], Loss: 0.5450, Accuracy: 0.7370\n",
      "Validation Loss: 1.5412, Validation Accuracy: 0.6000\n",
      "Epoch [102/250], Loss: 0.4622, Accuracy: 0.7815\n",
      "Validation Loss: 1.2483, Validation Accuracy: 0.6222\n",
      "Epoch [103/250], Loss: 0.4917, Accuracy: 0.7926\n",
      "Validation Loss: 0.7108, Validation Accuracy: 0.6963\n",
      "Epoch [104/250], Loss: 0.4604, Accuracy: 0.7630\n",
      "Validation Loss: 0.8141, Validation Accuracy: 0.6741\n",
      "Epoch [105/250], Loss: 0.4776, Accuracy: 0.7889\n",
      "Validation Loss: 1.5990, Validation Accuracy: 0.4741\n",
      "Epoch [106/250], Loss: 0.5415, Accuracy: 0.7407\n",
      "Validation Loss: 0.6578, Validation Accuracy: 0.6741\n",
      "Epoch [107/250], Loss: 0.5268, Accuracy: 0.7481\n",
      "Validation Loss: 0.6821, Validation Accuracy: 0.7111\n",
      "Epoch [108/250], Loss: 0.4627, Accuracy: 0.7741\n",
      "Validation Loss: 1.1077, Validation Accuracy: 0.6519\n",
      "Epoch [109/250], Loss: 0.4533, Accuracy: 0.7963\n",
      "Validation Loss: 1.3733, Validation Accuracy: 0.5407\n",
      "Epoch [110/250], Loss: 0.4848, Accuracy: 0.8037\n",
      "Validation Loss: 1.9629, Validation Accuracy: 0.4667\n",
      "Epoch [111/250], Loss: 0.5575, Accuracy: 0.7407\n",
      "Validation Loss: 1.3859, Validation Accuracy: 0.4519\n",
      "Epoch [112/250], Loss: 0.5734, Accuracy: 0.7296\n",
      "Validation Loss: 1.2124, Validation Accuracy: 0.4889\n",
      "Epoch [113/250], Loss: 0.4916, Accuracy: 0.7704\n",
      "Validation Loss: 0.6738, Validation Accuracy: 0.7259\n",
      "Epoch [114/250], Loss: 0.4860, Accuracy: 0.7667\n",
      "Validation Loss: 1.7143, Validation Accuracy: 0.6000\n",
      "Epoch [115/250], Loss: 0.4932, Accuracy: 0.7444\n",
      "Validation Loss: 0.7557, Validation Accuracy: 0.7037\n",
      "Epoch [116/250], Loss: 0.5440, Accuracy: 0.7815\n",
      "Validation Loss: 1.9776, Validation Accuracy: 0.6000\n",
      "Epoch [117/250], Loss: 0.5139, Accuracy: 0.7741\n",
      "Validation Loss: 0.6194, Validation Accuracy: 0.7111\n",
      "Epoch [118/250], Loss: 0.4610, Accuracy: 0.7630\n",
      "Validation Loss: 0.6050, Validation Accuracy: 0.7185\n",
      "Epoch [119/250], Loss: 0.4764, Accuracy: 0.7852\n",
      "Validation Loss: 2.7044, Validation Accuracy: 0.4296\n",
      "Epoch [120/250], Loss: 0.5507, Accuracy: 0.7778\n",
      "Validation Loss: 0.9389, Validation Accuracy: 0.6667\n",
      "Epoch [121/250], Loss: 0.4998, Accuracy: 0.7815\n",
      "Validation Loss: 1.4277, Validation Accuracy: 0.5259\n",
      "Epoch [122/250], Loss: 0.4231, Accuracy: 0.8259\n",
      "Validation Loss: 1.5716, Validation Accuracy: 0.5630\n",
      "Epoch [123/250], Loss: 0.4435, Accuracy: 0.7963\n",
      "Validation Loss: 2.0964, Validation Accuracy: 0.6000\n",
      "Epoch [124/250], Loss: 0.4955, Accuracy: 0.7815\n",
      "Validation Loss: 1.5623, Validation Accuracy: 0.6296\n",
      "Epoch [125/250], Loss: 0.5530, Accuracy: 0.7556\n",
      "Validation Loss: 0.6714, Validation Accuracy: 0.7259\n",
      "Epoch [126/250], Loss: 0.4394, Accuracy: 0.8000\n",
      "Validation Loss: 0.7307, Validation Accuracy: 0.7852\n",
      "Epoch [127/250], Loss: 0.4679, Accuracy: 0.7778\n",
      "Validation Loss: 2.3888, Validation Accuracy: 0.6000\n",
      "Epoch [128/250], Loss: 0.4533, Accuracy: 0.7926\n",
      "Validation Loss: 1.4617, Validation Accuracy: 0.6222\n",
      "Epoch [129/250], Loss: 0.5018, Accuracy: 0.7852\n",
      "Validation Loss: 1.8128, Validation Accuracy: 0.6000\n",
      "Epoch [130/250], Loss: 0.4731, Accuracy: 0.7704\n",
      "Validation Loss: 1.9405, Validation Accuracy: 0.6000\n",
      "Epoch [131/250], Loss: 0.4849, Accuracy: 0.7889\n",
      "Validation Loss: 1.4086, Validation Accuracy: 0.6000\n",
      "Epoch [132/250], Loss: 0.4757, Accuracy: 0.7778\n",
      "Validation Loss: 0.9533, Validation Accuracy: 0.6296\n",
      "Epoch [133/250], Loss: 0.4570, Accuracy: 0.7926\n",
      "Validation Loss: 1.9742, Validation Accuracy: 0.4519\n",
      "Epoch [134/250], Loss: 0.5101, Accuracy: 0.7630\n",
      "Validation Loss: 0.8578, Validation Accuracy: 0.7333\n",
      "Epoch [135/250], Loss: 0.4933, Accuracy: 0.7704\n",
      "Validation Loss: 1.6099, Validation Accuracy: 0.6000\n",
      "Epoch [136/250], Loss: 0.4602, Accuracy: 0.7852\n",
      "Validation Loss: 1.7582, Validation Accuracy: 0.6000\n",
      "Epoch [137/250], Loss: 0.4639, Accuracy: 0.7778\n",
      "Validation Loss: 1.4532, Validation Accuracy: 0.6593\n",
      "Epoch [138/250], Loss: 0.4589, Accuracy: 0.7963\n",
      "Validation Loss: 1.1550, Validation Accuracy: 0.6296\n",
      "Epoch [139/250], Loss: 0.4632, Accuracy: 0.8037\n",
      "Validation Loss: 0.9991, Validation Accuracy: 0.6519\n",
      "Epoch [140/250], Loss: 0.5110, Accuracy: 0.7296\n",
      "Validation Loss: 0.7796, Validation Accuracy: 0.7481\n",
      "Epoch [141/250], Loss: 0.4254, Accuracy: 0.8111\n",
      "Validation Loss: 2.2358, Validation Accuracy: 0.4667\n",
      "Epoch [142/250], Loss: 0.3816, Accuracy: 0.8111\n",
      "Validation Loss: 1.8612, Validation Accuracy: 0.4667\n",
      "Epoch [143/250], Loss: 0.4166, Accuracy: 0.8296\n",
      "Validation Loss: 2.2814, Validation Accuracy: 0.4148\n",
      "Epoch [144/250], Loss: 0.4557, Accuracy: 0.8222\n",
      "Validation Loss: 1.4318, Validation Accuracy: 0.4963\n",
      "Epoch [145/250], Loss: 0.4294, Accuracy: 0.7926\n",
      "Validation Loss: 0.5786, Validation Accuracy: 0.7185\n",
      "Epoch [146/250], Loss: 0.4450, Accuracy: 0.7963\n",
      "Validation Loss: 1.2945, Validation Accuracy: 0.6519\n",
      "Epoch [147/250], Loss: 0.4400, Accuracy: 0.8111\n",
      "Validation Loss: 1.6221, Validation Accuracy: 0.6148\n",
      "Epoch [148/250], Loss: 0.3949, Accuracy: 0.8407\n",
      "Validation Loss: 2.9834, Validation Accuracy: 0.4148\n",
      "Epoch [149/250], Loss: 0.4481, Accuracy: 0.8148\n",
      "Validation Loss: 0.8098, Validation Accuracy: 0.6667\n",
      "Epoch [150/250], Loss: 0.4920, Accuracy: 0.8259\n",
      "Validation Loss: 0.7021, Validation Accuracy: 0.7630\n",
      "Epoch [151/250], Loss: 0.5100, Accuracy: 0.8037\n",
      "Validation Loss: 2.6444, Validation Accuracy: 0.6000\n",
      "Epoch [152/250], Loss: 0.4993, Accuracy: 0.7630\n",
      "Validation Loss: 2.6718, Validation Accuracy: 0.6000\n",
      "Epoch [153/250], Loss: 0.4972, Accuracy: 0.7889\n",
      "Validation Loss: 1.3088, Validation Accuracy: 0.5037\n",
      "Epoch [154/250], Loss: 0.4536, Accuracy: 0.8074\n",
      "Validation Loss: 2.1159, Validation Accuracy: 0.4519\n",
      "Epoch [155/250], Loss: 0.5167, Accuracy: 0.7593\n",
      "Validation Loss: 2.8145, Validation Accuracy: 0.4296\n",
      "Epoch [156/250], Loss: 0.3802, Accuracy: 0.8296\n",
      "Validation Loss: 0.9894, Validation Accuracy: 0.7259\n",
      "Epoch [157/250], Loss: 0.4029, Accuracy: 0.8296\n",
      "Validation Loss: 1.5133, Validation Accuracy: 0.5778\n",
      "Epoch [158/250], Loss: 0.4521, Accuracy: 0.8037\n",
      "Validation Loss: 0.5178, Validation Accuracy: 0.7778\n",
      "Epoch [159/250], Loss: 0.4839, Accuracy: 0.8296\n",
      "Validation Loss: 2.4417, Validation Accuracy: 0.6000\n",
      "Epoch [160/250], Loss: 0.3855, Accuracy: 0.7926\n",
      "Validation Loss: 1.5842, Validation Accuracy: 0.6000\n",
      "Epoch [161/250], Loss: 0.4242, Accuracy: 0.8000\n",
      "Validation Loss: 0.4667, Validation Accuracy: 0.7852\n",
      "Epoch [162/250], Loss: 0.4255, Accuracy: 0.8222\n",
      "Validation Loss: 2.0593, Validation Accuracy: 0.4370\n",
      "Epoch [163/250], Loss: 0.4482, Accuracy: 0.8000\n",
      "Validation Loss: 1.8789, Validation Accuracy: 0.4963\n",
      "Epoch [164/250], Loss: 0.4423, Accuracy: 0.8111\n",
      "Validation Loss: 0.7475, Validation Accuracy: 0.7704\n",
      "Epoch [165/250], Loss: 0.4225, Accuracy: 0.8185\n",
      "Validation Loss: 0.7864, Validation Accuracy: 0.6889\n",
      "Epoch [166/250], Loss: 0.3890, Accuracy: 0.8037\n",
      "Validation Loss: 1.8447, Validation Accuracy: 0.4741\n",
      "Epoch [167/250], Loss: 0.4406, Accuracy: 0.8074\n",
      "Validation Loss: 0.9516, Validation Accuracy: 0.6148\n",
      "Epoch [168/250], Loss: 0.4756, Accuracy: 0.7926\n",
      "Validation Loss: 0.7500, Validation Accuracy: 0.7185\n",
      "Epoch [169/250], Loss: 0.3821, Accuracy: 0.8148\n",
      "Validation Loss: 1.8989, Validation Accuracy: 0.4889\n",
      "Epoch [170/250], Loss: 0.3947, Accuracy: 0.8185\n",
      "Validation Loss: 1.9601, Validation Accuracy: 0.4815\n",
      "Epoch [171/250], Loss: 0.3998, Accuracy: 0.8370\n",
      "Validation Loss: 1.6033, Validation Accuracy: 0.6000\n",
      "Epoch [172/250], Loss: 0.4077, Accuracy: 0.8185\n",
      "Validation Loss: 0.9833, Validation Accuracy: 0.7037\n",
      "Epoch [173/250], Loss: 0.4246, Accuracy: 0.8407\n",
      "Validation Loss: 1.3025, Validation Accuracy: 0.6519\n",
      "Epoch [174/250], Loss: 0.4399, Accuracy: 0.8000\n",
      "Validation Loss: 1.3546, Validation Accuracy: 0.4963\n",
      "Epoch [175/250], Loss: 0.3989, Accuracy: 0.8370\n",
      "Validation Loss: 0.4854, Validation Accuracy: 0.7778\n",
      "Epoch [176/250], Loss: 0.4507, Accuracy: 0.8296\n",
      "Validation Loss: 2.9599, Validation Accuracy: 0.6000\n",
      "Epoch [177/250], Loss: 0.3515, Accuracy: 0.8407\n",
      "Validation Loss: 2.9057, Validation Accuracy: 0.6000\n",
      "Epoch [178/250], Loss: 0.3741, Accuracy: 0.8667\n",
      "Validation Loss: 1.0312, Validation Accuracy: 0.6296\n",
      "Epoch [179/250], Loss: 0.4601, Accuracy: 0.8333\n",
      "Validation Loss: 2.7263, Validation Accuracy: 0.4222\n",
      "Epoch [180/250], Loss: 0.4150, Accuracy: 0.7889\n",
      "Validation Loss: 1.6092, Validation Accuracy: 0.6074\n",
      "Epoch [181/250], Loss: 0.4688, Accuracy: 0.8074\n",
      "Validation Loss: 2.7551, Validation Accuracy: 0.6000\n",
      "Epoch [182/250], Loss: 0.3671, Accuracy: 0.8185\n",
      "Validation Loss: 2.8819, Validation Accuracy: 0.6000\n",
      "Epoch [183/250], Loss: 0.3734, Accuracy: 0.8556\n",
      "Validation Loss: 1.4301, Validation Accuracy: 0.5407\n",
      "Epoch [184/250], Loss: 0.4318, Accuracy: 0.8074\n",
      "Validation Loss: 0.8155, Validation Accuracy: 0.6444\n",
      "Epoch [185/250], Loss: 0.4153, Accuracy: 0.8111\n",
      "Validation Loss: 1.3171, Validation Accuracy: 0.6000\n",
      "Epoch [186/250], Loss: 0.4364, Accuracy: 0.8111\n",
      "Validation Loss: 0.6325, Validation Accuracy: 0.7630\n",
      "Epoch [187/250], Loss: 0.4143, Accuracy: 0.8074\n",
      "Validation Loss: 2.3518, Validation Accuracy: 0.4593\n",
      "Epoch [188/250], Loss: 0.3618, Accuracy: 0.8222\n",
      "Validation Loss: 1.1471, Validation Accuracy: 0.6370\n",
      "Epoch [189/250], Loss: 0.4355, Accuracy: 0.8333\n",
      "Validation Loss: 2.6350, Validation Accuracy: 0.6074\n",
      "Epoch [190/250], Loss: 0.4026, Accuracy: 0.8444\n",
      "Validation Loss: 0.6406, Validation Accuracy: 0.7704\n",
      "Epoch [191/250], Loss: 0.4055, Accuracy: 0.8037\n",
      "Validation Loss: 2.0706, Validation Accuracy: 0.6000\n",
      "Epoch [192/250], Loss: 0.3555, Accuracy: 0.8407\n",
      "Validation Loss: 1.8726, Validation Accuracy: 0.6667\n",
      "Epoch [193/250], Loss: 0.3252, Accuracy: 0.8667\n",
      "Validation Loss: 1.2559, Validation Accuracy: 0.6222\n",
      "Epoch [194/250], Loss: 0.3385, Accuracy: 0.8333\n",
      "Validation Loss: 2.4184, Validation Accuracy: 0.6000\n",
      "Epoch [195/250], Loss: 0.3519, Accuracy: 0.8481\n",
      "Validation Loss: 2.1872, Validation Accuracy: 0.6074\n",
      "Epoch [196/250], Loss: 0.3574, Accuracy: 0.8556\n",
      "Validation Loss: 2.6218, Validation Accuracy: 0.6000\n",
      "Epoch [197/250], Loss: 0.3944, Accuracy: 0.8259\n",
      "Validation Loss: 0.5500, Validation Accuracy: 0.7333\n",
      "Epoch [198/250], Loss: 0.3767, Accuracy: 0.8407\n",
      "Validation Loss: 0.5041, Validation Accuracy: 0.7630\n",
      "Epoch [199/250], Loss: 0.3200, Accuracy: 0.8889\n",
      "Validation Loss: 0.9202, Validation Accuracy: 0.7185\n",
      "Epoch [200/250], Loss: 0.4466, Accuracy: 0.8593\n",
      "Validation Loss: 0.6615, Validation Accuracy: 0.7111\n",
      "Epoch [201/250], Loss: 0.3849, Accuracy: 0.8296\n",
      "Validation Loss: 1.9336, Validation Accuracy: 0.6000\n",
      "Epoch [202/250], Loss: 0.3478, Accuracy: 0.8481\n",
      "Validation Loss: 1.2970, Validation Accuracy: 0.6222\n",
      "Epoch [203/250], Loss: 0.4893, Accuracy: 0.8037\n",
      "Validation Loss: 0.6288, Validation Accuracy: 0.6741\n",
      "Epoch [204/250], Loss: 0.3943, Accuracy: 0.8296\n",
      "Validation Loss: 1.3395, Validation Accuracy: 0.5704\n",
      "Epoch [205/250], Loss: 0.3927, Accuracy: 0.8370\n",
      "Validation Loss: 2.5327, Validation Accuracy: 0.4222\n",
      "Epoch [206/250], Loss: 0.3219, Accuracy: 0.8370\n",
      "Validation Loss: 2.3551, Validation Accuracy: 0.4519\n",
      "Epoch [207/250], Loss: 0.3441, Accuracy: 0.8556\n",
      "Validation Loss: 3.4661, Validation Accuracy: 0.4222\n",
      "Epoch [208/250], Loss: 0.3436, Accuracy: 0.8296\n",
      "Validation Loss: 0.7776, Validation Accuracy: 0.7556\n",
      "Epoch [209/250], Loss: 0.3304, Accuracy: 0.8667\n",
      "Validation Loss: 1.9663, Validation Accuracy: 0.6593\n",
      "Epoch [210/250], Loss: 0.4046, Accuracy: 0.8296\n",
      "Validation Loss: 0.7434, Validation Accuracy: 0.8000\n",
      "Epoch [211/250], Loss: 0.2961, Accuracy: 0.8481\n",
      "Validation Loss: 2.2686, Validation Accuracy: 0.4963\n",
      "Epoch [212/250], Loss: 0.3848, Accuracy: 0.8630\n",
      "Validation Loss: 0.5696, Validation Accuracy: 0.6889\n",
      "Epoch [213/250], Loss: 0.4163, Accuracy: 0.8296\n",
      "Validation Loss: 0.5665, Validation Accuracy: 0.6889\n",
      "Epoch [214/250], Loss: 0.3430, Accuracy: 0.8556\n",
      "Validation Loss: 0.9024, Validation Accuracy: 0.6444\n",
      "Epoch [215/250], Loss: 0.2992, Accuracy: 0.8444\n",
      "Validation Loss: 0.6897, Validation Accuracy: 0.7852\n",
      "Epoch [216/250], Loss: 0.2931, Accuracy: 0.8667\n",
      "Validation Loss: 3.4506, Validation Accuracy: 0.6000\n",
      "Epoch [217/250], Loss: 0.2953, Accuracy: 0.8778\n",
      "Validation Loss: 3.1115, Validation Accuracy: 0.4222\n",
      "Epoch [218/250], Loss: 0.2968, Accuracy: 0.8519\n",
      "Validation Loss: 2.0957, Validation Accuracy: 0.4963\n",
      "Epoch [219/250], Loss: 0.3507, Accuracy: 0.8370\n",
      "Validation Loss: 0.6317, Validation Accuracy: 0.7926\n",
      "Epoch [220/250], Loss: 0.4555, Accuracy: 0.8222\n",
      "Validation Loss: 2.2920, Validation Accuracy: 0.5333\n",
      "Epoch [221/250], Loss: 0.3750, Accuracy: 0.8667\n",
      "Validation Loss: 1.1129, Validation Accuracy: 0.6963\n",
      "Epoch [222/250], Loss: 0.3916, Accuracy: 0.8296\n",
      "Validation Loss: 1.4186, Validation Accuracy: 0.6963\n",
      "Epoch [223/250], Loss: 0.3025, Accuracy: 0.8556\n",
      "Validation Loss: 1.8766, Validation Accuracy: 0.6296\n",
      "Epoch [224/250], Loss: 0.4236, Accuracy: 0.8481\n",
      "Validation Loss: 1.4987, Validation Accuracy: 0.5926\n",
      "Epoch [225/250], Loss: 0.3317, Accuracy: 0.8333\n",
      "Validation Loss: 1.9567, Validation Accuracy: 0.5926\n",
      "Epoch [226/250], Loss: 0.3019, Accuracy: 0.8741\n",
      "Validation Loss: 2.8657, Validation Accuracy: 0.6074\n",
      "Epoch [227/250], Loss: 0.2989, Accuracy: 0.8778\n",
      "Validation Loss: 2.1779, Validation Accuracy: 0.6593\n",
      "Epoch [228/250], Loss: 0.3554, Accuracy: 0.8444\n",
      "Validation Loss: 1.7214, Validation Accuracy: 0.5778\n",
      "Epoch [229/250], Loss: 0.3207, Accuracy: 0.8444\n",
      "Validation Loss: 1.3097, Validation Accuracy: 0.6148\n",
      "Epoch [230/250], Loss: 0.3050, Accuracy: 0.8741\n",
      "Validation Loss: 1.4831, Validation Accuracy: 0.7407\n",
      "Epoch [231/250], Loss: 0.3371, Accuracy: 0.8519\n",
      "Validation Loss: 1.3138, Validation Accuracy: 0.6667\n",
      "Epoch [232/250], Loss: 0.3653, Accuracy: 0.8630\n",
      "Validation Loss: 1.7061, Validation Accuracy: 0.5111\n",
      "Epoch [233/250], Loss: 0.3391, Accuracy: 0.8815\n",
      "Validation Loss: 1.7512, Validation Accuracy: 0.5630\n",
      "Epoch [234/250], Loss: 0.3162, Accuracy: 0.8519\n",
      "Validation Loss: 3.4333, Validation Accuracy: 0.4296\n",
      "Epoch [235/250], Loss: 0.2981, Accuracy: 0.8519\n",
      "Validation Loss: 1.9770, Validation Accuracy: 0.6074\n",
      "Epoch [236/250], Loss: 0.3160, Accuracy: 0.8778\n",
      "Validation Loss: 0.7713, Validation Accuracy: 0.7630\n",
      "Epoch [237/250], Loss: 0.3237, Accuracy: 0.8778\n",
      "Validation Loss: 2.4004, Validation Accuracy: 0.5852\n",
      "Epoch [238/250], Loss: 0.3171, Accuracy: 0.8519\n",
      "Validation Loss: 2.3037, Validation Accuracy: 0.6296\n",
      "Epoch [239/250], Loss: 0.2894, Accuracy: 0.8593\n",
      "Validation Loss: 1.8942, Validation Accuracy: 0.6444\n",
      "Epoch [240/250], Loss: 0.3068, Accuracy: 0.8556\n",
      "Validation Loss: 0.8209, Validation Accuracy: 0.6000\n",
      "Epoch [241/250], Loss: 0.3266, Accuracy: 0.8481\n",
      "Validation Loss: 1.6012, Validation Accuracy: 0.6000\n",
      "Epoch [242/250], Loss: 0.3286, Accuracy: 0.8444\n",
      "Validation Loss: 0.9161, Validation Accuracy: 0.6074\n",
      "Epoch [243/250], Loss: 0.3096, Accuracy: 0.8630\n",
      "Validation Loss: 2.0634, Validation Accuracy: 0.5407\n",
      "Epoch [244/250], Loss: 0.2921, Accuracy: 0.8741\n",
      "Validation Loss: 2.7432, Validation Accuracy: 0.5704\n",
      "Epoch [245/250], Loss: 0.3409, Accuracy: 0.8704\n",
      "Validation Loss: 1.5513, Validation Accuracy: 0.5259\n",
      "Epoch [246/250], Loss: 0.2788, Accuracy: 0.8815\n",
      "Validation Loss: 2.0538, Validation Accuracy: 0.4444\n",
      "Epoch [247/250], Loss: 0.3474, Accuracy: 0.8481\n",
      "Validation Loss: 2.4871, Validation Accuracy: 0.6000\n",
      "Epoch [248/250], Loss: 0.3335, Accuracy: 0.8519\n",
      "Validation Loss: 1.8862, Validation Accuracy: 0.6000\n",
      "Epoch [249/250], Loss: 0.3129, Accuracy: 0.8481\n",
      "Validation Loss: 0.8098, Validation Accuracy: 0.6593\n",
      "Epoch [250/250], Loss: 0.3299, Accuracy: 0.8815\n",
      "Validation Loss: 0.5230, Validation Accuracy: 0.7407\n",
      "Test Loss: 0.5365\n",
      "Test Accuracy: 0.7111\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 111\n",
      "label 1 is 48\n",
      "label 2 is 33\n",
      "label 3 is 91\n",
      "Not setting metadata\n",
      "283 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (255, 8, 325)\n",
      "255 train samples\n",
      "128 test samples\n",
      "Number of batches in train_loader: 4\n",
      "{-1: 1.1206140350877194, 0: 0.9028268551236749}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.2997, Accuracy: 0.4078\n",
      "Validation Loss: 1.0542, Validation Accuracy: 0.4688\n",
      "Epoch [2/250], Loss: 1.0640, Accuracy: 0.5333\n",
      "Validation Loss: 0.9204, Validation Accuracy: 0.4688\n",
      "Epoch [3/250], Loss: 0.8996, Accuracy: 0.5490\n",
      "Validation Loss: 0.8086, Validation Accuracy: 0.4688\n",
      "Epoch [4/250], Loss: 0.8221, Accuracy: 0.5529\n",
      "Validation Loss: 0.7849, Validation Accuracy: 0.4688\n",
      "Epoch [5/250], Loss: 0.8287, Accuracy: 0.5020\n",
      "Validation Loss: 0.7460, Validation Accuracy: 0.4688\n",
      "Epoch [6/250], Loss: 0.8560, Accuracy: 0.4588\n",
      "Validation Loss: 0.7777, Validation Accuracy: 0.4688\n",
      "Epoch [7/250], Loss: 0.7815, Accuracy: 0.5529\n",
      "Validation Loss: 0.7447, Validation Accuracy: 0.4688\n",
      "Epoch [8/250], Loss: 0.8348, Accuracy: 0.4784\n",
      "Validation Loss: 0.7558, Validation Accuracy: 0.4688\n",
      "Epoch [9/250], Loss: 0.8204, Accuracy: 0.4784\n",
      "Validation Loss: 0.7386, Validation Accuracy: 0.4688\n",
      "Epoch [10/250], Loss: 0.7933, Accuracy: 0.5137\n",
      "Validation Loss: 0.7545, Validation Accuracy: 0.4688\n",
      "Epoch [11/250], Loss: 0.7872, Accuracy: 0.5059\n",
      "Validation Loss: 0.7398, Validation Accuracy: 0.4688\n",
      "Epoch [12/250], Loss: 0.7859, Accuracy: 0.4980\n",
      "Validation Loss: 0.7577, Validation Accuracy: 0.4688\n",
      "Epoch [13/250], Loss: 0.7957, Accuracy: 0.5529\n",
      "Validation Loss: 0.7208, Validation Accuracy: 0.4688\n",
      "Epoch [14/250], Loss: 0.7670, Accuracy: 0.5451\n",
      "Validation Loss: 0.7516, Validation Accuracy: 0.4688\n",
      "Epoch [15/250], Loss: 0.7530, Accuracy: 0.5647\n",
      "Validation Loss: 0.7153, Validation Accuracy: 0.4688\n",
      "Epoch [16/250], Loss: 0.7543, Accuracy: 0.5569\n",
      "Validation Loss: 0.7498, Validation Accuracy: 0.4688\n",
      "Epoch [17/250], Loss: 0.7612, Accuracy: 0.5255\n",
      "Validation Loss: 0.7257, Validation Accuracy: 0.4688\n",
      "Epoch [18/250], Loss: 0.7612, Accuracy: 0.5451\n",
      "Validation Loss: 0.7071, Validation Accuracy: 0.4688\n",
      "Epoch [19/250], Loss: 0.7492, Accuracy: 0.5608\n",
      "Validation Loss: 0.6999, Validation Accuracy: 0.4766\n",
      "Epoch [20/250], Loss: 0.7515, Accuracy: 0.5529\n",
      "Validation Loss: 0.6957, Validation Accuracy: 0.4922\n",
      "Epoch [21/250], Loss: 0.7220, Accuracy: 0.5882\n",
      "Validation Loss: 0.6759, Validation Accuracy: 0.5938\n",
      "Epoch [22/250], Loss: 0.7642, Accuracy: 0.5373\n",
      "Validation Loss: 0.6665, Validation Accuracy: 0.6328\n",
      "Epoch [23/250], Loss: 0.7510, Accuracy: 0.5647\n",
      "Validation Loss: 0.6796, Validation Accuracy: 0.5938\n",
      "Epoch [24/250], Loss: 0.7450, Accuracy: 0.5804\n",
      "Validation Loss: 0.6713, Validation Accuracy: 0.5859\n",
      "Epoch [25/250], Loss: 0.7563, Accuracy: 0.5294\n",
      "Validation Loss: 0.6554, Validation Accuracy: 0.6250\n",
      "Epoch [26/250], Loss: 0.6887, Accuracy: 0.6235\n",
      "Validation Loss: 0.6640, Validation Accuracy: 0.5938\n",
      "Epoch [27/250], Loss: 0.7181, Accuracy: 0.5882\n",
      "Validation Loss: 0.6546, Validation Accuracy: 0.6562\n",
      "Epoch [28/250], Loss: 0.7089, Accuracy: 0.6157\n",
      "Validation Loss: 0.6688, Validation Accuracy: 0.5938\n",
      "Epoch [29/250], Loss: 0.6898, Accuracy: 0.6000\n",
      "Validation Loss: 0.7014, Validation Accuracy: 0.5234\n",
      "Epoch [30/250], Loss: 0.7119, Accuracy: 0.6000\n",
      "Validation Loss: 0.6722, Validation Accuracy: 0.5938\n",
      "Epoch [31/250], Loss: 0.7135, Accuracy: 0.6078\n",
      "Validation Loss: 0.6862, Validation Accuracy: 0.5781\n",
      "Epoch [32/250], Loss: 0.7281, Accuracy: 0.5961\n",
      "Validation Loss: 0.6440, Validation Accuracy: 0.6719\n",
      "Epoch [33/250], Loss: 0.6804, Accuracy: 0.6275\n",
      "Validation Loss: 0.6403, Validation Accuracy: 0.6406\n",
      "Epoch [34/250], Loss: 0.7063, Accuracy: 0.6196\n",
      "Validation Loss: 0.6239, Validation Accuracy: 0.6953\n",
      "Epoch [35/250], Loss: 0.7233, Accuracy: 0.5490\n",
      "Validation Loss: 0.6317, Validation Accuracy: 0.6406\n",
      "Epoch [36/250], Loss: 0.6969, Accuracy: 0.6353\n",
      "Validation Loss: 0.6204, Validation Accuracy: 0.6953\n",
      "Epoch [37/250], Loss: 0.7171, Accuracy: 0.5451\n",
      "Validation Loss: 0.7367, Validation Accuracy: 0.5859\n",
      "Epoch [38/250], Loss: 0.6684, Accuracy: 0.6235\n",
      "Validation Loss: 1.0296, Validation Accuracy: 0.4766\n",
      "Epoch [39/250], Loss: 0.6785, Accuracy: 0.6471\n",
      "Validation Loss: 0.7289, Validation Accuracy: 0.6250\n",
      "Epoch [40/250], Loss: 0.6591, Accuracy: 0.6627\n",
      "Validation Loss: 0.6879, Validation Accuracy: 0.6250\n",
      "Epoch [41/250], Loss: 0.7117, Accuracy: 0.6039\n",
      "Validation Loss: 1.0424, Validation Accuracy: 0.4922\n",
      "Epoch [42/250], Loss: 0.6366, Accuracy: 0.6824\n",
      "Validation Loss: 0.6250, Validation Accuracy: 0.6562\n",
      "Epoch [43/250], Loss: 0.7017, Accuracy: 0.5922\n",
      "Validation Loss: 0.6599, Validation Accuracy: 0.6641\n",
      "Epoch [44/250], Loss: 0.6862, Accuracy: 0.6471\n",
      "Validation Loss: 0.5896, Validation Accuracy: 0.6875\n",
      "Epoch [45/250], Loss: 0.6393, Accuracy: 0.6824\n",
      "Validation Loss: 0.8271, Validation Accuracy: 0.5547\n",
      "Epoch [46/250], Loss: 0.6139, Accuracy: 0.6902\n",
      "Validation Loss: 0.7065, Validation Accuracy: 0.6172\n",
      "Epoch [47/250], Loss: 0.6109, Accuracy: 0.6941\n",
      "Validation Loss: 1.4785, Validation Accuracy: 0.5469\n",
      "Epoch [48/250], Loss: 0.6552, Accuracy: 0.6667\n",
      "Validation Loss: 0.9735, Validation Accuracy: 0.5547\n",
      "Epoch [49/250], Loss: 0.6171, Accuracy: 0.6902\n",
      "Validation Loss: 0.8473, Validation Accuracy: 0.6094\n",
      "Epoch [50/250], Loss: 0.6590, Accuracy: 0.6471\n",
      "Validation Loss: 0.6560, Validation Accuracy: 0.6641\n",
      "Epoch [51/250], Loss: 0.6104, Accuracy: 0.7020\n",
      "Validation Loss: 0.7107, Validation Accuracy: 0.6172\n",
      "Epoch [52/250], Loss: 0.6110, Accuracy: 0.6941\n",
      "Validation Loss: 0.7887, Validation Accuracy: 0.5938\n",
      "Epoch [53/250], Loss: 0.6207, Accuracy: 0.6745\n",
      "Validation Loss: 1.4718, Validation Accuracy: 0.5391\n",
      "Epoch [54/250], Loss: 0.6222, Accuracy: 0.6745\n",
      "Validation Loss: 0.5639, Validation Accuracy: 0.7266\n",
      "Epoch [55/250], Loss: 0.6197, Accuracy: 0.6980\n",
      "Validation Loss: 0.5522, Validation Accuracy: 0.6953\n",
      "Epoch [56/250], Loss: 0.6468, Accuracy: 0.6471\n",
      "Validation Loss: 0.5811, Validation Accuracy: 0.6953\n",
      "Epoch [57/250], Loss: 0.5710, Accuracy: 0.7294\n",
      "Validation Loss: 0.5971, Validation Accuracy: 0.7031\n",
      "Epoch [58/250], Loss: 0.5856, Accuracy: 0.7137\n",
      "Validation Loss: 0.8480, Validation Accuracy: 0.5625\n",
      "Epoch [59/250], Loss: 0.5567, Accuracy: 0.7373\n",
      "Validation Loss: 0.6862, Validation Accuracy: 0.6719\n",
      "Epoch [60/250], Loss: 0.6544, Accuracy: 0.6667\n",
      "Validation Loss: 1.2507, Validation Accuracy: 0.5391\n",
      "Epoch [61/250], Loss: 0.5788, Accuracy: 0.7137\n",
      "Validation Loss: 0.6193, Validation Accuracy: 0.6797\n",
      "Epoch [62/250], Loss: 0.5522, Accuracy: 0.7294\n",
      "Validation Loss: 0.7754, Validation Accuracy: 0.6953\n",
      "Epoch [63/250], Loss: 0.6210, Accuracy: 0.6706\n",
      "Validation Loss: 0.5657, Validation Accuracy: 0.7422\n",
      "Epoch [64/250], Loss: 0.5950, Accuracy: 0.6824\n",
      "Validation Loss: 0.8090, Validation Accuracy: 0.6797\n",
      "Epoch [65/250], Loss: 0.5626, Accuracy: 0.7373\n",
      "Validation Loss: 0.6367, Validation Accuracy: 0.6875\n",
      "Epoch [66/250], Loss: 0.5813, Accuracy: 0.7020\n",
      "Validation Loss: 0.6613, Validation Accuracy: 0.7266\n",
      "Epoch [67/250], Loss: 0.5540, Accuracy: 0.7255\n",
      "Validation Loss: 0.6086, Validation Accuracy: 0.7344\n",
      "Epoch [68/250], Loss: 0.5524, Accuracy: 0.7294\n",
      "Validation Loss: 1.7299, Validation Accuracy: 0.5391\n",
      "Epoch [69/250], Loss: 0.5683, Accuracy: 0.7255\n",
      "Validation Loss: 1.2402, Validation Accuracy: 0.5078\n",
      "Epoch [70/250], Loss: 0.5619, Accuracy: 0.7608\n",
      "Validation Loss: 1.3952, Validation Accuracy: 0.4922\n",
      "Epoch [71/250], Loss: 0.5287, Accuracy: 0.7490\n",
      "Validation Loss: 1.2131, Validation Accuracy: 0.4922\n",
      "Epoch [72/250], Loss: 0.5663, Accuracy: 0.7451\n",
      "Validation Loss: 0.7120, Validation Accuracy: 0.6719\n",
      "Epoch [73/250], Loss: 0.5600, Accuracy: 0.6980\n",
      "Validation Loss: 0.8629, Validation Accuracy: 0.6406\n",
      "Epoch [74/250], Loss: 0.5692, Accuracy: 0.7647\n",
      "Validation Loss: 0.5320, Validation Accuracy: 0.7422\n",
      "Epoch [75/250], Loss: 0.5079, Accuracy: 0.7569\n",
      "Validation Loss: 1.0839, Validation Accuracy: 0.5469\n",
      "Epoch [76/250], Loss: 0.6131, Accuracy: 0.7020\n",
      "Validation Loss: 2.1336, Validation Accuracy: 0.5469\n",
      "Epoch [77/250], Loss: 0.5892, Accuracy: 0.7216\n",
      "Validation Loss: 0.7112, Validation Accuracy: 0.6406\n",
      "Epoch [78/250], Loss: 0.5554, Accuracy: 0.7216\n",
      "Validation Loss: 1.1211, Validation Accuracy: 0.5547\n",
      "Epoch [79/250], Loss: 0.5234, Accuracy: 0.7333\n",
      "Validation Loss: 0.6522, Validation Accuracy: 0.7266\n",
      "Epoch [80/250], Loss: 0.5390, Accuracy: 0.7216\n",
      "Validation Loss: 0.5765, Validation Accuracy: 0.7031\n",
      "Epoch [81/250], Loss: 0.5156, Accuracy: 0.7333\n",
      "Validation Loss: 1.0867, Validation Accuracy: 0.5703\n",
      "Epoch [82/250], Loss: 0.5370, Accuracy: 0.7725\n",
      "Validation Loss: 1.3710, Validation Accuracy: 0.5156\n",
      "Epoch [83/250], Loss: 0.5414, Accuracy: 0.7373\n",
      "Validation Loss: 0.7233, Validation Accuracy: 0.7031\n",
      "Epoch [84/250], Loss: 0.5220, Accuracy: 0.7529\n",
      "Validation Loss: 0.8201, Validation Accuracy: 0.6875\n",
      "Epoch [85/250], Loss: 0.5505, Accuracy: 0.7373\n",
      "Validation Loss: 2.0513, Validation Accuracy: 0.5469\n",
      "Epoch [86/250], Loss: 0.5439, Accuracy: 0.6902\n",
      "Validation Loss: 1.0048, Validation Accuracy: 0.6328\n",
      "Epoch [87/250], Loss: 0.4977, Accuracy: 0.7647\n",
      "Validation Loss: 0.5230, Validation Accuracy: 0.7422\n",
      "Epoch [88/250], Loss: 0.5476, Accuracy: 0.7333\n",
      "Validation Loss: 0.5201, Validation Accuracy: 0.7578\n",
      "Epoch [89/250], Loss: 0.5193, Accuracy: 0.7294\n",
      "Validation Loss: 2.3665, Validation Accuracy: 0.5391\n",
      "Epoch [90/250], Loss: 0.5530, Accuracy: 0.7020\n",
      "Validation Loss: 0.5842, Validation Accuracy: 0.7344\n",
      "Epoch [91/250], Loss: 0.5403, Accuracy: 0.7020\n",
      "Validation Loss: 2.2401, Validation Accuracy: 0.5391\n",
      "Epoch [92/250], Loss: 0.5171, Accuracy: 0.7529\n",
      "Validation Loss: 1.2388, Validation Accuracy: 0.6250\n",
      "Epoch [93/250], Loss: 0.5039, Accuracy: 0.7333\n",
      "Validation Loss: 1.3122, Validation Accuracy: 0.5469\n",
      "Epoch [94/250], Loss: 0.4709, Accuracy: 0.7882\n",
      "Validation Loss: 2.5128, Validation Accuracy: 0.5391\n",
      "Epoch [95/250], Loss: 0.5312, Accuracy: 0.7490\n",
      "Validation Loss: 2.0337, Validation Accuracy: 0.5469\n",
      "Epoch [96/250], Loss: 0.5549, Accuracy: 0.7294\n",
      "Validation Loss: 0.7824, Validation Accuracy: 0.6719\n",
      "Epoch [97/250], Loss: 0.5344, Accuracy: 0.7451\n",
      "Validation Loss: 1.4280, Validation Accuracy: 0.5469\n",
      "Epoch [98/250], Loss: 0.5046, Accuracy: 0.7529\n",
      "Validation Loss: 1.5457, Validation Accuracy: 0.5703\n",
      "Epoch [99/250], Loss: 0.4959, Accuracy: 0.7686\n",
      "Validation Loss: 0.5348, Validation Accuracy: 0.7500\n",
      "Epoch [100/250], Loss: 0.5461, Accuracy: 0.7373\n",
      "Validation Loss: 0.5440, Validation Accuracy: 0.7266\n",
      "Epoch [101/250], Loss: 0.5044, Accuracy: 0.7843\n",
      "Validation Loss: 0.9217, Validation Accuracy: 0.5938\n",
      "Epoch [102/250], Loss: 0.5078, Accuracy: 0.7569\n",
      "Validation Loss: 0.6751, Validation Accuracy: 0.6797\n",
      "Epoch [103/250], Loss: 0.5008, Accuracy: 0.7608\n",
      "Validation Loss: 1.1045, Validation Accuracy: 0.5703\n",
      "Epoch [104/250], Loss: 0.5202, Accuracy: 0.7373\n",
      "Validation Loss: 1.1081, Validation Accuracy: 0.6172\n",
      "Epoch [105/250], Loss: 0.4953, Accuracy: 0.7647\n",
      "Validation Loss: 0.6718, Validation Accuracy: 0.7188\n",
      "Epoch [106/250], Loss: 0.4924, Accuracy: 0.7608\n",
      "Validation Loss: 0.6588, Validation Accuracy: 0.7422\n",
      "Epoch [107/250], Loss: 0.4419, Accuracy: 0.7765\n",
      "Validation Loss: 1.1055, Validation Accuracy: 0.6250\n",
      "Epoch [108/250], Loss: 0.5267, Accuracy: 0.7529\n",
      "Validation Loss: 0.9054, Validation Accuracy: 0.7109\n",
      "Epoch [109/250], Loss: 0.5052, Accuracy: 0.7294\n",
      "Validation Loss: 2.8282, Validation Accuracy: 0.5312\n",
      "Epoch [110/250], Loss: 0.4646, Accuracy: 0.8000\n",
      "Validation Loss: 2.7950, Validation Accuracy: 0.5391\n",
      "Epoch [111/250], Loss: 0.4527, Accuracy: 0.7922\n",
      "Validation Loss: 0.6466, Validation Accuracy: 0.6797\n",
      "Epoch [112/250], Loss: 0.4736, Accuracy: 0.7608\n",
      "Validation Loss: 0.7252, Validation Accuracy: 0.7031\n",
      "Epoch [113/250], Loss: 0.5231, Accuracy: 0.7490\n",
      "Validation Loss: 0.8430, Validation Accuracy: 0.5703\n",
      "Epoch [114/250], Loss: 0.5336, Accuracy: 0.7490\n",
      "Validation Loss: 0.5617, Validation Accuracy: 0.7109\n",
      "Epoch [115/250], Loss: 0.5250, Accuracy: 0.7608\n",
      "Validation Loss: 0.5863, Validation Accuracy: 0.7031\n",
      "Epoch [116/250], Loss: 0.4837, Accuracy: 0.7804\n",
      "Validation Loss: 1.3925, Validation Accuracy: 0.5156\n",
      "Epoch [117/250], Loss: 0.4616, Accuracy: 0.7686\n",
      "Validation Loss: 1.4100, Validation Accuracy: 0.5469\n",
      "Epoch [118/250], Loss: 0.4440, Accuracy: 0.7843\n",
      "Validation Loss: 0.9213, Validation Accuracy: 0.7109\n",
      "Epoch [119/250], Loss: 0.4493, Accuracy: 0.7804\n",
      "Validation Loss: 1.0848, Validation Accuracy: 0.6328\n",
      "Epoch [120/250], Loss: 0.5178, Accuracy: 0.7451\n",
      "Validation Loss: 0.6461, Validation Accuracy: 0.6953\n",
      "Epoch [121/250], Loss: 0.4955, Accuracy: 0.7490\n",
      "Validation Loss: 1.0435, Validation Accuracy: 0.6328\n",
      "Epoch [122/250], Loss: 0.5031, Accuracy: 0.7451\n",
      "Validation Loss: 1.7197, Validation Accuracy: 0.5156\n",
      "Epoch [123/250], Loss: 0.4963, Accuracy: 0.7569\n",
      "Validation Loss: 0.5727, Validation Accuracy: 0.7422\n",
      "Epoch [124/250], Loss: 0.4937, Accuracy: 0.7569\n",
      "Validation Loss: 1.0198, Validation Accuracy: 0.6172\n",
      "Epoch [125/250], Loss: 0.5067, Accuracy: 0.7608\n",
      "Validation Loss: 0.5263, Validation Accuracy: 0.7578\n",
      "Epoch [126/250], Loss: 0.4871, Accuracy: 0.7686\n",
      "Validation Loss: 1.2070, Validation Accuracy: 0.5547\n",
      "Epoch [127/250], Loss: 0.4968, Accuracy: 0.7569\n",
      "Validation Loss: 1.2744, Validation Accuracy: 0.5703\n",
      "Epoch [128/250], Loss: 0.4612, Accuracy: 0.8000\n",
      "Validation Loss: 0.8002, Validation Accuracy: 0.6875\n",
      "Epoch [129/250], Loss: 0.4691, Accuracy: 0.7647\n",
      "Validation Loss: 1.1218, Validation Accuracy: 0.5938\n",
      "Epoch [130/250], Loss: 0.4776, Accuracy: 0.7569\n",
      "Validation Loss: 0.8568, Validation Accuracy: 0.6484\n",
      "Epoch [131/250], Loss: 0.4899, Accuracy: 0.7843\n",
      "Validation Loss: 1.0939, Validation Accuracy: 0.6484\n",
      "Epoch [132/250], Loss: 0.4639, Accuracy: 0.7961\n",
      "Validation Loss: 2.1368, Validation Accuracy: 0.4844\n",
      "Epoch [133/250], Loss: 0.4422, Accuracy: 0.8196\n",
      "Validation Loss: 1.5719, Validation Accuracy: 0.5234\n",
      "Epoch [134/250], Loss: 0.4639, Accuracy: 0.7725\n",
      "Validation Loss: 1.5653, Validation Accuracy: 0.5078\n",
      "Epoch [135/250], Loss: 0.4852, Accuracy: 0.7686\n",
      "Validation Loss: 0.9430, Validation Accuracy: 0.6797\n",
      "Epoch [136/250], Loss: 0.4844, Accuracy: 0.7608\n",
      "Validation Loss: 0.6452, Validation Accuracy: 0.7422\n",
      "Epoch [137/250], Loss: 0.4520, Accuracy: 0.7961\n",
      "Validation Loss: 1.4912, Validation Accuracy: 0.5547\n",
      "Epoch [138/250], Loss: 0.4407, Accuracy: 0.7608\n",
      "Validation Loss: 1.5448, Validation Accuracy: 0.5625\n",
      "Epoch [139/250], Loss: 0.4202, Accuracy: 0.7922\n",
      "Validation Loss: 1.3438, Validation Accuracy: 0.5547\n",
      "Epoch [140/250], Loss: 0.4205, Accuracy: 0.8275\n",
      "Validation Loss: 0.5519, Validation Accuracy: 0.7266\n",
      "Epoch [141/250], Loss: 0.4509, Accuracy: 0.7765\n",
      "Validation Loss: 0.6000, Validation Accuracy: 0.7578\n",
      "Epoch [142/250], Loss: 0.4454, Accuracy: 0.7961\n",
      "Validation Loss: 0.6070, Validation Accuracy: 0.7109\n",
      "Epoch [143/250], Loss: 0.4923, Accuracy: 0.7569\n",
      "Validation Loss: 0.8332, Validation Accuracy: 0.5547\n",
      "Epoch [144/250], Loss: 0.4963, Accuracy: 0.7373\n",
      "Validation Loss: 0.6609, Validation Accuracy: 0.5703\n",
      "Epoch [145/250], Loss: 0.4334, Accuracy: 0.8118\n",
      "Validation Loss: 0.7622, Validation Accuracy: 0.6562\n",
      "Epoch [146/250], Loss: 0.4790, Accuracy: 0.7647\n",
      "Validation Loss: 0.5322, Validation Accuracy: 0.7266\n",
      "Epoch [147/250], Loss: 0.4225, Accuracy: 0.7804\n",
      "Validation Loss: 0.5704, Validation Accuracy: 0.7188\n",
      "Epoch [148/250], Loss: 0.4372, Accuracy: 0.7843\n",
      "Validation Loss: 0.8781, Validation Accuracy: 0.6641\n",
      "Epoch [149/250], Loss: 0.4568, Accuracy: 0.7765\n",
      "Validation Loss: 2.0025, Validation Accuracy: 0.5469\n",
      "Epoch [150/250], Loss: 0.4397, Accuracy: 0.8000\n",
      "Validation Loss: 0.7223, Validation Accuracy: 0.7266\n",
      "Epoch [151/250], Loss: 0.4680, Accuracy: 0.7843\n",
      "Validation Loss: 0.6137, Validation Accuracy: 0.7578\n",
      "Epoch [152/250], Loss: 0.4401, Accuracy: 0.7804\n",
      "Validation Loss: 1.7845, Validation Accuracy: 0.5391\n",
      "Epoch [153/250], Loss: 0.4102, Accuracy: 0.8196\n",
      "Validation Loss: 1.4878, Validation Accuracy: 0.5781\n",
      "Epoch [154/250], Loss: 0.4830, Accuracy: 0.7882\n",
      "Validation Loss: 0.5925, Validation Accuracy: 0.7578\n",
      "Epoch [155/250], Loss: 0.4338, Accuracy: 0.7804\n",
      "Validation Loss: 0.6723, Validation Accuracy: 0.7188\n",
      "Epoch [156/250], Loss: 0.4455, Accuracy: 0.7922\n",
      "Validation Loss: 1.6767, Validation Accuracy: 0.5391\n",
      "Epoch [157/250], Loss: 0.4469, Accuracy: 0.8078\n",
      "Validation Loss: 0.5901, Validation Accuracy: 0.7422\n",
      "Epoch [158/250], Loss: 0.4627, Accuracy: 0.7922\n",
      "Validation Loss: 1.5945, Validation Accuracy: 0.5859\n",
      "Epoch [159/250], Loss: 0.3996, Accuracy: 0.8000\n",
      "Validation Loss: 2.6569, Validation Accuracy: 0.5000\n",
      "Epoch [160/250], Loss: 0.4492, Accuracy: 0.7922\n",
      "Validation Loss: 2.8425, Validation Accuracy: 0.4922\n",
      "Epoch [161/250], Loss: 0.4473, Accuracy: 0.8078\n",
      "Validation Loss: 2.9491, Validation Accuracy: 0.4766\n",
      "Epoch [162/250], Loss: 0.4388, Accuracy: 0.8000\n",
      "Validation Loss: 1.6577, Validation Accuracy: 0.5391\n",
      "Epoch [163/250], Loss: 0.4343, Accuracy: 0.7725\n",
      "Validation Loss: 2.2481, Validation Accuracy: 0.4922\n",
      "Epoch [164/250], Loss: 0.4687, Accuracy: 0.7686\n",
      "Validation Loss: 2.2148, Validation Accuracy: 0.4844\n",
      "Epoch [165/250], Loss: 0.4628, Accuracy: 0.7882\n",
      "Validation Loss: 1.0208, Validation Accuracy: 0.5469\n",
      "Epoch [166/250], Loss: 0.4373, Accuracy: 0.8000\n",
      "Validation Loss: 0.6116, Validation Accuracy: 0.6953\n",
      "Epoch [167/250], Loss: 0.4372, Accuracy: 0.7922\n",
      "Validation Loss: 2.1361, Validation Accuracy: 0.4844\n",
      "Epoch [168/250], Loss: 0.4409, Accuracy: 0.7725\n",
      "Validation Loss: 2.5065, Validation Accuracy: 0.4766\n",
      "Epoch [169/250], Loss: 0.4414, Accuracy: 0.8039\n",
      "Validation Loss: 2.0790, Validation Accuracy: 0.4922\n",
      "Epoch [170/250], Loss: 0.4369, Accuracy: 0.8078\n",
      "Validation Loss: 0.7810, Validation Accuracy: 0.6562\n",
      "Epoch [171/250], Loss: 0.4247, Accuracy: 0.8118\n",
      "Validation Loss: 0.9045, Validation Accuracy: 0.7031\n",
      "Epoch [172/250], Loss: 0.4124, Accuracy: 0.8157\n",
      "Validation Loss: 1.9253, Validation Accuracy: 0.5859\n",
      "Epoch [173/250], Loss: 0.4740, Accuracy: 0.7961\n",
      "Validation Loss: 1.8894, Validation Accuracy: 0.4922\n",
      "Epoch [174/250], Loss: 0.4748, Accuracy: 0.7804\n",
      "Validation Loss: 1.4475, Validation Accuracy: 0.5469\n",
      "Epoch [175/250], Loss: 0.3712, Accuracy: 0.8353\n",
      "Validation Loss: 0.7670, Validation Accuracy: 0.6562\n",
      "Epoch [176/250], Loss: 0.3919, Accuracy: 0.8000\n",
      "Validation Loss: 0.6659, Validation Accuracy: 0.7422\n",
      "Epoch [177/250], Loss: 0.4152, Accuracy: 0.7961\n",
      "Validation Loss: 1.4797, Validation Accuracy: 0.5312\n",
      "Epoch [178/250], Loss: 0.4349, Accuracy: 0.8039\n",
      "Validation Loss: 0.7957, Validation Accuracy: 0.7266\n",
      "Epoch [179/250], Loss: 0.3864, Accuracy: 0.8235\n",
      "Validation Loss: 1.4170, Validation Accuracy: 0.6406\n",
      "Epoch [180/250], Loss: 0.4474, Accuracy: 0.8078\n",
      "Validation Loss: 0.5800, Validation Accuracy: 0.7344\n",
      "Epoch [181/250], Loss: 0.4162, Accuracy: 0.8157\n",
      "Validation Loss: 0.7320, Validation Accuracy: 0.6953\n",
      "Epoch [182/250], Loss: 0.3886, Accuracy: 0.8392\n",
      "Validation Loss: 1.0179, Validation Accuracy: 0.6797\n",
      "Epoch [183/250], Loss: 0.4170, Accuracy: 0.8000\n",
      "Validation Loss: 1.4088, Validation Accuracy: 0.5938\n",
      "Epoch [184/250], Loss: 0.4231, Accuracy: 0.8000\n",
      "Validation Loss: 0.5842, Validation Accuracy: 0.7422\n",
      "Epoch [185/250], Loss: 0.4074, Accuracy: 0.8078\n",
      "Validation Loss: 0.6723, Validation Accuracy: 0.7344\n",
      "Epoch [186/250], Loss: 0.4187, Accuracy: 0.7843\n",
      "Validation Loss: 0.5314, Validation Accuracy: 0.7578\n",
      "Epoch [187/250], Loss: 0.3952, Accuracy: 0.8235\n",
      "Validation Loss: 0.9566, Validation Accuracy: 0.5781\n",
      "Epoch [188/250], Loss: 0.3990, Accuracy: 0.7961\n",
      "Validation Loss: 1.0822, Validation Accuracy: 0.5703\n",
      "Epoch [189/250], Loss: 0.4172, Accuracy: 0.7765\n",
      "Validation Loss: 1.8467, Validation Accuracy: 0.5547\n",
      "Epoch [190/250], Loss: 0.4129, Accuracy: 0.7882\n",
      "Validation Loss: 0.5590, Validation Accuracy: 0.7266\n",
      "Epoch [191/250], Loss: 0.3904, Accuracy: 0.8157\n",
      "Validation Loss: 2.4243, Validation Accuracy: 0.4922\n",
      "Epoch [192/250], Loss: 0.3841, Accuracy: 0.8118\n",
      "Validation Loss: 1.8603, Validation Accuracy: 0.5234\n",
      "Epoch [193/250], Loss: 0.4115, Accuracy: 0.7843\n",
      "Validation Loss: 1.4280, Validation Accuracy: 0.5391\n",
      "Epoch [194/250], Loss: 0.4801, Accuracy: 0.7529\n",
      "Validation Loss: 1.8087, Validation Accuracy: 0.4922\n",
      "Epoch [195/250], Loss: 0.4896, Accuracy: 0.7569\n",
      "Validation Loss: 0.5282, Validation Accuracy: 0.7734\n",
      "Epoch [196/250], Loss: 0.4307, Accuracy: 0.7882\n",
      "Validation Loss: 0.6074, Validation Accuracy: 0.7188\n",
      "Epoch [197/250], Loss: 0.3978, Accuracy: 0.7804\n",
      "Validation Loss: 1.3244, Validation Accuracy: 0.6797\n",
      "Epoch [198/250], Loss: 0.4349, Accuracy: 0.8000\n",
      "Validation Loss: 2.7380, Validation Accuracy: 0.5000\n",
      "Epoch [199/250], Loss: 0.3854, Accuracy: 0.8196\n",
      "Validation Loss: 0.7791, Validation Accuracy: 0.7266\n",
      "Epoch [200/250], Loss: 0.3621, Accuracy: 0.8314\n",
      "Validation Loss: 1.3020, Validation Accuracy: 0.5938\n",
      "Epoch [201/250], Loss: 0.3666, Accuracy: 0.8314\n",
      "Validation Loss: 1.9734, Validation Accuracy: 0.5938\n",
      "Epoch [202/250], Loss: 0.4133, Accuracy: 0.7961\n",
      "Validation Loss: 1.1542, Validation Accuracy: 0.6719\n",
      "Epoch [203/250], Loss: 0.4220, Accuracy: 0.8118\n",
      "Validation Loss: 0.6593, Validation Accuracy: 0.7656\n",
      "Epoch [204/250], Loss: 0.3911, Accuracy: 0.7882\n",
      "Validation Loss: 1.9246, Validation Accuracy: 0.5859\n",
      "Epoch [205/250], Loss: 0.3339, Accuracy: 0.8431\n",
      "Validation Loss: 4.1888, Validation Accuracy: 0.5391\n",
      "Epoch [206/250], Loss: 0.3834, Accuracy: 0.8157\n",
      "Validation Loss: 0.6093, Validation Accuracy: 0.7188\n",
      "Epoch [207/250], Loss: 0.4072, Accuracy: 0.8196\n",
      "Validation Loss: 1.2219, Validation Accuracy: 0.5469\n",
      "Epoch [208/250], Loss: 0.4219, Accuracy: 0.7882\n",
      "Validation Loss: 0.5873, Validation Accuracy: 0.7500\n",
      "Epoch [209/250], Loss: 0.4538, Accuracy: 0.8196\n",
      "Validation Loss: 0.7759, Validation Accuracy: 0.6328\n",
      "Epoch [210/250], Loss: 0.4231, Accuracy: 0.7804\n",
      "Validation Loss: 0.9353, Validation Accuracy: 0.5781\n",
      "Epoch [211/250], Loss: 0.4015, Accuracy: 0.8000\n",
      "Validation Loss: 0.5974, Validation Accuracy: 0.7266\n",
      "Epoch [212/250], Loss: 0.3915, Accuracy: 0.8196\n",
      "Validation Loss: 0.6054, Validation Accuracy: 0.7578\n",
      "Epoch [213/250], Loss: 0.3792, Accuracy: 0.8275\n",
      "Validation Loss: 0.7124, Validation Accuracy: 0.7031\n",
      "Epoch [214/250], Loss: 0.3539, Accuracy: 0.8392\n",
      "Validation Loss: 0.8631, Validation Accuracy: 0.7188\n",
      "Epoch [215/250], Loss: 0.3746, Accuracy: 0.8157\n",
      "Validation Loss: 0.8641, Validation Accuracy: 0.7188\n",
      "Epoch [216/250], Loss: 0.3893, Accuracy: 0.8275\n",
      "Validation Loss: 0.9176, Validation Accuracy: 0.6406\n",
      "Epoch [217/250], Loss: 0.3873, Accuracy: 0.8157\n",
      "Validation Loss: 0.6618, Validation Accuracy: 0.7188\n",
      "Epoch [218/250], Loss: 0.3227, Accuracy: 0.8510\n",
      "Validation Loss: 1.2883, Validation Accuracy: 0.5469\n",
      "Epoch [219/250], Loss: 0.4059, Accuracy: 0.8157\n",
      "Validation Loss: 0.5492, Validation Accuracy: 0.7656\n",
      "Epoch [220/250], Loss: 0.3642, Accuracy: 0.8039\n",
      "Validation Loss: 0.5400, Validation Accuracy: 0.7656\n",
      "Epoch [221/250], Loss: 0.3814, Accuracy: 0.8039\n",
      "Validation Loss: 0.6123, Validation Accuracy: 0.7422\n",
      "Epoch [222/250], Loss: 0.3819, Accuracy: 0.8235\n",
      "Validation Loss: 0.8575, Validation Accuracy: 0.7266\n",
      "Epoch [223/250], Loss: 0.3427, Accuracy: 0.8392\n",
      "Validation Loss: 0.8341, Validation Accuracy: 0.7500\n",
      "Epoch [224/250], Loss: 0.3730, Accuracy: 0.8039\n",
      "Validation Loss: 1.1354, Validation Accuracy: 0.6953\n",
      "Epoch [225/250], Loss: 0.3742, Accuracy: 0.8431\n",
      "Validation Loss: 1.3750, Validation Accuracy: 0.6328\n",
      "Epoch [226/250], Loss: 0.4051, Accuracy: 0.8000\n",
      "Validation Loss: 0.7488, Validation Accuracy: 0.6094\n",
      "Epoch [227/250], Loss: 0.3719, Accuracy: 0.8118\n",
      "Validation Loss: 0.9135, Validation Accuracy: 0.5859\n",
      "Epoch [228/250], Loss: 0.3559, Accuracy: 0.8392\n",
      "Validation Loss: 1.4820, Validation Accuracy: 0.5469\n",
      "Epoch [229/250], Loss: 0.4136, Accuracy: 0.7882\n",
      "Validation Loss: 0.9778, Validation Accuracy: 0.5703\n",
      "Epoch [230/250], Loss: 0.3999, Accuracy: 0.7882\n",
      "Validation Loss: 0.6481, Validation Accuracy: 0.6953\n",
      "Epoch [231/250], Loss: 0.3760, Accuracy: 0.8078\n",
      "Validation Loss: 0.6136, Validation Accuracy: 0.7500\n",
      "Epoch [232/250], Loss: 0.4094, Accuracy: 0.8157\n",
      "Validation Loss: 1.0040, Validation Accuracy: 0.7188\n",
      "Epoch [233/250], Loss: 0.3705, Accuracy: 0.8588\n",
      "Validation Loss: 2.8250, Validation Accuracy: 0.5312\n",
      "Epoch [234/250], Loss: 0.4103, Accuracy: 0.7922\n",
      "Validation Loss: 3.1705, Validation Accuracy: 0.5000\n",
      "Epoch [235/250], Loss: 0.3300, Accuracy: 0.8392\n",
      "Validation Loss: 1.0457, Validation Accuracy: 0.7031\n",
      "Epoch [236/250], Loss: 0.3794, Accuracy: 0.8275\n",
      "Validation Loss: 0.7965, Validation Accuracy: 0.6016\n",
      "Epoch [237/250], Loss: 0.3353, Accuracy: 0.8353\n",
      "Validation Loss: 1.9447, Validation Accuracy: 0.5469\n",
      "Epoch [238/250], Loss: 0.4165, Accuracy: 0.8157\n",
      "Validation Loss: 1.0650, Validation Accuracy: 0.5781\n",
      "Epoch [239/250], Loss: 0.3939, Accuracy: 0.8275\n",
      "Validation Loss: 0.8696, Validation Accuracy: 0.6484\n",
      "Epoch [240/250], Loss: 0.3308, Accuracy: 0.8392\n",
      "Validation Loss: 0.6073, Validation Accuracy: 0.7734\n",
      "Epoch [241/250], Loss: 0.3450, Accuracy: 0.8431\n",
      "Validation Loss: 1.0174, Validation Accuracy: 0.6250\n",
      "Epoch [242/250], Loss: 0.3295, Accuracy: 0.8353\n",
      "Validation Loss: 0.6066, Validation Accuracy: 0.7500\n",
      "Epoch [243/250], Loss: 0.3362, Accuracy: 0.8431\n",
      "Validation Loss: 1.1928, Validation Accuracy: 0.6719\n",
      "Epoch [244/250], Loss: 0.4135, Accuracy: 0.8000\n",
      "Validation Loss: 2.4874, Validation Accuracy: 0.5469\n",
      "Epoch [245/250], Loss: 0.3356, Accuracy: 0.8314\n",
      "Validation Loss: 1.2031, Validation Accuracy: 0.6094\n",
      "Epoch [246/250], Loss: 0.3665, Accuracy: 0.8235\n",
      "Validation Loss: 2.6626, Validation Accuracy: 0.5469\n",
      "Epoch [247/250], Loss: 0.3648, Accuracy: 0.7961\n",
      "Validation Loss: 1.4530, Validation Accuracy: 0.6094\n",
      "Epoch [248/250], Loss: 0.3803, Accuracy: 0.8039\n",
      "Validation Loss: 1.6089, Validation Accuracy: 0.5703\n",
      "Epoch [249/250], Loss: 0.2959, Accuracy: 0.8510\n",
      "Validation Loss: 1.5823, Validation Accuracy: 0.5781\n",
      "Epoch [250/250], Loss: 0.4308, Accuracy: 0.7961\n",
      "Validation Loss: 2.5298, Validation Accuracy: 0.5078\n",
      "Test Loss: 2.1470\n",
      "Test Accuracy: 0.6094\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 72\n",
      "label 1 is 201\n",
      "label 2 is 31\n",
      "label 3 is 23\n",
      "Not setting metadata\n",
      "327 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (277, 8, 325)\n",
      "277 train samples\n",
      "139 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.2171052631578947, 0: 0.8486238532110092}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.3214, Accuracy: 0.2996\n",
      "Validation Loss: 0.9561, Validation Accuracy: 0.5899\n",
      "Epoch [2/250], Loss: 0.9588, Accuracy: 0.5271\n",
      "Validation Loss: 0.7568, Validation Accuracy: 0.5899\n",
      "Epoch [3/250], Loss: 0.7629, Accuracy: 0.5884\n",
      "Validation Loss: 0.7485, Validation Accuracy: 0.5899\n",
      "Epoch [4/250], Loss: 0.7064, Accuracy: 0.6354\n",
      "Validation Loss: 0.8425, Validation Accuracy: 0.5899\n",
      "Epoch [5/250], Loss: 0.6399, Accuracy: 0.6823\n",
      "Validation Loss: 1.0823, Validation Accuracy: 0.5899\n",
      "Epoch [6/250], Loss: 0.5962, Accuracy: 0.7184\n",
      "Validation Loss: 1.4840, Validation Accuracy: 0.5899\n",
      "Epoch [7/250], Loss: 0.4293, Accuracy: 0.8448\n",
      "Validation Loss: 2.1211, Validation Accuracy: 0.5899\n",
      "Epoch [8/250], Loss: 0.3571, Accuracy: 0.8412\n",
      "Validation Loss: 2.5867, Validation Accuracy: 0.5899\n",
      "Epoch [9/250], Loss: 0.3139, Accuracy: 0.8845\n",
      "Validation Loss: 2.7956, Validation Accuracy: 0.5899\n",
      "Epoch [10/250], Loss: 0.2300, Accuracy: 0.9061\n",
      "Validation Loss: 3.1324, Validation Accuracy: 0.5899\n",
      "Epoch [11/250], Loss: 0.1747, Accuracy: 0.9495\n",
      "Validation Loss: 3.1259, Validation Accuracy: 0.5899\n",
      "Epoch [12/250], Loss: 0.1936, Accuracy: 0.9170\n",
      "Validation Loss: 3.1743, Validation Accuracy: 0.5899\n",
      "Epoch [13/250], Loss: 0.1527, Accuracy: 0.9639\n",
      "Validation Loss: 2.8466, Validation Accuracy: 0.5899\n",
      "Epoch [14/250], Loss: 0.1635, Accuracy: 0.9386\n",
      "Validation Loss: 3.2984, Validation Accuracy: 0.5899\n",
      "Epoch [15/250], Loss: 0.0848, Accuracy: 0.9747\n",
      "Validation Loss: 3.2588, Validation Accuracy: 0.5899\n",
      "Epoch [16/250], Loss: 0.1493, Accuracy: 0.9603\n",
      "Validation Loss: 0.5927, Validation Accuracy: 0.8345\n",
      "Epoch [17/250], Loss: 0.2362, Accuracy: 0.9531\n",
      "Validation Loss: 1.1982, Validation Accuracy: 0.6691\n",
      "Epoch [18/250], Loss: 0.1587, Accuracy: 0.9567\n",
      "Validation Loss: 1.5066, Validation Accuracy: 0.6403\n",
      "Epoch [19/250], Loss: 0.0954, Accuracy: 0.9783\n",
      "Validation Loss: 2.5544, Validation Accuracy: 0.5036\n",
      "Epoch [20/250], Loss: 0.0912, Accuracy: 0.9783\n",
      "Validation Loss: 0.1301, Validation Accuracy: 0.9712\n",
      "Epoch [21/250], Loss: 0.0705, Accuracy: 0.9892\n",
      "Validation Loss: 0.4618, Validation Accuracy: 0.8993\n",
      "Epoch [22/250], Loss: 0.0860, Accuracy: 0.9856\n",
      "Validation Loss: 0.9767, Validation Accuracy: 0.8345\n",
      "Epoch [23/250], Loss: 0.1175, Accuracy: 0.9531\n",
      "Validation Loss: 0.4722, Validation Accuracy: 0.9137\n",
      "Epoch [24/250], Loss: 0.0929, Accuracy: 0.9747\n",
      "Validation Loss: 0.2488, Validation Accuracy: 0.9353\n",
      "Epoch [25/250], Loss: 0.0741, Accuracy: 0.9819\n",
      "Validation Loss: 3.7118, Validation Accuracy: 0.5108\n",
      "Epoch [26/250], Loss: 0.0918, Accuracy: 0.9783\n",
      "Validation Loss: 0.7717, Validation Accuracy: 0.8345\n",
      "Epoch [27/250], Loss: 0.0498, Accuracy: 0.9856\n",
      "Validation Loss: 0.1075, Validation Accuracy: 0.9640\n",
      "Epoch [28/250], Loss: 0.0932, Accuracy: 0.9783\n",
      "Validation Loss: 0.1860, Validation Accuracy: 0.9424\n",
      "Epoch [29/250], Loss: 0.1136, Accuracy: 0.9747\n",
      "Validation Loss: 1.7865, Validation Accuracy: 0.6691\n",
      "Epoch [30/250], Loss: 0.1031, Accuracy: 0.9603\n",
      "Validation Loss: 0.2422, Validation Accuracy: 0.9353\n",
      "Epoch [31/250], Loss: 0.0879, Accuracy: 0.9711\n",
      "Validation Loss: 0.2351, Validation Accuracy: 0.9496\n",
      "Epoch [32/250], Loss: 0.0732, Accuracy: 0.9856\n",
      "Validation Loss: 1.7931, Validation Accuracy: 0.6906\n",
      "Epoch [33/250], Loss: 0.0571, Accuracy: 0.9819\n",
      "Validation Loss: 0.2552, Validation Accuracy: 0.9353\n",
      "Epoch [34/250], Loss: 0.1158, Accuracy: 0.9675\n",
      "Validation Loss: 0.1794, Validation Accuracy: 0.9424\n",
      "Epoch [35/250], Loss: 0.0641, Accuracy: 0.9819\n",
      "Validation Loss: 1.0554, Validation Accuracy: 0.8058\n",
      "Epoch [36/250], Loss: 0.0759, Accuracy: 0.9639\n",
      "Validation Loss: 0.5018, Validation Accuracy: 0.9065\n",
      "Epoch [37/250], Loss: 0.0442, Accuracy: 0.9819\n",
      "Validation Loss: 0.5529, Validation Accuracy: 0.8777\n",
      "Epoch [38/250], Loss: 0.0681, Accuracy: 0.9819\n",
      "Validation Loss: 1.9373, Validation Accuracy: 0.6403\n",
      "Epoch [39/250], Loss: 0.0853, Accuracy: 0.9711\n",
      "Validation Loss: 0.1794, Validation Accuracy: 0.9568\n",
      "Epoch [40/250], Loss: 0.0522, Accuracy: 0.9856\n",
      "Validation Loss: 0.1889, Validation Accuracy: 0.9568\n",
      "Epoch [41/250], Loss: 0.0299, Accuracy: 0.9892\n",
      "Validation Loss: 0.2037, Validation Accuracy: 0.9496\n",
      "Epoch [42/250], Loss: 0.0625, Accuracy: 0.9892\n",
      "Validation Loss: 0.3780, Validation Accuracy: 0.9424\n",
      "Epoch [43/250], Loss: 0.0534, Accuracy: 0.9856\n",
      "Validation Loss: 0.9185, Validation Accuracy: 0.8633\n",
      "Epoch [44/250], Loss: 0.1655, Accuracy: 0.9531\n",
      "Validation Loss: 0.8859, Validation Accuracy: 0.7986\n",
      "Epoch [45/250], Loss: 0.1056, Accuracy: 0.9675\n",
      "Validation Loss: 0.8427, Validation Accuracy: 0.7986\n",
      "Epoch [46/250], Loss: 0.0604, Accuracy: 0.9783\n",
      "Validation Loss: 2.2059, Validation Accuracy: 0.6691\n",
      "Epoch [47/250], Loss: 0.0829, Accuracy: 0.9783\n",
      "Validation Loss: 2.2267, Validation Accuracy: 0.5683\n",
      "Epoch [48/250], Loss: 0.0808, Accuracy: 0.9783\n",
      "Validation Loss: 0.4437, Validation Accuracy: 0.9065\n",
      "Epoch [49/250], Loss: 0.0296, Accuracy: 0.9928\n",
      "Validation Loss: 0.3215, Validation Accuracy: 0.8993\n",
      "Epoch [50/250], Loss: 0.0949, Accuracy: 0.9747\n",
      "Validation Loss: 3.6985, Validation Accuracy: 0.4245\n",
      "Epoch [51/250], Loss: 0.0371, Accuracy: 0.9856\n",
      "Validation Loss: 3.1402, Validation Accuracy: 0.4748\n",
      "Epoch [52/250], Loss: 0.0518, Accuracy: 0.9747\n",
      "Validation Loss: 0.2035, Validation Accuracy: 0.9424\n",
      "Epoch [53/250], Loss: 0.0510, Accuracy: 0.9856\n",
      "Validation Loss: 0.7685, Validation Accuracy: 0.8705\n",
      "Epoch [54/250], Loss: 0.0308, Accuracy: 0.9819\n",
      "Validation Loss: 2.1493, Validation Accuracy: 0.6403\n",
      "Epoch [55/250], Loss: 0.0310, Accuracy: 0.9928\n",
      "Validation Loss: 5.9175, Validation Accuracy: 0.4173\n",
      "Epoch [56/250], Loss: 0.0290, Accuracy: 0.9856\n",
      "Validation Loss: 0.3016, Validation Accuracy: 0.9353\n",
      "Epoch [57/250], Loss: 0.0099, Accuracy: 0.9964\n",
      "Validation Loss: 0.3514, Validation Accuracy: 0.9496\n",
      "Epoch [58/250], Loss: 0.0142, Accuracy: 0.9964\n",
      "Validation Loss: 3.7318, Validation Accuracy: 0.5827\n",
      "Epoch [59/250], Loss: 0.0288, Accuracy: 0.9856\n",
      "Validation Loss: 0.3944, Validation Accuracy: 0.9353\n",
      "Epoch [60/250], Loss: 0.0156, Accuracy: 0.9928\n",
      "Validation Loss: 0.2806, Validation Accuracy: 0.9496\n",
      "Epoch [61/250], Loss: 0.0471, Accuracy: 0.9819\n",
      "Validation Loss: 1.7814, Validation Accuracy: 0.7050\n",
      "Epoch [62/250], Loss: 0.1102, Accuracy: 0.9856\n",
      "Validation Loss: 2.7723, Validation Accuracy: 0.6547\n",
      "Epoch [63/250], Loss: 0.0371, Accuracy: 0.9819\n",
      "Validation Loss: 0.1470, Validation Accuracy: 0.9496\n",
      "Epoch [64/250], Loss: 0.0569, Accuracy: 0.9856\n",
      "Validation Loss: 0.6340, Validation Accuracy: 0.8849\n",
      "Epoch [65/250], Loss: 0.0710, Accuracy: 0.9819\n",
      "Validation Loss: 1.4581, Validation Accuracy: 0.7482\n",
      "Epoch [66/250], Loss: 0.0325, Accuracy: 0.9819\n",
      "Validation Loss: 1.6260, Validation Accuracy: 0.7554\n",
      "Epoch [67/250], Loss: 0.0642, Accuracy: 0.9783\n",
      "Validation Loss: 0.3919, Validation Accuracy: 0.9424\n",
      "Epoch [68/250], Loss: 0.0797, Accuracy: 0.9747\n",
      "Validation Loss: 1.2297, Validation Accuracy: 0.8201\n",
      "Epoch [69/250], Loss: 0.0440, Accuracy: 0.9856\n",
      "Validation Loss: 2.2596, Validation Accuracy: 0.7194\n",
      "Epoch [70/250], Loss: 0.0398, Accuracy: 0.9928\n",
      "Validation Loss: 0.2192, Validation Accuracy: 0.9640\n",
      "Epoch [71/250], Loss: 0.0474, Accuracy: 0.9819\n",
      "Validation Loss: 0.6628, Validation Accuracy: 0.8993\n",
      "Epoch [72/250], Loss: 0.0210, Accuracy: 0.9928\n",
      "Validation Loss: 3.9811, Validation Accuracy: 0.5971\n",
      "Epoch [73/250], Loss: 0.0201, Accuracy: 0.9928\n",
      "Validation Loss: 0.4840, Validation Accuracy: 0.9209\n",
      "Epoch [74/250], Loss: 0.0163, Accuracy: 0.9964\n",
      "Validation Loss: 0.2339, Validation Accuracy: 0.9496\n",
      "Epoch [75/250], Loss: 0.0450, Accuracy: 0.9856\n",
      "Validation Loss: 0.3429, Validation Accuracy: 0.9496\n",
      "Epoch [76/250], Loss: 0.0762, Accuracy: 0.9928\n",
      "Validation Loss: 0.7849, Validation Accuracy: 0.8705\n",
      "Epoch [77/250], Loss: 0.0605, Accuracy: 0.9819\n",
      "Validation Loss: 3.7130, Validation Accuracy: 0.5468\n",
      "Epoch [78/250], Loss: 0.0184, Accuracy: 0.9928\n",
      "Validation Loss: 1.4747, Validation Accuracy: 0.8058\n",
      "Epoch [79/250], Loss: 0.0524, Accuracy: 0.9856\n",
      "Validation Loss: 0.4537, Validation Accuracy: 0.9209\n",
      "Epoch [80/250], Loss: 0.0200, Accuracy: 0.9928\n",
      "Validation Loss: 2.3137, Validation Accuracy: 0.7050\n",
      "Epoch [81/250], Loss: 0.0644, Accuracy: 0.9856\n",
      "Validation Loss: 3.2943, Validation Accuracy: 0.6259\n",
      "Epoch [82/250], Loss: 0.1149, Accuracy: 0.9711\n",
      "Validation Loss: 2.4153, Validation Accuracy: 0.5899\n",
      "Epoch [83/250], Loss: 0.0300, Accuracy: 0.9892\n",
      "Validation Loss: 0.0822, Validation Accuracy: 0.9712\n",
      "Epoch [84/250], Loss: 0.0144, Accuracy: 0.9964\n",
      "Validation Loss: 0.1615, Validation Accuracy: 0.9568\n",
      "Epoch [85/250], Loss: 0.0161, Accuracy: 1.0000\n",
      "Validation Loss: 0.3073, Validation Accuracy: 0.9568\n",
      "Epoch [86/250], Loss: 0.0406, Accuracy: 0.9819\n",
      "Validation Loss: 0.0985, Validation Accuracy: 0.9784\n",
      "Epoch [87/250], Loss: 0.0208, Accuracy: 0.9964\n",
      "Validation Loss: 1.1074, Validation Accuracy: 0.8273\n",
      "Epoch [88/250], Loss: 0.0464, Accuracy: 0.9856\n",
      "Validation Loss: 0.0990, Validation Accuracy: 0.9784\n",
      "Epoch [89/250], Loss: 0.0181, Accuracy: 0.9928\n",
      "Validation Loss: 0.4137, Validation Accuracy: 0.9496\n",
      "Epoch [90/250], Loss: 0.0041, Accuracy: 1.0000\n",
      "Validation Loss: 0.4667, Validation Accuracy: 0.9424\n",
      "Epoch [91/250], Loss: 0.0205, Accuracy: 0.9928\n",
      "Validation Loss: 0.4422, Validation Accuracy: 0.9424\n",
      "Epoch [92/250], Loss: 0.0149, Accuracy: 0.9928\n",
      "Validation Loss: 3.3690, Validation Accuracy: 0.6547\n",
      "Epoch [93/250], Loss: 0.0299, Accuracy: 0.9928\n",
      "Validation Loss: 0.7002, Validation Accuracy: 0.9065\n",
      "Epoch [94/250], Loss: 0.0491, Accuracy: 0.9856\n",
      "Validation Loss: 0.2922, Validation Accuracy: 0.9424\n",
      "Epoch [95/250], Loss: 0.0093, Accuracy: 0.9964\n",
      "Validation Loss: 0.2620, Validation Accuracy: 0.9424\n",
      "Epoch [96/250], Loss: 0.0197, Accuracy: 0.9928\n",
      "Validation Loss: 1.4255, Validation Accuracy: 0.7626\n",
      "Epoch [97/250], Loss: 0.0307, Accuracy: 0.9928\n",
      "Validation Loss: 5.7730, Validation Accuracy: 0.4820\n",
      "Epoch [98/250], Loss: 0.0143, Accuracy: 0.9964\n",
      "Validation Loss: 0.2496, Validation Accuracy: 0.9568\n",
      "Epoch [99/250], Loss: 0.0060, Accuracy: 1.0000\n",
      "Validation Loss: 0.6281, Validation Accuracy: 0.9209\n",
      "Epoch [100/250], Loss: 0.0764, Accuracy: 0.9892\n",
      "Validation Loss: 5.7040, Validation Accuracy: 0.5899\n",
      "Epoch [101/250], Loss: 0.1266, Accuracy: 0.9603\n",
      "Validation Loss: 6.3980, Validation Accuracy: 0.4101\n",
      "Epoch [102/250], Loss: 0.0281, Accuracy: 0.9892\n",
      "Validation Loss: 4.3309, Validation Accuracy: 0.4532\n",
      "Epoch [103/250], Loss: 0.0227, Accuracy: 0.9928\n",
      "Validation Loss: 2.1042, Validation Accuracy: 0.7122\n",
      "Epoch [104/250], Loss: 0.0087, Accuracy: 0.9964\n",
      "Validation Loss: 1.2539, Validation Accuracy: 0.8417\n",
      "Epoch [105/250], Loss: 0.0198, Accuracy: 0.9892\n",
      "Validation Loss: 6.6963, Validation Accuracy: 0.4317\n",
      "Epoch [106/250], Loss: 0.0358, Accuracy: 0.9892\n",
      "Validation Loss: 0.6727, Validation Accuracy: 0.8921\n",
      "Epoch [107/250], Loss: 0.0904, Accuracy: 0.9856\n",
      "Validation Loss: 0.2245, Validation Accuracy: 0.9640\n",
      "Epoch [108/250], Loss: 0.0966, Accuracy: 0.9747\n",
      "Validation Loss: 1.4765, Validation Accuracy: 0.7770\n",
      "Epoch [109/250], Loss: 0.0546, Accuracy: 0.9783\n",
      "Validation Loss: 2.2265, Validation Accuracy: 0.6763\n",
      "Epoch [110/250], Loss: 0.0504, Accuracy: 0.9856\n",
      "Validation Loss: 1.4956, Validation Accuracy: 0.7554\n",
      "Epoch [111/250], Loss: 0.0916, Accuracy: 0.9675\n",
      "Validation Loss: 0.7755, Validation Accuracy: 0.8417\n",
      "Epoch [112/250], Loss: 0.0708, Accuracy: 0.9747\n",
      "Validation Loss: 0.3798, Validation Accuracy: 0.9209\n",
      "Epoch [113/250], Loss: 0.1385, Accuracy: 0.9783\n",
      "Validation Loss: 0.8713, Validation Accuracy: 0.8561\n",
      "Epoch [114/250], Loss: 0.1003, Accuracy: 0.9567\n",
      "Validation Loss: 4.6136, Validation Accuracy: 0.4101\n",
      "Epoch [115/250], Loss: 0.0401, Accuracy: 0.9747\n",
      "Validation Loss: 4.8622, Validation Accuracy: 0.4173\n",
      "Epoch [116/250], Loss: 0.0490, Accuracy: 0.9856\n",
      "Validation Loss: 0.6561, Validation Accuracy: 0.8633\n",
      "Epoch [117/250], Loss: 0.0292, Accuracy: 0.9892\n",
      "Validation Loss: 0.1905, Validation Accuracy: 0.9568\n",
      "Epoch [118/250], Loss: 0.0189, Accuracy: 0.9964\n",
      "Validation Loss: 0.1543, Validation Accuracy: 0.9712\n",
      "Epoch [119/250], Loss: 0.0168, Accuracy: 0.9964\n",
      "Validation Loss: 0.1635, Validation Accuracy: 0.9640\n",
      "Epoch [120/250], Loss: 0.0165, Accuracy: 0.9928\n",
      "Validation Loss: 0.2438, Validation Accuracy: 0.9568\n",
      "Epoch [121/250], Loss: 0.0051, Accuracy: 1.0000\n",
      "Validation Loss: 0.1738, Validation Accuracy: 0.9712\n",
      "Epoch [122/250], Loss: 0.0029, Accuracy: 1.0000\n",
      "Validation Loss: 0.1236, Validation Accuracy: 0.9712\n",
      "Epoch [123/250], Loss: 0.0113, Accuracy: 0.9964\n",
      "Validation Loss: 0.5016, Validation Accuracy: 0.9353\n",
      "Epoch [124/250], Loss: 0.0057, Accuracy: 1.0000\n",
      "Validation Loss: 0.1537, Validation Accuracy: 0.9640\n",
      "Epoch [125/250], Loss: 0.0089, Accuracy: 0.9964\n",
      "Validation Loss: 2.3047, Validation Accuracy: 0.7698\n",
      "Epoch [126/250], Loss: 0.0110, Accuracy: 0.9964\n",
      "Validation Loss: 1.3617, Validation Accuracy: 0.8417\n",
      "Epoch [127/250], Loss: 0.0061, Accuracy: 0.9964\n",
      "Validation Loss: 0.3598, Validation Accuracy: 0.9496\n",
      "Epoch [128/250], Loss: 0.0022, Accuracy: 1.0000\n",
      "Validation Loss: 0.2325, Validation Accuracy: 0.9640\n",
      "Epoch [129/250], Loss: 0.0048, Accuracy: 1.0000\n",
      "Validation Loss: 0.3359, Validation Accuracy: 0.9568\n",
      "Epoch [130/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.2569, Validation Accuracy: 0.9568\n",
      "Epoch [131/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.1201, Validation Accuracy: 0.9784\n",
      "Epoch [132/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.1215, Validation Accuracy: 0.9856\n",
      "Epoch [133/250], Loss: 0.0077, Accuracy: 0.9964\n",
      "Validation Loss: 0.2483, Validation Accuracy: 0.9568\n",
      "Epoch [134/250], Loss: 0.0101, Accuracy: 0.9928\n",
      "Validation Loss: 0.1535, Validation Accuracy: 0.9640\n",
      "Epoch [135/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.3337, Validation Accuracy: 0.9568\n",
      "Epoch [136/250], Loss: 0.0041, Accuracy: 1.0000\n",
      "Validation Loss: 0.3356, Validation Accuracy: 0.9568\n",
      "Epoch [137/250], Loss: 0.0040, Accuracy: 0.9964\n",
      "Validation Loss: 0.2115, Validation Accuracy: 0.9640\n",
      "Epoch [138/250], Loss: 0.0079, Accuracy: 0.9964\n",
      "Validation Loss: 0.9028, Validation Accuracy: 0.9065\n",
      "Epoch [139/250], Loss: 0.0138, Accuracy: 0.9928\n",
      "Validation Loss: 0.7182, Validation Accuracy: 0.9281\n",
      "Epoch [140/250], Loss: 0.0048, Accuracy: 0.9964\n",
      "Validation Loss: 2.0171, Validation Accuracy: 0.7914\n",
      "Epoch [141/250], Loss: 0.0063, Accuracy: 0.9964\n",
      "Validation Loss: 0.4646, Validation Accuracy: 0.9353\n",
      "Epoch [142/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.4008, Validation Accuracy: 0.9496\n",
      "Epoch [143/250], Loss: 0.0065, Accuracy: 0.9964\n",
      "Validation Loss: 0.4615, Validation Accuracy: 0.9496\n",
      "Epoch [144/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.5791, Validation Accuracy: 0.9424\n",
      "Epoch [145/250], Loss: 0.0302, Accuracy: 0.9928\n",
      "Validation Loss: 0.9452, Validation Accuracy: 0.9065\n",
      "Epoch [146/250], Loss: 0.0065, Accuracy: 0.9964\n",
      "Validation Loss: 1.6021, Validation Accuracy: 0.8345\n",
      "Epoch [147/250], Loss: 0.1309, Accuracy: 0.9783\n",
      "Validation Loss: 1.7454, Validation Accuracy: 0.8058\n",
      "Epoch [148/250], Loss: 0.0262, Accuracy: 0.9928\n",
      "Validation Loss: 1.0283, Validation Accuracy: 0.8489\n",
      "Epoch [149/250], Loss: 0.0142, Accuracy: 0.9928\n",
      "Validation Loss: 0.1044, Validation Accuracy: 0.9784\n",
      "Epoch [150/250], Loss: 0.0516, Accuracy: 0.9964\n",
      "Validation Loss: 0.8787, Validation Accuracy: 0.8921\n",
      "Epoch [151/250], Loss: 0.0050, Accuracy: 1.0000\n",
      "Validation Loss: 1.8518, Validation Accuracy: 0.7914\n",
      "Epoch [152/250], Loss: 0.0286, Accuracy: 0.9928\n",
      "Validation Loss: 3.4832, Validation Accuracy: 0.6619\n",
      "Epoch [153/250], Loss: 0.0075, Accuracy: 1.0000\n",
      "Validation Loss: 0.2104, Validation Accuracy: 0.9640\n",
      "Epoch [154/250], Loss: 0.0178, Accuracy: 0.9928\n",
      "Validation Loss: 0.1758, Validation Accuracy: 0.9640\n",
      "Epoch [155/250], Loss: 0.0083, Accuracy: 0.9964\n",
      "Validation Loss: 0.1935, Validation Accuracy: 0.9712\n",
      "Epoch [156/250], Loss: 0.0031, Accuracy: 1.0000\n",
      "Validation Loss: 0.2253, Validation Accuracy: 0.9712\n",
      "Epoch [157/250], Loss: 0.0020, Accuracy: 1.0000\n",
      "Validation Loss: 0.2236, Validation Accuracy: 0.9712\n",
      "Epoch [158/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.2130, Validation Accuracy: 0.9712\n",
      "Epoch [159/250], Loss: 0.0095, Accuracy: 0.9964\n",
      "Validation Loss: 0.5145, Validation Accuracy: 0.9209\n",
      "Epoch [160/250], Loss: 0.0772, Accuracy: 0.9856\n",
      "Validation Loss: 0.3083, Validation Accuracy: 0.9568\n",
      "Epoch [161/250], Loss: 0.0859, Accuracy: 0.9711\n",
      "Validation Loss: 8.0756, Validation Accuracy: 0.4101\n",
      "Epoch [162/250], Loss: 0.0241, Accuracy: 0.9928\n",
      "Validation Loss: 8.1863, Validation Accuracy: 0.4101\n",
      "Epoch [163/250], Loss: 0.0493, Accuracy: 0.9892\n",
      "Validation Loss: 1.3118, Validation Accuracy: 0.8561\n",
      "Epoch [164/250], Loss: 0.0516, Accuracy: 0.9856\n",
      "Validation Loss: 1.5406, Validation Accuracy: 0.8058\n",
      "Epoch [165/250], Loss: 0.0167, Accuracy: 0.9928\n",
      "Validation Loss: 6.2582, Validation Accuracy: 0.4532\n",
      "Epoch [166/250], Loss: 0.0228, Accuracy: 0.9892\n",
      "Validation Loss: 0.8697, Validation Accuracy: 0.8849\n",
      "Epoch [167/250], Loss: 0.0040, Accuracy: 1.0000\n",
      "Validation Loss: 0.3032, Validation Accuracy: 0.9568\n",
      "Epoch [168/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.0801, Validation Accuracy: 0.9928\n",
      "Epoch [169/250], Loss: 0.0158, Accuracy: 0.9964\n",
      "Validation Loss: 0.6018, Validation Accuracy: 0.9353\n",
      "Epoch [170/250], Loss: 0.0236, Accuracy: 0.9928\n",
      "Validation Loss: 0.0996, Validation Accuracy: 0.9856\n",
      "Epoch [171/250], Loss: 0.0239, Accuracy: 0.9928\n",
      "Validation Loss: 0.1617, Validation Accuracy: 0.9640\n",
      "Epoch [172/250], Loss: 0.0102, Accuracy: 1.0000\n",
      "Validation Loss: 0.7060, Validation Accuracy: 0.8849\n",
      "Epoch [173/250], Loss: 0.0066, Accuracy: 1.0000\n",
      "Validation Loss: 0.7554, Validation Accuracy: 0.8921\n",
      "Epoch [174/250], Loss: 0.0089, Accuracy: 0.9964\n",
      "Validation Loss: 0.3156, Validation Accuracy: 0.9568\n",
      "Epoch [175/250], Loss: 0.0071, Accuracy: 1.0000\n",
      "Validation Loss: 0.1544, Validation Accuracy: 0.9712\n",
      "Epoch [176/250], Loss: 0.0207, Accuracy: 0.9964\n",
      "Validation Loss: 0.2670, Validation Accuracy: 0.9568\n",
      "Epoch [177/250], Loss: 0.0053, Accuracy: 1.0000\n",
      "Validation Loss: 0.1535, Validation Accuracy: 0.9784\n",
      "Epoch [178/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.1633, Validation Accuracy: 0.9712\n",
      "Epoch [179/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.1857, Validation Accuracy: 0.9784\n",
      "Epoch [180/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.1611, Validation Accuracy: 0.9784\n",
      "Epoch [181/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.1356, Validation Accuracy: 0.9784\n",
      "Epoch [182/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.1369, Validation Accuracy: 0.9784\n",
      "Epoch [183/250], Loss: 0.0060, Accuracy: 1.0000\n",
      "Validation Loss: 0.6615, Validation Accuracy: 0.9424\n",
      "Epoch [184/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.1423, Validation Accuracy: 0.9712\n",
      "Epoch [185/250], Loss: 0.0054, Accuracy: 0.9964\n",
      "Validation Loss: 0.1382, Validation Accuracy: 0.9856\n",
      "Epoch [186/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.5483, Validation Accuracy: 0.9281\n",
      "Epoch [187/250], Loss: 0.0037, Accuracy: 1.0000\n",
      "Validation Loss: 0.0854, Validation Accuracy: 0.9928\n",
      "Epoch [188/250], Loss: 0.1742, Accuracy: 0.9603\n",
      "Validation Loss: 0.4112, Validation Accuracy: 0.9353\n",
      "Epoch [189/250], Loss: 0.0924, Accuracy: 0.9747\n",
      "Validation Loss: 3.3734, Validation Accuracy: 0.6187\n",
      "Epoch [190/250], Loss: 0.0436, Accuracy: 0.9819\n",
      "Validation Loss: 0.1823, Validation Accuracy: 0.9496\n",
      "Epoch [191/250], Loss: 0.0110, Accuracy: 1.0000\n",
      "Validation Loss: 1.1027, Validation Accuracy: 0.8273\n",
      "Epoch [192/250], Loss: 0.0046, Accuracy: 1.0000\n",
      "Validation Loss: 0.2592, Validation Accuracy: 0.9496\n",
      "Epoch [193/250], Loss: 0.0614, Accuracy: 0.9856\n",
      "Validation Loss: 0.9876, Validation Accuracy: 0.8417\n",
      "Epoch [194/250], Loss: 0.0382, Accuracy: 0.9856\n",
      "Validation Loss: 0.3048, Validation Accuracy: 0.9496\n",
      "Epoch [195/250], Loss: 0.0156, Accuracy: 0.9964\n",
      "Validation Loss: 0.2723, Validation Accuracy: 0.9496\n",
      "Epoch [196/250], Loss: 0.0095, Accuracy: 0.9964\n",
      "Validation Loss: 0.3284, Validation Accuracy: 0.9496\n",
      "Epoch [197/250], Loss: 0.0029, Accuracy: 1.0000\n",
      "Validation Loss: 0.3287, Validation Accuracy: 0.9568\n",
      "Epoch [198/250], Loss: 0.0240, Accuracy: 0.9928\n",
      "Validation Loss: 0.1187, Validation Accuracy: 0.9712\n",
      "Epoch [199/250], Loss: 0.0059, Accuracy: 0.9964\n",
      "Validation Loss: 2.8948, Validation Accuracy: 0.7122\n",
      "Epoch [200/250], Loss: 0.0443, Accuracy: 0.9819\n",
      "Validation Loss: 0.2732, Validation Accuracy: 0.9568\n",
      "Epoch [201/250], Loss: 0.0200, Accuracy: 0.9964\n",
      "Validation Loss: 0.8142, Validation Accuracy: 0.8705\n",
      "Epoch [202/250], Loss: 0.0146, Accuracy: 0.9964\n",
      "Validation Loss: 0.1297, Validation Accuracy: 0.9784\n",
      "Epoch [203/250], Loss: 0.0287, Accuracy: 0.9928\n",
      "Validation Loss: 1.7578, Validation Accuracy: 0.7986\n",
      "Epoch [204/250], Loss: 0.0150, Accuracy: 0.9964\n",
      "Validation Loss: 0.5972, Validation Accuracy: 0.9209\n",
      "Epoch [205/250], Loss: 0.0091, Accuracy: 0.9964\n",
      "Validation Loss: 0.3355, Validation Accuracy: 0.9496\n",
      "Epoch [206/250], Loss: 0.0267, Accuracy: 0.9928\n",
      "Validation Loss: 6.6710, Validation Accuracy: 0.4173\n",
      "Epoch [207/250], Loss: 0.0041, Accuracy: 1.0000\n",
      "Validation Loss: 1.8685, Validation Accuracy: 0.8058\n",
      "Epoch [208/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.6200, Validation Accuracy: 0.9209\n",
      "Epoch [209/250], Loss: 0.0064, Accuracy: 0.9964\n",
      "Validation Loss: 0.2799, Validation Accuracy: 0.9640\n",
      "Epoch [210/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.3167, Validation Accuracy: 0.9568\n",
      "Epoch [211/250], Loss: 0.0710, Accuracy: 0.9856\n",
      "Validation Loss: 3.6684, Validation Accuracy: 0.5108\n",
      "Epoch [212/250], Loss: 0.0052, Accuracy: 1.0000\n",
      "Validation Loss: 0.5218, Validation Accuracy: 0.8849\n",
      "Epoch [213/250], Loss: 0.0152, Accuracy: 0.9928\n",
      "Validation Loss: 0.2505, Validation Accuracy: 0.9424\n",
      "Epoch [214/250], Loss: 0.0105, Accuracy: 1.0000\n",
      "Validation Loss: 5.8322, Validation Accuracy: 0.4173\n",
      "Epoch [215/250], Loss: 0.0230, Accuracy: 0.9928\n",
      "Validation Loss: 1.1839, Validation Accuracy: 0.8705\n",
      "Epoch [216/250], Loss: 0.0178, Accuracy: 0.9928\n",
      "Validation Loss: 0.3133, Validation Accuracy: 0.9424\n",
      "Epoch [217/250], Loss: 0.0190, Accuracy: 0.9964\n",
      "Validation Loss: 0.8134, Validation Accuracy: 0.8849\n",
      "Epoch [218/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.3471, Validation Accuracy: 0.9568\n",
      "Epoch [219/250], Loss: 0.0043, Accuracy: 1.0000\n",
      "Validation Loss: 0.3374, Validation Accuracy: 0.9568\n",
      "Epoch [220/250], Loss: 0.0277, Accuracy: 0.9964\n",
      "Validation Loss: 0.9308, Validation Accuracy: 0.8777\n",
      "Epoch [221/250], Loss: 0.0030, Accuracy: 1.0000\n",
      "Validation Loss: 2.5186, Validation Accuracy: 0.6763\n",
      "Epoch [222/250], Loss: 0.0115, Accuracy: 1.0000\n",
      "Validation Loss: 0.2478, Validation Accuracy: 0.9496\n",
      "Epoch [223/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.1862, Validation Accuracy: 0.9712\n",
      "Epoch [224/250], Loss: 0.0026, Accuracy: 1.0000\n",
      "Validation Loss: 0.3044, Validation Accuracy: 0.9568\n",
      "Epoch [225/250], Loss: 0.0548, Accuracy: 0.9964\n",
      "Validation Loss: 0.5297, Validation Accuracy: 0.9209\n",
      "Epoch [226/250], Loss: 0.1437, Accuracy: 0.9783\n",
      "Validation Loss: 3.6994, Validation Accuracy: 0.5683\n",
      "Epoch [227/250], Loss: 0.0404, Accuracy: 0.9819\n",
      "Validation Loss: 0.9081, Validation Accuracy: 0.8345\n",
      "Epoch [228/250], Loss: 0.0128, Accuracy: 0.9964\n",
      "Validation Loss: 0.2231, Validation Accuracy: 0.9568\n",
      "Epoch [229/250], Loss: 0.0210, Accuracy: 0.9964\n",
      "Validation Loss: 0.1839, Validation Accuracy: 0.9568\n",
      "Epoch [230/250], Loss: 0.0094, Accuracy: 0.9964\n",
      "Validation Loss: 0.1476, Validation Accuracy: 0.9568\n",
      "Epoch [231/250], Loss: 0.0165, Accuracy: 0.9928\n",
      "Validation Loss: 0.1999, Validation Accuracy: 0.9568\n",
      "Epoch [232/250], Loss: 0.0035, Accuracy: 1.0000\n",
      "Validation Loss: 0.1588, Validation Accuracy: 0.9640\n",
      "Epoch [233/250], Loss: 0.0020, Accuracy: 1.0000\n",
      "Validation Loss: 0.1135, Validation Accuracy: 0.9640\n",
      "Epoch [234/250], Loss: 0.0054, Accuracy: 0.9964\n",
      "Validation Loss: 0.2287, Validation Accuracy: 0.9640\n",
      "Epoch [235/250], Loss: 0.0161, Accuracy: 0.9964\n",
      "Validation Loss: 0.2793, Validation Accuracy: 0.9568\n",
      "Epoch [236/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.1194, Validation Accuracy: 0.9640\n",
      "Epoch [237/250], Loss: 0.0075, Accuracy: 1.0000\n",
      "Validation Loss: 0.3207, Validation Accuracy: 0.9568\n",
      "Epoch [238/250], Loss: 0.0078, Accuracy: 0.9964\n",
      "Validation Loss: 0.0775, Validation Accuracy: 0.9928\n",
      "Epoch [239/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.1467, Validation Accuracy: 0.9640\n",
      "Epoch [240/250], Loss: 0.0307, Accuracy: 0.9928\n",
      "Validation Loss: 1.2281, Validation Accuracy: 0.8345\n",
      "Epoch [241/250], Loss: 0.0048, Accuracy: 1.0000\n",
      "Validation Loss: 0.3718, Validation Accuracy: 0.9496\n",
      "Epoch [242/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.2046, Validation Accuracy: 0.9640\n",
      "Epoch [243/250], Loss: 0.0189, Accuracy: 0.9928\n",
      "Validation Loss: 2.0857, Validation Accuracy: 0.7842\n",
      "Epoch [244/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 3.0397, Validation Accuracy: 0.6978\n",
      "Epoch [245/250], Loss: 0.0134, Accuracy: 0.9964\n",
      "Validation Loss: 0.1959, Validation Accuracy: 0.9640\n",
      "Epoch [246/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.2272, Validation Accuracy: 0.9568\n",
      "Epoch [247/250], Loss: 0.0024, Accuracy: 1.0000\n",
      "Validation Loss: 0.1403, Validation Accuracy: 0.9712\n",
      "Epoch [248/250], Loss: 0.0034, Accuracy: 0.9964\n",
      "Validation Loss: 2.2274, Validation Accuracy: 0.7698\n",
      "Epoch [249/250], Loss: 0.0191, Accuracy: 0.9928\n",
      "Validation Loss: 0.3821, Validation Accuracy: 0.9568\n",
      "Epoch [250/250], Loss: 0.0156, Accuracy: 0.9928\n",
      "Validation Loss: 0.2761, Validation Accuracy: 0.9568\n",
      "Test Loss: 0.1942\n",
      "Test Accuracy: 0.9424\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 173\n",
      "label 1 is 202\n",
      "label 2 is 24\n",
      "label 3 is 22\n",
      "Not setting metadata\n",
      "421 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (324, 8, 325)\n",
      "324 train samples\n",
      "162 test samples\n",
      "Number of batches in train_loader: 6\n",
      "{-1: 1.4232456140350878, 0: 0.7707838479809976}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.2077, Accuracy: 0.4846\n",
      "Validation Loss: 0.9199, Validation Accuracy: 0.5951\n",
      "Epoch [2/250], Loss: 0.8921, Accuracy: 0.6605\n",
      "Validation Loss: 0.7961, Validation Accuracy: 0.5951\n",
      "Epoch [3/250], Loss: 0.8694, Accuracy: 0.6790\n",
      "Validation Loss: 0.7383, Validation Accuracy: 0.5951\n",
      "Epoch [4/250], Loss: 0.7273, Accuracy: 0.6728\n",
      "Validation Loss: 0.7349, Validation Accuracy: 0.5951\n",
      "Epoch [5/250], Loss: 0.6621, Accuracy: 0.7006\n",
      "Validation Loss: 0.8277, Validation Accuracy: 0.4049\n",
      "Epoch [6/250], Loss: 0.5741, Accuracy: 0.7346\n",
      "Validation Loss: 0.9283, Validation Accuracy: 0.4049\n",
      "Epoch [7/250], Loss: 0.4528, Accuracy: 0.8086\n",
      "Validation Loss: 2.5436, Validation Accuracy: 0.4049\n",
      "Epoch [8/250], Loss: 0.3527, Accuracy: 0.9167\n",
      "Validation Loss: 3.6465, Validation Accuracy: 0.4049\n",
      "Epoch [9/250], Loss: 0.1843, Accuracy: 0.9475\n",
      "Validation Loss: 3.9894, Validation Accuracy: 0.4049\n",
      "Epoch [10/250], Loss: 0.1047, Accuracy: 0.9784\n",
      "Validation Loss: 4.6986, Validation Accuracy: 0.4049\n",
      "Epoch [11/250], Loss: 0.0764, Accuracy: 0.9846\n",
      "Validation Loss: 0.2194, Validation Accuracy: 0.9325\n",
      "Epoch [12/250], Loss: 0.0995, Accuracy: 0.9722\n",
      "Validation Loss: 3.3451, Validation Accuracy: 0.5092\n",
      "Epoch [13/250], Loss: 0.0642, Accuracy: 0.9815\n",
      "Validation Loss: 3.3770, Validation Accuracy: 0.5337\n",
      "Epoch [14/250], Loss: 0.0439, Accuracy: 0.9907\n",
      "Validation Loss: 0.6485, Validation Accuracy: 0.8650\n",
      "Epoch [15/250], Loss: 0.0839, Accuracy: 0.9784\n",
      "Validation Loss: 0.0447, Validation Accuracy: 0.9877\n",
      "Epoch [16/250], Loss: 0.0407, Accuracy: 0.9907\n",
      "Validation Loss: 0.0016, Validation Accuracy: 1.0000\n",
      "Epoch [17/250], Loss: 0.0452, Accuracy: 1.0000\n",
      "Validation Loss: 0.1293, Validation Accuracy: 0.9509\n",
      "Epoch [18/250], Loss: 0.1042, Accuracy: 0.9753\n",
      "Validation Loss: 4.0091, Validation Accuracy: 0.5951\n",
      "Epoch [19/250], Loss: 0.1636, Accuracy: 0.9660\n",
      "Validation Loss: 1.1980, Validation Accuracy: 0.8405\n",
      "Epoch [20/250], Loss: 0.1869, Accuracy: 0.9475\n",
      "Validation Loss: 0.0190, Validation Accuracy: 0.9939\n",
      "Epoch [21/250], Loss: 0.3665, Accuracy: 0.9877\n",
      "Validation Loss: 0.0027, Validation Accuracy: 1.0000\n",
      "Epoch [22/250], Loss: 0.0545, Accuracy: 0.9877\n",
      "Validation Loss: 0.0027, Validation Accuracy: 1.0000\n",
      "Epoch [23/250], Loss: 0.0398, Accuracy: 0.9938\n",
      "Validation Loss: 0.0013, Validation Accuracy: 1.0000\n",
      "Epoch [24/250], Loss: 0.0226, Accuracy: 0.9938\n",
      "Validation Loss: 0.0009, Validation Accuracy: 1.0000\n",
      "Epoch [25/250], Loss: 0.0212, Accuracy: 0.9969\n",
      "Validation Loss: 0.0007, Validation Accuracy: 1.0000\n",
      "Epoch [26/250], Loss: 0.0208, Accuracy: 0.9907\n",
      "Validation Loss: 0.0006, Validation Accuracy: 1.0000\n",
      "Epoch [27/250], Loss: 0.0385, Accuracy: 0.9938\n",
      "Validation Loss: 0.0215, Validation Accuracy: 0.9939\n",
      "Epoch [28/250], Loss: 0.0321, Accuracy: 0.9938\n",
      "Validation Loss: 0.2360, Validation Accuracy: 0.9448\n",
      "Epoch [29/250], Loss: 0.0736, Accuracy: 0.9691\n",
      "Validation Loss: 0.0007, Validation Accuracy: 1.0000\n",
      "Epoch [30/250], Loss: 0.0084, Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [31/250], Loss: 0.0199, Accuracy: 0.9938\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [32/250], Loss: 0.0090, Accuracy: 0.9969\n",
      "Validation Loss: 0.0172, Validation Accuracy: 0.9939\n",
      "Epoch [33/250], Loss: 0.0127, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [34/250], Loss: 0.0796, Accuracy: 0.9938\n",
      "Validation Loss: 0.4126, Validation Accuracy: 0.9264\n",
      "Epoch [35/250], Loss: 0.1730, Accuracy: 0.9691\n",
      "Validation Loss: 0.7036, Validation Accuracy: 0.8282\n",
      "Epoch [36/250], Loss: 0.1348, Accuracy: 0.9444\n",
      "Validation Loss: 0.0020, Validation Accuracy: 1.0000\n",
      "Epoch [37/250], Loss: 0.5417, Accuracy: 0.9815\n",
      "Validation Loss: 0.7500, Validation Accuracy: 0.8650\n",
      "Epoch [38/250], Loss: 0.4166, Accuracy: 0.8642\n",
      "Validation Loss: 0.0182, Validation Accuracy: 1.0000\n",
      "Epoch [39/250], Loss: 0.0711, Accuracy: 0.9938\n",
      "Validation Loss: 0.0056, Validation Accuracy: 1.0000\n",
      "Epoch [40/250], Loss: 0.0421, Accuracy: 0.9969\n",
      "Validation Loss: 0.0029, Validation Accuracy: 1.0000\n",
      "Epoch [41/250], Loss: 0.0469, Accuracy: 0.9907\n",
      "Validation Loss: 0.0020, Validation Accuracy: 1.0000\n",
      "Epoch [42/250], Loss: 0.0305, Accuracy: 0.9938\n",
      "Validation Loss: 0.0013, Validation Accuracy: 1.0000\n",
      "Epoch [43/250], Loss: 0.0445, Accuracy: 0.9907\n",
      "Validation Loss: 0.0010, Validation Accuracy: 1.0000\n",
      "Epoch [44/250], Loss: 0.0205, Accuracy: 0.9969\n",
      "Validation Loss: 0.0008, Validation Accuracy: 1.0000\n",
      "Epoch [45/250], Loss: 0.3050, Accuracy: 0.9938\n",
      "Validation Loss: 0.2695, Validation Accuracy: 0.9448\n",
      "Epoch [46/250], Loss: 0.0870, Accuracy: 0.9784\n",
      "Validation Loss: 0.1536, Validation Accuracy: 0.9571\n",
      "Epoch [47/250], Loss: 0.0351, Accuracy: 1.0000\n",
      "Validation Loss: 0.0013, Validation Accuracy: 1.0000\n",
      "Epoch [48/250], Loss: 0.0256, Accuracy: 0.9907\n",
      "Validation Loss: 0.0005, Validation Accuracy: 1.0000\n",
      "Epoch [49/250], Loss: 0.0316, Accuracy: 0.9938\n",
      "Validation Loss: 0.0004, Validation Accuracy: 1.0000\n",
      "Epoch [50/250], Loss: 0.0576, Accuracy: 0.9969\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [51/250], Loss: 0.0179, Accuracy: 0.9969\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [52/250], Loss: 0.0118, Accuracy: 0.9969\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [53/250], Loss: 0.0260, Accuracy: 0.9969\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [54/250], Loss: 0.0086, Accuracy: 0.9969\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [55/250], Loss: 0.0065, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [56/250], Loss: 0.0095, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [57/250], Loss: 0.0386, Accuracy: 0.9969\n",
      "Validation Loss: 0.1246, Validation Accuracy: 0.9693\n",
      "Epoch [58/250], Loss: 0.0362, Accuracy: 0.9877\n",
      "Validation Loss: 0.1949, Validation Accuracy: 0.9693\n",
      "Epoch [59/250], Loss: 0.1849, Accuracy: 0.9846\n",
      "Validation Loss: 0.0040, Validation Accuracy: 0.9939\n",
      "Epoch [60/250], Loss: 0.0085, Accuracy: 1.0000\n",
      "Validation Loss: 0.0011, Validation Accuracy: 1.0000\n",
      "Epoch [61/250], Loss: 0.1112, Accuracy: 0.9907\n",
      "Validation Loss: 0.0005, Validation Accuracy: 1.0000\n",
      "Epoch [62/250], Loss: 0.0102, Accuracy: 0.9969\n",
      "Validation Loss: 0.0154, Validation Accuracy: 0.9939\n",
      "Epoch [63/250], Loss: 0.0234, Accuracy: 0.9907\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [64/250], Loss: 0.0061, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [65/250], Loss: 0.0334, Accuracy: 0.9938\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [66/250], Loss: 0.0108, Accuracy: 0.9969\n",
      "Validation Loss: 0.0176, Validation Accuracy: 0.9939\n",
      "Epoch [67/250], Loss: 0.0109, Accuracy: 0.9969\n",
      "Validation Loss: 0.0017, Validation Accuracy: 1.0000\n",
      "Epoch [68/250], Loss: 0.0098, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [69/250], Loss: 0.0085, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [70/250], Loss: 0.0042, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [71/250], Loss: 0.0098, Accuracy: 0.9969\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [72/250], Loss: 0.0148, Accuracy: 0.9969\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [73/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [74/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [75/250], Loss: 0.0083, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [76/250], Loss: 0.0030, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [77/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [78/250], Loss: 0.0067, Accuracy: 0.9969\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [79/250], Loss: 0.0051, Accuracy: 0.9969\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [80/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [81/250], Loss: 0.0131, Accuracy: 0.9938\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [82/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [83/250], Loss: 0.0200, Accuracy: 0.9969\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [84/250], Loss: 0.0044, Accuracy: 0.9969\n",
      "Validation Loss: 0.0005, Validation Accuracy: 1.0000\n",
      "Epoch [85/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [86/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [87/250], Loss: 0.0065, Accuracy: 0.9969\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [88/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [89/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [90/250], Loss: 0.0045, Accuracy: 0.9969\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [91/250], Loss: 0.0026, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [92/250], Loss: 0.0250, Accuracy: 0.9938\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [93/250], Loss: 1.4102, Accuracy: 0.9877\n",
      "Validation Loss: 4.0728, Validation Accuracy: 0.5767\n",
      "Epoch [94/250], Loss: 0.3678, Accuracy: 0.8981\n",
      "Validation Loss: 0.1505, Validation Accuracy: 0.9264\n",
      "Epoch [95/250], Loss: 0.1550, Accuracy: 0.9352\n",
      "Validation Loss: 0.1238, Validation Accuracy: 0.9693\n",
      "Epoch [96/250], Loss: 0.0735, Accuracy: 0.9691\n",
      "Validation Loss: 0.2557, Validation Accuracy: 0.9509\n",
      "Epoch [97/250], Loss: 0.0554, Accuracy: 0.9877\n",
      "Validation Loss: 0.0284, Validation Accuracy: 0.9877\n",
      "Epoch [98/250], Loss: 0.0279, Accuracy: 0.9969\n",
      "Validation Loss: 0.0102, Validation Accuracy: 0.9939\n",
      "Epoch [99/250], Loss: 0.0219, Accuracy: 0.9969\n",
      "Validation Loss: 0.0029, Validation Accuracy: 1.0000\n",
      "Epoch [100/250], Loss: 0.8382, Accuracy: 0.9877\n",
      "Validation Loss: 0.0588, Validation Accuracy: 0.9877\n",
      "Epoch [101/250], Loss: 0.0825, Accuracy: 0.9846\n",
      "Validation Loss: 0.0666, Validation Accuracy: 0.9877\n",
      "Epoch [102/250], Loss: 0.0427, Accuracy: 0.9938\n",
      "Validation Loss: 0.0078, Validation Accuracy: 1.0000\n",
      "Epoch [103/250], Loss: 0.0384, Accuracy: 0.9969\n",
      "Validation Loss: 0.0037, Validation Accuracy: 1.0000\n",
      "Epoch [104/250], Loss: 0.0289, Accuracy: 0.9969\n",
      "Validation Loss: 0.0017, Validation Accuracy: 1.0000\n",
      "Epoch [105/250], Loss: 0.1028, Accuracy: 0.9969\n",
      "Validation Loss: 0.0022, Validation Accuracy: 1.0000\n",
      "Epoch [106/250], Loss: 0.0518, Accuracy: 0.9907\n",
      "Validation Loss: 0.0267, Validation Accuracy: 0.9877\n",
      "Epoch [107/250], Loss: 0.0378, Accuracy: 0.9938\n",
      "Validation Loss: 0.0007, Validation Accuracy: 1.0000\n",
      "Epoch [108/250], Loss: 0.0283, Accuracy: 0.9938\n",
      "Validation Loss: 0.0005, Validation Accuracy: 1.0000\n",
      "Epoch [109/250], Loss: 0.0220, Accuracy: 0.9969\n",
      "Validation Loss: 0.0193, Validation Accuracy: 0.9939\n",
      "Epoch [110/250], Loss: 0.0243, Accuracy: 0.9938\n",
      "Validation Loss: 0.0117, Validation Accuracy: 0.9939\n",
      "Epoch [111/250], Loss: 0.0268, Accuracy: 0.9877\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [112/250], Loss: 0.0093, Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [113/250], Loss: 0.0066, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [114/250], Loss: 0.0133, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [115/250], Loss: 0.0058, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [116/250], Loss: 0.0080, Accuracy: 0.9969\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [117/250], Loss: 0.0053, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [118/250], Loss: 0.0044, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [119/250], Loss: 0.0249, Accuracy: 0.9969\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [120/250], Loss: 0.0065, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [121/250], Loss: 1.1186, Accuracy: 0.9877\n",
      "Validation Loss: 0.0163, Validation Accuracy: 0.9939\n",
      "Epoch [122/250], Loss: 0.1430, Accuracy: 0.9784\n",
      "Validation Loss: 0.0853, Validation Accuracy: 0.9632\n",
      "Epoch [123/250], Loss: 0.0385, Accuracy: 0.9969\n",
      "Validation Loss: 0.2341, Validation Accuracy: 0.9080\n",
      "Epoch [124/250], Loss: 0.3323, Accuracy: 0.9938\n",
      "Validation Loss: 0.0554, Validation Accuracy: 0.9939\n",
      "Epoch [125/250], Loss: 0.1125, Accuracy: 0.9815\n",
      "Validation Loss: 0.0194, Validation Accuracy: 0.9939\n",
      "Epoch [126/250], Loss: 0.3269, Accuracy: 0.9877\n",
      "Validation Loss: 0.0136, Validation Accuracy: 0.9939\n",
      "Epoch [127/250], Loss: 0.0729, Accuracy: 0.9877\n",
      "Validation Loss: 0.0271, Validation Accuracy: 0.9877\n",
      "Epoch [128/250], Loss: 0.0514, Accuracy: 1.0000\n",
      "Validation Loss: 0.0059, Validation Accuracy: 1.0000\n",
      "Epoch [129/250], Loss: 0.0318, Accuracy: 0.9969\n",
      "Validation Loss: 0.0037, Validation Accuracy: 1.0000\n",
      "Epoch [130/250], Loss: 0.0250, Accuracy: 1.0000\n",
      "Validation Loss: 0.0025, Validation Accuracy: 1.0000\n",
      "Epoch [131/250], Loss: 0.0173, Accuracy: 1.0000\n",
      "Validation Loss: 0.0017, Validation Accuracy: 1.0000\n",
      "Epoch [132/250], Loss: 0.6198, Accuracy: 0.9877\n",
      "Validation Loss: 0.0049, Validation Accuracy: 1.0000\n",
      "Epoch [133/250], Loss: 0.0700, Accuracy: 0.9907\n",
      "Validation Loss: 0.0733, Validation Accuracy: 0.9632\n",
      "Epoch [134/250], Loss: 0.1265, Accuracy: 0.9938\n",
      "Validation Loss: 0.0687, Validation Accuracy: 0.9632\n",
      "Epoch [135/250], Loss: 0.0234, Accuracy: 1.0000\n",
      "Validation Loss: 0.0065, Validation Accuracy: 0.9939\n",
      "Epoch [136/250], Loss: 0.0218, Accuracy: 1.0000\n",
      "Validation Loss: 0.0016, Validation Accuracy: 1.0000\n",
      "Epoch [137/250], Loss: 0.0174, Accuracy: 0.9969\n",
      "Validation Loss: 0.0011, Validation Accuracy: 1.0000\n",
      "Epoch [138/250], Loss: 0.0167, Accuracy: 1.0000\n",
      "Validation Loss: 0.0008, Validation Accuracy: 1.0000\n",
      "Epoch [139/250], Loss: 0.0427, Accuracy: 1.0000\n",
      "Validation Loss: 0.0017, Validation Accuracy: 1.0000\n",
      "Epoch [140/250], Loss: 0.2768, Accuracy: 0.9938\n",
      "Validation Loss: 0.0009, Validation Accuracy: 1.0000\n",
      "Epoch [141/250], Loss: 0.0206, Accuracy: 0.9969\n",
      "Validation Loss: 0.0010, Validation Accuracy: 1.0000\n",
      "Epoch [142/250], Loss: 0.0348, Accuracy: 0.9907\n",
      "Validation Loss: 0.0012, Validation Accuracy: 1.0000\n",
      "Epoch [143/250], Loss: 0.0134, Accuracy: 0.9969\n",
      "Validation Loss: 0.0010, Validation Accuracy: 1.0000\n",
      "Epoch [144/250], Loss: 0.0153, Accuracy: 0.9969\n",
      "Validation Loss: 0.0011, Validation Accuracy: 1.0000\n",
      "Epoch [145/250], Loss: 0.0063, Accuracy: 1.0000\n",
      "Validation Loss: 0.0004, Validation Accuracy: 1.0000\n",
      "Epoch [146/250], Loss: 0.0121, Accuracy: 0.9969\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [147/250], Loss: 0.0073, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [148/250], Loss: 0.0082, Accuracy: 0.9969\n",
      "Validation Loss: 0.0004, Validation Accuracy: 1.0000\n",
      "Epoch [149/250], Loss: 0.0052, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [150/250], Loss: 0.0057, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [151/250], Loss: 0.0847, Accuracy: 0.9969\n",
      "Validation Loss: 0.0100, Validation Accuracy: 0.9939\n",
      "Epoch [152/250], Loss: 0.0433, Accuracy: 0.9938\n",
      "Validation Loss: 0.1255, Validation Accuracy: 0.9509\n",
      "Epoch [153/250], Loss: 0.0163, Accuracy: 0.9938\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [154/250], Loss: 0.0983, Accuracy: 0.9969\n",
      "Validation Loss: 2.9771, Validation Accuracy: 0.5951\n",
      "Epoch [155/250], Loss: 0.0469, Accuracy: 0.9815\n",
      "Validation Loss: 3.1225, Validation Accuracy: 0.5951\n",
      "Epoch [156/250], Loss: 0.0340, Accuracy: 0.9877\n",
      "Validation Loss: 0.6681, Validation Accuracy: 0.8098\n",
      "Epoch [157/250], Loss: 0.0228, Accuracy: 0.9969\n",
      "Validation Loss: 0.0773, Validation Accuracy: 0.9755\n",
      "Epoch [158/250], Loss: 0.0221, Accuracy: 0.9938\n",
      "Validation Loss: 0.0138, Validation Accuracy: 0.9939\n",
      "Epoch [159/250], Loss: 0.0144, Accuracy: 0.9938\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [160/250], Loss: 0.0145, Accuracy: 0.9969\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [161/250], Loss: 0.0094, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [162/250], Loss: 0.0155, Accuracy: 0.9938\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [163/250], Loss: 0.0040, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [164/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [165/250], Loss: 0.0302, Accuracy: 0.9938\n",
      "Validation Loss: 0.0138, Validation Accuracy: 0.9877\n",
      "Epoch [166/250], Loss: 0.0159, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [167/250], Loss: 0.0083, Accuracy: 0.9969\n",
      "Validation Loss: 0.0079, Validation Accuracy: 0.9939\n",
      "Epoch [168/250], Loss: 0.0072, Accuracy: 1.0000\n",
      "Validation Loss: 0.0200, Validation Accuracy: 0.9877\n",
      "Epoch [169/250], Loss: 0.0054, Accuracy: 0.9969\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [170/250], Loss: 0.0080, Accuracy: 0.9969\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [171/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [172/250], Loss: 0.0075, Accuracy: 0.9969\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [173/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [174/250], Loss: 0.1607, Accuracy: 0.9969\n",
      "Validation Loss: 0.6547, Validation Accuracy: 0.9325\n",
      "Epoch [175/250], Loss: 0.0883, Accuracy: 0.9815\n",
      "Validation Loss: 0.0041, Validation Accuracy: 0.9939\n",
      "Epoch [176/250], Loss: 0.0076, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [177/250], Loss: 0.0222, Accuracy: 0.9969\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [178/250], Loss: 0.0079, Accuracy: 1.0000\n",
      "Validation Loss: 0.0024, Validation Accuracy: 1.0000\n",
      "Epoch [179/250], Loss: 0.0049, Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [180/250], Loss: 0.0064, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [181/250], Loss: 0.0052, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [182/250], Loss: 0.0143, Accuracy: 0.9938\n",
      "Validation Loss: 0.0345, Validation Accuracy: 0.9877\n",
      "Epoch [183/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.0012, Validation Accuracy: 1.0000\n",
      "Epoch [184/250], Loss: 0.0045, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [185/250], Loss: 0.0033, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [186/250], Loss: 0.0050, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [187/250], Loss: 0.1315, Accuracy: 0.9938\n",
      "Validation Loss: 0.2148, Validation Accuracy: 0.9448\n",
      "Epoch [188/250], Loss: 0.0236, Accuracy: 0.9907\n",
      "Validation Loss: 0.1187, Validation Accuracy: 0.9693\n",
      "Epoch [189/250], Loss: 0.0526, Accuracy: 0.9815\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [190/250], Loss: 0.0226, Accuracy: 0.9938\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [191/250], Loss: 0.0636, Accuracy: 0.9938\n",
      "Validation Loss: 3.9321, Validation Accuracy: 0.6196\n",
      "Epoch [192/250], Loss: 0.0826, Accuracy: 0.9846\n",
      "Validation Loss: 4.5782, Validation Accuracy: 0.5951\n",
      "Epoch [193/250], Loss: 0.0396, Accuracy: 0.9877\n",
      "Validation Loss: 4.7901, Validation Accuracy: 0.5951\n",
      "Epoch [194/250], Loss: 0.0941, Accuracy: 0.9938\n",
      "Validation Loss: 2.7204, Validation Accuracy: 0.6196\n",
      "Epoch [195/250], Loss: 0.3020, Accuracy: 0.8981\n",
      "Validation Loss: 2.2024, Validation Accuracy: 0.6074\n",
      "Epoch [196/250], Loss: 0.1646, Accuracy: 0.9691\n",
      "Validation Loss: 0.1703, Validation Accuracy: 0.9141\n",
      "Epoch [197/250], Loss: 0.0262, Accuracy: 0.9907\n",
      "Validation Loss: 0.0381, Validation Accuracy: 0.9755\n",
      "Epoch [198/250], Loss: 0.0282, Accuracy: 0.9877\n",
      "Validation Loss: 0.0933, Validation Accuracy: 0.9632\n",
      "Epoch [199/250], Loss: 0.0191, Accuracy: 1.0000\n",
      "Validation Loss: 0.0939, Validation Accuracy: 0.9755\n",
      "Epoch [200/250], Loss: 0.0061, Accuracy: 1.0000\n",
      "Validation Loss: 0.0437, Validation Accuracy: 0.9816\n",
      "Epoch [201/250], Loss: 0.0105, Accuracy: 0.9969\n",
      "Validation Loss: 0.0142, Validation Accuracy: 0.9939\n",
      "Epoch [202/250], Loss: 0.0065, Accuracy: 1.0000\n",
      "Validation Loss: 0.0019, Validation Accuracy: 1.0000\n",
      "Epoch [203/250], Loss: 0.0106, Accuracy: 0.9969\n",
      "Validation Loss: 0.0038, Validation Accuracy: 1.0000\n",
      "Epoch [204/250], Loss: 0.0061, Accuracy: 1.0000\n",
      "Validation Loss: 0.0020, Validation Accuracy: 1.0000\n",
      "Epoch [205/250], Loss: 0.9291, Accuracy: 0.9877\n",
      "Validation Loss: 0.0148, Validation Accuracy: 1.0000\n",
      "Epoch [206/250], Loss: 0.1337, Accuracy: 0.9815\n",
      "Validation Loss: 0.0344, Validation Accuracy: 1.0000\n",
      "Epoch [207/250], Loss: 0.1679, Accuracy: 0.9938\n",
      "Validation Loss: 0.0162, Validation Accuracy: 1.0000\n",
      "Epoch [208/250], Loss: 0.0890, Accuracy: 0.9907\n",
      "Validation Loss: 0.0228, Validation Accuracy: 0.9877\n",
      "Epoch [209/250], Loss: 0.0338, Accuracy: 0.9938\n",
      "Validation Loss: 0.0476, Validation Accuracy: 0.9693\n",
      "Epoch [210/250], Loss: 0.0236, Accuracy: 1.0000\n",
      "Validation Loss: 0.0179, Validation Accuracy: 0.9816\n",
      "Epoch [211/250], Loss: 0.0306, Accuracy: 1.0000\n",
      "Validation Loss: 0.0020, Validation Accuracy: 1.0000\n",
      "Epoch [212/250], Loss: 0.1296, Accuracy: 0.9877\n",
      "Validation Loss: 1.1749, Validation Accuracy: 0.8712\n",
      "Epoch [213/250], Loss: 0.0497, Accuracy: 0.9846\n",
      "Validation Loss: 1.2533, Validation Accuracy: 0.8650\n",
      "Epoch [214/250], Loss: 0.0213, Accuracy: 0.9907\n",
      "Validation Loss: 0.2008, Validation Accuracy: 0.9571\n",
      "Epoch [215/250], Loss: 0.0300, Accuracy: 0.9938\n",
      "Validation Loss: 0.0015, Validation Accuracy: 1.0000\n",
      "Epoch [216/250], Loss: 0.0099, Accuracy: 1.0000\n",
      "Validation Loss: 0.0006, Validation Accuracy: 1.0000\n",
      "Epoch [217/250], Loss: 0.0083, Accuracy: 1.0000\n",
      "Validation Loss: 0.0004, Validation Accuracy: 1.0000\n",
      "Epoch [218/250], Loss: 0.0071, Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [219/250], Loss: 0.3043, Accuracy: 0.9969\n",
      "Validation Loss: 0.0400, Validation Accuracy: 0.9939\n",
      "Epoch [220/250], Loss: 0.0715, Accuracy: 0.9846\n",
      "Validation Loss: 0.0443, Validation Accuracy: 0.9939\n",
      "Epoch [221/250], Loss: 0.0231, Accuracy: 0.9969\n",
      "Validation Loss: 0.0021, Validation Accuracy: 1.0000\n",
      "Epoch [222/250], Loss: 0.0303, Accuracy: 0.9938\n",
      "Validation Loss: 0.0008, Validation Accuracy: 1.0000\n",
      "Epoch [223/250], Loss: 0.0201, Accuracy: 0.9907\n",
      "Validation Loss: 0.0005, Validation Accuracy: 1.0000\n",
      "Epoch [224/250], Loss: 0.0136, Accuracy: 0.9969\n",
      "Validation Loss: 0.0005, Validation Accuracy: 1.0000\n",
      "Epoch [225/250], Loss: 0.0179, Accuracy: 1.0000\n",
      "Validation Loss: 0.0004, Validation Accuracy: 1.0000\n",
      "Epoch [226/250], Loss: 0.0120, Accuracy: 0.9969\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [227/250], Loss: 0.0072, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [228/250], Loss: 0.0138, Accuracy: 0.9969\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [229/250], Loss: 0.0081, Accuracy: 0.9969\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [230/250], Loss: 0.0043, Accuracy: 1.0000\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [231/250], Loss: 0.0163, Accuracy: 0.9969\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [232/250], Loss: 0.0033, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [233/250], Loss: 0.0041, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [234/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [235/250], Loss: 0.0033, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [236/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [237/250], Loss: 0.0040, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [238/250], Loss: 0.0045, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [239/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [240/250], Loss: 0.0050, Accuracy: 0.9969\n",
      "Validation Loss: 0.0015, Validation Accuracy: 1.0000\n",
      "Epoch [241/250], Loss: 0.0026, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [242/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [243/250], Loss: 0.4411, Accuracy: 0.9938\n",
      "Validation Loss: 0.0219, Validation Accuracy: 0.9939\n",
      "Epoch [244/250], Loss: 0.0198, Accuracy: 0.9938\n",
      "Validation Loss: 0.1633, Validation Accuracy: 0.9755\n",
      "Epoch [245/250], Loss: 0.0571, Accuracy: 0.9846\n",
      "Validation Loss: 0.0308, Validation Accuracy: 0.9877\n",
      "Epoch [246/250], Loss: 0.0139, Accuracy: 0.9938\n",
      "Validation Loss: 0.0073, Validation Accuracy: 0.9939\n",
      "Epoch [247/250], Loss: 0.0081, Accuracy: 1.0000\n",
      "Validation Loss: 0.0050, Validation Accuracy: 0.9939\n",
      "Epoch [248/250], Loss: 0.0121, Accuracy: 0.9969\n",
      "Validation Loss: 0.0005, Validation Accuracy: 1.0000\n",
      "Epoch [249/250], Loss: 0.0056, Accuracy: 1.0000\n",
      "Validation Loss: 0.0007, Validation Accuracy: 1.0000\n",
      "Epoch [250/250], Loss: 0.0070, Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Test Loss: 0.1005\n",
      "Test Accuracy: 0.9938\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 86\n",
      "label 1 is 64\n",
      "label 2 is 27\n",
      "label 3 is 33\n",
      "Not setting metadata\n",
      "210 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (219, 8, 325)\n",
      "219 train samples\n",
      "109 test samples\n",
      "Number of batches in train_loader: 4\n",
      "{-1: 0.9605263157894737, 0: 1.042857142857143}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.2338, Accuracy: 0.4658\n",
      "Validation Loss: 0.9760, Validation Accuracy: 0.6000\n",
      "Epoch [2/250], Loss: 0.9332, Accuracy: 0.7032\n",
      "Validation Loss: 0.8267, Validation Accuracy: 0.6000\n",
      "Epoch [3/250], Loss: 0.6995, Accuracy: 0.8219\n",
      "Validation Loss: 0.9126, Validation Accuracy: 0.6000\n",
      "Epoch [4/250], Loss: 0.5009, Accuracy: 0.8995\n",
      "Validation Loss: 1.3050, Validation Accuracy: 0.6000\n",
      "Epoch [5/250], Loss: 0.2867, Accuracy: 0.9772\n",
      "Validation Loss: 2.0608, Validation Accuracy: 0.6000\n",
      "Epoch [6/250], Loss: 0.1406, Accuracy: 0.9954\n",
      "Validation Loss: 2.6589, Validation Accuracy: 0.6000\n",
      "Epoch [7/250], Loss: 0.0748, Accuracy: 1.0000\n",
      "Validation Loss: 3.1050, Validation Accuracy: 0.6000\n",
      "Epoch [8/250], Loss: 0.0512, Accuracy: 1.0000\n",
      "Validation Loss: 3.3260, Validation Accuracy: 0.6000\n",
      "Epoch [9/250], Loss: 0.0389, Accuracy: 1.0000\n",
      "Validation Loss: 3.5376, Validation Accuracy: 0.6000\n",
      "Epoch [10/250], Loss: 0.0303, Accuracy: 1.0000\n",
      "Validation Loss: 3.7546, Validation Accuracy: 0.6000\n",
      "Epoch [11/250], Loss: 0.0223, Accuracy: 1.0000\n",
      "Validation Loss: 3.9507, Validation Accuracy: 0.6000\n",
      "Epoch [12/250], Loss: 0.0168, Accuracy: 1.0000\n",
      "Validation Loss: 4.0491, Validation Accuracy: 0.6000\n",
      "Epoch [13/250], Loss: 0.0228, Accuracy: 0.9954\n",
      "Validation Loss: 4.1941, Validation Accuracy: 0.6000\n",
      "Epoch [14/250], Loss: 0.0148, Accuracy: 1.0000\n",
      "Validation Loss: 4.1692, Validation Accuracy: 0.6000\n",
      "Epoch [15/250], Loss: 0.0126, Accuracy: 1.0000\n",
      "Validation Loss: 3.8301, Validation Accuracy: 0.6000\n",
      "Epoch [16/250], Loss: 0.0102, Accuracy: 1.0000\n",
      "Validation Loss: 3.4108, Validation Accuracy: 0.6091\n",
      "Epoch [17/250], Loss: 0.0114, Accuracy: 1.0000\n",
      "Validation Loss: 3.5071, Validation Accuracy: 0.6091\n",
      "Epoch [18/250], Loss: 0.0069, Accuracy: 1.0000\n",
      "Validation Loss: 3.1719, Validation Accuracy: 0.6455\n",
      "Epoch [19/250], Loss: 0.0099, Accuracy: 1.0000\n",
      "Validation Loss: 2.1394, Validation Accuracy: 0.7545\n",
      "Epoch [20/250], Loss: 0.0082, Accuracy: 1.0000\n",
      "Validation Loss: 4.0065, Validation Accuracy: 0.6000\n",
      "Epoch [21/250], Loss: 0.0050, Accuracy: 1.0000\n",
      "Validation Loss: 4.0976, Validation Accuracy: 0.6182\n",
      "Epoch [22/250], Loss: 0.0044, Accuracy: 1.0000\n",
      "Validation Loss: 0.9203, Validation Accuracy: 0.8727\n",
      "Epoch [23/250], Loss: 0.0143, Accuracy: 0.9954\n",
      "Validation Loss: 7.3953, Validation Accuracy: 0.4000\n",
      "Epoch [24/250], Loss: 0.0058, Accuracy: 1.0000\n",
      "Validation Loss: 7.4065, Validation Accuracy: 0.4000\n",
      "Epoch [25/250], Loss: 0.0046, Accuracy: 1.0000\n",
      "Validation Loss: 7.2272, Validation Accuracy: 0.4000\n",
      "Epoch [26/250], Loss: 0.0056, Accuracy: 1.0000\n",
      "Validation Loss: 6.6643, Validation Accuracy: 0.4000\n",
      "Epoch [27/250], Loss: 0.0040, Accuracy: 1.0000\n",
      "Validation Loss: 0.2208, Validation Accuracy: 0.9273\n",
      "Epoch [28/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [29/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [30/250], Loss: 0.0037, Accuracy: 1.0000\n",
      "Validation Loss: 0.0009, Validation Accuracy: 1.0000\n",
      "Epoch [31/250], Loss: 0.0040, Accuracy: 1.0000\n",
      "Validation Loss: 0.3438, Validation Accuracy: 0.9636\n",
      "Epoch [32/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.1029, Validation Accuracy: 0.9636\n",
      "Epoch [33/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.0063, Validation Accuracy: 0.9909\n",
      "Epoch [34/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [35/250], Loss: 0.0069, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [36/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [37/250], Loss: 0.0039, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [38/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [39/250], Loss: 0.0030, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [40/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [41/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [42/250], Loss: 0.0024, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [43/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [44/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [45/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [46/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [47/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [48/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [49/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [50/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [51/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [52/250], Loss: 0.0033, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [53/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [54/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [55/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [56/250], Loss: 0.0052, Accuracy: 0.9954\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [57/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [58/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [59/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [60/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [61/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [62/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [63/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [64/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [65/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [66/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [67/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [68/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [69/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [70/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [71/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 8.9919, Validation Accuracy: 0.4000\n",
      "Epoch [72/250], Loss: 0.0717, Accuracy: 0.9909\n",
      "Validation Loss: 4.1487, Validation Accuracy: 0.6455\n",
      "Epoch [73/250], Loss: 0.0408, Accuracy: 0.9909\n",
      "Validation Loss: 0.0434, Validation Accuracy: 0.9818\n",
      "Epoch [74/250], Loss: 0.0168, Accuracy: 0.9954\n",
      "Validation Loss: 0.1560, Validation Accuracy: 0.9636\n",
      "Epoch [75/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0009, Validation Accuracy: 1.0000\n",
      "Epoch [76/250], Loss: 0.0022, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [77/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [78/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [79/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [80/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [81/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [82/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [83/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [84/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [85/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [86/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [87/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [88/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [89/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [90/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [91/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [92/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.0288, Validation Accuracy: 0.9909\n",
      "Epoch [93/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.9410, Validation Accuracy: 0.8818\n",
      "Epoch [94/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0147, Validation Accuracy: 0.9909\n",
      "Epoch [95/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [96/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [97/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [98/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [99/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [100/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [101/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [102/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [103/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [104/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [105/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [106/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [107/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [108/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [109/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [110/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [111/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [112/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [113/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [114/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [115/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [116/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [117/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [118/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [119/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [120/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [121/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [122/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [123/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [124/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [125/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [126/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [127/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [128/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [129/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [130/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [131/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [132/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [133/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [134/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [135/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [136/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [137/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [138/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [139/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [140/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [141/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [142/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [143/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [144/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [145/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [146/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [147/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [148/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [149/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [150/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [151/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [152/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [153/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [154/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [155/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [156/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [157/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [158/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [159/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [160/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [161/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [162/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [163/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [164/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [165/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [166/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [167/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [168/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [169/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [170/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [171/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [172/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [173/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [174/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [175/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [176/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [177/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [178/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [179/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [180/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [181/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [182/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [183/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [184/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [185/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [186/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [187/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [188/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [189/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [190/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [191/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [192/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [193/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [194/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [195/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [196/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [197/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [198/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [199/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [200/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [201/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [202/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [203/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [204/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [205/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [206/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [207/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [208/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [209/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [210/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [211/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [212/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [213/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [214/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [215/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [216/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [217/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [218/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [219/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [220/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [221/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [222/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [223/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [224/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [225/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [226/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [227/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [228/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [229/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [230/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [231/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [232/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [233/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [234/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [235/250], Loss: 0.0000, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [236/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [237/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [238/250], Loss: 0.0002, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [239/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [240/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [241/250], Loss: 0.0001, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [242/250], Loss: 0.2131, Accuracy: 0.9772\n",
      "Validation Loss: 12.2785, Validation Accuracy: 0.4000\n",
      "Epoch [243/250], Loss: 0.3659, Accuracy: 0.9315\n",
      "Validation Loss: 4.4810, Validation Accuracy: 0.4000\n",
      "Epoch [244/250], Loss: 0.0288, Accuracy: 0.9909\n",
      "Validation Loss: 2.9244, Validation Accuracy: 0.7727\n",
      "Epoch [245/250], Loss: 0.0055, Accuracy: 0.9954\n",
      "Validation Loss: 4.5630, Validation Accuracy: 0.4545\n",
      "Epoch [246/250], Loss: 0.0276, Accuracy: 0.9954\n",
      "Validation Loss: 2.6420, Validation Accuracy: 0.8000\n",
      "Epoch [247/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 2.2225, Validation Accuracy: 0.8182\n",
      "Epoch [248/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.9548, Validation Accuracy: 0.9273\n",
      "Epoch [249/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.6935, Validation Accuracy: 0.9455\n",
      "Epoch [250/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.3200, Validation Accuracy: 0.9727\n",
      "Test Loss: 0.1090\n",
      "Test Accuracy: 0.9908\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 125\n",
      "label 1 is 110\n",
      "label 2 is 22\n",
      "label 3 is 40\n",
      "Not setting metadata\n",
      "297 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (262, 8, 325)\n",
      "262 train samples\n",
      "131 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.1513157894736843, 0: 0.8838383838383839}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.3106, Accuracy: 0.3282\n",
      "Validation Loss: 1.1306, Validation Accuracy: 0.4773\n",
      "Epoch [2/250], Loss: 1.0526, Accuracy: 0.5725\n",
      "Validation Loss: 1.0729, Validation Accuracy: 0.4773\n",
      "Epoch [3/250], Loss: 0.9264, Accuracy: 0.5725\n",
      "Validation Loss: 0.8519, Validation Accuracy: 0.4773\n",
      "Epoch [4/250], Loss: 0.8368, Accuracy: 0.5534\n",
      "Validation Loss: 0.9075, Validation Accuracy: 0.4773\n",
      "Epoch [5/250], Loss: 0.7603, Accuracy: 0.5611\n",
      "Validation Loss: 0.8227, Validation Accuracy: 0.4773\n",
      "Epoch [6/250], Loss: 0.7483, Accuracy: 0.5382\n",
      "Validation Loss: 0.8939, Validation Accuracy: 0.4773\n",
      "Epoch [7/250], Loss: 0.8033, Accuracy: 0.5611\n",
      "Validation Loss: 0.8120, Validation Accuracy: 0.4773\n",
      "Epoch [8/250], Loss: 0.7489, Accuracy: 0.5115\n",
      "Validation Loss: 0.9425, Validation Accuracy: 0.4773\n",
      "Epoch [9/250], Loss: 0.7007, Accuracy: 0.5878\n",
      "Validation Loss: 0.9434, Validation Accuracy: 0.4773\n",
      "Epoch [10/250], Loss: 0.8270, Accuracy: 0.4924\n",
      "Validation Loss: 0.8741, Validation Accuracy: 0.4773\n",
      "Epoch [11/250], Loss: 0.7256, Accuracy: 0.5382\n",
      "Validation Loss: 0.7945, Validation Accuracy: 0.4773\n",
      "Epoch [12/250], Loss: 0.7129, Accuracy: 0.5954\n",
      "Validation Loss: 0.8488, Validation Accuracy: 0.4773\n",
      "Epoch [13/250], Loss: 0.6768, Accuracy: 0.5649\n",
      "Validation Loss: 1.0044, Validation Accuracy: 0.4773\n",
      "Epoch [14/250], Loss: 0.6766, Accuracy: 0.6069\n",
      "Validation Loss: 1.1522, Validation Accuracy: 0.4773\n",
      "Epoch [15/250], Loss: 0.7123, Accuracy: 0.6145\n",
      "Validation Loss: 0.8732, Validation Accuracy: 0.4848\n",
      "Epoch [16/250], Loss: 0.6775, Accuracy: 0.6641\n",
      "Validation Loss: 0.8674, Validation Accuracy: 0.4924\n",
      "Epoch [17/250], Loss: 0.6813, Accuracy: 0.6107\n",
      "Validation Loss: 0.6535, Validation Accuracy: 0.5379\n",
      "Epoch [18/250], Loss: 0.6176, Accuracy: 0.6450\n",
      "Validation Loss: 0.5307, Validation Accuracy: 0.6742\n",
      "Epoch [19/250], Loss: 0.5935, Accuracy: 0.6870\n",
      "Validation Loss: 0.6358, Validation Accuracy: 0.5985\n",
      "Epoch [20/250], Loss: 0.5511, Accuracy: 0.6908\n",
      "Validation Loss: 0.5607, Validation Accuracy: 0.6894\n",
      "Epoch [21/250], Loss: 0.6149, Accuracy: 0.7634\n",
      "Validation Loss: 0.5882, Validation Accuracy: 0.6742\n",
      "Epoch [22/250], Loss: 0.6576, Accuracy: 0.7252\n",
      "Validation Loss: 0.4656, Validation Accuracy: 0.7727\n",
      "Epoch [23/250], Loss: 0.4499, Accuracy: 0.7634\n",
      "Validation Loss: 0.3823, Validation Accuracy: 0.8409\n",
      "Epoch [24/250], Loss: 0.4608, Accuracy: 0.7595\n",
      "Validation Loss: 0.4409, Validation Accuracy: 0.8182\n",
      "Epoch [25/250], Loss: 0.5587, Accuracy: 0.7786\n",
      "Validation Loss: 0.6839, Validation Accuracy: 0.7576\n",
      "Epoch [26/250], Loss: 0.6186, Accuracy: 0.7099\n",
      "Validation Loss: 0.9640, Validation Accuracy: 0.6667\n",
      "Epoch [27/250], Loss: 0.5175, Accuracy: 0.7290\n",
      "Validation Loss: 0.4467, Validation Accuracy: 0.8258\n",
      "Epoch [28/250], Loss: 0.4845, Accuracy: 0.7824\n",
      "Validation Loss: 0.4426, Validation Accuracy: 0.8409\n",
      "Epoch [29/250], Loss: 0.5012, Accuracy: 0.7939\n",
      "Validation Loss: 0.4153, Validation Accuracy: 0.8409\n",
      "Epoch [30/250], Loss: 0.4248, Accuracy: 0.8206\n",
      "Validation Loss: 0.6398, Validation Accuracy: 0.8182\n",
      "Epoch [31/250], Loss: 0.4892, Accuracy: 0.7748\n",
      "Validation Loss: 1.0761, Validation Accuracy: 0.7576\n",
      "Epoch [32/250], Loss: 0.5122, Accuracy: 0.7290\n",
      "Validation Loss: 1.3379, Validation Accuracy: 0.6970\n",
      "Epoch [33/250], Loss: 0.4929, Accuracy: 0.7863\n",
      "Validation Loss: 0.7119, Validation Accuracy: 0.7500\n",
      "Epoch [34/250], Loss: 0.4211, Accuracy: 0.8053\n",
      "Validation Loss: 1.1044, Validation Accuracy: 0.7273\n",
      "Epoch [35/250], Loss: 0.4208, Accuracy: 0.8359\n",
      "Validation Loss: 0.3923, Validation Accuracy: 0.8788\n",
      "Epoch [36/250], Loss: 0.3787, Accuracy: 0.8092\n",
      "Validation Loss: 0.6949, Validation Accuracy: 0.7955\n",
      "Epoch [37/250], Loss: 0.3971, Accuracy: 0.8130\n",
      "Validation Loss: 0.6543, Validation Accuracy: 0.7576\n",
      "Epoch [38/250], Loss: 0.3296, Accuracy: 0.8626\n",
      "Validation Loss: 0.4929, Validation Accuracy: 0.8258\n",
      "Epoch [39/250], Loss: 0.3724, Accuracy: 0.8626\n",
      "Validation Loss: 0.3928, Validation Accuracy: 0.8636\n",
      "Epoch [40/250], Loss: 0.3593, Accuracy: 0.8206\n",
      "Validation Loss: 0.3655, Validation Accuracy: 0.8712\n",
      "Epoch [41/250], Loss: 0.3981, Accuracy: 0.8359\n",
      "Validation Loss: 0.5078, Validation Accuracy: 0.8485\n",
      "Epoch [42/250], Loss: 0.4159, Accuracy: 0.8473\n",
      "Validation Loss: 0.6079, Validation Accuracy: 0.8106\n",
      "Epoch [43/250], Loss: 0.4890, Accuracy: 0.7595\n",
      "Validation Loss: 2.0695, Validation Accuracy: 0.5455\n",
      "Epoch [44/250], Loss: 0.3233, Accuracy: 0.8588\n",
      "Validation Loss: 1.3117, Validation Accuracy: 0.7197\n",
      "Epoch [45/250], Loss: 0.5180, Accuracy: 0.8435\n",
      "Validation Loss: 1.7468, Validation Accuracy: 0.6061\n",
      "Epoch [46/250], Loss: 0.3995, Accuracy: 0.8168\n",
      "Validation Loss: 2.2246, Validation Accuracy: 0.5606\n",
      "Epoch [47/250], Loss: 0.3497, Accuracy: 0.8397\n",
      "Validation Loss: 1.9823, Validation Accuracy: 0.6364\n",
      "Epoch [48/250], Loss: 0.4147, Accuracy: 0.8282\n",
      "Validation Loss: 1.4054, Validation Accuracy: 0.7197\n",
      "Epoch [49/250], Loss: 0.4103, Accuracy: 0.8321\n",
      "Validation Loss: 2.2763, Validation Accuracy: 0.5530\n",
      "Epoch [50/250], Loss: 0.4138, Accuracy: 0.8244\n",
      "Validation Loss: 2.3033, Validation Accuracy: 0.5530\n",
      "Epoch [51/250], Loss: 0.4125, Accuracy: 0.8588\n",
      "Validation Loss: 1.4680, Validation Accuracy: 0.6742\n",
      "Epoch [52/250], Loss: 0.4053, Accuracy: 0.8244\n",
      "Validation Loss: 0.5083, Validation Accuracy: 0.8258\n",
      "Epoch [53/250], Loss: 0.4449, Accuracy: 0.8473\n",
      "Validation Loss: 0.9579, Validation Accuracy: 0.6667\n",
      "Epoch [54/250], Loss: 0.4460, Accuracy: 0.8397\n",
      "Validation Loss: 0.4336, Validation Accuracy: 0.8485\n",
      "Epoch [55/250], Loss: 0.3310, Accuracy: 0.8626\n",
      "Validation Loss: 0.3256, Validation Accuracy: 0.8561\n",
      "Epoch [56/250], Loss: 0.2954, Accuracy: 0.8626\n",
      "Validation Loss: 0.3358, Validation Accuracy: 0.8712\n",
      "Epoch [57/250], Loss: 0.4219, Accuracy: 0.8511\n",
      "Validation Loss: 1.3832, Validation Accuracy: 0.6970\n",
      "Epoch [58/250], Loss: 0.4206, Accuracy: 0.8244\n",
      "Validation Loss: 1.0170, Validation Accuracy: 0.7424\n",
      "Epoch [59/250], Loss: 0.3161, Accuracy: 0.8779\n",
      "Validation Loss: 0.3481, Validation Accuracy: 0.8636\n",
      "Epoch [60/250], Loss: 0.4860, Accuracy: 0.8702\n",
      "Validation Loss: 0.3484, Validation Accuracy: 0.9015\n",
      "Epoch [61/250], Loss: 0.3470, Accuracy: 0.8740\n",
      "Validation Loss: 0.6249, Validation Accuracy: 0.7500\n",
      "Epoch [62/250], Loss: 0.3129, Accuracy: 0.8588\n",
      "Validation Loss: 1.6286, Validation Accuracy: 0.5455\n",
      "Epoch [63/250], Loss: 0.2628, Accuracy: 0.9046\n",
      "Validation Loss: 0.6156, Validation Accuracy: 0.8485\n",
      "Epoch [64/250], Loss: 0.2413, Accuracy: 0.8740\n",
      "Validation Loss: 0.6755, Validation Accuracy: 0.8258\n",
      "Epoch [65/250], Loss: 0.3338, Accuracy: 0.8817\n",
      "Validation Loss: 0.3160, Validation Accuracy: 0.8788\n",
      "Epoch [66/250], Loss: 0.4018, Accuracy: 0.8702\n",
      "Validation Loss: 0.5959, Validation Accuracy: 0.8561\n",
      "Epoch [67/250], Loss: 0.2981, Accuracy: 0.8473\n",
      "Validation Loss: 0.2882, Validation Accuracy: 0.8712\n",
      "Epoch [68/250], Loss: 0.3037, Accuracy: 0.8664\n",
      "Validation Loss: 0.3202, Validation Accuracy: 0.8788\n",
      "Epoch [69/250], Loss: 0.2516, Accuracy: 0.9122\n",
      "Validation Loss: 0.7041, Validation Accuracy: 0.8333\n",
      "Epoch [70/250], Loss: 0.3246, Accuracy: 0.8550\n",
      "Validation Loss: 1.5395, Validation Accuracy: 0.6742\n",
      "Epoch [71/250], Loss: 0.4064, Accuracy: 0.8702\n",
      "Validation Loss: 0.2835, Validation Accuracy: 0.8712\n",
      "Epoch [72/250], Loss: 0.2959, Accuracy: 0.8740\n",
      "Validation Loss: 0.8018, Validation Accuracy: 0.7500\n",
      "Epoch [73/250], Loss: 0.3294, Accuracy: 0.8664\n",
      "Validation Loss: 0.6954, Validation Accuracy: 0.7424\n",
      "Epoch [74/250], Loss: 0.4075, Accuracy: 0.8092\n",
      "Validation Loss: 1.7554, Validation Accuracy: 0.5303\n",
      "Epoch [75/250], Loss: 0.2859, Accuracy: 0.8779\n",
      "Validation Loss: 1.0051, Validation Accuracy: 0.6742\n",
      "Epoch [76/250], Loss: 0.2496, Accuracy: 0.8702\n",
      "Validation Loss: 0.7886, Validation Accuracy: 0.7576\n",
      "Epoch [77/250], Loss: 0.2400, Accuracy: 0.9084\n",
      "Validation Loss: 0.7722, Validation Accuracy: 0.7803\n",
      "Epoch [78/250], Loss: 0.3099, Accuracy: 0.9084\n",
      "Validation Loss: 0.4933, Validation Accuracy: 0.8182\n",
      "Epoch [79/250], Loss: 0.2639, Accuracy: 0.8779\n",
      "Validation Loss: 1.6321, Validation Accuracy: 0.6818\n",
      "Epoch [80/250], Loss: 0.2667, Accuracy: 0.8855\n",
      "Validation Loss: 0.8954, Validation Accuracy: 0.7652\n",
      "Epoch [81/250], Loss: 0.3203, Accuracy: 0.8817\n",
      "Validation Loss: 1.3934, Validation Accuracy: 0.7273\n",
      "Epoch [82/250], Loss: 0.2594, Accuracy: 0.8969\n",
      "Validation Loss: 0.5054, Validation Accuracy: 0.8864\n",
      "Epoch [83/250], Loss: 0.2745, Accuracy: 0.9046\n",
      "Validation Loss: 0.4011, Validation Accuracy: 0.8864\n",
      "Epoch [84/250], Loss: 0.2783, Accuracy: 0.8893\n",
      "Validation Loss: 0.3485, Validation Accuracy: 0.8864\n",
      "Epoch [85/250], Loss: 0.3358, Accuracy: 0.8855\n",
      "Validation Loss: 0.4935, Validation Accuracy: 0.8485\n",
      "Epoch [86/250], Loss: 0.4161, Accuracy: 0.8740\n",
      "Validation Loss: 2.3286, Validation Accuracy: 0.5379\n",
      "Epoch [87/250], Loss: 0.3923, Accuracy: 0.8168\n",
      "Validation Loss: 2.6440, Validation Accuracy: 0.5303\n",
      "Epoch [88/250], Loss: 0.3364, Accuracy: 0.8664\n",
      "Validation Loss: 2.4469, Validation Accuracy: 0.5152\n",
      "Epoch [89/250], Loss: 0.3382, Accuracy: 0.8817\n",
      "Validation Loss: 2.5149, Validation Accuracy: 0.5227\n",
      "Epoch [90/250], Loss: 0.2492, Accuracy: 0.9122\n",
      "Validation Loss: 0.7782, Validation Accuracy: 0.7955\n",
      "Epoch [91/250], Loss: 0.3571, Accuracy: 0.8664\n",
      "Validation Loss: 0.6921, Validation Accuracy: 0.8106\n",
      "Epoch [92/250], Loss: 0.2831, Accuracy: 0.8779\n",
      "Validation Loss: 0.8026, Validation Accuracy: 0.7727\n",
      "Epoch [93/250], Loss: 0.2328, Accuracy: 0.9046\n",
      "Validation Loss: 0.4945, Validation Accuracy: 0.8788\n",
      "Epoch [94/250], Loss: 0.5183, Accuracy: 0.8740\n",
      "Validation Loss: 0.4893, Validation Accuracy: 0.9015\n",
      "Epoch [95/250], Loss: 0.3406, Accuracy: 0.8550\n",
      "Validation Loss: 0.4081, Validation Accuracy: 0.8106\n",
      "Epoch [96/250], Loss: 0.2391, Accuracy: 0.8855\n",
      "Validation Loss: 1.0565, Validation Accuracy: 0.7652\n",
      "Epoch [97/250], Loss: 0.4102, Accuracy: 0.9122\n",
      "Validation Loss: 1.8735, Validation Accuracy: 0.5530\n",
      "Epoch [98/250], Loss: 0.2838, Accuracy: 0.8702\n",
      "Validation Loss: 0.7414, Validation Accuracy: 0.7879\n",
      "Epoch [99/250], Loss: 0.2760, Accuracy: 0.8855\n",
      "Validation Loss: 0.3440, Validation Accuracy: 0.9015\n",
      "Epoch [100/250], Loss: 0.2434, Accuracy: 0.9084\n",
      "Validation Loss: 0.4831, Validation Accuracy: 0.8939\n",
      "Epoch [101/250], Loss: 0.1783, Accuracy: 0.9198\n",
      "Validation Loss: 1.6220, Validation Accuracy: 0.6894\n",
      "Epoch [102/250], Loss: 0.2824, Accuracy: 0.9198\n",
      "Validation Loss: 0.9362, Validation Accuracy: 0.8409\n",
      "Epoch [103/250], Loss: 0.4160, Accuracy: 0.8321\n",
      "Validation Loss: 1.1735, Validation Accuracy: 0.7500\n",
      "Epoch [104/250], Loss: 0.2699, Accuracy: 0.8931\n",
      "Validation Loss: 0.5881, Validation Accuracy: 0.8182\n",
      "Epoch [105/250], Loss: 0.2834, Accuracy: 0.9237\n",
      "Validation Loss: 1.4762, Validation Accuracy: 0.6894\n",
      "Epoch [106/250], Loss: 0.2947, Accuracy: 0.9008\n",
      "Validation Loss: 1.0487, Validation Accuracy: 0.7424\n",
      "Epoch [107/250], Loss: 0.2586, Accuracy: 0.8855\n",
      "Validation Loss: 0.3627, Validation Accuracy: 0.8864\n",
      "Epoch [108/250], Loss: 0.2196, Accuracy: 0.9313\n",
      "Validation Loss: 0.4249, Validation Accuracy: 0.8636\n",
      "Epoch [109/250], Loss: 0.2477, Accuracy: 0.8931\n",
      "Validation Loss: 1.0624, Validation Accuracy: 0.7727\n",
      "Epoch [110/250], Loss: 0.3204, Accuracy: 0.8893\n",
      "Validation Loss: 0.6623, Validation Accuracy: 0.8939\n",
      "Epoch [111/250], Loss: 0.1621, Accuracy: 0.9275\n",
      "Validation Loss: 0.5166, Validation Accuracy: 0.8939\n",
      "Epoch [112/250], Loss: 0.1755, Accuracy: 0.9198\n",
      "Validation Loss: 0.6487, Validation Accuracy: 0.8939\n",
      "Epoch [113/250], Loss: 0.3297, Accuracy: 0.9198\n",
      "Validation Loss: 1.6165, Validation Accuracy: 0.6439\n",
      "Epoch [114/250], Loss: 0.3149, Accuracy: 0.8740\n",
      "Validation Loss: 0.3809, Validation Accuracy: 0.8939\n",
      "Epoch [115/250], Loss: 0.5801, Accuracy: 0.8931\n",
      "Validation Loss: 0.3891, Validation Accuracy: 0.8636\n",
      "Epoch [116/250], Loss: 0.3271, Accuracy: 0.8435\n",
      "Validation Loss: 0.2803, Validation Accuracy: 0.8712\n",
      "Epoch [117/250], Loss: 0.2711, Accuracy: 0.8931\n",
      "Validation Loss: 0.4020, Validation Accuracy: 0.9015\n",
      "Epoch [118/250], Loss: 0.3710, Accuracy: 0.9008\n",
      "Validation Loss: 0.5997, Validation Accuracy: 0.8712\n",
      "Epoch [119/250], Loss: 0.2874, Accuracy: 0.8511\n",
      "Validation Loss: 2.0439, Validation Accuracy: 0.5530\n",
      "Epoch [120/250], Loss: 0.2179, Accuracy: 0.9237\n",
      "Validation Loss: 1.2830, Validation Accuracy: 0.6894\n",
      "Epoch [121/250], Loss: 0.2013, Accuracy: 0.9237\n",
      "Validation Loss: 0.6394, Validation Accuracy: 0.9091\n",
      "Epoch [122/250], Loss: 0.2495, Accuracy: 0.9313\n",
      "Validation Loss: 0.6161, Validation Accuracy: 0.8788\n",
      "Epoch [123/250], Loss: 0.1922, Accuracy: 0.8969\n",
      "Validation Loss: 0.6147, Validation Accuracy: 0.8258\n",
      "Epoch [124/250], Loss: 0.1786, Accuracy: 0.8969\n",
      "Validation Loss: 1.0655, Validation Accuracy: 0.7652\n",
      "Epoch [125/250], Loss: 0.2804, Accuracy: 0.9351\n",
      "Validation Loss: 0.6717, Validation Accuracy: 0.8485\n",
      "Epoch [126/250], Loss: 0.2340, Accuracy: 0.9084\n",
      "Validation Loss: 0.5174, Validation Accuracy: 0.8939\n",
      "Epoch [127/250], Loss: 0.2056, Accuracy: 0.9351\n",
      "Validation Loss: 0.6127, Validation Accuracy: 0.8788\n",
      "Epoch [128/250], Loss: 0.2076, Accuracy: 0.9160\n",
      "Validation Loss: 0.5632, Validation Accuracy: 0.9015\n",
      "Epoch [129/250], Loss: 0.1688, Accuracy: 0.9351\n",
      "Validation Loss: 0.5964, Validation Accuracy: 0.8939\n",
      "Epoch [130/250], Loss: 0.2427, Accuracy: 0.9198\n",
      "Validation Loss: 0.2230, Validation Accuracy: 0.9091\n",
      "Epoch [131/250], Loss: 0.4099, Accuracy: 0.9198\n",
      "Validation Loss: 0.2825, Validation Accuracy: 0.9015\n",
      "Epoch [132/250], Loss: 0.2414, Accuracy: 0.9122\n",
      "Validation Loss: 0.9091, Validation Accuracy: 0.8258\n",
      "Epoch [133/250], Loss: 0.2283, Accuracy: 0.9122\n",
      "Validation Loss: 2.0718, Validation Accuracy: 0.6591\n",
      "Epoch [134/250], Loss: 0.2734, Accuracy: 0.8855\n",
      "Validation Loss: 1.2098, Validation Accuracy: 0.7273\n",
      "Epoch [135/250], Loss: 0.1929, Accuracy: 0.9313\n",
      "Validation Loss: 1.5020, Validation Accuracy: 0.7273\n",
      "Epoch [136/250], Loss: 0.1475, Accuracy: 0.9313\n",
      "Validation Loss: 0.6229, Validation Accuracy: 0.8864\n",
      "Epoch [137/250], Loss: 0.2450, Accuracy: 0.8969\n",
      "Validation Loss: 0.3874, Validation Accuracy: 0.9167\n",
      "Epoch [138/250], Loss: 0.1698, Accuracy: 0.9084\n",
      "Validation Loss: 0.3080, Validation Accuracy: 0.8864\n",
      "Epoch [139/250], Loss: 0.2554, Accuracy: 0.8931\n",
      "Validation Loss: 0.6236, Validation Accuracy: 0.8636\n",
      "Epoch [140/250], Loss: 0.1843, Accuracy: 0.9237\n",
      "Validation Loss: 1.0301, Validation Accuracy: 0.7424\n",
      "Epoch [141/250], Loss: 0.2298, Accuracy: 0.9351\n",
      "Validation Loss: 0.6052, Validation Accuracy: 0.8788\n",
      "Epoch [142/250], Loss: 0.1776, Accuracy: 0.9084\n",
      "Validation Loss: 0.8351, Validation Accuracy: 0.8030\n",
      "Epoch [143/250], Loss: 0.1570, Accuracy: 0.9351\n",
      "Validation Loss: 0.4393, Validation Accuracy: 0.9318\n",
      "Epoch [144/250], Loss: 0.2658, Accuracy: 0.8969\n",
      "Validation Loss: 0.8701, Validation Accuracy: 0.7803\n",
      "Epoch [145/250], Loss: 0.2591, Accuracy: 0.8779\n",
      "Validation Loss: 0.4770, Validation Accuracy: 0.9167\n",
      "Epoch [146/250], Loss: 0.2026, Accuracy: 0.9466\n",
      "Validation Loss: 1.4869, Validation Accuracy: 0.6742\n",
      "Epoch [147/250], Loss: 0.2152, Accuracy: 0.9084\n",
      "Validation Loss: 1.7705, Validation Accuracy: 0.6288\n",
      "Epoch [148/250], Loss: 0.3108, Accuracy: 0.9275\n",
      "Validation Loss: 2.2513, Validation Accuracy: 0.5455\n",
      "Epoch [149/250], Loss: 0.4158, Accuracy: 0.8855\n",
      "Validation Loss: 1.1758, Validation Accuracy: 0.6515\n",
      "Epoch [150/250], Loss: 0.2447, Accuracy: 0.8931\n",
      "Validation Loss: 0.1863, Validation Accuracy: 0.9091\n",
      "Epoch [151/250], Loss: 0.2149, Accuracy: 0.9160\n",
      "Validation Loss: 0.3268, Validation Accuracy: 0.8864\n",
      "Epoch [152/250], Loss: 0.1772, Accuracy: 0.9313\n",
      "Validation Loss: 0.2976, Validation Accuracy: 0.9015\n",
      "Epoch [153/250], Loss: 0.1273, Accuracy: 0.9580\n",
      "Validation Loss: 0.6046, Validation Accuracy: 0.9091\n",
      "Epoch [154/250], Loss: 0.1835, Accuracy: 0.9313\n",
      "Validation Loss: 0.4219, Validation Accuracy: 0.9015\n",
      "Epoch [155/250], Loss: 0.2114, Accuracy: 0.9084\n",
      "Validation Loss: 0.2285, Validation Accuracy: 0.8939\n",
      "Epoch [156/250], Loss: 0.1644, Accuracy: 0.9160\n",
      "Validation Loss: 0.7787, Validation Accuracy: 0.8030\n",
      "Epoch [157/250], Loss: 0.2640, Accuracy: 0.9008\n",
      "Validation Loss: 0.4102, Validation Accuracy: 0.9091\n",
      "Epoch [158/250], Loss: 0.1788, Accuracy: 0.9198\n",
      "Validation Loss: 0.7405, Validation Accuracy: 0.8409\n",
      "Epoch [159/250], Loss: 0.1906, Accuracy: 0.9313\n",
      "Validation Loss: 1.7506, Validation Accuracy: 0.6061\n",
      "Epoch [160/250], Loss: 0.2615, Accuracy: 0.9351\n",
      "Validation Loss: 0.5229, Validation Accuracy: 0.9091\n",
      "Epoch [161/250], Loss: 0.1806, Accuracy: 0.9084\n",
      "Validation Loss: 0.3630, Validation Accuracy: 0.9242\n",
      "Epoch [162/250], Loss: 0.2011, Accuracy: 0.9122\n",
      "Validation Loss: 0.4882, Validation Accuracy: 0.8561\n",
      "Epoch [163/250], Loss: 0.2359, Accuracy: 0.9084\n",
      "Validation Loss: 1.5739, Validation Accuracy: 0.6667\n",
      "Epoch [164/250], Loss: 0.2372, Accuracy: 0.9084\n",
      "Validation Loss: 3.6083, Validation Accuracy: 0.5227\n",
      "Epoch [165/250], Loss: 0.2019, Accuracy: 0.8931\n",
      "Validation Loss: 3.1037, Validation Accuracy: 0.5227\n",
      "Epoch [166/250], Loss: 0.1778, Accuracy: 0.9122\n",
      "Validation Loss: 1.6603, Validation Accuracy: 0.6136\n",
      "Epoch [167/250], Loss: 0.1701, Accuracy: 0.9466\n",
      "Validation Loss: 1.1168, Validation Accuracy: 0.7273\n",
      "Epoch [168/250], Loss: 0.1434, Accuracy: 0.9313\n",
      "Validation Loss: 1.0690, Validation Accuracy: 0.7348\n",
      "Epoch [169/250], Loss: 0.1523, Accuracy: 0.9351\n",
      "Validation Loss: 0.4721, Validation Accuracy: 0.9318\n",
      "Epoch [170/250], Loss: 0.1743, Accuracy: 0.9275\n",
      "Validation Loss: 0.7721, Validation Accuracy: 0.8409\n",
      "Epoch [171/250], Loss: 0.2247, Accuracy: 0.9008\n",
      "Validation Loss: 0.1581, Validation Accuracy: 0.9545\n",
      "Epoch [172/250], Loss: 0.2114, Accuracy: 0.9237\n",
      "Validation Loss: 0.4793, Validation Accuracy: 0.9015\n",
      "Epoch [173/250], Loss: 0.1804, Accuracy: 0.8931\n",
      "Validation Loss: 0.3050, Validation Accuracy: 0.8939\n",
      "Epoch [174/250], Loss: 0.1970, Accuracy: 0.9351\n",
      "Validation Loss: 1.0169, Validation Accuracy: 0.8106\n",
      "Epoch [175/250], Loss: 0.2137, Accuracy: 0.9160\n",
      "Validation Loss: 0.2724, Validation Accuracy: 0.8939\n",
      "Epoch [176/250], Loss: 0.4367, Accuracy: 0.9198\n",
      "Validation Loss: 0.9607, Validation Accuracy: 0.8106\n",
      "Epoch [177/250], Loss: 0.3075, Accuracy: 0.9046\n",
      "Validation Loss: 1.7569, Validation Accuracy: 0.6667\n",
      "Epoch [178/250], Loss: 0.2196, Accuracy: 0.9008\n",
      "Validation Loss: 2.2568, Validation Accuracy: 0.5606\n",
      "Epoch [179/250], Loss: 0.1652, Accuracy: 0.9389\n",
      "Validation Loss: 1.3974, Validation Accuracy: 0.7197\n",
      "Epoch [180/250], Loss: 0.1776, Accuracy: 0.9313\n",
      "Validation Loss: 0.4739, Validation Accuracy: 0.8409\n",
      "Epoch [181/250], Loss: 0.1333, Accuracy: 0.9351\n",
      "Validation Loss: 0.2579, Validation Accuracy: 0.9015\n",
      "Epoch [182/250], Loss: 0.2113, Accuracy: 0.9351\n",
      "Validation Loss: 1.5079, Validation Accuracy: 0.6970\n",
      "Epoch [183/250], Loss: 0.2918, Accuracy: 0.8702\n",
      "Validation Loss: 2.4782, Validation Accuracy: 0.5379\n",
      "Epoch [184/250], Loss: 0.4171, Accuracy: 0.8855\n",
      "Validation Loss: 1.6058, Validation Accuracy: 0.5606\n",
      "Epoch [185/250], Loss: 0.2983, Accuracy: 0.8817\n",
      "Validation Loss: 1.5809, Validation Accuracy: 0.5682\n",
      "Epoch [186/250], Loss: 0.3785, Accuracy: 0.9122\n",
      "Validation Loss: 1.5089, Validation Accuracy: 0.6061\n",
      "Epoch [187/250], Loss: 0.2868, Accuracy: 0.8740\n",
      "Validation Loss: 1.0588, Validation Accuracy: 0.6591\n",
      "Epoch [188/250], Loss: 0.3397, Accuracy: 0.8626\n",
      "Validation Loss: 0.3620, Validation Accuracy: 0.8712\n",
      "Epoch [189/250], Loss: 0.3059, Accuracy: 0.8664\n",
      "Validation Loss: 1.4163, Validation Accuracy: 0.7348\n",
      "Epoch [190/250], Loss: 0.1785, Accuracy: 0.9313\n",
      "Validation Loss: 0.4160, Validation Accuracy: 0.8561\n",
      "Epoch [191/250], Loss: 0.1525, Accuracy: 0.9466\n",
      "Validation Loss: 0.7320, Validation Accuracy: 0.8485\n",
      "Epoch [192/250], Loss: 0.2544, Accuracy: 0.9122\n",
      "Validation Loss: 0.7173, Validation Accuracy: 0.8788\n",
      "Epoch [193/250], Loss: 0.1395, Accuracy: 0.9427\n",
      "Validation Loss: 0.7126, Validation Accuracy: 0.9015\n",
      "Epoch [194/250], Loss: 0.1393, Accuracy: 0.9466\n",
      "Validation Loss: 0.4064, Validation Accuracy: 0.9242\n",
      "Epoch [195/250], Loss: 0.2583, Accuracy: 0.9351\n",
      "Validation Loss: 0.4391, Validation Accuracy: 0.9167\n",
      "Epoch [196/250], Loss: 0.2837, Accuracy: 0.9046\n",
      "Validation Loss: 0.3797, Validation Accuracy: 0.9242\n",
      "Epoch [197/250], Loss: 0.2350, Accuracy: 0.9198\n",
      "Validation Loss: 0.4086, Validation Accuracy: 0.8636\n",
      "Epoch [198/250], Loss: 0.1995, Accuracy: 0.9198\n",
      "Validation Loss: 0.3069, Validation Accuracy: 0.8864\n",
      "Epoch [199/250], Loss: 0.1446, Accuracy: 0.9275\n",
      "Validation Loss: 0.9718, Validation Accuracy: 0.7652\n",
      "Epoch [200/250], Loss: 0.2438, Accuracy: 0.9389\n",
      "Validation Loss: 0.8244, Validation Accuracy: 0.8409\n",
      "Epoch [201/250], Loss: 0.1845, Accuracy: 0.9008\n",
      "Validation Loss: 0.5310, Validation Accuracy: 0.9167\n",
      "Epoch [202/250], Loss: 0.2900, Accuracy: 0.9275\n",
      "Validation Loss: 1.7268, Validation Accuracy: 0.5606\n",
      "Epoch [203/250], Loss: 0.2108, Accuracy: 0.8969\n",
      "Validation Loss: 1.2355, Validation Accuracy: 0.6212\n",
      "Epoch [204/250], Loss: 0.1415, Accuracy: 0.9237\n",
      "Validation Loss: 0.5554, Validation Accuracy: 0.8788\n",
      "Epoch [205/250], Loss: 0.1317, Accuracy: 0.9427\n",
      "Validation Loss: 0.6791, Validation Accuracy: 0.8561\n",
      "Epoch [206/250], Loss: 0.1519, Accuracy: 0.9504\n",
      "Validation Loss: 0.5693, Validation Accuracy: 0.8939\n",
      "Epoch [207/250], Loss: 0.1323, Accuracy: 0.9389\n",
      "Validation Loss: 0.3923, Validation Accuracy: 0.9091\n",
      "Epoch [208/250], Loss: 0.1464, Accuracy: 0.9313\n",
      "Validation Loss: 0.4149, Validation Accuracy: 0.9318\n",
      "Epoch [209/250], Loss: 0.2227, Accuracy: 0.9389\n",
      "Validation Loss: 0.4878, Validation Accuracy: 0.8636\n",
      "Epoch [210/250], Loss: 0.1655, Accuracy: 0.9351\n",
      "Validation Loss: 0.6683, Validation Accuracy: 0.8409\n",
      "Epoch [211/250], Loss: 0.1399, Accuracy: 0.9466\n",
      "Validation Loss: 0.4485, Validation Accuracy: 0.8636\n",
      "Epoch [212/250], Loss: 0.1231, Accuracy: 0.9427\n",
      "Validation Loss: 0.3847, Validation Accuracy: 0.8939\n",
      "Epoch [213/250], Loss: 0.2503, Accuracy: 0.9275\n",
      "Validation Loss: 2.7556, Validation Accuracy: 0.5455\n",
      "Epoch [214/250], Loss: 0.3584, Accuracy: 0.9275\n",
      "Validation Loss: 2.7388, Validation Accuracy: 0.5227\n",
      "Epoch [215/250], Loss: 0.1945, Accuracy: 0.9275\n",
      "Validation Loss: 2.1240, Validation Accuracy: 0.5303\n",
      "Epoch [216/250], Loss: 0.1621, Accuracy: 0.9198\n",
      "Validation Loss: 1.7434, Validation Accuracy: 0.6364\n",
      "Epoch [217/250], Loss: 0.2271, Accuracy: 0.9122\n",
      "Validation Loss: 1.4079, Validation Accuracy: 0.6818\n",
      "Epoch [218/250], Loss: 0.1444, Accuracy: 0.9389\n",
      "Validation Loss: 0.8138, Validation Accuracy: 0.8485\n",
      "Epoch [219/250], Loss: 0.1822, Accuracy: 0.9198\n",
      "Validation Loss: 0.2852, Validation Accuracy: 0.8864\n",
      "Epoch [220/250], Loss: 0.1580, Accuracy: 0.9351\n",
      "Validation Loss: 0.7139, Validation Accuracy: 0.8409\n",
      "Epoch [221/250], Loss: 0.1419, Accuracy: 0.9542\n",
      "Validation Loss: 2.6120, Validation Accuracy: 0.6212\n",
      "Epoch [222/250], Loss: 0.1620, Accuracy: 0.9427\n",
      "Validation Loss: 1.6230, Validation Accuracy: 0.7273\n",
      "Epoch [223/250], Loss: 0.1433, Accuracy: 0.9466\n",
      "Validation Loss: 1.1011, Validation Accuracy: 0.7879\n",
      "Epoch [224/250], Loss: 0.1725, Accuracy: 0.9351\n",
      "Validation Loss: 0.4026, Validation Accuracy: 0.9318\n",
      "Epoch [225/250], Loss: 0.1855, Accuracy: 0.9504\n",
      "Validation Loss: 3.4910, Validation Accuracy: 0.5379\n",
      "Epoch [226/250], Loss: 0.1707, Accuracy: 0.9351\n",
      "Validation Loss: 0.9249, Validation Accuracy: 0.8258\n",
      "Epoch [227/250], Loss: 0.1395, Accuracy: 0.9198\n",
      "Validation Loss: 0.7854, Validation Accuracy: 0.8788\n",
      "Epoch [228/250], Loss: 0.1901, Accuracy: 0.9427\n",
      "Validation Loss: 1.3333, Validation Accuracy: 0.6970\n",
      "Epoch [229/250], Loss: 0.2046, Accuracy: 0.9427\n",
      "Validation Loss: 0.6491, Validation Accuracy: 0.8485\n",
      "Epoch [230/250], Loss: 0.1790, Accuracy: 0.9160\n",
      "Validation Loss: 1.1090, Validation Accuracy: 0.7424\n",
      "Epoch [231/250], Loss: 0.1691, Accuracy: 0.9237\n",
      "Validation Loss: 1.1514, Validation Accuracy: 0.7576\n",
      "Epoch [232/250], Loss: 0.1972, Accuracy: 0.9275\n",
      "Validation Loss: 0.6071, Validation Accuracy: 0.8333\n",
      "Epoch [233/250], Loss: 0.1771, Accuracy: 0.9313\n",
      "Validation Loss: 0.5574, Validation Accuracy: 0.8485\n",
      "Epoch [234/250], Loss: 0.1107, Accuracy: 0.9618\n",
      "Validation Loss: 0.3781, Validation Accuracy: 0.9394\n",
      "Epoch [235/250], Loss: 0.2999, Accuracy: 0.9313\n",
      "Validation Loss: 2.0590, Validation Accuracy: 0.7273\n",
      "Epoch [236/250], Loss: 0.1825, Accuracy: 0.9160\n",
      "Validation Loss: 0.4549, Validation Accuracy: 0.8939\n",
      "Epoch [237/250], Loss: 0.1690, Accuracy: 0.9275\n",
      "Validation Loss: 0.3085, Validation Accuracy: 0.9394\n",
      "Epoch [238/250], Loss: 0.1476, Accuracy: 0.9466\n",
      "Validation Loss: 1.2072, Validation Accuracy: 0.8106\n",
      "Epoch [239/250], Loss: 0.1342, Accuracy: 0.9427\n",
      "Validation Loss: 2.4997, Validation Accuracy: 0.7273\n",
      "Epoch [240/250], Loss: 0.2114, Accuracy: 0.9275\n",
      "Validation Loss: 1.0540, Validation Accuracy: 0.7424\n",
      "Epoch [241/250], Loss: 0.3865, Accuracy: 0.8931\n",
      "Validation Loss: 0.6801, Validation Accuracy: 0.8030\n",
      "Epoch [242/250], Loss: 0.1879, Accuracy: 0.9275\n",
      "Validation Loss: 0.5755, Validation Accuracy: 0.8258\n",
      "Epoch [243/250], Loss: 0.2057, Accuracy: 0.9313\n",
      "Validation Loss: 0.3182, Validation Accuracy: 0.9091\n",
      "Epoch [244/250], Loss: 0.1800, Accuracy: 0.9237\n",
      "Validation Loss: 0.9133, Validation Accuracy: 0.8485\n",
      "Epoch [245/250], Loss: 0.1282, Accuracy: 0.9351\n",
      "Validation Loss: 0.7511, Validation Accuracy: 0.9091\n",
      "Epoch [246/250], Loss: 0.1255, Accuracy: 0.9504\n",
      "Validation Loss: 1.5652, Validation Accuracy: 0.6818\n",
      "Epoch [247/250], Loss: 0.1548, Accuracy: 0.9466\n",
      "Validation Loss: 0.3203, Validation Accuracy: 0.8864\n",
      "Epoch [248/250], Loss: 0.1032, Accuracy: 0.9618\n",
      "Validation Loss: 0.3779, Validation Accuracy: 0.8864\n",
      "Epoch [249/250], Loss: 0.1729, Accuracy: 0.9542\n",
      "Validation Loss: 0.5050, Validation Accuracy: 0.8712\n",
      "Epoch [250/250], Loss: 0.2325, Accuracy: 0.8969\n",
      "Validation Loss: 0.9397, Validation Accuracy: 0.7576\n",
      "Test Loss: 1.2629\n",
      "Test Accuracy: 0.8168\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 78\n",
      "label 1 is 179\n",
      "label 2 is 28\n",
      "label 3 is 27\n",
      "Not setting metadata\n",
      "312 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (270, 8, 325)\n",
      "270 train samples\n",
      "135 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.1842105263157894, 0: 0.8653846153846154}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.2786, Accuracy: 0.3704\n",
      "Validation Loss: 1.0209, Validation Accuracy: 0.6000\n",
      "Epoch [2/250], Loss: 0.9593, Accuracy: 0.6222\n",
      "Validation Loss: 0.9145, Validation Accuracy: 0.6000\n",
      "Epoch [3/250], Loss: 0.8040, Accuracy: 0.6370\n",
      "Validation Loss: 1.0980, Validation Accuracy: 0.6000\n",
      "Epoch [4/250], Loss: 0.5996, Accuracy: 0.7519\n",
      "Validation Loss: 1.5889, Validation Accuracy: 0.6000\n",
      "Epoch [5/250], Loss: 0.3954, Accuracy: 0.8778\n",
      "Validation Loss: 2.3098, Validation Accuracy: 0.6000\n",
      "Epoch [6/250], Loss: 0.1564, Accuracy: 0.9778\n",
      "Validation Loss: 3.0005, Validation Accuracy: 0.6000\n",
      "Epoch [7/250], Loss: 0.0805, Accuracy: 0.9889\n",
      "Validation Loss: 3.4445, Validation Accuracy: 0.6000\n",
      "Epoch [8/250], Loss: 0.0658, Accuracy: 0.9815\n",
      "Validation Loss: 3.7794, Validation Accuracy: 0.6000\n",
      "Epoch [9/250], Loss: 0.0687, Accuracy: 0.9889\n",
      "Validation Loss: 3.9248, Validation Accuracy: 0.6000\n",
      "Epoch [10/250], Loss: 0.1186, Accuracy: 0.9704\n",
      "Validation Loss: 4.3577, Validation Accuracy: 0.6000\n",
      "Epoch [11/250], Loss: 0.1237, Accuracy: 0.9519\n",
      "Validation Loss: 4.4187, Validation Accuracy: 0.6000\n",
      "Epoch [12/250], Loss: 0.0358, Accuracy: 0.9889\n",
      "Validation Loss: 4.3537, Validation Accuracy: 0.6000\n",
      "Epoch [13/250], Loss: 0.1043, Accuracy: 0.9963\n",
      "Validation Loss: 4.3485, Validation Accuracy: 0.6000\n",
      "Epoch [14/250], Loss: 0.0542, Accuracy: 0.9815\n",
      "Validation Loss: 3.5365, Validation Accuracy: 0.6074\n",
      "Epoch [15/250], Loss: 0.0271, Accuracy: 0.9889\n",
      "Validation Loss: 2.9836, Validation Accuracy: 0.6222\n",
      "Epoch [16/250], Loss: 0.0210, Accuracy: 0.9926\n",
      "Validation Loss: 1.7576, Validation Accuracy: 0.7481\n",
      "Epoch [17/250], Loss: 0.0309, Accuracy: 0.9889\n",
      "Validation Loss: 1.2752, Validation Accuracy: 0.8444\n",
      "Epoch [18/250], Loss: 0.0288, Accuracy: 0.9926\n",
      "Validation Loss: 2.1883, Validation Accuracy: 0.7259\n",
      "Epoch [19/250], Loss: 0.0116, Accuracy: 0.9963\n",
      "Validation Loss: 0.8604, Validation Accuracy: 0.8815\n",
      "Epoch [20/250], Loss: 0.0111, Accuracy: 0.9963\n",
      "Validation Loss: 0.0005, Validation Accuracy: 1.0000\n",
      "Epoch [21/250], Loss: 0.0193, Accuracy: 0.9963\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [22/250], Loss: 0.0333, Accuracy: 0.9963\n",
      "Validation Loss: 3.5583, Validation Accuracy: 0.4815\n",
      "Epoch [23/250], Loss: 0.0109, Accuracy: 0.9963\n",
      "Validation Loss: 0.0040, Validation Accuracy: 0.9926\n",
      "Epoch [24/250], Loss: 0.0081, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [25/250], Loss: 0.0092, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [26/250], Loss: 0.0072, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [27/250], Loss: 0.0047, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [28/250], Loss: 0.0067, Accuracy: 1.0000\n",
      "Validation Loss: 0.3231, Validation Accuracy: 0.9926\n",
      "Epoch [29/250], Loss: 0.0063, Accuracy: 1.0000\n",
      "Validation Loss: 0.3857, Validation Accuracy: 0.9926\n",
      "Epoch [30/250], Loss: 0.0032, Accuracy: 1.0000\n",
      "Validation Loss: 0.0008, Validation Accuracy: 1.0000\n",
      "Epoch [31/250], Loss: 0.0047, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [32/250], Loss: 0.0472, Accuracy: 0.9963\n",
      "Validation Loss: 8.2003, Validation Accuracy: 0.4000\n",
      "Epoch [33/250], Loss: 0.0767, Accuracy: 0.9778\n",
      "Validation Loss: 8.5023, Validation Accuracy: 0.4000\n",
      "Epoch [34/250], Loss: 0.0665, Accuracy: 0.9852\n",
      "Validation Loss: 6.9415, Validation Accuracy: 0.4000\n",
      "Epoch [35/250], Loss: 0.0330, Accuracy: 0.9926\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [36/250], Loss: 0.1266, Accuracy: 0.9926\n",
      "Validation Loss: 0.0002, Validation Accuracy: 1.0000\n",
      "Epoch [37/250], Loss: 0.1466, Accuracy: 0.9741\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [38/250], Loss: 0.0145, Accuracy: 0.9963\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [39/250], Loss: 0.0116, Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [40/250], Loss: 0.0086, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [41/250], Loss: 0.0084, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [42/250], Loss: 0.0981, Accuracy: 0.9815\n",
      "Validation Loss: 5.9793, Validation Accuracy: 0.4074\n",
      "Epoch [43/250], Loss: 0.0158, Accuracy: 0.9926\n",
      "Validation Loss: 5.1682, Validation Accuracy: 0.4000\n",
      "Epoch [44/250], Loss: 0.0170, Accuracy: 0.9926\n",
      "Validation Loss: 1.3811, Validation Accuracy: 0.8000\n",
      "Epoch [45/250], Loss: 0.0133, Accuracy: 1.0000\n",
      "Validation Loss: 0.1167, Validation Accuracy: 0.9778\n",
      "Epoch [46/250], Loss: 0.0104, Accuracy: 0.9963\n",
      "Validation Loss: 0.9762, Validation Accuracy: 0.8963\n",
      "Epoch [47/250], Loss: 0.0252, Accuracy: 0.9889\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [48/250], Loss: 0.0217, Accuracy: 0.9889\n",
      "Validation Loss: 0.0295, Validation Accuracy: 0.9926\n",
      "Epoch [49/250], Loss: 0.0043, Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [50/250], Loss: 0.0241, Accuracy: 0.9963\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [51/250], Loss: 0.0127, Accuracy: 0.9963\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [52/250], Loss: 0.0029, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [53/250], Loss: 0.0653, Accuracy: 0.9963\n",
      "Validation Loss: 0.0349, Validation Accuracy: 0.9926\n",
      "Epoch [54/250], Loss: 0.0850, Accuracy: 0.9815\n",
      "Validation Loss: 2.6923, Validation Accuracy: 0.6519\n",
      "Epoch [55/250], Loss: 0.0112, Accuracy: 0.9926\n",
      "Validation Loss: 0.5244, Validation Accuracy: 0.9630\n",
      "Epoch [56/250], Loss: 0.0304, Accuracy: 0.9926\n",
      "Validation Loss: 0.0741, Validation Accuracy: 0.9926\n",
      "Epoch [57/250], Loss: 0.1905, Accuracy: 0.9741\n",
      "Validation Loss: 0.0007, Validation Accuracy: 1.0000\n",
      "Epoch [58/250], Loss: 0.1527, Accuracy: 0.9815\n",
      "Validation Loss: 0.0239, Validation Accuracy: 0.9926\n",
      "Epoch [59/250], Loss: 0.0435, Accuracy: 0.9852\n",
      "Validation Loss: 0.0027, Validation Accuracy: 1.0000\n",
      "Epoch [60/250], Loss: 0.0104, Accuracy: 1.0000\n",
      "Validation Loss: 0.0415, Validation Accuracy: 0.9778\n",
      "Epoch [61/250], Loss: 0.0079, Accuracy: 1.0000\n",
      "Validation Loss: 0.0045, Validation Accuracy: 0.9926\n",
      "Epoch [62/250], Loss: 0.0138, Accuracy: 0.9963\n",
      "Validation Loss: 0.0004, Validation Accuracy: 1.0000\n",
      "Epoch [63/250], Loss: 0.0044, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [64/250], Loss: 0.0105, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [65/250], Loss: 0.0054, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [66/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [67/250], Loss: 0.0026, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [68/250], Loss: 0.0036, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [69/250], Loss: 0.0039, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [70/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [71/250], Loss: 0.0032, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [72/250], Loss: 0.0022, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [73/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [74/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [75/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [76/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [77/250], Loss: 0.0826, Accuracy: 0.9963\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [78/250], Loss: 0.0756, Accuracy: 0.9889\n",
      "Validation Loss: 0.9186, Validation Accuracy: 0.8296\n",
      "Epoch [79/250], Loss: 0.0105, Accuracy: 0.9963\n",
      "Validation Loss: 6.4339, Validation Accuracy: 0.4074\n",
      "Epoch [80/250], Loss: 0.0103, Accuracy: 0.9963\n",
      "Validation Loss: 5.6705, Validation Accuracy: 0.4074\n",
      "Epoch [81/250], Loss: 0.0240, Accuracy: 1.0000\n",
      "Validation Loss: 6.4074, Validation Accuracy: 0.4074\n",
      "Epoch [82/250], Loss: 0.0089, Accuracy: 1.0000\n",
      "Validation Loss: 5.5334, Validation Accuracy: 0.4074\n",
      "Epoch [83/250], Loss: 0.0020, Accuracy: 1.0000\n",
      "Validation Loss: 0.1446, Validation Accuracy: 0.9630\n",
      "Epoch [84/250], Loss: 0.0149, Accuracy: 0.9963\n",
      "Validation Loss: 6.4070, Validation Accuracy: 0.4074\n",
      "Epoch [85/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 6.6725, Validation Accuracy: 0.4074\n",
      "Epoch [86/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.7510, Validation Accuracy: 0.8741\n",
      "Epoch [87/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [88/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [89/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [90/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [91/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [92/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [93/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [94/250], Loss: 0.0113, Accuracy: 0.9963\n",
      "Validation Loss: 0.4247, Validation Accuracy: 0.9926\n",
      "Epoch [95/250], Loss: 0.0021, Accuracy: 1.0000\n",
      "Validation Loss: 0.3782, Validation Accuracy: 0.9926\n",
      "Epoch [96/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0482, Validation Accuracy: 0.9926\n",
      "Epoch [97/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [98/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [99/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [100/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [101/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [102/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [103/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [104/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [105/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [106/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [107/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [108/250], Loss: 0.0049, Accuracy: 0.9963\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [109/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [110/250], Loss: 0.0162, Accuracy: 0.9963\n",
      "Validation Loss: 0.5504, Validation Accuracy: 0.9926\n",
      "Epoch [111/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [112/250], Loss: 0.0070, Accuracy: 0.9963\n",
      "Validation Loss: 3.6364, Validation Accuracy: 0.5852\n",
      "Epoch [113/250], Loss: 0.0048, Accuracy: 0.9963\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [114/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [115/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [116/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0008, Validation Accuracy: 1.0000\n",
      "Epoch [117/250], Loss: 0.0062, Accuracy: 0.9963\n",
      "Validation Loss: 0.5271, Validation Accuracy: 0.9926\n",
      "Epoch [118/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.4208, Validation Accuracy: 0.9926\n",
      "Epoch [119/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.1090, Validation Accuracy: 0.9926\n",
      "Epoch [120/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0105, Validation Accuracy: 1.0000\n",
      "Epoch [121/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0114, Validation Accuracy: 1.0000\n",
      "Epoch [122/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0040, Validation Accuracy: 1.0000\n",
      "Epoch [123/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.2077, Validation Accuracy: 0.9926\n",
      "Epoch [124/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0020, Validation Accuracy: 1.0000\n",
      "Epoch [125/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0101, Validation Accuracy: 1.0000\n",
      "Epoch [126/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [127/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [128/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [129/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [130/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [131/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [132/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [133/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [134/250], Loss: 0.0230, Accuracy: 0.9963\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [135/250], Loss: 1.1936, Accuracy: 0.9704\n",
      "Validation Loss: 3.3346, Validation Accuracy: 0.6074\n",
      "Epoch [136/250], Loss: 0.3406, Accuracy: 0.8704\n",
      "Validation Loss: 0.1353, Validation Accuracy: 0.9926\n",
      "Epoch [137/250], Loss: 0.0782, Accuracy: 0.9852\n",
      "Validation Loss: 0.0430, Validation Accuracy: 0.9926\n",
      "Epoch [138/250], Loss: 0.0649, Accuracy: 0.9852\n",
      "Validation Loss: 0.2939, Validation Accuracy: 0.9630\n",
      "Epoch [139/250], Loss: 0.0370, Accuracy: 0.9889\n",
      "Validation Loss: 0.3672, Validation Accuracy: 0.9704\n",
      "Epoch [140/250], Loss: 0.0265, Accuracy: 0.9889\n",
      "Validation Loss: 0.1053, Validation Accuracy: 0.9852\n",
      "Epoch [141/250], Loss: 0.0138, Accuracy: 0.9963\n",
      "Validation Loss: 0.0286, Validation Accuracy: 1.0000\n",
      "Epoch [142/250], Loss: 0.0425, Accuracy: 0.9852\n",
      "Validation Loss: 0.1396, Validation Accuracy: 0.9926\n",
      "Epoch [143/250], Loss: 0.0146, Accuracy: 0.9963\n",
      "Validation Loss: 0.0007, Validation Accuracy: 1.0000\n",
      "Epoch [144/250], Loss: 0.0119, Accuracy: 0.9963\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [145/250], Loss: 0.0055, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [146/250], Loss: 0.0555, Accuracy: 0.9926\n",
      "Validation Loss: 0.6951, Validation Accuracy: 0.9259\n",
      "Epoch [147/250], Loss: 0.0127, Accuracy: 0.9963\n",
      "Validation Loss: 0.4600, Validation Accuracy: 0.9852\n",
      "Epoch [148/250], Loss: 0.0080, Accuracy: 1.0000\n",
      "Validation Loss: 0.3554, Validation Accuracy: 0.9926\n",
      "Epoch [149/250], Loss: 0.0079, Accuracy: 0.9963\n",
      "Validation Loss: 0.0006, Validation Accuracy: 1.0000\n",
      "Epoch [150/250], Loss: 0.0044, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [151/250], Loss: 0.0144, Accuracy: 0.9963\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [152/250], Loss: 0.0050, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [153/250], Loss: 0.0025, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [154/250], Loss: 0.0082, Accuracy: 0.9963\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [155/250], Loss: 0.0038, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [156/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [157/250], Loss: 0.0055, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [158/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [159/250], Loss: 0.0038, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [160/250], Loss: 0.0256, Accuracy: 0.9963\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [161/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [162/250], Loss: 0.0053, Accuracy: 0.9963\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [163/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [164/250], Loss: 0.0022, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [165/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [166/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [167/250], Loss: 0.0111, Accuracy: 0.9963\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [168/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [169/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [170/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [171/250], Loss: 0.0018, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [172/250], Loss: 0.0034, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [173/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [174/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [175/250], Loss: 0.0031, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [176/250], Loss: 0.0062, Accuracy: 1.0000\n",
      "Validation Loss: 0.0008, Validation Accuracy: 1.0000\n",
      "Epoch [177/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0266, Validation Accuracy: 1.0000\n",
      "Epoch [178/250], Loss: 0.0014, Accuracy: 1.0000\n",
      "Validation Loss: 0.0001, Validation Accuracy: 1.0000\n",
      "Epoch [179/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [180/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [181/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [182/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [183/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [184/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [185/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [186/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [187/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [188/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [189/250], Loss: 0.0008, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [190/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [191/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [192/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [193/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [194/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [195/250], Loss: 0.0011, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [196/250], Loss: 0.0019, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [197/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [198/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [199/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [200/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [201/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [202/250], Loss: 0.0627, Accuracy: 0.9963\n",
      "Validation Loss: 0.1197, Validation Accuracy: 0.9778\n",
      "Epoch [203/250], Loss: 0.0662, Accuracy: 0.9852\n",
      "Validation Loss: 7.7047, Validation Accuracy: 0.4000\n",
      "Epoch [204/250], Loss: 0.0327, Accuracy: 0.9926\n",
      "Validation Loss: 7.4642, Validation Accuracy: 0.4000\n",
      "Epoch [205/250], Loss: 0.0096, Accuracy: 0.9963\n",
      "Validation Loss: 6.9109, Validation Accuracy: 0.4000\n",
      "Epoch [206/250], Loss: 0.0047, Accuracy: 1.0000\n",
      "Validation Loss: 0.7933, Validation Accuracy: 0.8815\n",
      "Epoch [207/250], Loss: 0.0179, Accuracy: 0.9926\n",
      "Validation Loss: 0.0740, Validation Accuracy: 0.9852\n",
      "Epoch [208/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.0715, Validation Accuracy: 0.9852\n",
      "Epoch [209/250], Loss: 0.0130, Accuracy: 0.9926\n",
      "Validation Loss: 0.7862, Validation Accuracy: 0.9259\n",
      "Epoch [210/250], Loss: 0.0045, Accuracy: 0.9963\n",
      "Validation Loss: 0.0347, Validation Accuracy: 0.9926\n",
      "Epoch [211/250], Loss: 0.0012, Accuracy: 1.0000\n",
      "Validation Loss: 0.4414, Validation Accuracy: 0.9926\n",
      "Epoch [212/250], Loss: 0.0098, Accuracy: 1.0000\n",
      "Validation Loss: 1.2054, Validation Accuracy: 0.9037\n",
      "Epoch [213/250], Loss: 0.0288, Accuracy: 0.9963\n",
      "Validation Loss: 2.6581, Validation Accuracy: 0.7407\n",
      "Epoch [214/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.8421, Validation Accuracy: 0.9407\n",
      "Epoch [215/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.4283, Validation Accuracy: 0.9926\n",
      "Epoch [216/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.0003, Validation Accuracy: 1.0000\n",
      "Epoch [217/250], Loss: 0.0086, Accuracy: 0.9963\n",
      "Validation Loss: 0.5552, Validation Accuracy: 0.9852\n",
      "Epoch [218/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.3704, Validation Accuracy: 0.9926\n",
      "Epoch [219/250], Loss: 0.0023, Accuracy: 1.0000\n",
      "Validation Loss: 0.2152, Validation Accuracy: 0.9926\n",
      "Epoch [220/250], Loss: 0.0043, Accuracy: 0.9963\n",
      "Validation Loss: 0.3827, Validation Accuracy: 0.9926\n",
      "Epoch [221/250], Loss: 0.0028, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [222/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [223/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [224/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [225/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [226/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [227/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [228/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [229/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [230/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [231/250], Loss: 0.0094, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [232/250], Loss: 0.0010, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [233/250], Loss: 0.0197, Accuracy: 0.9926\n",
      "Validation Loss: 0.1829, Validation Accuracy: 0.9926\n",
      "Epoch [234/250], Loss: 0.0046, Accuracy: 0.9963\n",
      "Validation Loss: 0.0227, Validation Accuracy: 0.9926\n",
      "Epoch [235/250], Loss: 0.0013, Accuracy: 1.0000\n",
      "Validation Loss: 0.0011, Validation Accuracy: 1.0000\n",
      "Epoch [236/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [237/250], Loss: 0.0004, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [238/250], Loss: 0.0016, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [239/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [240/250], Loss: 0.0102, Accuracy: 0.9963\n",
      "Validation Loss: 2.6935, Validation Accuracy: 0.7185\n",
      "Epoch [241/250], Loss: 0.0478, Accuracy: 0.9926\n",
      "Validation Loss: 0.1927, Validation Accuracy: 0.9407\n",
      "Epoch [242/250], Loss: 0.0009, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [243/250], Loss: 0.0015, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [244/250], Loss: 0.0006, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [245/250], Loss: 0.0007, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [246/250], Loss: 0.0003, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [247/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [248/250], Loss: 0.0005, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [249/250], Loss: 0.0027, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Epoch [250/250], Loss: 0.0017, Accuracy: 1.0000\n",
      "Validation Loss: 0.0000, Validation Accuracy: 1.0000\n",
      "Test Loss: 0.0000\n",
      "Test Accuracy: 1.0000\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 175\n",
      "label 1 is 84\n",
      "label 2 is 24\n",
      "label 3 is 66\n",
      "Not setting metadata\n",
      "349 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (288, 8, 325)\n",
      "288 train samples\n",
      "144 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.2653508771929824, 0: 0.826647564469914}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.1341, Accuracy: 0.4931\n",
      "Validation Loss: 0.8606, Validation Accuracy: 0.5724\n",
      "Epoch [2/250], Loss: 0.8690, Accuracy: 0.6146\n",
      "Validation Loss: 0.7586, Validation Accuracy: 0.5724\n",
      "Epoch [3/250], Loss: 0.7553, Accuracy: 0.6007\n",
      "Validation Loss: 0.7645, Validation Accuracy: 0.5724\n",
      "Epoch [4/250], Loss: 0.7416, Accuracy: 0.5938\n",
      "Validation Loss: 0.7245, Validation Accuracy: 0.5724\n",
      "Epoch [5/250], Loss: 0.7121, Accuracy: 0.5833\n",
      "Validation Loss: 0.7469, Validation Accuracy: 0.5724\n",
      "Epoch [6/250], Loss: 0.7106, Accuracy: 0.5729\n",
      "Validation Loss: 0.7093, Validation Accuracy: 0.5724\n",
      "Epoch [7/250], Loss: 0.7306, Accuracy: 0.5590\n",
      "Validation Loss: 0.7005, Validation Accuracy: 0.5724\n",
      "Epoch [8/250], Loss: 0.6791, Accuracy: 0.6319\n",
      "Validation Loss: 0.7060, Validation Accuracy: 0.5724\n",
      "Epoch [9/250], Loss: 0.7072, Accuracy: 0.6076\n",
      "Validation Loss: 0.6980, Validation Accuracy: 0.5724\n",
      "Epoch [10/250], Loss: 0.6965, Accuracy: 0.6042\n",
      "Validation Loss: 0.7281, Validation Accuracy: 0.5724\n",
      "Epoch [11/250], Loss: 0.7190, Accuracy: 0.5938\n",
      "Validation Loss: 0.7042, Validation Accuracy: 0.5724\n",
      "Epoch [12/250], Loss: 0.6867, Accuracy: 0.5764\n",
      "Validation Loss: 0.7353, Validation Accuracy: 0.5724\n",
      "Epoch [13/250], Loss: 0.6774, Accuracy: 0.6181\n",
      "Validation Loss: 0.6924, Validation Accuracy: 0.5793\n",
      "Epoch [14/250], Loss: 0.6425, Accuracy: 0.6458\n",
      "Validation Loss: 0.6875, Validation Accuracy: 0.5655\n",
      "Epoch [15/250], Loss: 0.6595, Accuracy: 0.6354\n",
      "Validation Loss: 0.7672, Validation Accuracy: 0.5931\n",
      "Epoch [16/250], Loss: 0.6549, Accuracy: 0.6042\n",
      "Validation Loss: 0.6452, Validation Accuracy: 0.6483\n",
      "Epoch [17/250], Loss: 0.5947, Accuracy: 0.6736\n",
      "Validation Loss: 1.1275, Validation Accuracy: 0.5931\n",
      "Epoch [18/250], Loss: 0.5512, Accuracy: 0.7049\n",
      "Validation Loss: 1.5613, Validation Accuracy: 0.5793\n",
      "Epoch [19/250], Loss: 0.5722, Accuracy: 0.7326\n",
      "Validation Loss: 1.6186, Validation Accuracy: 0.5862\n",
      "Epoch [20/250], Loss: 0.5583, Accuracy: 0.7188\n",
      "Validation Loss: 1.7794, Validation Accuracy: 0.5724\n",
      "Epoch [21/250], Loss: 0.4879, Accuracy: 0.7674\n",
      "Validation Loss: 2.0155, Validation Accuracy: 0.5724\n",
      "Epoch [22/250], Loss: 0.4218, Accuracy: 0.8160\n",
      "Validation Loss: 2.0400, Validation Accuracy: 0.5724\n",
      "Epoch [23/250], Loss: 0.3794, Accuracy: 0.8056\n",
      "Validation Loss: 1.3867, Validation Accuracy: 0.6207\n",
      "Epoch [24/250], Loss: 0.4407, Accuracy: 0.7986\n",
      "Validation Loss: 1.1298, Validation Accuracy: 0.6276\n",
      "Epoch [25/250], Loss: 0.4749, Accuracy: 0.7535\n",
      "Validation Loss: 2.1410, Validation Accuracy: 0.5724\n",
      "Epoch [26/250], Loss: 0.4842, Accuracy: 0.7535\n",
      "Validation Loss: 1.5850, Validation Accuracy: 0.5793\n",
      "Epoch [27/250], Loss: 0.4088, Accuracy: 0.7986\n",
      "Validation Loss: 0.6904, Validation Accuracy: 0.6966\n",
      "Epoch [28/250], Loss: 0.4098, Accuracy: 0.8264\n",
      "Validation Loss: 2.1751, Validation Accuracy: 0.5724\n",
      "Epoch [29/250], Loss: 0.4120, Accuracy: 0.8056\n",
      "Validation Loss: 2.4407, Validation Accuracy: 0.5724\n",
      "Epoch [30/250], Loss: 0.4161, Accuracy: 0.8056\n",
      "Validation Loss: 0.5290, Validation Accuracy: 0.7517\n",
      "Epoch [31/250], Loss: 0.4191, Accuracy: 0.8299\n",
      "Validation Loss: 2.4216, Validation Accuracy: 0.5724\n",
      "Epoch [32/250], Loss: 0.3894, Accuracy: 0.8090\n",
      "Validation Loss: 2.3745, Validation Accuracy: 0.5724\n",
      "Epoch [33/250], Loss: 0.3771, Accuracy: 0.8438\n",
      "Validation Loss: 1.1370, Validation Accuracy: 0.6276\n",
      "Epoch [34/250], Loss: 0.4055, Accuracy: 0.8021\n",
      "Validation Loss: 1.0711, Validation Accuracy: 0.6483\n",
      "Epoch [35/250], Loss: 0.3950, Accuracy: 0.8368\n",
      "Validation Loss: 2.1873, Validation Accuracy: 0.5724\n",
      "Epoch [36/250], Loss: 0.4389, Accuracy: 0.7847\n",
      "Validation Loss: 0.4699, Validation Accuracy: 0.8069\n",
      "Epoch [37/250], Loss: 0.3911, Accuracy: 0.8333\n",
      "Validation Loss: 0.5801, Validation Accuracy: 0.7931\n",
      "Epoch [38/250], Loss: 0.4065, Accuracy: 0.8056\n",
      "Validation Loss: 0.3861, Validation Accuracy: 0.8207\n",
      "Epoch [39/250], Loss: 0.3794, Accuracy: 0.8299\n",
      "Validation Loss: 0.5362, Validation Accuracy: 0.7931\n",
      "Epoch [40/250], Loss: 0.3628, Accuracy: 0.8299\n",
      "Validation Loss: 0.4166, Validation Accuracy: 0.8276\n",
      "Epoch [41/250], Loss: 0.3505, Accuracy: 0.8299\n",
      "Validation Loss: 0.9239, Validation Accuracy: 0.6345\n",
      "Epoch [42/250], Loss: 0.3355, Accuracy: 0.8542\n",
      "Validation Loss: 0.5376, Validation Accuracy: 0.8000\n",
      "Epoch [43/250], Loss: 0.3389, Accuracy: 0.8333\n",
      "Validation Loss: 1.5954, Validation Accuracy: 0.4966\n",
      "Epoch [44/250], Loss: 0.3945, Accuracy: 0.8403\n",
      "Validation Loss: 0.5013, Validation Accuracy: 0.8138\n",
      "Epoch [45/250], Loss: 0.3444, Accuracy: 0.8438\n",
      "Validation Loss: 0.5160, Validation Accuracy: 0.8000\n",
      "Epoch [46/250], Loss: 0.3357, Accuracy: 0.8576\n",
      "Validation Loss: 0.9465, Validation Accuracy: 0.6828\n",
      "Epoch [47/250], Loss: 0.3550, Accuracy: 0.8438\n",
      "Validation Loss: 0.3872, Validation Accuracy: 0.8207\n",
      "Epoch [48/250], Loss: 0.3403, Accuracy: 0.8403\n",
      "Validation Loss: 0.5741, Validation Accuracy: 0.7931\n",
      "Epoch [49/250], Loss: 0.3227, Accuracy: 0.8611\n",
      "Validation Loss: 0.4118, Validation Accuracy: 0.8276\n",
      "Epoch [50/250], Loss: 0.3938, Accuracy: 0.8438\n",
      "Validation Loss: 0.3951, Validation Accuracy: 0.8207\n",
      "Epoch [51/250], Loss: 0.3370, Accuracy: 0.8438\n",
      "Validation Loss: 0.4067, Validation Accuracy: 0.8138\n",
      "Epoch [52/250], Loss: 0.3035, Accuracy: 0.8576\n",
      "Validation Loss: 0.4058, Validation Accuracy: 0.8345\n",
      "Epoch [53/250], Loss: 0.2777, Accuracy: 0.8819\n",
      "Validation Loss: 0.6648, Validation Accuracy: 0.8069\n",
      "Epoch [54/250], Loss: 0.3082, Accuracy: 0.8681\n",
      "Validation Loss: 0.6653, Validation Accuracy: 0.7862\n",
      "Epoch [55/250], Loss: 0.4013, Accuracy: 0.8472\n",
      "Validation Loss: 0.4484, Validation Accuracy: 0.8207\n",
      "Epoch [56/250], Loss: 0.3585, Accuracy: 0.8333\n",
      "Validation Loss: 1.8308, Validation Accuracy: 0.5724\n",
      "Epoch [57/250], Loss: 0.3887, Accuracy: 0.8264\n",
      "Validation Loss: 2.2446, Validation Accuracy: 0.5655\n",
      "Epoch [58/250], Loss: 0.3479, Accuracy: 0.8472\n",
      "Validation Loss: 0.6552, Validation Accuracy: 0.7448\n",
      "Epoch [59/250], Loss: 0.3064, Accuracy: 0.8646\n",
      "Validation Loss: 0.5017, Validation Accuracy: 0.8345\n",
      "Epoch [60/250], Loss: 0.3087, Accuracy: 0.8542\n",
      "Validation Loss: 0.7400, Validation Accuracy: 0.7448\n",
      "Epoch [61/250], Loss: 0.3214, Accuracy: 0.8368\n",
      "Validation Loss: 0.7750, Validation Accuracy: 0.7586\n",
      "Epoch [62/250], Loss: 0.2817, Accuracy: 0.8854\n",
      "Validation Loss: 1.0629, Validation Accuracy: 0.7241\n",
      "Epoch [63/250], Loss: 0.3369, Accuracy: 0.8785\n",
      "Validation Loss: 0.6815, Validation Accuracy: 0.8000\n",
      "Epoch [64/250], Loss: 0.3011, Accuracy: 0.8715\n",
      "Validation Loss: 0.6906, Validation Accuracy: 0.8069\n",
      "Epoch [65/250], Loss: 0.2862, Accuracy: 0.8819\n",
      "Validation Loss: 1.5151, Validation Accuracy: 0.7034\n",
      "Epoch [66/250], Loss: 0.2842, Accuracy: 0.8854\n",
      "Validation Loss: 1.1409, Validation Accuracy: 0.7310\n",
      "Epoch [67/250], Loss: 0.3374, Accuracy: 0.8646\n",
      "Validation Loss: 0.4571, Validation Accuracy: 0.8138\n",
      "Epoch [68/250], Loss: 0.3115, Accuracy: 0.8576\n",
      "Validation Loss: 0.3660, Validation Accuracy: 0.8414\n",
      "Epoch [69/250], Loss: 0.2942, Accuracy: 0.8611\n",
      "Validation Loss: 2.1077, Validation Accuracy: 0.5862\n",
      "Epoch [70/250], Loss: 0.2835, Accuracy: 0.8646\n",
      "Validation Loss: 0.3191, Validation Accuracy: 0.8621\n",
      "Epoch [71/250], Loss: 0.2443, Accuracy: 0.9062\n",
      "Validation Loss: 0.4263, Validation Accuracy: 0.8345\n",
      "Epoch [72/250], Loss: 0.3210, Accuracy: 0.8958\n",
      "Validation Loss: 0.5256, Validation Accuracy: 0.8276\n",
      "Epoch [73/250], Loss: 0.3482, Accuracy: 0.8472\n",
      "Validation Loss: 0.4383, Validation Accuracy: 0.8276\n",
      "Epoch [74/250], Loss: 0.3238, Accuracy: 0.8403\n",
      "Validation Loss: 0.3973, Validation Accuracy: 0.8552\n",
      "Epoch [75/250], Loss: 0.3161, Accuracy: 0.8681\n",
      "Validation Loss: 1.7574, Validation Accuracy: 0.6138\n",
      "Epoch [76/250], Loss: 0.2771, Accuracy: 0.8958\n",
      "Validation Loss: 0.6292, Validation Accuracy: 0.8138\n",
      "Epoch [77/250], Loss: 0.2489, Accuracy: 0.8993\n",
      "Validation Loss: 0.7613, Validation Accuracy: 0.7931\n",
      "Epoch [78/250], Loss: 0.2689, Accuracy: 0.8889\n",
      "Validation Loss: 0.7131, Validation Accuracy: 0.8138\n",
      "Epoch [79/250], Loss: 0.2388, Accuracy: 0.8854\n",
      "Validation Loss: 0.8368, Validation Accuracy: 0.7931\n",
      "Epoch [80/250], Loss: 0.2964, Accuracy: 0.8681\n",
      "Validation Loss: 1.2292, Validation Accuracy: 0.6897\n",
      "Epoch [81/250], Loss: 0.2303, Accuracy: 0.8958\n",
      "Validation Loss: 1.2999, Validation Accuracy: 0.6966\n",
      "Epoch [82/250], Loss: 0.2384, Accuracy: 0.8958\n",
      "Validation Loss: 1.0064, Validation Accuracy: 0.7517\n",
      "Epoch [83/250], Loss: 0.2097, Accuracy: 0.9097\n",
      "Validation Loss: 0.9583, Validation Accuracy: 0.7793\n",
      "Epoch [84/250], Loss: 0.3049, Accuracy: 0.8854\n",
      "Validation Loss: 1.3427, Validation Accuracy: 0.6690\n",
      "Epoch [85/250], Loss: 0.2971, Accuracy: 0.8646\n",
      "Validation Loss: 0.7377, Validation Accuracy: 0.7862\n",
      "Epoch [86/250], Loss: 0.2525, Accuracy: 0.8750\n",
      "Validation Loss: 0.7874, Validation Accuracy: 0.7931\n",
      "Epoch [87/250], Loss: 0.2826, Accuracy: 0.8819\n",
      "Validation Loss: 0.8637, Validation Accuracy: 0.7862\n",
      "Epoch [88/250], Loss: 0.2802, Accuracy: 0.8819\n",
      "Validation Loss: 0.6075, Validation Accuracy: 0.8414\n",
      "Epoch [89/250], Loss: 0.2376, Accuracy: 0.9167\n",
      "Validation Loss: 0.9557, Validation Accuracy: 0.7793\n",
      "Epoch [90/250], Loss: 0.2301, Accuracy: 0.9097\n",
      "Validation Loss: 1.1004, Validation Accuracy: 0.7655\n",
      "Epoch [91/250], Loss: 0.1940, Accuracy: 0.9097\n",
      "Validation Loss: 0.6023, Validation Accuracy: 0.8276\n",
      "Epoch [92/250], Loss: 0.2572, Accuracy: 0.9028\n",
      "Validation Loss: 0.6025, Validation Accuracy: 0.8483\n",
      "Epoch [93/250], Loss: 0.2074, Accuracy: 0.8958\n",
      "Validation Loss: 0.7384, Validation Accuracy: 0.8207\n",
      "Epoch [94/250], Loss: 0.2367, Accuracy: 0.9167\n",
      "Validation Loss: 2.1782, Validation Accuracy: 0.6138\n",
      "Epoch [95/250], Loss: 0.1880, Accuracy: 0.9167\n",
      "Validation Loss: 0.7373, Validation Accuracy: 0.8276\n",
      "Epoch [96/250], Loss: 0.3117, Accuracy: 0.8785\n",
      "Validation Loss: 1.3032, Validation Accuracy: 0.6966\n",
      "Epoch [97/250], Loss: 0.2255, Accuracy: 0.9062\n",
      "Validation Loss: 0.6736, Validation Accuracy: 0.7862\n",
      "Epoch [98/250], Loss: 0.2484, Accuracy: 0.8819\n",
      "Validation Loss: 0.7608, Validation Accuracy: 0.8207\n",
      "Epoch [99/250], Loss: 0.2224, Accuracy: 0.9062\n",
      "Validation Loss: 1.0453, Validation Accuracy: 0.7862\n",
      "Epoch [100/250], Loss: 0.2235, Accuracy: 0.9132\n",
      "Validation Loss: 0.5970, Validation Accuracy: 0.8552\n",
      "Epoch [101/250], Loss: 0.2296, Accuracy: 0.9062\n",
      "Validation Loss: 0.6834, Validation Accuracy: 0.8207\n",
      "Epoch [102/250], Loss: 0.2109, Accuracy: 0.9167\n",
      "Validation Loss: 1.5737, Validation Accuracy: 0.7103\n",
      "Epoch [103/250], Loss: 0.2411, Accuracy: 0.9167\n",
      "Validation Loss: 1.2234, Validation Accuracy: 0.7172\n",
      "Epoch [104/250], Loss: 0.2187, Accuracy: 0.9097\n",
      "Validation Loss: 0.9246, Validation Accuracy: 0.7655\n",
      "Epoch [105/250], Loss: 0.2116, Accuracy: 0.9132\n",
      "Validation Loss: 0.7092, Validation Accuracy: 0.8483\n",
      "Epoch [106/250], Loss: 0.2262, Accuracy: 0.8958\n",
      "Validation Loss: 1.2905, Validation Accuracy: 0.7655\n",
      "Epoch [107/250], Loss: 0.2081, Accuracy: 0.9201\n",
      "Validation Loss: 1.5040, Validation Accuracy: 0.7448\n",
      "Epoch [108/250], Loss: 0.2375, Accuracy: 0.9097\n",
      "Validation Loss: 0.5580, Validation Accuracy: 0.8552\n",
      "Epoch [109/250], Loss: 0.2082, Accuracy: 0.9201\n",
      "Validation Loss: 0.6411, Validation Accuracy: 0.8207\n",
      "Epoch [110/250], Loss: 0.2152, Accuracy: 0.9028\n",
      "Validation Loss: 0.7531, Validation Accuracy: 0.8138\n",
      "Epoch [111/250], Loss: 0.1865, Accuracy: 0.9167\n",
      "Validation Loss: 2.7839, Validation Accuracy: 0.6276\n",
      "Epoch [112/250], Loss: 0.2528, Accuracy: 0.8924\n",
      "Validation Loss: 1.2239, Validation Accuracy: 0.7172\n",
      "Epoch [113/250], Loss: 0.1993, Accuracy: 0.9132\n",
      "Validation Loss: 0.6108, Validation Accuracy: 0.8759\n",
      "Epoch [114/250], Loss: 0.2135, Accuracy: 0.9167\n",
      "Validation Loss: 1.1773, Validation Accuracy: 0.7448\n",
      "Epoch [115/250], Loss: 0.2087, Accuracy: 0.9201\n",
      "Validation Loss: 1.9705, Validation Accuracy: 0.6552\n",
      "Epoch [116/250], Loss: 0.1922, Accuracy: 0.9201\n",
      "Validation Loss: 0.6606, Validation Accuracy: 0.8276\n",
      "Epoch [117/250], Loss: 0.1988, Accuracy: 0.9340\n",
      "Validation Loss: 1.0425, Validation Accuracy: 0.7517\n",
      "Epoch [118/250], Loss: 0.1969, Accuracy: 0.9167\n",
      "Validation Loss: 1.0506, Validation Accuracy: 0.7517\n",
      "Epoch [119/250], Loss: 0.2061, Accuracy: 0.9132\n",
      "Validation Loss: 0.4863, Validation Accuracy: 0.8621\n",
      "Epoch [120/250], Loss: 0.2256, Accuracy: 0.8924\n",
      "Validation Loss: 0.9329, Validation Accuracy: 0.7655\n",
      "Epoch [121/250], Loss: 0.2656, Accuracy: 0.8889\n",
      "Validation Loss: 1.5222, Validation Accuracy: 0.7172\n",
      "Epoch [122/250], Loss: 0.2199, Accuracy: 0.9062\n",
      "Validation Loss: 0.6353, Validation Accuracy: 0.8414\n",
      "Epoch [123/250], Loss: 0.1934, Accuracy: 0.9062\n",
      "Validation Loss: 1.3507, Validation Accuracy: 0.7793\n",
      "Epoch [124/250], Loss: 0.1627, Accuracy: 0.9375\n",
      "Validation Loss: 0.9295, Validation Accuracy: 0.7931\n",
      "Epoch [125/250], Loss: 0.1597, Accuracy: 0.9444\n",
      "Validation Loss: 4.0259, Validation Accuracy: 0.5862\n",
      "Epoch [126/250], Loss: 0.1926, Accuracy: 0.9236\n",
      "Validation Loss: 0.6683, Validation Accuracy: 0.8345\n",
      "Epoch [127/250], Loss: 0.1948, Accuracy: 0.9306\n",
      "Validation Loss: 0.6141, Validation Accuracy: 0.8690\n",
      "Epoch [128/250], Loss: 0.2047, Accuracy: 0.9271\n",
      "Validation Loss: 1.0767, Validation Accuracy: 0.7724\n",
      "Epoch [129/250], Loss: 0.2198, Accuracy: 0.9167\n",
      "Validation Loss: 0.5420, Validation Accuracy: 0.8621\n",
      "Epoch [130/250], Loss: 0.2278, Accuracy: 0.9306\n",
      "Validation Loss: 1.2184, Validation Accuracy: 0.7103\n",
      "Epoch [131/250], Loss: 0.2467, Accuracy: 0.8854\n",
      "Validation Loss: 0.9110, Validation Accuracy: 0.7724\n",
      "Epoch [132/250], Loss: 0.1860, Accuracy: 0.9167\n",
      "Validation Loss: 0.6122, Validation Accuracy: 0.8552\n",
      "Epoch [133/250], Loss: 0.1748, Accuracy: 0.9444\n",
      "Validation Loss: 1.3150, Validation Accuracy: 0.7793\n",
      "Epoch [134/250], Loss: 0.2358, Accuracy: 0.9062\n",
      "Validation Loss: 0.8526, Validation Accuracy: 0.7724\n",
      "Epoch [135/250], Loss: 0.2073, Accuracy: 0.9271\n",
      "Validation Loss: 0.9776, Validation Accuracy: 0.8069\n",
      "Epoch [136/250], Loss: 0.1892, Accuracy: 0.9306\n",
      "Validation Loss: 0.6398, Validation Accuracy: 0.8345\n",
      "Epoch [137/250], Loss: 0.1377, Accuracy: 0.9479\n",
      "Validation Loss: 1.6674, Validation Accuracy: 0.7655\n",
      "Epoch [138/250], Loss: 0.1557, Accuracy: 0.9375\n",
      "Validation Loss: 1.4405, Validation Accuracy: 0.8000\n",
      "Epoch [139/250], Loss: 0.1537, Accuracy: 0.9271\n",
      "Validation Loss: 0.8425, Validation Accuracy: 0.8414\n",
      "Epoch [140/250], Loss: 0.2020, Accuracy: 0.9306\n",
      "Validation Loss: 1.2302, Validation Accuracy: 0.7379\n",
      "Epoch [141/250], Loss: 0.2539, Accuracy: 0.9028\n",
      "Validation Loss: 0.5559, Validation Accuracy: 0.8414\n",
      "Epoch [142/250], Loss: 0.2182, Accuracy: 0.8993\n",
      "Validation Loss: 0.6471, Validation Accuracy: 0.8483\n",
      "Epoch [143/250], Loss: 0.1456, Accuracy: 0.9479\n",
      "Validation Loss: 0.6796, Validation Accuracy: 0.8759\n",
      "Epoch [144/250], Loss: 0.1555, Accuracy: 0.9271\n",
      "Validation Loss: 1.3692, Validation Accuracy: 0.7448\n",
      "Epoch [145/250], Loss: 0.1533, Accuracy: 0.9271\n",
      "Validation Loss: 2.0178, Validation Accuracy: 0.6483\n",
      "Epoch [146/250], Loss: 0.1719, Accuracy: 0.9410\n",
      "Validation Loss: 2.0712, Validation Accuracy: 0.6828\n",
      "Epoch [147/250], Loss: 0.2169, Accuracy: 0.9201\n",
      "Validation Loss: 3.0079, Validation Accuracy: 0.5931\n",
      "Epoch [148/250], Loss: 0.1427, Accuracy: 0.9444\n",
      "Validation Loss: 1.4996, Validation Accuracy: 0.7517\n",
      "Epoch [149/250], Loss: 0.1973, Accuracy: 0.9271\n",
      "Validation Loss: 2.7287, Validation Accuracy: 0.6207\n",
      "Epoch [150/250], Loss: 0.1976, Accuracy: 0.9306\n",
      "Validation Loss: 0.7834, Validation Accuracy: 0.7931\n",
      "Epoch [151/250], Loss: 0.1842, Accuracy: 0.9375\n",
      "Validation Loss: 0.5884, Validation Accuracy: 0.8621\n",
      "Epoch [152/250], Loss: 0.1700, Accuracy: 0.9306\n",
      "Validation Loss: 0.7891, Validation Accuracy: 0.8414\n",
      "Epoch [153/250], Loss: 0.1244, Accuracy: 0.9444\n",
      "Validation Loss: 0.8057, Validation Accuracy: 0.8759\n",
      "Epoch [154/250], Loss: 0.1735, Accuracy: 0.9306\n",
      "Validation Loss: 1.6154, Validation Accuracy: 0.7517\n",
      "Epoch [155/250], Loss: 0.1627, Accuracy: 0.9410\n",
      "Validation Loss: 0.6303, Validation Accuracy: 0.8483\n",
      "Epoch [156/250], Loss: 0.1395, Accuracy: 0.9306\n",
      "Validation Loss: 0.6559, Validation Accuracy: 0.8414\n",
      "Epoch [157/250], Loss: 0.1591, Accuracy: 0.9340\n",
      "Validation Loss: 2.2626, Validation Accuracy: 0.7034\n",
      "Epoch [158/250], Loss: 0.1256, Accuracy: 0.9444\n",
      "Validation Loss: 1.6086, Validation Accuracy: 0.7724\n",
      "Epoch [159/250], Loss: 0.1829, Accuracy: 0.9306\n",
      "Validation Loss: 1.4007, Validation Accuracy: 0.8000\n",
      "Epoch [160/250], Loss: 0.1300, Accuracy: 0.9479\n",
      "Validation Loss: 1.0108, Validation Accuracy: 0.8276\n",
      "Epoch [161/250], Loss: 0.1765, Accuracy: 0.9375\n",
      "Validation Loss: 1.4683, Validation Accuracy: 0.7862\n",
      "Epoch [162/250], Loss: 0.1367, Accuracy: 0.9479\n",
      "Validation Loss: 1.5093, Validation Accuracy: 0.7862\n",
      "Epoch [163/250], Loss: 0.1538, Accuracy: 0.9514\n",
      "Validation Loss: 1.0555, Validation Accuracy: 0.8207\n",
      "Epoch [164/250], Loss: 0.1793, Accuracy: 0.9306\n",
      "Validation Loss: 1.4400, Validation Accuracy: 0.7655\n",
      "Epoch [165/250], Loss: 0.1288, Accuracy: 0.9479\n",
      "Validation Loss: 1.7366, Validation Accuracy: 0.7793\n",
      "Epoch [166/250], Loss: 0.1578, Accuracy: 0.9375\n",
      "Validation Loss: 4.0577, Validation Accuracy: 0.5862\n",
      "Epoch [167/250], Loss: 0.1616, Accuracy: 0.9271\n",
      "Validation Loss: 1.7291, Validation Accuracy: 0.7724\n",
      "Epoch [168/250], Loss: 0.1822, Accuracy: 0.9201\n",
      "Validation Loss: 1.4222, Validation Accuracy: 0.7034\n",
      "Epoch [169/250], Loss: 0.1593, Accuracy: 0.9410\n",
      "Validation Loss: 0.8754, Validation Accuracy: 0.8000\n",
      "Epoch [170/250], Loss: 0.2071, Accuracy: 0.9201\n",
      "Validation Loss: 1.3519, Validation Accuracy: 0.7379\n",
      "Epoch [171/250], Loss: 0.1481, Accuracy: 0.9410\n",
      "Validation Loss: 0.6933, Validation Accuracy: 0.8483\n",
      "Epoch [172/250], Loss: 0.1313, Accuracy: 0.9479\n",
      "Validation Loss: 1.6071, Validation Accuracy: 0.7448\n",
      "Epoch [173/250], Loss: 0.1230, Accuracy: 0.9549\n",
      "Validation Loss: 0.8438, Validation Accuracy: 0.8138\n",
      "Epoch [174/250], Loss: 0.1549, Accuracy: 0.9514\n",
      "Validation Loss: 0.9034, Validation Accuracy: 0.8000\n",
      "Epoch [175/250], Loss: 0.1850, Accuracy: 0.9236\n",
      "Validation Loss: 1.1110, Validation Accuracy: 0.7931\n",
      "Epoch [176/250], Loss: 0.1861, Accuracy: 0.9167\n",
      "Validation Loss: 1.3997, Validation Accuracy: 0.7724\n",
      "Epoch [177/250], Loss: 0.1776, Accuracy: 0.9271\n",
      "Validation Loss: 4.5395, Validation Accuracy: 0.5724\n",
      "Epoch [178/250], Loss: 0.1458, Accuracy: 0.9444\n",
      "Validation Loss: 0.6010, Validation Accuracy: 0.8759\n",
      "Epoch [179/250], Loss: 0.1455, Accuracy: 0.9549\n",
      "Validation Loss: 0.9475, Validation Accuracy: 0.8069\n",
      "Epoch [180/250], Loss: 0.1209, Accuracy: 0.9549\n",
      "Validation Loss: 0.6539, Validation Accuracy: 0.8966\n",
      "Epoch [181/250], Loss: 0.1248, Accuracy: 0.9479\n",
      "Validation Loss: 0.5965, Validation Accuracy: 0.8897\n",
      "Epoch [182/250], Loss: 0.1419, Accuracy: 0.9444\n",
      "Validation Loss: 0.4986, Validation Accuracy: 0.8759\n",
      "Epoch [183/250], Loss: 0.1533, Accuracy: 0.9271\n",
      "Validation Loss: 0.7547, Validation Accuracy: 0.8069\n",
      "Epoch [184/250], Loss: 0.1450, Accuracy: 0.9444\n",
      "Validation Loss: 0.5513, Validation Accuracy: 0.8414\n",
      "Epoch [185/250], Loss: 0.1595, Accuracy: 0.9340\n",
      "Validation Loss: 0.7505, Validation Accuracy: 0.8345\n",
      "Epoch [186/250], Loss: 0.1724, Accuracy: 0.9410\n",
      "Validation Loss: 0.7057, Validation Accuracy: 0.8414\n",
      "Epoch [187/250], Loss: 0.2055, Accuracy: 0.9375\n",
      "Validation Loss: 1.4678, Validation Accuracy: 0.6621\n",
      "Epoch [188/250], Loss: 0.1831, Accuracy: 0.9271\n",
      "Validation Loss: 0.7915, Validation Accuracy: 0.8207\n",
      "Epoch [189/250], Loss: 0.1439, Accuracy: 0.9375\n",
      "Validation Loss: 0.9434, Validation Accuracy: 0.8000\n",
      "Epoch [190/250], Loss: 0.1656, Accuracy: 0.9201\n",
      "Validation Loss: 1.0010, Validation Accuracy: 0.7931\n",
      "Epoch [191/250], Loss: 0.2061, Accuracy: 0.9410\n",
      "Validation Loss: 0.5678, Validation Accuracy: 0.8276\n",
      "Epoch [192/250], Loss: 0.2325, Accuracy: 0.8958\n",
      "Validation Loss: 0.5785, Validation Accuracy: 0.8345\n",
      "Epoch [193/250], Loss: 0.1749, Accuracy: 0.9271\n",
      "Validation Loss: 0.5562, Validation Accuracy: 0.8276\n",
      "Epoch [194/250], Loss: 0.1626, Accuracy: 0.9340\n",
      "Validation Loss: 0.8753, Validation Accuracy: 0.7793\n",
      "Epoch [195/250], Loss: 0.1366, Accuracy: 0.9410\n",
      "Validation Loss: 0.6631, Validation Accuracy: 0.8345\n",
      "Epoch [196/250], Loss: 0.1323, Accuracy: 0.9410\n",
      "Validation Loss: 2.9885, Validation Accuracy: 0.6138\n",
      "Epoch [197/250], Loss: 0.1562, Accuracy: 0.9444\n",
      "Validation Loss: 1.6796, Validation Accuracy: 0.7655\n",
      "Epoch [198/250], Loss: 0.1339, Accuracy: 0.9479\n",
      "Validation Loss: 1.5202, Validation Accuracy: 0.7793\n",
      "Epoch [199/250], Loss: 0.1326, Accuracy: 0.9514\n",
      "Validation Loss: 0.6335, Validation Accuracy: 0.8552\n",
      "Epoch [200/250], Loss: 0.1410, Accuracy: 0.9340\n",
      "Validation Loss: 1.0390, Validation Accuracy: 0.7931\n",
      "Epoch [201/250], Loss: 0.1075, Accuracy: 0.9688\n",
      "Validation Loss: 0.5196, Validation Accuracy: 0.8552\n",
      "Epoch [202/250], Loss: 0.1711, Accuracy: 0.9410\n",
      "Validation Loss: 1.0116, Validation Accuracy: 0.8000\n",
      "Epoch [203/250], Loss: 0.1324, Accuracy: 0.9549\n",
      "Validation Loss: 0.9923, Validation Accuracy: 0.7862\n",
      "Epoch [204/250], Loss: 0.1781, Accuracy: 0.9479\n",
      "Validation Loss: 0.8292, Validation Accuracy: 0.8207\n",
      "Epoch [205/250], Loss: 0.1210, Accuracy: 0.9479\n",
      "Validation Loss: 0.6715, Validation Accuracy: 0.8690\n",
      "Epoch [206/250], Loss: 0.1102, Accuracy: 0.9514\n",
      "Validation Loss: 0.7780, Validation Accuracy: 0.8759\n",
      "Epoch [207/250], Loss: 0.1080, Accuracy: 0.9618\n",
      "Validation Loss: 2.3153, Validation Accuracy: 0.7034\n",
      "Epoch [208/250], Loss: 0.1319, Accuracy: 0.9479\n",
      "Validation Loss: 1.0931, Validation Accuracy: 0.7586\n",
      "Epoch [209/250], Loss: 0.1409, Accuracy: 0.9479\n",
      "Validation Loss: 1.3801, Validation Accuracy: 0.7517\n",
      "Epoch [210/250], Loss: 0.1370, Accuracy: 0.9444\n",
      "Validation Loss: 1.2741, Validation Accuracy: 0.7724\n",
      "Epoch [211/250], Loss: 0.1007, Accuracy: 0.9653\n",
      "Validation Loss: 0.6891, Validation Accuracy: 0.8207\n",
      "Epoch [212/250], Loss: 0.1500, Accuracy: 0.9375\n",
      "Validation Loss: 0.5257, Validation Accuracy: 0.8138\n",
      "Epoch [213/250], Loss: 0.1192, Accuracy: 0.9444\n",
      "Validation Loss: 1.6953, Validation Accuracy: 0.7655\n",
      "Epoch [214/250], Loss: 0.1316, Accuracy: 0.9306\n",
      "Validation Loss: 0.7513, Validation Accuracy: 0.8621\n",
      "Epoch [215/250], Loss: 0.1397, Accuracy: 0.9653\n",
      "Validation Loss: 0.6812, Validation Accuracy: 0.8414\n",
      "Epoch [216/250], Loss: 0.1332, Accuracy: 0.9410\n",
      "Validation Loss: 0.7707, Validation Accuracy: 0.8207\n",
      "Epoch [217/250], Loss: 0.0940, Accuracy: 0.9618\n",
      "Validation Loss: 0.7347, Validation Accuracy: 0.8621\n",
      "Epoch [218/250], Loss: 0.1862, Accuracy: 0.9271\n",
      "Validation Loss: 0.9229, Validation Accuracy: 0.8345\n",
      "Epoch [219/250], Loss: 0.1292, Accuracy: 0.9444\n",
      "Validation Loss: 0.9120, Validation Accuracy: 0.8276\n",
      "Epoch [220/250], Loss: 0.2096, Accuracy: 0.9167\n",
      "Validation Loss: 1.0271, Validation Accuracy: 0.7448\n",
      "Epoch [221/250], Loss: 0.1245, Accuracy: 0.9514\n",
      "Validation Loss: 0.8941, Validation Accuracy: 0.8483\n",
      "Epoch [222/250], Loss: 0.0947, Accuracy: 0.9722\n",
      "Validation Loss: 1.0953, Validation Accuracy: 0.8207\n",
      "Epoch [223/250], Loss: 0.1170, Accuracy: 0.9549\n",
      "Validation Loss: 1.1831, Validation Accuracy: 0.8276\n",
      "Epoch [224/250], Loss: 0.1143, Accuracy: 0.9549\n",
      "Validation Loss: 1.4914, Validation Accuracy: 0.7793\n",
      "Epoch [225/250], Loss: 0.1675, Accuracy: 0.9306\n",
      "Validation Loss: 1.8974, Validation Accuracy: 0.6828\n",
      "Epoch [226/250], Loss: 0.1989, Accuracy: 0.9236\n",
      "Validation Loss: 2.6998, Validation Accuracy: 0.5862\n",
      "Epoch [227/250], Loss: 0.0967, Accuracy: 0.9583\n",
      "Validation Loss: 0.9047, Validation Accuracy: 0.7862\n",
      "Epoch [228/250], Loss: 0.1235, Accuracy: 0.9688\n",
      "Validation Loss: 1.3770, Validation Accuracy: 0.7724\n",
      "Epoch [229/250], Loss: 0.1415, Accuracy: 0.9340\n",
      "Validation Loss: 1.5422, Validation Accuracy: 0.7517\n",
      "Epoch [230/250], Loss: 0.1285, Accuracy: 0.9549\n",
      "Validation Loss: 2.5339, Validation Accuracy: 0.6552\n",
      "Epoch [231/250], Loss: 0.1084, Accuracy: 0.9583\n",
      "Validation Loss: 1.1869, Validation Accuracy: 0.7931\n",
      "Epoch [232/250], Loss: 0.1289, Accuracy: 0.9618\n",
      "Validation Loss: 1.1323, Validation Accuracy: 0.8276\n",
      "Epoch [233/250], Loss: 0.1288, Accuracy: 0.9653\n",
      "Validation Loss: 4.3404, Validation Accuracy: 0.5655\n",
      "Epoch [234/250], Loss: 0.1455, Accuracy: 0.9306\n",
      "Validation Loss: 0.8803, Validation Accuracy: 0.8207\n",
      "Epoch [235/250], Loss: 0.1116, Accuracy: 0.9653\n",
      "Validation Loss: 1.2001, Validation Accuracy: 0.7862\n",
      "Epoch [236/250], Loss: 0.0734, Accuracy: 0.9722\n",
      "Validation Loss: 4.1913, Validation Accuracy: 0.6069\n",
      "Epoch [237/250], Loss: 0.0782, Accuracy: 0.9618\n",
      "Validation Loss: 2.3787, Validation Accuracy: 0.7724\n",
      "Epoch [238/250], Loss: 0.1359, Accuracy: 0.9583\n",
      "Validation Loss: 1.0120, Validation Accuracy: 0.8000\n",
      "Epoch [239/250], Loss: 0.1712, Accuracy: 0.9340\n",
      "Validation Loss: 0.9775, Validation Accuracy: 0.8414\n",
      "Epoch [240/250], Loss: 0.1234, Accuracy: 0.9444\n",
      "Validation Loss: 0.8697, Validation Accuracy: 0.8552\n",
      "Epoch [241/250], Loss: 0.1131, Accuracy: 0.9792\n",
      "Validation Loss: 1.0342, Validation Accuracy: 0.8276\n",
      "Epoch [242/250], Loss: 0.0951, Accuracy: 0.9618\n",
      "Validation Loss: 1.4203, Validation Accuracy: 0.7793\n",
      "Epoch [243/250], Loss: 0.1244, Accuracy: 0.9514\n",
      "Validation Loss: 1.2988, Validation Accuracy: 0.7379\n",
      "Epoch [244/250], Loss: 0.1177, Accuracy: 0.9410\n",
      "Validation Loss: 1.6157, Validation Accuracy: 0.7379\n",
      "Epoch [245/250], Loss: 0.1204, Accuracy: 0.9583\n",
      "Validation Loss: 0.7104, Validation Accuracy: 0.8414\n",
      "Epoch [246/250], Loss: 0.1054, Accuracy: 0.9514\n",
      "Validation Loss: 0.7485, Validation Accuracy: 0.8552\n",
      "Epoch [247/250], Loss: 0.1123, Accuracy: 0.9514\n",
      "Validation Loss: 2.7879, Validation Accuracy: 0.6897\n",
      "Epoch [248/250], Loss: 0.1404, Accuracy: 0.9375\n",
      "Validation Loss: 0.6330, Validation Accuracy: 0.8621\n",
      "Epoch [249/250], Loss: 0.1004, Accuracy: 0.9514\n",
      "Validation Loss: 0.9203, Validation Accuracy: 0.8069\n",
      "Epoch [250/250], Loss: 0.1932, Accuracy: 0.9340\n",
      "Validation Loss: 3.1875, Validation Accuracy: 0.5793\n",
      "Test Loss: 2.9496\n",
      "Test Accuracy: 0.6111\n",
      "label 0 is 57\n",
      "label 1 is 57\n",
      "label 2 is 57\n",
      "label 3 is 57\n",
      "Not setting metadata\n",
      "228 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "label 0 is 27\n",
      "label 1 is 22\n",
      "label 2 is 164\n",
      "label 3 is 140\n",
      "Not setting metadata\n",
      "353 matching events found\n",
      "Setting baseline interval to [0.0, 1.296] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "[0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "There are 2 unique classes in the dataset\n",
      "X_train shape: (290, 8, 325)\n",
      "290 train samples\n",
      "145 test samples\n",
      "Number of batches in train_loader: 5\n",
      "{-1: 1.2741228070175439, 0: 0.8229461756373938}\n",
      "================================================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)                            Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "================================================================================================================================================================\n",
      "EEGConformer (EEGConformer)                                  [1, 8, 325]               [1, 4]                    --                        --\n",
      "├─_PatchEmbedding (patch_embedding): 1-1                     [1, 1, 8, 325]            [1, 16, 40]               --                        --\n",
      "│    └─Sequential (shallownet): 2-1                          [1, 1, 8, 325]            [1, 40, 1, 16]            --                        --\n",
      "│    │    └─Conv2d (0): 3-1                                  [1, 1, 8, 325]            [1, 40, 8, 301]           1,040                     [1, 25]\n",
      "│    │    └─Conv2d (1): 3-2                                  [1, 40, 8, 301]           [1, 40, 1, 301]           12,840                    [8, 1]\n",
      "│    │    └─BatchNorm2d (2): 3-3                             [1, 40, 1, 301]           [1, 40, 1, 301]           80                        --\n",
      "│    │    └─ELU (3): 3-4                                     [1, 40, 1, 301]           [1, 40, 1, 301]           --                        --\n",
      "│    │    └─AvgPool2d (4): 3-5                               [1, 40, 1, 301]           [1, 40, 1, 16]            --                        [1, 75]\n",
      "│    │    └─Dropout (5): 3-6                                 [1, 40, 1, 16]            [1, 40, 1, 16]            --                        --\n",
      "│    └─Sequential (projection): 2-2                          [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "│    │    └─Conv2d (0): 3-7                                  [1, 40, 1, 16]            [1, 40, 1, 16]            1,640                     [1, 1]\n",
      "│    │    └─Rearrange (1): 3-8                               [1, 40, 1, 16]            [1, 16, 40]               --                        --\n",
      "├─_TransformerEncoder (transformer): 1-2                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    └─_TransformerEncoderBlock (0): 2-3                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-9                            [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-10                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (1): 2-4                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-11                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-12                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (2): 2-5                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-13                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-14                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (3): 2-6                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-15                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-16                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (4): 2-7                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-17                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-18                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "│    └─_TransformerEncoderBlock (5): 2-8                     [1, 16, 40]               [1, 16, 40]               --                        --\n",
      "│    │    └─_ResidualAdd (0): 3-19                           [1, 16, 40]               [1, 16, 40]               6,640                     --\n",
      "│    │    └─_ResidualAdd (1): 3-20                           [1, 16, 40]               [1, 16, 40]               13,080                    --\n",
      "├─_FullyConnected (fc): 1-3                                  [1, 16, 40]               [1, 32]                   --                        --\n",
      "│    └─Sequential (fc): 2-9                                  [1, 640]                  [1, 32]                   --                        --\n",
      "│    │    └─Linear (0): 3-21                                 [1, 640]                  [1, 256]                  164,096                   --\n",
      "│    │    └─ELU (1): 3-22                                    [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Dropout (2): 3-23                                [1, 256]                  [1, 256]                  --                        --\n",
      "│    │    └─Linear (3): 3-24                                 [1, 256]                  [1, 32]                   8,224                     --\n",
      "│    │    └─ELU (4): 3-25                                    [1, 32]                   [1, 32]                   --                        --\n",
      "│    │    └─Dropout (5): 3-26                                [1, 32]                   [1, 32]                   --                        --\n",
      "├─_FinalLayer (final_layer): 1-4                             [1, 32]                   [1, 4]                    --                        --\n",
      "│    └─Sequential (final_layer): 2-10                        [1, 32]                   [1, 4]                    --                        --\n",
      "│    │    └─Linear (0): 3-27                                 [1, 32]                   [1, 4]                    132                       --\n",
      "│    │    └─LogSoftmax (classification): 3-28                [1, 4]                    [1, 4]                    --                        --\n",
      "================================================================================================================================================================\n",
      "Total params: 306,372\n",
      "Trainable params: 306,372\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 6.69\n",
      "================================================================================================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.31\n",
      "Params size (MB): 1.23\n",
      "Estimated Total Size (MB): 2.54\n",
      "================================================================================================================================================================\n",
      "Output shape after transformer: torch.Size([1, 16, 40])\n",
      "Calculated `final_fc_length`: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\braindecode\\models\\base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
      "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 1.1978, Accuracy: 0.3724\n",
      "Validation Loss: 0.7939, Validation Accuracy: 0.6027\n",
      "Epoch [2/250], Loss: 0.8247, Accuracy: 0.6069\n",
      "Validation Loss: 0.7851, Validation Accuracy: 0.6027\n",
      "Epoch [3/250], Loss: 0.7681, Accuracy: 0.6172\n",
      "Validation Loss: 0.7407, Validation Accuracy: 0.6027\n",
      "Epoch [4/250], Loss: 0.7312, Accuracy: 0.5931\n",
      "Validation Loss: 0.7339, Validation Accuracy: 0.6027\n",
      "Epoch [5/250], Loss: 0.7165, Accuracy: 0.5897\n",
      "Validation Loss: 0.7132, Validation Accuracy: 0.6027\n",
      "Epoch [6/250], Loss: 0.7145, Accuracy: 0.6069\n",
      "Validation Loss: 0.7037, Validation Accuracy: 0.6027\n",
      "Epoch [7/250], Loss: 0.7030, Accuracy: 0.5724\n",
      "Validation Loss: 0.7458, Validation Accuracy: 0.6027\n",
      "Epoch [8/250], Loss: 0.7264, Accuracy: 0.5690\n",
      "Validation Loss: 0.6911, Validation Accuracy: 0.6027\n",
      "Epoch [9/250], Loss: 0.7063, Accuracy: 0.5759\n",
      "Validation Loss: 0.6964, Validation Accuracy: 0.6027\n",
      "Epoch [10/250], Loss: 0.7058, Accuracy: 0.5517\n",
      "Validation Loss: 0.7213, Validation Accuracy: 0.6027\n",
      "Epoch [11/250], Loss: 0.7540, Accuracy: 0.5552\n",
      "Validation Loss: 0.7238, Validation Accuracy: 0.6027\n",
      "Epoch [12/250], Loss: 0.6896, Accuracy: 0.5690\n",
      "Validation Loss: 0.7049, Validation Accuracy: 0.6027\n",
      "Epoch [13/250], Loss: 0.6931, Accuracy: 0.5759\n",
      "Validation Loss: 0.7486, Validation Accuracy: 0.6027\n",
      "Epoch [14/250], Loss: 0.7287, Accuracy: 0.5759\n",
      "Validation Loss: 0.7126, Validation Accuracy: 0.6027\n",
      "Epoch [15/250], Loss: 0.7140, Accuracy: 0.6000\n",
      "Validation Loss: 0.7003, Validation Accuracy: 0.6027\n",
      "Epoch [16/250], Loss: 0.6930, Accuracy: 0.5862\n",
      "Validation Loss: 0.7056, Validation Accuracy: 0.6027\n",
      "Epoch [17/250], Loss: 0.7048, Accuracy: 0.6034\n",
      "Validation Loss: 0.7287, Validation Accuracy: 0.6027\n",
      "Epoch [18/250], Loss: 0.7038, Accuracy: 0.6069\n",
      "Validation Loss: 0.6937, Validation Accuracy: 0.6027\n",
      "Epoch [19/250], Loss: 0.6806, Accuracy: 0.6034\n",
      "Validation Loss: 0.7121, Validation Accuracy: 0.6027\n",
      "Epoch [20/250], Loss: 0.6984, Accuracy: 0.5759\n",
      "Validation Loss: 0.7090, Validation Accuracy: 0.6027\n",
      "Epoch [21/250], Loss: 0.6803, Accuracy: 0.5931\n",
      "Validation Loss: 0.6754, Validation Accuracy: 0.6027\n",
      "Epoch [22/250], Loss: 0.7054, Accuracy: 0.5897\n",
      "Validation Loss: 0.6986, Validation Accuracy: 0.6027\n",
      "Epoch [23/250], Loss: 0.6826, Accuracy: 0.5931\n",
      "Validation Loss: 0.7119, Validation Accuracy: 0.6027\n",
      "Epoch [24/250], Loss: 0.6763, Accuracy: 0.6103\n",
      "Validation Loss: 0.7216, Validation Accuracy: 0.6096\n",
      "Epoch [25/250], Loss: 0.6801, Accuracy: 0.6172\n",
      "Validation Loss: 0.7345, Validation Accuracy: 0.6096\n",
      "Epoch [26/250], Loss: 0.6751, Accuracy: 0.6069\n",
      "Validation Loss: 0.7264, Validation Accuracy: 0.6096\n",
      "Epoch [27/250], Loss: 0.6625, Accuracy: 0.6724\n",
      "Validation Loss: 0.6551, Validation Accuracy: 0.6301\n",
      "Epoch [28/250], Loss: 0.6533, Accuracy: 0.6103\n",
      "Validation Loss: 0.9303, Validation Accuracy: 0.4452\n",
      "Epoch [29/250], Loss: 0.6278, Accuracy: 0.6724\n",
      "Validation Loss: 0.6752, Validation Accuracy: 0.6164\n",
      "Epoch [30/250], Loss: 0.6786, Accuracy: 0.6586\n",
      "Validation Loss: 0.6431, Validation Accuracy: 0.6712\n",
      "Epoch [31/250], Loss: 0.6355, Accuracy: 0.6931\n",
      "Validation Loss: 0.8407, Validation Accuracy: 0.5411\n",
      "Epoch [32/250], Loss: 0.6211, Accuracy: 0.6586\n",
      "Validation Loss: 1.7068, Validation Accuracy: 0.4178\n",
      "Epoch [33/250], Loss: 0.6080, Accuracy: 0.7138\n",
      "Validation Loss: 2.1414, Validation Accuracy: 0.4041\n",
      "Epoch [34/250], Loss: 0.6325, Accuracy: 0.7069\n",
      "Validation Loss: 0.7052, Validation Accuracy: 0.6370\n",
      "Epoch [35/250], Loss: 0.5980, Accuracy: 0.6862\n",
      "Validation Loss: 1.6291, Validation Accuracy: 0.4521\n",
      "Epoch [36/250], Loss: 0.6089, Accuracy: 0.7103\n",
      "Validation Loss: 0.6238, Validation Accuracy: 0.6986\n",
      "Epoch [37/250], Loss: 0.5813, Accuracy: 0.7207\n",
      "Validation Loss: 1.8152, Validation Accuracy: 0.4041\n",
      "Epoch [38/250], Loss: 0.5710, Accuracy: 0.7448\n",
      "Validation Loss: 1.0699, Validation Accuracy: 0.4932\n",
      "Epoch [39/250], Loss: 0.5886, Accuracy: 0.7310\n",
      "Validation Loss: 0.7792, Validation Accuracy: 0.6438\n",
      "Epoch [40/250], Loss: 0.5533, Accuracy: 0.7448\n",
      "Validation Loss: 0.8435, Validation Accuracy: 0.6370\n",
      "Epoch [41/250], Loss: 0.5936, Accuracy: 0.7069\n",
      "Validation Loss: 2.8484, Validation Accuracy: 0.3973\n",
      "Epoch [42/250], Loss: 0.5541, Accuracy: 0.7483\n",
      "Validation Loss: 0.6409, Validation Accuracy: 0.6986\n",
      "Epoch [43/250], Loss: 0.5248, Accuracy: 0.7793\n",
      "Validation Loss: 0.6274, Validation Accuracy: 0.7329\n",
      "Epoch [44/250], Loss: 0.5222, Accuracy: 0.7724\n",
      "Validation Loss: 0.6129, Validation Accuracy: 0.7603\n",
      "Epoch [45/250], Loss: 0.5521, Accuracy: 0.7586\n",
      "Validation Loss: 0.6126, Validation Accuracy: 0.7260\n",
      "Epoch [46/250], Loss: 0.4796, Accuracy: 0.7897\n",
      "Validation Loss: 1.9030, Validation Accuracy: 0.4384\n",
      "Epoch [47/250], Loss: 0.5200, Accuracy: 0.7759\n",
      "Validation Loss: 0.8957, Validation Accuracy: 0.6096\n",
      "Epoch [48/250], Loss: 0.5504, Accuracy: 0.7414\n",
      "Validation Loss: 0.9601, Validation Accuracy: 0.6027\n",
      "Epoch [49/250], Loss: 0.5135, Accuracy: 0.7931\n",
      "Validation Loss: 0.8415, Validation Accuracy: 0.6301\n",
      "Epoch [50/250], Loss: 0.4928, Accuracy: 0.7759\n",
      "Validation Loss: 0.7036, Validation Accuracy: 0.6781\n",
      "Epoch [51/250], Loss: 0.4925, Accuracy: 0.7793\n",
      "Validation Loss: 0.9663, Validation Accuracy: 0.6096\n",
      "Epoch [52/250], Loss: 0.4614, Accuracy: 0.7931\n",
      "Validation Loss: 2.1677, Validation Accuracy: 0.4452\n",
      "Epoch [53/250], Loss: 0.5415, Accuracy: 0.7862\n",
      "Validation Loss: 0.7100, Validation Accuracy: 0.6781\n",
      "Epoch [54/250], Loss: 0.4883, Accuracy: 0.8103\n",
      "Validation Loss: 0.9776, Validation Accuracy: 0.6096\n",
      "Epoch [55/250], Loss: 0.5082, Accuracy: 0.7759\n",
      "Validation Loss: 0.8524, Validation Accuracy: 0.6507\n",
      "Epoch [56/250], Loss: 0.4790, Accuracy: 0.7966\n",
      "Validation Loss: 0.6292, Validation Accuracy: 0.7534\n",
      "Epoch [57/250], Loss: 0.5097, Accuracy: 0.7862\n",
      "Validation Loss: 0.7646, Validation Accuracy: 0.6781\n",
      "Epoch [58/250], Loss: 0.4757, Accuracy: 0.7966\n",
      "Validation Loss: 0.8909, Validation Accuracy: 0.6849\n",
      "Epoch [59/250], Loss: 0.4980, Accuracy: 0.7931\n",
      "Validation Loss: 0.7117, Validation Accuracy: 0.6781\n",
      "Epoch [60/250], Loss: 0.4667, Accuracy: 0.8103\n",
      "Validation Loss: 0.9406, Validation Accuracy: 0.6096\n",
      "Epoch [61/250], Loss: 0.4744, Accuracy: 0.8034\n",
      "Validation Loss: 0.5983, Validation Accuracy: 0.7740\n",
      "Epoch [62/250], Loss: 0.4830, Accuracy: 0.8069\n",
      "Validation Loss: 0.5516, Validation Accuracy: 0.7740\n",
      "Epoch [63/250], Loss: 0.4997, Accuracy: 0.7862\n",
      "Validation Loss: 3.9386, Validation Accuracy: 0.3973\n",
      "Epoch [64/250], Loss: 0.5143, Accuracy: 0.7828\n",
      "Validation Loss: 0.8379, Validation Accuracy: 0.6438\n",
      "Epoch [65/250], Loss: 0.5256, Accuracy: 0.8034\n",
      "Validation Loss: 0.5337, Validation Accuracy: 0.7603\n",
      "Epoch [66/250], Loss: 0.4550, Accuracy: 0.8103\n",
      "Validation Loss: 1.4729, Validation Accuracy: 0.5548\n",
      "Epoch [67/250], Loss: 0.4679, Accuracy: 0.8034\n",
      "Validation Loss: 0.6315, Validation Accuracy: 0.7397\n",
      "Epoch [68/250], Loss: 0.4638, Accuracy: 0.7862\n",
      "Validation Loss: 0.5860, Validation Accuracy: 0.7671\n",
      "Epoch [69/250], Loss: 0.5049, Accuracy: 0.7828\n",
      "Validation Loss: 2.1449, Validation Accuracy: 0.4795\n",
      "Epoch [70/250], Loss: 0.5256, Accuracy: 0.7690\n",
      "Validation Loss: 3.2551, Validation Accuracy: 0.4110\n",
      "Epoch [71/250], Loss: 0.4411, Accuracy: 0.8207\n",
      "Validation Loss: 1.7673, Validation Accuracy: 0.5205\n",
      "Epoch [72/250], Loss: 0.4736, Accuracy: 0.8034\n",
      "Validation Loss: 0.6901, Validation Accuracy: 0.6849\n",
      "Epoch [73/250], Loss: 0.4491, Accuracy: 0.8207\n",
      "Validation Loss: 3.7256, Validation Accuracy: 0.3973\n",
      "Epoch [74/250], Loss: 0.4579, Accuracy: 0.8138\n",
      "Validation Loss: 1.8051, Validation Accuracy: 0.4932\n",
      "Epoch [75/250], Loss: 0.4499, Accuracy: 0.8103\n",
      "Validation Loss: 0.7046, Validation Accuracy: 0.7123\n",
      "Epoch [76/250], Loss: 0.4267, Accuracy: 0.8310\n",
      "Validation Loss: 0.5884, Validation Accuracy: 0.7671\n",
      "Epoch [77/250], Loss: 0.4379, Accuracy: 0.8276\n",
      "Validation Loss: 0.7632, Validation Accuracy: 0.6781\n",
      "Epoch [78/250], Loss: 0.4075, Accuracy: 0.8276\n",
      "Validation Loss: 3.8828, Validation Accuracy: 0.3973\n",
      "Epoch [79/250], Loss: 0.4945, Accuracy: 0.7897\n",
      "Validation Loss: 0.7558, Validation Accuracy: 0.6781\n",
      "Epoch [80/250], Loss: 0.4064, Accuracy: 0.8276\n",
      "Validation Loss: 0.5403, Validation Accuracy: 0.7877\n",
      "Epoch [81/250], Loss: 0.4666, Accuracy: 0.7966\n",
      "Validation Loss: 0.7695, Validation Accuracy: 0.6849\n",
      "Epoch [82/250], Loss: 0.4508, Accuracy: 0.8172\n",
      "Validation Loss: 0.5299, Validation Accuracy: 0.7945\n",
      "Epoch [83/250], Loss: 0.5078, Accuracy: 0.7793\n",
      "Validation Loss: 0.6177, Validation Accuracy: 0.7603\n",
      "Epoch [84/250], Loss: 0.4300, Accuracy: 0.8172\n",
      "Validation Loss: 0.8116, Validation Accuracy: 0.6575\n",
      "Epoch [85/250], Loss: 0.4207, Accuracy: 0.8241\n",
      "Validation Loss: 0.6831, Validation Accuracy: 0.7192\n",
      "Epoch [86/250], Loss: 0.4172, Accuracy: 0.8172\n",
      "Validation Loss: 0.8433, Validation Accuracy: 0.6575\n",
      "Epoch [87/250], Loss: 0.4172, Accuracy: 0.8448\n",
      "Validation Loss: 0.6059, Validation Accuracy: 0.7740\n",
      "Epoch [88/250], Loss: 0.4661, Accuracy: 0.7966\n",
      "Validation Loss: 3.6512, Validation Accuracy: 0.3973\n",
      "Epoch [89/250], Loss: 0.4011, Accuracy: 0.8276\n",
      "Validation Loss: 1.5702, Validation Accuracy: 0.5890\n",
      "Epoch [90/250], Loss: 0.3711, Accuracy: 0.8448\n",
      "Validation Loss: 0.6201, Validation Accuracy: 0.7808\n",
      "Epoch [91/250], Loss: 0.4328, Accuracy: 0.8414\n",
      "Validation Loss: 0.5658, Validation Accuracy: 0.8014\n",
      "Epoch [92/250], Loss: 0.3801, Accuracy: 0.8448\n",
      "Validation Loss: 0.9153, Validation Accuracy: 0.6233\n",
      "Epoch [93/250], Loss: 0.3994, Accuracy: 0.8310\n",
      "Validation Loss: 1.0050, Validation Accuracy: 0.6986\n",
      "Epoch [94/250], Loss: 0.4554, Accuracy: 0.8172\n",
      "Validation Loss: 0.5760, Validation Accuracy: 0.8151\n",
      "Epoch [95/250], Loss: 0.4499, Accuracy: 0.8379\n",
      "Validation Loss: 0.7965, Validation Accuracy: 0.6575\n",
      "Epoch [96/250], Loss: 0.4551, Accuracy: 0.8172\n",
      "Validation Loss: 0.6560, Validation Accuracy: 0.7329\n",
      "Epoch [97/250], Loss: 0.4132, Accuracy: 0.8172\n",
      "Validation Loss: 1.7971, Validation Accuracy: 0.5411\n",
      "Epoch [98/250], Loss: 0.3880, Accuracy: 0.8310\n",
      "Validation Loss: 0.5590, Validation Accuracy: 0.8014\n",
      "Epoch [99/250], Loss: 0.3924, Accuracy: 0.8483\n",
      "Validation Loss: 0.9027, Validation Accuracy: 0.6507\n",
      "Epoch [100/250], Loss: 0.4469, Accuracy: 0.8207\n",
      "Validation Loss: 0.5616, Validation Accuracy: 0.7945\n",
      "Epoch [101/250], Loss: 0.4402, Accuracy: 0.8172\n",
      "Validation Loss: 3.3655, Validation Accuracy: 0.3973\n",
      "Epoch [102/250], Loss: 0.4131, Accuracy: 0.8310\n",
      "Validation Loss: 2.3144, Validation Accuracy: 0.4726\n",
      "Epoch [103/250], Loss: 0.4008, Accuracy: 0.8345\n",
      "Validation Loss: 0.8914, Validation Accuracy: 0.6438\n",
      "Epoch [104/250], Loss: 0.4101, Accuracy: 0.8276\n",
      "Validation Loss: 0.9365, Validation Accuracy: 0.6301\n",
      "Epoch [105/250], Loss: 0.4344, Accuracy: 0.8276\n",
      "Validation Loss: 4.0301, Validation Accuracy: 0.3973\n",
      "Epoch [106/250], Loss: 0.4429, Accuracy: 0.8379\n",
      "Validation Loss: 0.5183, Validation Accuracy: 0.7945\n",
      "Epoch [107/250], Loss: 0.3749, Accuracy: 0.8655\n",
      "Validation Loss: 0.7851, Validation Accuracy: 0.6781\n",
      "Epoch [108/250], Loss: 0.3466, Accuracy: 0.8690\n",
      "Validation Loss: 4.9220, Validation Accuracy: 0.3973\n",
      "Epoch [109/250], Loss: 0.3872, Accuracy: 0.8448\n",
      "Validation Loss: 0.7102, Validation Accuracy: 0.7534\n",
      "Epoch [110/250], Loss: 0.3871, Accuracy: 0.8379\n",
      "Validation Loss: 0.7306, Validation Accuracy: 0.7329\n",
      "Epoch [111/250], Loss: 0.3905, Accuracy: 0.8586\n",
      "Validation Loss: 0.7929, Validation Accuracy: 0.6986\n",
      "Epoch [112/250], Loss: 0.4451, Accuracy: 0.8414\n",
      "Validation Loss: 1.0457, Validation Accuracy: 0.6096\n",
      "Epoch [113/250], Loss: 0.4022, Accuracy: 0.8138\n",
      "Validation Loss: 0.8038, Validation Accuracy: 0.6712\n",
      "Epoch [114/250], Loss: 0.3668, Accuracy: 0.8621\n",
      "Validation Loss: 0.5594, Validation Accuracy: 0.7808\n",
      "Epoch [115/250], Loss: 0.3965, Accuracy: 0.8483\n",
      "Validation Loss: 0.6431, Validation Accuracy: 0.7945\n",
      "Epoch [116/250], Loss: 0.3908, Accuracy: 0.8621\n",
      "Validation Loss: 2.8849, Validation Accuracy: 0.4589\n",
      "Epoch [117/250], Loss: 0.4241, Accuracy: 0.8241\n",
      "Validation Loss: 0.9957, Validation Accuracy: 0.6096\n",
      "Epoch [118/250], Loss: 0.3996, Accuracy: 0.8448\n",
      "Validation Loss: 0.7469, Validation Accuracy: 0.7397\n",
      "Epoch [119/250], Loss: 0.3813, Accuracy: 0.8517\n",
      "Validation Loss: 0.7315, Validation Accuracy: 0.7055\n",
      "Epoch [120/250], Loss: 0.3915, Accuracy: 0.8448\n",
      "Validation Loss: 1.2741, Validation Accuracy: 0.6507\n",
      "Epoch [121/250], Loss: 0.3819, Accuracy: 0.8517\n",
      "Validation Loss: 1.0037, Validation Accuracy: 0.6233\n",
      "Epoch [122/250], Loss: 0.3866, Accuracy: 0.8586\n",
      "Validation Loss: 3.5024, Validation Accuracy: 0.4110\n",
      "Epoch [123/250], Loss: 0.3828, Accuracy: 0.8517\n",
      "Validation Loss: 0.7760, Validation Accuracy: 0.7055\n",
      "Epoch [124/250], Loss: 0.3617, Accuracy: 0.8655\n",
      "Validation Loss: 2.0534, Validation Accuracy: 0.5137\n",
      "Epoch [125/250], Loss: 0.4151, Accuracy: 0.8414\n",
      "Validation Loss: 1.1901, Validation Accuracy: 0.6096\n",
      "Epoch [126/250], Loss: 0.3909, Accuracy: 0.8586\n",
      "Validation Loss: 0.6394, Validation Accuracy: 0.7945\n",
      "Epoch [127/250], Loss: 0.3816, Accuracy: 0.8448\n",
      "Validation Loss: 0.8771, Validation Accuracy: 0.6712\n",
      "Epoch [128/250], Loss: 0.3233, Accuracy: 0.8552\n",
      "Validation Loss: 1.5978, Validation Accuracy: 0.5753\n",
      "Epoch [129/250], Loss: 0.3691, Accuracy: 0.8724\n",
      "Validation Loss: 0.7102, Validation Accuracy: 0.7397\n",
      "Epoch [130/250], Loss: 0.3936, Accuracy: 0.8621\n",
      "Validation Loss: 0.7817, Validation Accuracy: 0.6918\n",
      "Epoch [131/250], Loss: 0.3459, Accuracy: 0.8724\n",
      "Validation Loss: 1.5552, Validation Accuracy: 0.6027\n",
      "Epoch [132/250], Loss: 0.4030, Accuracy: 0.8552\n",
      "Validation Loss: 0.6432, Validation Accuracy: 0.7740\n",
      "Epoch [133/250], Loss: 0.3479, Accuracy: 0.8655\n",
      "Validation Loss: 1.2352, Validation Accuracy: 0.6507\n",
      "Epoch [134/250], Loss: 0.3856, Accuracy: 0.8379\n",
      "Validation Loss: 3.9961, Validation Accuracy: 0.3973\n",
      "Epoch [135/250], Loss: 0.3837, Accuracy: 0.8690\n",
      "Validation Loss: 1.3265, Validation Accuracy: 0.6438\n",
      "Epoch [136/250], Loss: 0.3546, Accuracy: 0.8552\n",
      "Validation Loss: 4.3052, Validation Accuracy: 0.4041\n",
      "Epoch [137/250], Loss: 0.3478, Accuracy: 0.8724\n",
      "Validation Loss: 1.2352, Validation Accuracy: 0.6575\n",
      "Epoch [138/250], Loss: 0.3243, Accuracy: 0.8759\n",
      "Validation Loss: 2.5616, Validation Accuracy: 0.5068\n",
      "Epoch [139/250], Loss: 0.3337, Accuracy: 0.8759\n",
      "Validation Loss: 0.5592, Validation Accuracy: 0.7945\n",
      "Epoch [140/250], Loss: 0.3149, Accuracy: 0.8897\n",
      "Validation Loss: 0.9267, Validation Accuracy: 0.7466\n",
      "Epoch [141/250], Loss: 0.3132, Accuracy: 0.8828\n",
      "Validation Loss: 4.8125, Validation Accuracy: 0.4041\n",
      "Epoch [142/250], Loss: 0.3382, Accuracy: 0.8655\n",
      "Validation Loss: 0.7458, Validation Accuracy: 0.7603\n",
      "Epoch [143/250], Loss: 0.3428, Accuracy: 0.8793\n",
      "Validation Loss: 0.7302, Validation Accuracy: 0.7466\n",
      "Epoch [144/250], Loss: 0.3572, Accuracy: 0.8552\n",
      "Validation Loss: 2.4312, Validation Accuracy: 0.4863\n",
      "Epoch [145/250], Loss: 0.3723, Accuracy: 0.8517\n",
      "Validation Loss: 0.8645, Validation Accuracy: 0.6712\n",
      "Epoch [146/250], Loss: 0.3239, Accuracy: 0.8793\n",
      "Validation Loss: 0.8053, Validation Accuracy: 0.6918\n",
      "Epoch [147/250], Loss: 0.3227, Accuracy: 0.8690\n",
      "Validation Loss: 1.1556, Validation Accuracy: 0.6096\n",
      "Epoch [148/250], Loss: 0.3204, Accuracy: 0.8690\n",
      "Validation Loss: 0.9123, Validation Accuracy: 0.7671\n",
      "Epoch [149/250], Loss: 0.3078, Accuracy: 0.8759\n",
      "Validation Loss: 5.2280, Validation Accuracy: 0.3973\n",
      "Epoch [150/250], Loss: 0.4069, Accuracy: 0.8379\n",
      "Validation Loss: 5.7239, Validation Accuracy: 0.3973\n",
      "Epoch [151/250], Loss: 0.3286, Accuracy: 0.8724\n",
      "Validation Loss: 5.5311, Validation Accuracy: 0.3973\n",
      "Epoch [152/250], Loss: 0.3403, Accuracy: 0.8655\n",
      "Validation Loss: 0.9639, Validation Accuracy: 0.7397\n",
      "Epoch [153/250], Loss: 0.3212, Accuracy: 0.8724\n",
      "Validation Loss: 0.7590, Validation Accuracy: 0.7534\n",
      "Epoch [154/250], Loss: 0.3560, Accuracy: 0.8690\n",
      "Validation Loss: 0.6485, Validation Accuracy: 0.7877\n",
      "Epoch [155/250], Loss: 0.3439, Accuracy: 0.8862\n",
      "Validation Loss: 1.1567, Validation Accuracy: 0.6027\n",
      "Epoch [156/250], Loss: 0.3598, Accuracy: 0.8621\n",
      "Validation Loss: 1.1125, Validation Accuracy: 0.6027\n",
      "Epoch [157/250], Loss: 0.3390, Accuracy: 0.8586\n",
      "Validation Loss: 0.7046, Validation Accuracy: 0.7329\n",
      "Epoch [158/250], Loss: 0.3870, Accuracy: 0.8586\n",
      "Validation Loss: 0.4831, Validation Accuracy: 0.8151\n",
      "Epoch [159/250], Loss: 0.3215, Accuracy: 0.8862\n",
      "Validation Loss: 0.5225, Validation Accuracy: 0.8356\n",
      "Epoch [160/250], Loss: 0.3333, Accuracy: 0.8759\n",
      "Validation Loss: 4.8548, Validation Accuracy: 0.4041\n",
      "Epoch [161/250], Loss: 0.3225, Accuracy: 0.8897\n",
      "Validation Loss: 0.9518, Validation Accuracy: 0.6644\n",
      "Epoch [162/250], Loss: 0.2705, Accuracy: 0.9000\n",
      "Validation Loss: 0.8172, Validation Accuracy: 0.7192\n",
      "Epoch [163/250], Loss: 0.3679, Accuracy: 0.8483\n",
      "Validation Loss: 1.0154, Validation Accuracy: 0.6575\n",
      "Epoch [164/250], Loss: 0.3470, Accuracy: 0.8724\n",
      "Validation Loss: 5.1010, Validation Accuracy: 0.3973\n",
      "Epoch [165/250], Loss: 0.3032, Accuracy: 0.8724\n",
      "Validation Loss: 0.6977, Validation Accuracy: 0.7945\n",
      "Epoch [166/250], Loss: 0.3224, Accuracy: 0.8759\n",
      "Validation Loss: 2.2268, Validation Accuracy: 0.4932\n",
      "Epoch [167/250], Loss: 0.2765, Accuracy: 0.8862\n",
      "Validation Loss: 0.6065, Validation Accuracy: 0.8219\n",
      "Epoch [168/250], Loss: 0.3165, Accuracy: 0.8621\n",
      "Validation Loss: 5.8463, Validation Accuracy: 0.3973\n",
      "Epoch [169/250], Loss: 0.3048, Accuracy: 0.8793\n",
      "Validation Loss: 0.6670, Validation Accuracy: 0.7808\n",
      "Epoch [170/250], Loss: 0.3715, Accuracy: 0.8724\n",
      "Validation Loss: 0.5561, Validation Accuracy: 0.8219\n",
      "Epoch [171/250], Loss: 0.3458, Accuracy: 0.8552\n",
      "Validation Loss: 0.8126, Validation Accuracy: 0.6507\n",
      "Epoch [172/250], Loss: 0.2727, Accuracy: 0.9069\n",
      "Validation Loss: 4.7462, Validation Accuracy: 0.3973\n",
      "Epoch [173/250], Loss: 0.3148, Accuracy: 0.9034\n",
      "Validation Loss: 3.2796, Validation Accuracy: 0.4726\n",
      "Epoch [174/250], Loss: 0.3621, Accuracy: 0.8759\n",
      "Validation Loss: 1.1428, Validation Accuracy: 0.6027\n",
      "Epoch [175/250], Loss: 0.3902, Accuracy: 0.8276\n",
      "Validation Loss: 0.7476, Validation Accuracy: 0.6644\n",
      "Epoch [176/250], Loss: 0.3396, Accuracy: 0.8828\n",
      "Validation Loss: 3.1245, Validation Accuracy: 0.4384\n",
      "Epoch [177/250], Loss: 0.2721, Accuracy: 0.9034\n",
      "Validation Loss: 5.4664, Validation Accuracy: 0.3973\n",
      "Epoch [178/250], Loss: 0.3298, Accuracy: 0.8793\n",
      "Validation Loss: 5.6022, Validation Accuracy: 0.3973\n",
      "Epoch [179/250], Loss: 0.2657, Accuracy: 0.8966\n",
      "Validation Loss: 5.4916, Validation Accuracy: 0.3973\n",
      "Epoch [180/250], Loss: 0.3005, Accuracy: 0.8931\n",
      "Validation Loss: 6.1938, Validation Accuracy: 0.3973\n",
      "Epoch [181/250], Loss: 0.3059, Accuracy: 0.8931\n",
      "Validation Loss: 0.6395, Validation Accuracy: 0.8082\n",
      "Epoch [182/250], Loss: 0.4531, Accuracy: 0.8414\n",
      "Validation Loss: 3.9550, Validation Accuracy: 0.4041\n",
      "Epoch [183/250], Loss: 0.3215, Accuracy: 0.8759\n",
      "Validation Loss: 5.1361, Validation Accuracy: 0.3973\n",
      "Epoch [184/250], Loss: 0.3000, Accuracy: 0.8897\n",
      "Validation Loss: 1.2814, Validation Accuracy: 0.6849\n",
      "Epoch [185/250], Loss: 0.3459, Accuracy: 0.8759\n",
      "Validation Loss: 0.5606, Validation Accuracy: 0.7945\n",
      "Epoch [186/250], Loss: 0.2911, Accuracy: 0.9034\n",
      "Validation Loss: 0.8602, Validation Accuracy: 0.7260\n",
      "Epoch [187/250], Loss: 0.3118, Accuracy: 0.8862\n",
      "Validation Loss: 4.6803, Validation Accuracy: 0.4041\n",
      "Epoch [188/250], Loss: 0.2872, Accuracy: 0.8931\n",
      "Validation Loss: 0.4672, Validation Accuracy: 0.8288\n",
      "Epoch [189/250], Loss: 0.3227, Accuracy: 0.8724\n",
      "Validation Loss: 0.9981, Validation Accuracy: 0.6986\n",
      "Epoch [190/250], Loss: 0.3001, Accuracy: 0.8897\n",
      "Validation Loss: 0.7029, Validation Accuracy: 0.7603\n",
      "Epoch [191/250], Loss: 0.3200, Accuracy: 0.9000\n",
      "Validation Loss: 4.1826, Validation Accuracy: 0.4041\n",
      "Epoch [192/250], Loss: 0.3050, Accuracy: 0.8793\n",
      "Validation Loss: 4.6567, Validation Accuracy: 0.3973\n",
      "Epoch [193/250], Loss: 0.3118, Accuracy: 0.8828\n",
      "Validation Loss: 0.4913, Validation Accuracy: 0.8356\n",
      "Epoch [194/250], Loss: 0.3016, Accuracy: 0.8931\n",
      "Validation Loss: 0.8142, Validation Accuracy: 0.7260\n",
      "Epoch [195/250], Loss: 0.3135, Accuracy: 0.8724\n",
      "Validation Loss: 0.9516, Validation Accuracy: 0.7123\n",
      "Epoch [196/250], Loss: 0.3100, Accuracy: 0.9034\n",
      "Validation Loss: 3.1618, Validation Accuracy: 0.4658\n",
      "Epoch [197/250], Loss: 0.2776, Accuracy: 0.8931\n",
      "Validation Loss: 0.8358, Validation Accuracy: 0.7260\n",
      "Epoch [198/250], Loss: 0.2582, Accuracy: 0.9172\n",
      "Validation Loss: 1.6730, Validation Accuracy: 0.6438\n",
      "Epoch [199/250], Loss: 0.3013, Accuracy: 0.8759\n",
      "Validation Loss: 0.8506, Validation Accuracy: 0.7397\n",
      "Epoch [200/250], Loss: 0.2775, Accuracy: 0.9034\n",
      "Validation Loss: 5.6329, Validation Accuracy: 0.3973\n",
      "Epoch [201/250], Loss: 0.3049, Accuracy: 0.8759\n",
      "Validation Loss: 1.3305, Validation Accuracy: 0.6164\n",
      "Epoch [202/250], Loss: 0.2622, Accuracy: 0.9103\n",
      "Validation Loss: 0.7180, Validation Accuracy: 0.7055\n",
      "Epoch [203/250], Loss: 0.3035, Accuracy: 0.8793\n",
      "Validation Loss: 0.4143, Validation Accuracy: 0.8630\n",
      "Epoch [204/250], Loss: 0.2985, Accuracy: 0.8759\n",
      "Validation Loss: 1.1948, Validation Accuracy: 0.6164\n",
      "Epoch [205/250], Loss: 0.2799, Accuracy: 0.9000\n",
      "Validation Loss: 3.5134, Validation Accuracy: 0.4863\n",
      "Epoch [206/250], Loss: 0.2848, Accuracy: 0.8793\n",
      "Validation Loss: 2.7373, Validation Accuracy: 0.5411\n",
      "Epoch [207/250], Loss: 0.2557, Accuracy: 0.9034\n",
      "Validation Loss: 0.5595, Validation Accuracy: 0.8082\n",
      "Epoch [208/250], Loss: 0.2700, Accuracy: 0.9069\n",
      "Validation Loss: 1.4237, Validation Accuracy: 0.6027\n",
      "Epoch [209/250], Loss: 0.2762, Accuracy: 0.8931\n",
      "Validation Loss: 0.6912, Validation Accuracy: 0.7808\n",
      "Epoch [210/250], Loss: 0.3068, Accuracy: 0.8828\n",
      "Validation Loss: 1.9609, Validation Accuracy: 0.5616\n",
      "Epoch [211/250], Loss: 0.2709, Accuracy: 0.9103\n",
      "Validation Loss: 1.3808, Validation Accuracy: 0.6027\n",
      "Epoch [212/250], Loss: 0.2673, Accuracy: 0.9138\n",
      "Validation Loss: 1.1187, Validation Accuracy: 0.6918\n",
      "Epoch [213/250], Loss: 0.2819, Accuracy: 0.8897\n",
      "Validation Loss: 4.7031, Validation Accuracy: 0.3973\n",
      "Epoch [214/250], Loss: 0.2761, Accuracy: 0.8931\n",
      "Validation Loss: 0.9371, Validation Accuracy: 0.7603\n",
      "Epoch [215/250], Loss: 0.2690, Accuracy: 0.9172\n",
      "Validation Loss: 1.2936, Validation Accuracy: 0.6096\n",
      "Epoch [216/250], Loss: 0.3423, Accuracy: 0.8828\n",
      "Validation Loss: 0.3884, Validation Accuracy: 0.8493\n",
      "Epoch [217/250], Loss: 0.2757, Accuracy: 0.9103\n",
      "Validation Loss: 3.3392, Validation Accuracy: 0.4521\n",
      "Epoch [218/250], Loss: 0.2081, Accuracy: 0.9276\n",
      "Validation Loss: 0.7347, Validation Accuracy: 0.7603\n",
      "Epoch [219/250], Loss: 0.3372, Accuracy: 0.8655\n",
      "Validation Loss: 6.3635, Validation Accuracy: 0.3973\n",
      "Epoch [220/250], Loss: 0.3127, Accuracy: 0.9034\n",
      "Validation Loss: 1.3058, Validation Accuracy: 0.6027\n",
      "Epoch [221/250], Loss: 0.2207, Accuracy: 0.9276\n",
      "Validation Loss: 1.3892, Validation Accuracy: 0.6849\n",
      "Epoch [222/250], Loss: 0.2649, Accuracy: 0.9103\n",
      "Validation Loss: 0.8007, Validation Accuracy: 0.7945\n",
      "Epoch [223/250], Loss: 0.2825, Accuracy: 0.9000\n",
      "Validation Loss: 6.7569, Validation Accuracy: 0.3973\n",
      "Epoch [224/250], Loss: 0.2698, Accuracy: 0.9069\n",
      "Validation Loss: 5.0054, Validation Accuracy: 0.4110\n",
      "Epoch [225/250], Loss: 0.2829, Accuracy: 0.9034\n",
      "Validation Loss: 1.5681, Validation Accuracy: 0.6027\n",
      "Epoch [226/250], Loss: 0.3148, Accuracy: 0.8759\n",
      "Validation Loss: 0.5852, Validation Accuracy: 0.8219\n",
      "Epoch [227/250], Loss: 0.2633, Accuracy: 0.9069\n",
      "Validation Loss: 2.6124, Validation Accuracy: 0.5068\n",
      "Epoch [228/250], Loss: 0.2481, Accuracy: 0.9172\n",
      "Validation Loss: 5.4983, Validation Accuracy: 0.4041\n",
      "Epoch [229/250], Loss: 0.2222, Accuracy: 0.9172\n",
      "Validation Loss: 0.7521, Validation Accuracy: 0.7945\n",
      "Epoch [230/250], Loss: 0.2831, Accuracy: 0.9138\n",
      "Validation Loss: 0.6769, Validation Accuracy: 0.8082\n",
      "Epoch [231/250], Loss: 0.2734, Accuracy: 0.9034\n",
      "Validation Loss: 0.8728, Validation Accuracy: 0.7192\n",
      "Epoch [232/250], Loss: 0.2306, Accuracy: 0.9310\n",
      "Validation Loss: 0.5755, Validation Accuracy: 0.7945\n",
      "Epoch [233/250], Loss: 0.2560, Accuracy: 0.9069\n",
      "Validation Loss: 1.6292, Validation Accuracy: 0.6164\n",
      "Epoch [234/250], Loss: 0.2463, Accuracy: 0.9241\n",
      "Validation Loss: 1.1650, Validation Accuracy: 0.7192\n",
      "Epoch [235/250], Loss: 0.2802, Accuracy: 0.8966\n",
      "Validation Loss: 3.9052, Validation Accuracy: 0.4521\n",
      "Epoch [236/250], Loss: 0.2530, Accuracy: 0.8966\n",
      "Validation Loss: 1.3018, Validation Accuracy: 0.7055\n",
      "Epoch [237/250], Loss: 0.3047, Accuracy: 0.9000\n",
      "Validation Loss: 1.6153, Validation Accuracy: 0.6027\n",
      "Epoch [238/250], Loss: 0.2520, Accuracy: 0.9000\n",
      "Validation Loss: 0.9593, Validation Accuracy: 0.6575\n",
      "Epoch [239/250], Loss: 0.2651, Accuracy: 0.8931\n",
      "Validation Loss: 2.0095, Validation Accuracy: 0.5890\n",
      "Epoch [240/250], Loss: 0.2851, Accuracy: 0.9069\n",
      "Validation Loss: 2.6351, Validation Accuracy: 0.4589\n",
      "Epoch [241/250], Loss: 0.2238, Accuracy: 0.9310\n",
      "Validation Loss: 3.2128, Validation Accuracy: 0.4589\n",
      "Epoch [242/250], Loss: 0.2473, Accuracy: 0.8966\n",
      "Validation Loss: 0.5149, Validation Accuracy: 0.8562\n",
      "Epoch [243/250], Loss: 0.2207, Accuracy: 0.9241\n",
      "Validation Loss: 4.1546, Validation Accuracy: 0.3973\n",
      "Epoch [244/250], Loss: 0.2505, Accuracy: 0.8966\n",
      "Validation Loss: 4.9527, Validation Accuracy: 0.3973\n",
      "Epoch [245/250], Loss: 0.2527, Accuracy: 0.9069\n",
      "Validation Loss: 0.8801, Validation Accuracy: 0.7534\n",
      "Epoch [246/250], Loss: 0.2204, Accuracy: 0.9241\n",
      "Validation Loss: 1.1074, Validation Accuracy: 0.7192\n",
      "Epoch [247/250], Loss: 0.2567, Accuracy: 0.9172\n",
      "Validation Loss: 6.5250, Validation Accuracy: 0.3973\n",
      "Epoch [248/250], Loss: 0.2185, Accuracy: 0.9172\n",
      "Validation Loss: 4.7325, Validation Accuracy: 0.4041\n",
      "Epoch [249/250], Loss: 0.2387, Accuracy: 0.9103\n",
      "Validation Loss: 1.0990, Validation Accuracy: 0.7397\n",
      "Epoch [250/250], Loss: 0.2348, Accuracy: 0.9207\n",
      "Validation Loss: 0.4681, Validation Accuracy: 0.8425\n",
      "Test Loss: 0.5708\n",
      "Test Accuracy: 0.8207\n",
      "Mean Test Accuracy: 0.84\n",
      "Test Accuracy Standard Deviation: 0.17\n",
      "Minimum Test Accuracy: 0.48\n",
      "Maximum Test Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "subject_ids = [1,8,10,11,12,15,16,19,20,21,22,23,25,26,27,30,31,33,34,35,36,37,38,39,40,41]\n",
    "results_df = pd.DataFrame(columns=['subject_id', 'test_accuracy'])\n",
    "\n",
    "# Loop through each subject\n",
    "for subject_id in subject_ids:\n",
    "\n",
    "    epochs_calibration, X_calibration, y_calibration_original = load_data_labels_based_on_dataset(\n",
    "        dataset_info,\n",
    "        subject_id,\n",
    "        data_path,\n",
    "        game_mode=\"calibration3\",\n",
    "    )\n",
    "    \n",
    "    epochs_singleplayer, X_singleplayer, y_singleplayer_original = load_data_labels_based_on_dataset(\n",
    "        dataset_info,\n",
    "        subject_id,\n",
    "        data_path,\n",
    "        game_mode=\"singleplayer\",\n",
    "    )\n",
    "    y_calibration = [0] * len(y_calibration_original)\n",
    "    y_singleplayer = [1] * len(y_singleplayer_original)\n",
    "    \n",
    "    X = np.concatenate((X_calibration, X_singleplayer), axis=0)\n",
    "    y = y_calibration + y_singleplayer\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Split the temp data into 50% test and 50% validation, resulting in 25% of the original data each\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    print(y_train)\n",
    "    num_classess = len(set(y_train))\n",
    "    print(f'There are {num_classess} unique classes in the dataset')\n",
    "    \n",
    "    kernels, chans, samples = 1, dataset_info[\"#_channels\"], dataset_info[\"samples\"]\n",
    "    \n",
    "    # y_train = y_train - 1\n",
    "    # y_val = y_val - 1\n",
    "    # y_test = y_test - 1\n",
    "    \n",
    "    # X_train      = X_train.reshape(X_train.shape[0], chans, samples)\n",
    "    # X_val   = X_val.reshape(X_val.shape[0], chans, samples)\n",
    "    # X_test       = X_test.reshape(X_test.shape[0], chans, samples)\n",
    "    \n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_test.shape[0], 'test samples')\n",
    "    \n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # Keep as integers\n",
    "    \n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "    \n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    # Create datasets and loaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "    \n",
    "    train_loader_size = len(train_loader)\n",
    "    print(f\"Number of batches in train_loader: {train_loader_size}\")\n",
    "    \n",
    "    counts = Counter(y)\n",
    "    \n",
    "    total_samples = sum(counts.values())\n",
    "    \n",
    "    num_classes = len(counts)\n",
    "    \n",
    "    class_weights = {class_label-1: total_samples / (num_classes * count) for class_label, count in counts.items()}\n",
    "    \n",
    "    print(class_weights)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #device = 'cpu'\n",
    "    \n",
    "    n_classes = dataset_info[\"#_class\"]\n",
    "    classes = list(range(n_classes))\n",
    "    \n",
    "    n_outputs = dataset_info[\"#_class\"]\n",
    "    n_chans = dataset_info[\"#_channels\"]\n",
    "    n_filters_time = 40\n",
    "    filter_time_length = 25\n",
    "    pool_time_length = 75\n",
    "    pool_time_stride = 15\n",
    "    drop_prob = 0.5\n",
    "    att_depth = 6\n",
    "    att_heads = 10\n",
    "    att_drop_prob = 0.5\n",
    "    final_fc_length = 640\n",
    "    return_features = False\n",
    "    n_times = dataset_info[\"samples\"]\n",
    "    chs_info = None\n",
    "    input_window_seconds = None\n",
    "    sfreq = dataset_info[\"sample_rate\"]\n",
    "    add_log_softmax = True\n",
    "    \n",
    "    # Initialize the EEGConformer model\n",
    "    conformer = EEGConformer(\n",
    "        n_outputs=n_outputs,\n",
    "        n_chans=n_chans,\n",
    "        n_filters_time=n_filters_time,\n",
    "        filter_time_length=filter_time_length,\n",
    "        pool_time_length=pool_time_length,\n",
    "        pool_time_stride=pool_time_stride,\n",
    "        drop_prob=drop_prob,\n",
    "        att_depth=att_depth,\n",
    "        att_heads=att_heads,\n",
    "        att_drop_prob=att_drop_prob,\n",
    "        final_fc_length=final_fc_length,\n",
    "        return_features=return_features,\n",
    "        n_times=n_times,\n",
    "        chs_info=chs_info,\n",
    "        input_window_seconds=input_window_seconds,\n",
    "        sfreq=sfreq,\n",
    "        add_log_softmax=add_log_softmax\n",
    "    )\n",
    "    conformer = conformer.to(device)\n",
    "    \n",
    "    print(conformer)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(conformer.parameters(), lr =  0.0002,betas  = [0.5, 0.999])\n",
    "    \n",
    "    import torch\n",
    "    \n",
    "    conformer.to(device)\n",
    "    \n",
    "    # Create a dummy input with the correct shape and move it to the same device\n",
    "    dummy_input = torch.randn(kernels, chans, samples).to(device)  # Batch size\n",
    "    \n",
    "    # Pass the dummy input through the model up to the transformer encoder\n",
    "    try:\n",
    "        with torch.no_grad():  # Disable gradient calculation for inference\n",
    "            x = torch.unsqueeze(dummy_input, dim=1)  # Add an extra dimension to match input shape\n",
    "            x = conformer.patch_embedding(x)  # Pass through Patch Embedding\n",
    "            x = conformer.transformer(x)  # Pass through Transformer Encoder\n",
    "            \n",
    "            # Get the shape after the transformer and calculate the new `final_fc_length`\n",
    "            print(f\"Output shape after transformer: {x.shape}\")\n",
    "            final_fc_length_calculated = x.shape[1] * x.shape[2]\n",
    "            print(f\"Calculated `final_fc_length`: {final_fc_length_calculated}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Error during partial forward pass:\", str(e))\n",
    "        \n",
    "        \n",
    "    num_epochs = 250\n",
    "    ## TRAIN\n",
    "    for epoch in range(num_epochs):\n",
    "        conformer.train()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = conformer(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted == y_batch).sum().item()\n",
    "            total_predictions += y_batch.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "    \n",
    "    ## Validation\n",
    "        conformer.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "    \n",
    "                outputs = conformer(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                val_loss += loss.item()\n",
    "    \n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == y_batch).sum().item()\n",
    "                total_predictions += y_batch.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        ## TEST\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "    \n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            outputs = conformer(X_batch)\n",
    "            \n",
    "            loss = criterion(outputs, y_batch)\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "            _, predicted = torch.max(outputs, 1)  # Get the class with the highest score\n",
    "            correct_predictions += (predicted == y_batch).sum().item()\n",
    "            total_predictions += y_batch.size(0)\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    temp_df = pd.DataFrame({'subject_id': [subject_id], 'test_accuracy': [test_accuracy]})\n",
    "    \n",
    "    # Concatenate the temporary dataframe with the results dataframe\n",
    "    results_df = pd.concat([results_df, temp_df], ignore_index=True)\n",
    "\n",
    "mean_accuracy = results_df['test_accuracy'].mean()\n",
    "std_accuracy = results_df['test_accuracy'].std()\n",
    "min_accuracy = results_df['test_accuracy'].min()\n",
    "max_accuracy = results_df['test_accuracy'].max()\n",
    "\n",
    "# Report the results\n",
    "print(f\"Mean Test Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy Standard Deviation: {std_accuracy:.2f}\")\n",
    "print(f\"Minimum Test Accuracy: {min_accuracy:.2f}\")\n",
    "print(f\"Maximum Test Accuracy: {max_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Accuracy: 0.84\n",
      "Test Accuracy Standard Deviation: 0.17\n",
      "Minimum Test Accuracy: 0.48\n",
      "Maximum Test Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean_accuracy = results_df['test_accuracy'].mean()\n",
    "std_accuracy = results_df['test_accuracy'].std()\n",
    "min_accuracy = results_df['test_accuracy'].min()\n",
    "max_accuracy = results_df['test_accuracy'].max()\n",
    "\n",
    "# Report the results\n",
    "print(f\"Mean Test Accuracy: {mean_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy Standard Deviation: {std_accuracy:.2f}\")\n",
    "print(f\"Minimum Test Accuracy: {min_accuracy:.2f}\")\n",
    "print(f\"Maximum Test Accuracy: {max_accuracy:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T00:03:22.246010Z",
     "start_time": "2025-01-24T00:03:22.205616800Z"
    }
   },
   "id": "6f7b981e88cc79ea",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "036f5f63-82a0-4fe3-94fe-d48aac560d54",
   "metadata": {},
   "source": [
    "Do this to find the right final_fc_length"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the Seaborn palette\n",
    "sns.set_palette(\"Set2\")\n",
    "\n",
    "# Create a boxplot using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=results_df['test_accuracy'])\n",
    "plt.title('Boxplot of Test Accuracies')\n",
    "plt.xlabel('Subjects')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T22:06:49.245377Z",
     "start_time": "2025-01-23T22:06:49.133532100Z"
    }
   },
   "id": "83e32096ded4c246",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Report of one subject"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8de45eec10e91e4a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "                        Test Report                         \n",
      "============================================================\n",
      "Total Batches: 2\n",
      "Average Test Loss: 1.1538\n",
      "Overall Test Accuracy: 0.8509\n",
      "============================================================\n",
      "\n",
      "Batch-wise Results:\n",
      " Batch     Loss  Accuracy\n",
      "     1 1.074396  0.859375\n",
      "     2 1.233160  0.840000\n"
     ]
    }
   ],
   "source": [
    "## TEST\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize variables\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Define loss criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Track loss and accuracy per batch\n",
    "batch_results = []\n",
    "\n",
    "# Disable gradient calculation for inference\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(test_loader):\n",
    "        # Move data to the appropriate device (GPU/CPU)\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        outputs = conformer(X_batch)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest score\n",
    "        correct_predictions += (predicted == y_batch).sum().item()\n",
    "        total_predictions += y_batch.size(0)\n",
    "\n",
    "        # Store individual batch results\n",
    "        batch_results.append({\n",
    "            'Batch': batch_idx + 1,\n",
    "            'Loss': loss.item(),\n",
    "            'Accuracy': (predicted == y_batch).sum().item() / y_batch.size(0)\n",
    "        })\n",
    "\n",
    "# Calculate average loss and overall accuracy\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Create DataFrame for detailed batch results\n",
    "df_results = pd.DataFrame(batch_results)\n",
    "\n",
    "# Print detailed report\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Test Report':^60}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total Batches: {len(test_loader)}\")\n",
    "print(f\"Average Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Overall Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nBatch-wise Results:\")\n",
    "print(df_results.to_string(index=False))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-22T20:24:25.199134300Z",
     "start_time": "2025-01-22T20:24:25.155130100Z"
    }
   },
   "id": "f0565c3c4101da64",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "                        Test Report                         \n",
      "============================================================\n",
      "Total Batches: 2\n",
      "Average Test Loss: 1.1538\n",
      "Overall Test Accuracy: 0.8509\n",
      "============================================================\n",
      "\n",
      "Batch-wise Results:\n",
      " Batch     Loss  Accuracy\n",
      "     1 1.074396  0.859375\n",
      "     2 1.233160  0.840000\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAHMCAYAAADbH6G9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGhUlEQVR4nO3deVxV1fo/8M9mOIyCpEI4IIjiWDklit5wSFD7EViaEyDOOQaGN+eyxJw1Ec2iQqErWg5UF03B9HpTUhyScgxlUgRUhJg8DPv3B5fz7QQoZ4DDYX/e39e537v3XnuvB7j17GfttdcRRFEUQURERJJhoOsAiIiIqGEx+RMREUkMkz8REZHEMPkTERFJDJM/ERGRxDD5ExERSQyTPxERkcQw+RMREUkMkz8REZHEGOk6ACJ98dlnn+HQoUMwNjaGXC5HYGAgRowYoeuwiIhUxsqf9EJqaipWrlyJ119/Hd7e3hg2bBi8vb2xevVqnD17FqWlpfXaf1xcHDZv3ozQ0FB89913GDt2LG7duqXVPtavX49hw4ahuLhYq9d9lqSkJHh7e6Nfv37o3LkzNm3a9NT2UVFR6Ny5MwYOHAhvb288fPhQpf6uXbuG0NBQ5OfnqxxrYGAgxowZo/J5RKSMyZ8avWPHjsHHxwcdOnTAt99+i5iYGMTHx2PDhg24fPkyAgICcOrUqXqN4dy5c2jRogU6duwIAJgyZQpmz56t1T5atGiB1q1bw9DQUKvXfZYXXngBMTExGDp0KARBQFRUFHJzc2tsK5fLER4eDgAYP348YmJi0KJFC5X6u3btGrZv365W8re1tUXr1q1VPo+IlDH5U6N28+ZNBAcHw9/fHwEBAZDJZIpjLi4u2LVrF0xNTes9jvz8fJiYmCi2DQwMYGSk3adm06ZNQ2RkpNLP2NA8PDxQVFSEr776qsbj+/fvx0svvdTAUf2fpUuXYtu2bTrrn6ip4DN/atR27NgBuVwOPz+/Go+3aNECc+fOhZ2dndL+r7/+Gnv37kVpaSnkcjnc3NywcOFCRZW6bt06xMXFIS0tDdu2bcPx48dx48YNFBYWYsyYMZgzZw4AoKSkBOPGjUNmZiaKiorg7e0NAFi5ciU+/PBDpKWloUePHoiMjFRc98iRI8jMzER8fDzatm0LAMjJycGGDRtw7do1RWU/YMAAzJgxA8899xyWLFmCs2fPVjsPAM6cOYOwsDDcv38fFRUV6NixI4KCgtCtWzcAQGxsLHbt2oXr169jzpw5qKiowJkzZ3D//n30798f77//PiwtLev0+x48eDAyMjIQFRWFKVOmwMbGRnFMLpcjMjISGzZswNGjR6ude+3aNYSHh+PWrVswMDBARUUFPDw8MHPmTMUNzZo1a3Ds2DEAwMyZM2FsbAwzMzNER0fDz88Pt2/fxoMHDxATE4MNGzbg/v37+OOPP7BkyRKcPn0a169fx4MHD3Djxg3F3+bWrVswNDTEsGHDsHXrVixZsgRxcXGwtLTEpEmTMH369Dr97ESSIhI1UuXl5WKvXr3EYcOGqXTe2rVrxd69e4uXL18WRVEUCwoKRF9fX9HDw0P8888/Fe0SEhJEFxcXcfz48WJWVpYoiqIYFxcnuri4iGfOnFG65nvvvScOGTKkWl++vr6ir6+v0r4DBw6ILi4uYnp6umJfQECAuHjxYrG8vFwURVG8ffu26OrqKiYkJDz1vLi4OLFLly7iv/71L1EURbGiokJct26d+NJLL4m//fabUr8uLi6iu7u7eP78eVEURfHevXti7969xa1bt9bp9/bee++JBw4cUPwONm/erHQ8MjJS/Pjjj8X09HTRxcVF3LZtm9LxXbt2iUFBQeKTJ09EURTF3Nxccdy4cWJISMgzfz9Vtm3bJrq4uIgLFy4UCwoKFHF99dVXSsf/avPmzWLnzp3F06dPi6IoiqmpqeLIkSPFvLy8Ov3cRFLEYX9qtHJzc1FYWIiWLVvW+Zy0tDRERETgzTffVAxPW1hYYPHixUhJSUFERES1c4YPHw5bW1sAwNChQ2Fubo6EhASt/AxVLl++DAcHBxgYVP4j5+TkhEWLFuH555+v9RxRFBESEoLOnTtjwoQJAABBEBAYGAhTU1OsW7eu2jldunRB3759AQD29vbo3bs3zp49q1Ksw4YNQ7du3RAZGYnHjx8DqKz69+zZg2nTptV63ujRo/HBBx8oqvzmzZvD29sb+/fvhyiKKsXg6+sLCwsLAMCSJUswevToWtvOnTsXLi4uWLx4MbKzs7Fo0SIsW7YMVlZWKvVJJCVM/tRoCYKg8jlnzpxBRUVFtefS3bt3h0wmw3//+99q53To0EGpT2tra+Tk5Kge8FP0798fYWFhWLZsmeLthDfffBPt27ev9Zw7d+7g7t27ePHFF5X2y2QydO/eHYmJiSgpKVE65uTkpLRtY2ODBw8eqBzvnDlzUFhYqHj2v3//fri7u6NVq1a1nmNlZYV9+/Zh/Pjx8PLygre3N3bt2oXi4mKVf5+dOnVS/Hdra2tYW1vX2lYmk2HdunV4/PgxvL290a1bNwwcOFCl/oikhsmfGq3mzZvDwsJCpeRVNUu9pmRhbW2NR48eVdtvZmamtF31vFqbPvnkEwQGBuLChQsICAjAoEGDsGXLFsjl8lrPqfpZmjdvXu1Y8+bNUV5ejry8PKX95ubmStvq/iyvvvoqOnfujKioKGRnZ2P37t2YMWPGU89ZtmwZwsPDsXLlSnz//feIiYnBggULAOCpP2dN6jpHoUrXrl3h6+uLR48ewc3NTaVziaSIyZ8aLQMDA7zyyivIyMh4auWYkJCA5ORkAFBMUPt7Uqza99xzz2k9xr8PaRcWFlZrJ5PJMH36dBw9ehQHDx7E4MGD8emnn2LHjh21XrvqZ6kaev+rx48fw9DQ8KkVsSYEQcCcOXNQUFCAyZMn45VXXlE8GqlJSUkJYmNj8dprrykmIjakoqIi/Pzzz+jSpQs+/PDDGv/+RPR/mPypUZs/fz5MTU0RFRVV4/FLly5h8uTJioVmBg4cCAMDA/z6669K7a5evQq5XI5BgwZpNb6WLVtWSzS3b9+u1i4oKEjx37t3745169bBxcUF169fr/XaTk5OaNOmDZKSkpT2y+VyXL16FX379q3X1xw9PT3h4uKCjIwMzJw586lty8rKUF5erpjTUKWmm7aqVySrbpoSExNx//59jWJdt24dxo0bh61btyI/Px8ffvihRtcjauqY/KlRc3Z2xieffIKoqChEREQoDR+fP38eCxYswNSpU9GvXz8AQLt27RAQEICDBw/iypUrACqrwnXr1sHR0REBAQFaja9///5ITk7GzZs3AQB//PEHfvnll2rtYmNj8cMPPyi209LScP/+/acOUQuCgGXLluH69evYv38/gMqEGRoaiuLiYrz33nta/Vlq6j8sLAz/+te/qr1K+XeWlpbo168fYmNjkZ6eDgDIzMxEdHR0tbZVrzFmZWWhrKwMwcHBinPU8fPPPyM1NRWTJk2Ck5MTgoKC8MMPP+DHH39U+5pETZ0gqjoNl0gHUlNT8fnnn+PSpUswMjKCKIpo0aIFJk6ciOHDh1drHxUVhb1796KsrAxPnjyBm5sb3n33XcV7/jt37sTBgweRlpYGBwcHTJo0Ca+++irmzp2L5ORkmJubo0OHDoiIiFB6z9/Z2RkdO3ZULIFbWlqKdevW4fjx42jRogVeeukldOrUCatWrYKzszPGjx8Pf39/fPHFFzh+/DgKCwsVjwreeOMNxc3IX9/z/+t5QOUkxu3bt+P+/fsQRRHOzs4ICgpC9+7dAQCnT5/Gxo0bcf36dbRs2RL9+/fHpk2bEBAQgKtXryri3rRpk2KFwr9KS0vD/PnzkZmZCXNzc7Rr106xbsHfrVu3DqdOnUJycjJatmyJli1bYt++fTA1NUV2djbWrFmDxMREtG7dGi1atEC7du2we/duODs7Y+bMmfDx8QEArFixAj///DPMzMzQr18/vP/++5g7dy4uX76MBw8eoEuXLnjppZeUKvhp06Yp3vPv0qULZs+ejW+++Qa//vorrKyssGTJEgwYMAATJ07EjRs3YG5urrQGAxH9HyZ/IiIiieGwPxERkcQw+RMREUkMkz8REZHEMPkTERFJDJM/ERGRxDD5ExERSYyRrgOoLzdu3EBRUZFiNTEiItIvpaWlEAQBvXr1qrc+bty4ofJ3T9RGJpOhc+fOWrlWfWuymVEul0MURaTcfajrUCTD0ECA7XMWyH5UiPIKLh/RUNraa/f7CugpRBEV5WUwMDQC1PjWSVKNKIqo75Vo5HI5iopLkP2o+ndyqML2OQstRdQwmmzyBwBjY2O8teRbXYchGS4OLfDlytexJOwEbqbxpquh3IjbqOsQJKP0STEeZ96Gla0DjE3Mnn0CaeRhxs0G6Sf7USHeWnpQo2vsX/MGHNvU33dtaBuf+RMREUlMk678iYiI6kTHj3F++eUXLFmyBG3atFHa/49//EPpWzUPHTqEyMhImJmZobi4GFOmTIGXl5fK/TH5ExERCbofCB89ejTmz59f6/Hvv/8eH374IQ4ePAgnJyckJydjzJgxMDExgYeHh0p96f6nJSIi0jVB0OxTz0RRxJYtW+Dl5QUnJycAlV95PmLECMW3jKqCyZ+IiKiRu3XrFu7evVvttcfevXsjJSUFd+7cUel6HPYnIiJpEwTNh/0FAZmZmQgMDKy1SXx8/FMvcfnyZcyYMUOxRo2bmxsmT54MU1NTpKamAgBsbW2VzqnaTklJUYwI1AWTPxERkY4n/DVr1gx2dnZYtGgRbGxscO/ePcyePRs//vgj9u3bh8LCynUIZDKZ0nlV20VFRSr1x+RPRESkBfb29s+s7mvTrVs3rFmzRrHdunVrvPvuu5gxYwaOHz8OC4vKRYT+vhph1ba5ublK/fGZPxERkWCg2aceVA3jp6eno3379gCA7OxspTZV246Ojipdm8mfiIhIx7P9N23ahPT0dKV99+/fBwDY2dmhU6dOaNOmDS5duqTU5tKlS3B0dFTpeT/A5E9ERKRzly9fRkREBMrLywEABQUFCAsLQ5s2bTB8+HAIgoCgoCD88MMPSElJAQAkJyfjyJEjWLhwocr98Zk/ERFJnBZm+0Oz6n/WrFnYv38/xo8fDxMTExQVFeGFF17Ahg0bFM/7vby8UFpaiqCgIJibm6OoqAirVq2Cp6enyv0x+RMREel4tv+gQYMwaNCgZ7Z744038MYbb2jcH4f9iYiIJIaVPxERUSNY278hMfkTERHpeNi/oTH5ExGRtAnQwvK+WomkwUhrnIOIiIhY+RMRkdTp/lW/hsbkT0REZKBfyVtTHPYnIiKSGFb+REREfNWPiIhIYiT2qp+0bnWIiIiIlT8RERGH/YmIiKSGw/5ERETUlLHyJyIiaRO0sMiPno0cMPkTERHpWfLWFJM/ERGRxCb8SeunJSIiIlb+REREHPYnIiKSFOl9qx+H/YmIiCSGlT8RERGH/YmIiCSGs/2JiIioKWPlT0RE0iZACyv8aSWSBsPkT0REJLFn/hz2JyIikhhW/kREJHHSe8+fyZ+IiEhiw/5M/kRERI3oVb/8/Hx4eXnB0NAQJ06cUOwPDQ1FXFwcrKyslNrPmDEDr7zyikp9MPkTERE1IqtWrUJJSQksLCyqHVu6dClcXV017qPx3OoQERHpiiBo9tGSo0ePIi8vD0OGDNHaNWvC5E9ERJInCIJGH23IycnB5s2bERISopXrPQ2H/YmIiLQgMzMTgYGBtR6Pj49/6vnLly/H/PnzYWdnV2ubw4cPY/v27SgrK0OzZs3g4+ODUaNGqRwrkz8REUmetqp3de3fvx8mJibw8vKqtY29vT1MTEywatUqyGQyJCYmYtasWbhw4QJWrFihUn9M/kREJG0CNH9NX6hMzs+q7muSnp6O8PBwREdHP7XdmDFjlLb79u2LCRMmIDw8HG+//TZatWpV5z6Z/ImIiHTop59+gomJCd555x3Fvtu3byM/Px9+fn4AgMjIyBrPdXJygiiKyMjIYPInIiKqO21M2lP/fH9/f/j7+yvtW7x4Mc6dO6eU9IOCgrBlyxaldpmZmQDw1HkCNeFsfyIikrzGMNv/WWJjYxEbG6vYTktLQ3R0NDw9PdG6dWuVrsXKn4iIqJE4fvw49uzZozTs7+rqinnz5uH999/H3r17ERUVBQAoKSmBv78/AgICVO6HyZ+IiCRP17P9qwwfPhzDhw+v8djEiRMxceJErfTD5E9ERJLXWJJ/Q2HyJyIiklbu54Q/IiIiqWHlT0REksdhfyIiIgmp/GI+zZK/vt07cNifiIhIYlj5ExGR5HHYn4iISGKklvw57E9ERCQxrPyJiIikVfgz+RMRkdTp9lv9dIHD/kRERBLDyp+IiCRPahP+mPyJiEjymPyJiIikRlq5n8/8iYiIpIaVPxERSZsW1vbXt5EDJn8iIpI0AVr4Yh/thNJgOOxPREQkMaz8iYhI8jjbn4iISGKklvw57E9ERCQxrPyJiIikVfgz+RMRkdTxi32IiIioiWPlT0REkie1CX9M/kREJG1c4Y+IiEiC9Cx5a4rP/KnejPhHD1w/ugZh7/vqOhSiOssvKMa7a75G51eDkXH/Ua3tLv6eAo/Ja+G3cEcDRkekHaz8qc7a2T+HM9HLcCcjp9qx9zZ8g4ePHgMAzE1l2LZ8Il5waQu7FlYNHCWR+v6beAPvbz0AM1PjWtuUlpVjS8QxxJ+5hkePC/i/8SaiMT3zz8/Ph5eXFwwNDXHixAmlY6dOnUJoaChMTExQWFgIHx8fBAQEqNwHkz+p5PK1NHi9/UmNx1wcWgAARg3uifsP8rDw42jkJGxryPCINLIjKg6h709G/JnfcCvleI1tEpIykP9nMQ5+GgSv6RsbOEKqL40p+a9atQolJSWwsLBQ2p+YmIi5c+ciIiICffv2RU5ODkaPHg0AKt8ANKrkf+fOHYSEhCA/Px9yuRy9evVCcHBwtV8ANW6HjiXiWkr10QGixm7PprdhZGiI+DO/1dpmwIvt4DWqI4xNTBowMpKKo0ePIi8vD0OGDMG5c+eUjm3duhWurq7o27cvAKBVq1YYP348QkNDMX78eJiamta5n0bzzD83Nxd+fn7o27cv9u/fj2+//RapqakIDg7WdWikovKKCl2HQKQWI0PDOrRpNP/aJC2p+kpfjT5aiCMnJwebN29GSEhItWMFBQVITExEr169lPb37t1bcUwVjabyj4yMRHFxMaZOnQoAMDIywuzZs+Hr64uLFy+id+/eOo6QAKDVc82w8wM/dGxvBxsrc9xMycKufSdx6twNXYdGRKQ2bQz7Z2ZmIjAwsNbj8fHxTz1/+fLlmD9/Puzs7KodS0tLgyiKsLW1Vdpf1TYlJQWDBg2qc6yN5hb25MmT6NatG2QymWLfSy+9BAMDA5w8eVJ3gZFCRUUFDAwE7Dl8BsOnbMTACWuQdDMDB0Pnws97gK7DIyLSW/v374eJiQm8vLxqPF5UVAQASjnyr9tVx+uq0VT+qampGDx4sNI+mUwGGxsbpKSkqHVNURQVk9BIO3z/91pT1e/1wJEEvOb+AkKC3sDMpZ8BAByet1Y6x8rChH+HelT6pFjXITQ55eVlAIAyeYnS77es9InS/xdFERViBf8G9UUUgYaaiKeFbuzt7Z9Z3dckPT0d4eHhiI6OrrWNubk5AEAulyvtr9quOl5XjSb5FxUVVbujASpvAAoLC9W6ZmlpKb5c+bqmodEzPN9chmYWZlg91wMlxUX4YKa70vGBL7Xj36EePc68resQmpySP3MBAPnZabCoyK12vODBXQBARXkZyp6U8G9QjwyMan/tUpt0Odv/p59+gomJCd555x3Fvtu3byM/Px9+fn4AgJ07d0IQBGRnZyudW7Xt6OioUp+NJvmbm5tXu6MBKu9q1J3tb2xsDL8VBzQNjf7HwtwEZWXleCIvU9ofGDACE7xs8fmhi/Ab0QUffHYKaffzAAC/HOiDn39Nx0fbv9NFyJJwcGegrkNockybpQAArGwd0NzORrG/rPQJCh7chWXLNjAyNoGBoRGMTEzR3L6DjiJt2vKz0xqmI0EL3+qnwfn+/v7w9/dX2rd48WKcO3cOkZGRin19+vTBpUuXlNpdvHgRlpaWijcA6qrRJP/27dtXu6ORy+XIzc1V+Y6miiAIuJn2UAvREQCEve+L5NRsbI44prTfsW0rFBY/wZnLd+A3ogvS7ucp/d7zC5/w71CPjE3MdB1Ck2NoWPmvRiOZaY2/XyNjExibmEEQBBgIBvwb1JdG9O59YxAYGIipU6fiwoUL6NOnDx48eIDo6GjMmzdPpdf8gEaU/N3d3bFnzx7I5XLF8P+VK1dQUVEBd3f3Z5xNDWXqmH8g5sRlJKdV3qhNfXMQBvTqiA9CD+OJvFTH0RERqaex3GccP34ce/bsURr2d3V1xbx58/Dyyy9j+/bt+PjjjxUr/E2bNk2/V/jz9/fHN998g4iICMycORNlZWXYuXMnhgwZgj59+ug6PAIQFnUCeX8WY/faaRBFEdbNzHH/QR5mrojAN0cTFZP6bKws8J+vZyjOG/mPF/CfrxcjMSkFC9fWPqGFSNe2Rx7D8f/+hgeP/gQAzFwaDmNjI6xdNA5dO7ZRtHvrnZ2oEIHsh/nIzSuE96zNsLdtjk8/mqqr0ElDjWWFv+HDh2P48OG1Hnd3d9dKQdxokr+NjQ327NmDkJAQxMfH48mTJ+jZsycWLVqk69Dof64m38PSzc+eQ5GbX4hXJq1tgIiItGuenwfm+Xk8s93+T2ZzqJ/0WqNJ/gDQoUMHfPHFF7oOg4iIJKaRFP4NplElfyIiooZWtbyvptfQJ41mhT8iIiJqGKz8iYhI8jjsT0REJCUCYGCg6SI/2gmloXDYn4iISGJY+RMRkeRx2J+IiEhiGssiPw2FyZ+IiCRPYrmfz/yJiIikhpU/ERFJHof9iYiIJIQr/BEREVGTx8qfiIgkT2Kj/kz+REQkdYIWnvnr190Dh/2JiIgkhpU/ERFJm6CFYX/9KvyZ/ImIiKT2qh+H/YmIiCSGlT8REUmexAp/Jn8iIiKpDfsz+RMRkaRVrvCn+TX0CZ/5ExERSQwrfyIikjwO+xMREUmMxHI/h/2JiIikhpU/ERFJHof9iYiIpITL+xIREVFDu3LlCvbu3YvU1FQYGRkhLy8PDg4OCAwMhLOzMwBg8eLFuH37NkxMTJTOXbp0Kbp27apSf0z+REQkeboe9j9y5AjkcjkiIyNhaGiIsrIyvPPOO5gyZQpOnTqliG/z5s1o27atxv0x+RMRkeTp+pH/2LFjYWVlBUNDQwCAkZERXF1dERcXh4KCAjRr1kyr/TH5ExER6ViHDh2UttPT03HgwAFMmjRJ64kfYPInIiLSyrB/ZmYmAgMDaz0eHx//zGucPHkS69evR3p6OqZPn44FCxYoHf/iiy9w69YtlJWVoUWLFpg4cSIGDhyocqx8z5+IiCStcm1/QbOPlmIZPHgwYmNjERMTgx9//BHvvPOO4pijoyO6deuG3bt3Izo6Gj4+PpgxYwa+/PJLlfth5U9ERJKnjWf+9vb2daru66JDhw4IDg7G7Nmzcfr0afzjH//A22+/rdRm+PDh8PT0RFhYGPz9/WFkVPeUzsqfiIhIx+RyebV9nTp1AgBcv3691vOcnJxQUFCAR48eqdQfkz8REUmchkP+ggBNV/kZMWIEHj58qLQvKysLANC8eXM8fPgQq1evrnZeZmYmTExM0Lx5c5X6Y/InIiJp+98Kf5p8tPHQf+fOnSgvLwcAFBQUYNu2bWjVqhU8PDxQXFyM6OhoJCYmKtr/9ttviI2NxaRJkyCTyVTqi8/8iYiIdCw4OBiHDh3C2LFjYWZmhsLCQnTt2hVr1qyBtbU1TE1NERgYiI0bN8LIyAjl5eUoLS3F0qVLMXbsWJX7Y/InIiLJ0/UKf6NGjcKoUaNqPW5iYoLp06dj+vTpWumPyZ+IiCRP1yv8NTQ+8yciIpIYVv5ERCR5BhIr/Zn8iYhI0ipX+NP8GvqEw/5EREQSUy/J/969e/VxWSIionqh+SI/+qVekv/cuXPr47JERET1wkDQ7KNv6vTM39/fX6WLpqamqhUMERGRLuhj9a6JOlX+SUlJEEWxzh8iIiJqvOpU+bdv3x6RkZF1vqiPj4+68RARETUsQQuL/OjZwEGdkv+WLVtUuqiq7YmIiHRJ0LfsraE6Dfs7OTnVuD8zMxOHDx/G119/DQC4c+fOU9sTERGR7qm1yE9FRQU++ugj7Nu3DxUVFWjZsiUmTZqEsLAwpKWlITw8HFZWVtqOlYiISOsEaD5jX9/GDdR61e/TTz/F8ePHMW/ePGzfvh3NmzcHAKxfvx4DBgzA1q1btRgiERFR/ZLae/5qVf7fffcdvv76a7Rv3x4AEBYWBgAwMDDAggULMGbMGO1FSERERFqlVvI3NDRUJP6ajpWWlmoUFBERUUPSw+JdI2oN+8vlcqSnp9d4LD09HXK5XKOgiIiIGo4AA0Gzj7499Ver8h81ahQmTpyIqVOnonfv3igtLcXNmzdx9epV7NixA6+//rq24yQiIiItUSv5z5s3D8nJyVi3bh0EQYAoivD29gYAeHh4YPbs2VoNkoiIqD5JbdhfreRvbGyM7du3IyEhAWfOnEFubi5sbGwwaNAg9OvXT9sxEhER1SvNZ+zr19L2aiX/Kv3790f//v21FQsREVGDE7SwvK++jRxolPx/+eUXXLp0CVlZWbCzs0OvXr3g6uqqrdiIiIioHqiV/PPy8hAYGIiEhASlb/ETBEGxyA9X+CMiIn1hwGH/ZwsJCUFqaiqWLl2KF198EdbW1nj8+DF+/fVX7N69G2vWrMHatWu1HSsREVG90LNRe42plfxPnTqFmJgYPP/880r7e/bsieHDh2P06NFaCY6IiIi0T63kb29vXy3xV2ndujXs7Ow0CoqIiKgh6eP6/JpQa4U/Z2dnpKam1ngsJSUFbdu21SgoIiKihmQgaPbRN3Wq/M+fP6+07eHhgXfeeQcjR46Ei4sLLC0t8eeff+LmzZs4dOgQF/khIiJqxOqU/P38/KoNiYiiiOvXrwOAYpW/KkuXLoWPj4/2oiQiIqonAjQf9te34r9Oyd/BwQGrV6+u0wVFUcSKFSs0CoqIiKgh6fqR/5UrV7B3716kpqbCyMgIeXl5cHBwQGBgIJydnRXtDh06hMjISJiZmaG4uBhTpkyBl5eXyv3VKfkPGTJEpWV7hwwZonIgREREUnXkyBHI5XJERkbC0NAQZWVleOeddzBlyhScOnUKgiDg+++/x4cffoiDBw/CyckJycnJGDNmDExMTODh4aFSf3Wa8LdkyRKVLtqtWzeV2hMREemSIAgafTQ1duxYLFmyBIaGhgAAIyMjuLq6IisrCwUFBRBFEVu2bIGXlxecnJwAVE6+HzFiBDZt2qRyf2rN9v+rBw8e4N69e0qfzz//XNPLEhERNRhdz/bv0KEDWrZsqdhOT0/HgQMHMGnSJDRr1gy3bt3C3bt30atXL6XzevfujZSUFNy5c0el/tR6z18ul2Pz5s3Yt28fSkpK1LkEERFR4yBo4T1/AcjMzERgYGCtTeLj4595mZMnT2L9+vVIT0/H9OnTsWDBAgBQvF5va2ur1L5qOyUlRTEiUBdqJf/PPvsMly9fxnvvvYddu3YpgsvOzsa+fftUfvZAREREwODBgzF48GDcvn0b8+bNQ3JyMrZt24bCwkIAgEwmU2pftV1UVKRSP2ol/7i4OOzZswdWVlbYt2+f0nK+r7/+ep3fDCAiImoMtDHZ397evk7VfV106NABwcHBmD17Nk6fPg0LCwsAlSPvf1W1bW5urtL11XrmLwiC4lv7ysvLlY7Z29vj4cOH6lyWiIiowQmo/FY/TT6a3jz8PakDQKdOnQAA169fR/v27QFUjrD/VdW2o6OjSv2plfwrKioUSd/c3Fyx2A9QOUnh7t276lyWiIhIkkaMGFGtcM7KygIANG/eHJ06dUKbNm1w6dIlpTaXLl2Co6OjSs/7ATWTf8eOHfHPf/4TBQUFGDZsGAICArB69WqEhIRgwoQJePnll9W5LBERkU4IgmYfbdi5c6eisC4oKMC2bdvQqlUreHh4QBAEBAUF4YcffkBKSgoAIDk5GUeOHMHChQtV7kutZ/4zZszAf/7zHzx58gSTJ0/GjRs3sHfvXpSXl6Nfv34qrwtARESkO9p4V1+z84ODg3Ho0CGMHTsWZmZmKCwsRNeuXbFmzRpYW1sDALy8vFBaWoqgoCCYm5ujqKgIq1atgqenp8r9qZX8u3Tpgi5duii2N27ciJCQEJSVlSkmJRAREVHdjBo1CqNGjXpmuzfeeANvvPGGxv1pvMhPFRMTE0Xij4qK0tZliYiI6l1jGPZvSHWq/O/du6fSRaOjo+Hr66tWQERERA3NQB8zuAbqlPyHDh2qlbWLiYiISPfqlPzt7e0Vq/g9iyiK2L59u0ZBERERNSSp1bd1Sv49e/ZUWsXvWU6fPq12QERERA1J0MLa/vp28yCIoijqOoj6kJSUBADo1PUFHUciHcVFRbh96xo6dOoKMxWXmiT12YzeqesQJMPF3hxfzuqBqbt+w81M1dZSJ9Xtf+dFAIDXqwPrrY+kpCQ8LCrFgXtmGl3nzdbFaGFujBde0I+co7XZ/kRERKQf1HrPn4iIqCmR2qR2Jn8iIpI8A2nlfg77ExERSQ0rfyIikjypVf4aJf8LFy4gISEBxcXFCA4ORmJiIrp37w4zM81mTRIRETUUAVp41U87oTQYtYb9S0pKMGvWLPj6+iI0NBSHDx8GABw9ehReXl7IzMzUZoxERESkRWol/61btyIjIwNr167FoUOHYGNjAwBYvnw5pk2bhi1btmg1SCIiovpkIGj20TdqDfvHx8dj3759eO655yovYvR/l5kwYQK++eYb7URHRETUACT2pp96lb+xsbEi8dekuLhY7YCIiIiofqmV/EVRxG+//Vbjsd9//x0GBnyDkIiI9IeBIGj00TdqDfuPGzcOfn5+ePPNN9G7d28UFRXhp59+wu+//46oqCjMnz9f23ESERHVCwGaL3qjb+lfreQfEBCAe/fuISoqCl9//TVEUcScOXMgCAImT56MSZMmaTtOIiKi+iFo4Zm/nmV/td/zX7p0Kfz8/HDmzBnk5ubCxsYGbm5uaNeunTbjIyIiIi3TaJGfdu3aYdy4cdX2l5WVKb0BQERE1Jjp43N7TdTLzLyxY8fWx2WJiIjqhSBo9tE3apXnS5Yseerxe/fuqRUMERER1T+1kv/3338PW1tbpX2FhYXIy8uDpaUlrK2ttRIcERFRQ9DHVfo0oVby79ixo2I9/796+PAhPv/8cwwePFjDsIiIiBqGAM2f+evbvYNaz/xDQ0Nr3N+iRQssXrwYn376qUZBERERUf1Rq/J/1ut8d+/eVSsYIiIiXdDHSXuaUCv5nz9/vto+URSRl5eHo0ePolmzZhoHRkRE1FD4zL8O/Pz8IPztNkkURQBA69at+ZW+REREjZhayd/BwQGrV69W2mdgYICWLVvCwcGBX+xDRER6RICg8ZQ9zc7/5ZdfEB0djZycHIiiiIKCAnh4eGDatGkwNTUFUDnfLi4uDlZWVkrnzpgxA6+88opK/amV/N98803069dPnVOJiIgaF0ELw/4anr98+XKMHDkSmzdvhiAISElJwVtvvYWbN2/ik08+UbRbunQpXF1dNQxWzdn+4eHhcHV1RXp6usYBEBER6VLlq36afTS9d3BxccH06dMVj9QdHR0xcuRIHDt2DIWFhRr/jH+nVuUviiIOHDiAtm3bajseIiIiyQkLC6u2z9TUFIIgwNDQUOv9qb3Iz9MS//Xr19GlSxe1gyIiImpIf5/Ero7MzEwEBgbWejw+Pl6l650/fx6enp6KZ/4AcPjwYWzfvh1lZWVo1qwZfHx8MGrUKJVjVWvYf9CgQTh16lStx5+19j8REVFjoumwv7bFxsYiKysLS5cuVeyzt7eHk5MTvvjiC+zduxczZ87EihUr8NFHH6l8fbUq/4qKCqxcuRIuLi7o2LEjLCwslI7n5OSoc1kiIiK9ZW9vr3J1X5MrV65g/fr1CA8PR6tWrRT7x4wZo9Sub9++mDBhAsLDw/H2228rtX0WtZL/jh07AABZWVk4ffp0tePaGD4hIiJqKI0lbV25cgWLFi3Czp070bVr12e2d3JygiiKyMjIqP/k36VLlxq/2KeKj4+POpclIiLSCU2/2EcbLly4gGXLliEsLAwdO3YEABw5cgQ9evRAu3btEBQUVG0RvczMTACAnZ2dSn2p9cx/5syZTz0eHByszmWJiIgkKSEhAfPmzcP8+fNRXFyMpKQkJCUlISYmBvfu3QNQOQ8gNjZWcU5aWhqio6Ph6emJ1q1bq9RfnSv/oUOHQhAE9OvXDx9//PFT2w4aNEilIIiIiHSl6j1/Ta+hiaCgIDx69AgLFy6sdmzKlCkAgPfffx979+5FVFQUAKCkpAT+/v4ICAhQub86J38zMzN89tlnSq8cEBERNQW6HvU/e/bsM9tMnDgREydO1Ep/dU7+MpkMbdq00UqnREREpDv18g08U6dOrY/LEhER1QsDCBp99E2dK//Hjx8/dYb/X6WkpKgZDhERUQMTtDDsr2f5v87JPzMzE0uWLIEois9sy/f8iYhIn9THKn2NWZ2Tv4ODA1avXv3MdqIoYuXKlRoFRURERPWnzsnfwsIC/fr1q1Pbzp07qx0QERFRQ6p81U+z0l/fBg7UWuHvWbZt21YflyUiIqoXUntaXefZ/qWlpcjMzMSjR4/qMx4iIiKqZ3VO/kVFRfD19cWGDRvqMx4iIqIGZyAIGn30TZ2H/U+cOFGfcRAREemMHuZvjdTLIj9ERETUeNXLhD8iIiJ9IUDzSljfBg6Y/ImISPKktjgdh/2JiIgkhpU/ERFJnrTqfiZ/IiKSOkEb38ynX7cPTP5ERCR5+pW6Ncdn/kRERBLDyp+IiCRP48n+z/62+0aFyZ+IiCRP41f99Cz5c9ifiIhIYlj5ExGRpHGFPyIiIgniCn9ERETUpLHyJyIiyZNW3c/kT0RExGF/IiIiatpY+RMRkeRJrRJm8iciIkkToPmwv749NGDyJyIiydN18v7ll18QHR2NnJwciKKIgoICeHh4YNq0aTA1NVW0O3XqFEJDQ2FiYoLCwkL4+PggICBA5f6Y/ImIiHRs+fLlGDlyJDZv3gxBEJCSkoK33noLN2/exCeffAIASExMxNy5cxEREYG+ffsiJycHo0ePBgCVbwCk9piDiIioGkHQ7KMpFxcXTJ8+XfH4wdHRESNHjsSxY8dQWFgIANi6dStcXV3Rt29fAECrVq0wfvx4hIaGoqSkRKX+mPyJiEjyDCBo9NFUWFgYrKyslPaZmppCEAQYGhqioKAAiYmJ6NWrl1Kb3r17K46pgsP+REREWpCZmYnAwMBaj8fHx6t0vfPnz8PT0xOmpqa4evUqRFGEra2tUhs7OzsAQEpKCgYNGlTnazP5ExGR5DW2NX5iY2ORlZWFXbt2AQCKiooAADKZTKld1XbV8bpi8iciIskTtDB0b29vr3J1X5MrV65g/fr1CA8PR6tWrQAA5ubmAAC5XK7Utmq76nhd8Zk/ERFRI3HlyhUsWrQIO3fuRNeuXRX7HRwcIAgCsrOzldpXbTs6OqrUD5M/ERFJm4Yz/QUBWlko4MKFC/jnP/+JsLAwReI/cuQI0tPTYWlpiT59+uDSpUtK51y8eBGWlpaKNwDqismfiIgkTYDms/01zf0JCQmYN28e5s+fj+LiYiQlJSEpKQkxMTG4d+8eACAwMBDnzp3DhQsXAAAPHjxAdHQ05s2bp7QQUF3wmT8REZGOBQUF4dGjR1i4cGG1Y1OmTAEAvPzyy9i+fTs+/vhjxQp/06ZN4wp/RERE6tD1bP+zZ8/WqZ27uzvc3d017o/Jn4iIJE/Xyb+hMfkTEZHECVp4aq9fdw+c8EdERCQxrPyJiEjyDPSrcNcYkz8REUla5Wv6mmV/fbt34LA/ERGRxLDyJyIiyeNsfyIiIonRxhf76BMO+xMR1SLAoxtyD83Ge+NUWzedqLFj5U9aEXfmKj7ZfQzZD3JRWv4dZDJjjHJ/ESvnvq7r0IjUYm0hw/JJ/Wo9bmJsiPk+PfGaqxMMBMDG0hRpOX9i4zcXcPLXjAaMlLSBs/2JVLTn8Bls+OIIItdOgXFZLjp06oqw6P/gX98nMPmT3lo2sR8Srt3Ha65O1Y4ZGgj4ZsVruPugAKOWHkaxvAzNzIzx3Ufe6NPJlslfD3HYX8fi4uLg7u6OxYsX6zoUqoO7WblYvPEbhAS9gc5Ozyv2z5k4FOsXvaXDyIjU1739c/Dq3wFro8/XePytwV3RxeE5BO48hWJ5GQDgz+JSvL01Ht+dvd2QoRKppdFU/sXFxQgODoaZmRlKS0t1HQ7VUXTsOTwpLcNwt+5ARZliv7mpDK+6ddNhZETqWzt9ED6OPo+8QnmNx9/4hwtO/ZqBJ6XlSvtvZOQ2RHhUDzjbX0dKSkowadIkuLm5YejQoboOh+oo4XIy7FpY4cLvKdgQfgRpd7NhYWEBr6E9ETh5OExkxroOkUglowc6o5mZDJFx19C2ZbNqxw2NjOBgZ41DP99G4Bu98PqADmhmLkN69p8I++5XxF9K10HUpCmJ5f7Gk/xtbGzg5uam6zBIRRn3c/EorxDvrt2HL1b7Qyh5gIdPzBCwNAIXfk/F/q2zdR0iUZ2ZyYywyn8AZmyJgyjW3MbYWAYAmDayB779z02MWnYY5RUi3h3TB/uXv4bpm4/j0M/JDRg1aUoAYKBh6a9vNw+NJvnXB1EUUVxUpOswmrSSJ3I8kZdh/qQhaNvKEnfTH+DFjnYI8HHDlt1x+Onsb+j/Ugddh9mkudib6zqEJmPW/+uJ31NykJuXDxd7c9g/ZwoAaNHMGC725nBoaQoDxbRwEV/GXoJDCxMAwKH//A6/YZ3xUcAA/H47U0c/QdNibGiA0vIKXYfRJDXp5F9aWorbt67pOowmzdigsjyylpXgbnoKAOBuegpaWVb+Axt3OhG25k90FZ4kfDmrh65DaBKMZTJ06NQVyTeuKn6nVVW+dx9buLWt3Ff+v2RkKJZi59SuStewNC6HlXVz7J7zEsrLlecDkHru5ZY0SD/6Vrlrqkknf2NjY7Rz7KjrMJq0Hp0v4Vb6I7Ru54Q2bZrjbnoK2rRzROvsypsCm+ds0aFT12dchTQxOPgbXYfQJHgP7IQptiUQrNqiaqaKsVHlC1GGZjYwfs4UDx4XoPmTBygrr0DqgxJM3fWb0jXWzmiJIb2aI3DPDeQWNEzSasrWTXBpmI4EaJ799ezuoUknf0EQYGbOIdH65DW0Nw7FXcYf6Q/RzdkeAGBiaobkjIcAgP69OvJvUM9uZvLRljZs+PZXbPj2V6V97Vo1w5XPfPH5kd+wbl8iXOzN8eWsHjh37R56dLBF+kO54lU/AGhra43UrHz8cutRQ4ffJHHIv/40uvf8Sb94D+uJ/j2dsSXiGLIf/gkAuJ2Rg8/3n8Lwgd0xqE8D3bkTNaAd312EoYGApRNfVuybPrI7nO2tsSoyQYeRkboEDf9P3zTpyp/qn4GBAfZteRshn/6A12aHwkgQYWhkDD9vN7w71VPX4RGpxcpchh9WeyuG/ad4dsdrrk448J/KOUS3MnLhtSIGK33748ouX5RVVCArtwjjQ2Jx/GKaLkMnNfE9fx1atmwZ0tLSkJOTg9OnT8PPzw+enp7w9fXVdWj0FFaWZlgXPBYfzHkNt29dQ4dOXTnUT3otv0iOVxZWn0vhYm+OsT0rJ/5d+iMHoz/4vqFDI9KKRpX8Q0JCdB0CERFJkMQK/8aV/ImIiHRCYtmfE/6IiIgkhpU/ERFJnj7O2NcEkz8REUmaoPgP6WDyJyIiydM099fyPVCNFp/5ExERSQwrfyIiIg77ExERSYnmS/SKWrp7iIuLw0cffYQBAwZg7dq1SsdCQ0MRFxcHKysrpf0zZszAK6+8olI/TP5EREQ6VlxcjODgYJiZmaG0tLTWdkuXLoWrq6vG/TH5ExGR5Ol6bf+SkhJMmjQJbm5uGDp0aL33x+RPRESSp43cn5mZicDAwFqPx8fH13rMxsYGbm5uWoiibpj8iYiI9MThw4exfft2lJWVoVmzZvDx8cGoUaNUvg6TPxERkRZKf3t7+6dW99q4vomJCVatWgWZTIbExETMmjULFy5cwIoVK1S6FpM/ERFJnj4s7ztmzBil7b59+2LChAkIDw/H22+/jVatWtX5Wlzkh4iISE85OTlBFEVkZGSodB6TPxERSZtQOdtfk09DDBwEBQVV25eZmQkAsLOzU+laTP5ERCR5goafhhAbG4vY2FjFdlpaGqKjo+Hp6YnWrVurdC0+8yciImoEj/yXLVuGtLQ05OTk4PTp0/Dz84Onpyd8fX0BAO+//z727t2LqKgoAJVrA/j7+yMgIEDlvpj8iYiIGoGQkJCnHp84cSImTpyolb6Y/ImISNIqh+41K/0bwcCBSpj8iYhI8nS9vG9D44Q/IiIiiWHlT0REkiexwp/Jn4iISGrZn8P+REREEsPKn4iIJE8f1vbXJiZ/IiKSPM72JyIioiaNlT8REUmexAp/Jn8iIiKpZX8mfyIikjypTfjjM38iIiKJYeVPRESSJ7XZ/kz+REQkaQI0f+Svb/cOHPYnIiKSGFb+RERE+la6a4jJn4iIJI+z/YmIiKhJY+VPRETSJmhhtr+eDRww+RMRkeTpWe7WGJM/ERGRxLI/n/kTERFJDCt/IiKSPKnN9mfyJyIiyZPa8r4c9iciIpIYVv5ERCR5Eiv8mfyJiEjaBGg+7K9vNw8c9iciIpIYJn8iIiLFF/uq+9GOuLg4uLu7Y/HixTUeP3XqFMaMGYNJkybBx8cHERERavXDYX8iIpI8Xc/2Ly4uRnBwMMzMzFBaWlpjm8TERMydOxcRERHo27cvcnJyMHr0aABAQECASv2x8iciItKxkpISTJo0CRs3boSpqWmNbbZu3QpXV1f07dsXANCqVSuMHz8eoaGhKCkpUak/Vv5ERCR52ij8MzMzERgYWOvx+Pj4Wo/Z2NjAzc2t1uMFBQVITEzEvHnzlPb37t0boaGhSExMxKBBg+ocKyt/IiKSPEHQ7FPf0tLSIIoibG1tlfbb2dkBAFJSUlS6Hit/IiKSOEELy/sKsLe3f2p1r4mioiIAgEwmU9pftV11vK5Y+RMRETVy5ubmAAC5XK60v2q76nhdsfInIiJq5Kv0ODg4QBAEZGdnK+2v2nZ0dFTpekz+REQkeY0898PS0hJ9+vTBpUuXlPZfvHgRlpaWijcA6orD/kRERHogMDAQ586dw4ULFwAADx48QHR0NObNm1fr64G1YeVPRETSpo0Z+1oYOli2bBnS0tKQk5OD06dPw8/PD56envD19QUAvPzyy9i+fTs+/vhjmJiYoLCwENOmTVN5gR+AyZ+IiEgLs/01FxIS8sw27u7ucHd317gvDvsTERFJDCt/IiIi3Rf+DYrJn4iIJE0b38unb/cOHPYnIiKSGFb+REQkebr+St+GxuRPRESS1xhm+zckJn8iIpI8qVX+fOZPREQkMUz+REREEsNhfyIikjwO+xMREVGTxsqfiIgkj7P9iYiIJIbD/kRERNSksfInIiJJk+La/kz+RERE+pa9NcRhfyIiIolh5U9ERJLH2f5EREQSI7XZ/kz+REQkeRLL/XzmT0REJDWs/ImISNok+K4fkz8REUme1Cb8cdifiIhIYgRRFEVdB1EfkpKSUFpaCiNjY12HIhlihYiyslIYGRlDMJDWXbQupWbl6zoEyTA2NEArKxly8uUoLa/QdThNnq2VDOUVgFv/l+utj6SkJMjlchjLZBpdp1Quh0wmwwsvvKClyOpXkx32l8lkKCsrk9hAjm4JBgJkGv4DRKpztLPSdQiS06Yl/3feEEpLSyGr53fwtPXvLJlMplf//muylT8RERHVjM/8iYiIJIbJn4iISGKY/ImIiCSGyZ+IiEhimPyJiIgkhsmfiIhIYpj8iYiIJIbJn4iISGKY/ImIiCSGyZ+IiEhimPyJiIgkhsmfiIhIYpj8SWN37tzB9OnT8dZbb8HHxwerVq1CYWGhrsMi0rq4uDi4u7tj8eLFug6FSCNM/qSR3Nxc+Pn5oW/fvti/fz++/fZbpKamIjg4WNehEWlNcXEx5s6di6NHj6K0tFTX4RBpjMmfNBIZGYni4mJMnToVAGBkZITZs2fjxIkTuHjxoo6jI9KOkpISTJo0CRs3boSpqamuwyHSGJM/aeTkyZPo1q0bZDKZYt9LL70EAwMDnDx5UneBEWmRjY0N3NzcdB0GkdYw+ZNGUlNTYWtrq7RPJpPBxsYGKSkpugmKiIieismfNFJUVKRU9VeRyWSc9EdE1Egx+ZNGzM3NIZfLq+2Xy+WwsLDQQURERPQsTP6kkfbt2yM7O1tpn1wuR25uLhwdHXUTFBERPRWTP2nE3d0dV69eVar+r1y5goqKCri7u+swMiIiqg2TP2nE398fZmZmiIiIAACUlZVh586dGDJkCPr06aPb4IiIqEaCKIqiroMg/Xb79m2EhISgoKAAT548Qc+ePbFo0SI+86cmZdmyZUhLS8Ply5dhZWWFDh06wNPTE76+vroOjUhlTP5EREQSw2F/IiIiiWHyJyIikhgmfyIiIolh8iciIpIYJn8iIiKJYfInIiKSGCZ/IiIiiWHyJyIikhgmfyItkMvl8Pb2Rr9+/TB06FBdh1OrixcvwtvbGz169MDixYuf2jYwMBCDBw9G586dkZGRoVI/a9aswfDhw9G5c2f88ssvmoQMoHIVSW9vb/Tq1Qt+fn4aX49I6pj8Sa+VlJTA29sbAwcOROfOnTFq1Ch4e3vD09MTr776KhYtWqRy4lKHTCZDTExMjYk/KioKAwYMQGZmpsrXjYiIQFxcnDZCBAD07t0bMTExsLW1fWbbrVu3YsGCBWr1s3TpUqxevVqtc2vSoUMHxMTEoEePHlq7JpGUMfmTXjM1NUVMTAzGjx8PAPjss88QExODH3/8EV999RUuX76MMWPGVPva4YZkbW2N1q1bQyaTqXzunj17tJr8iYgAJn9qwtq1a4epU6ciNzcX3377rc7i8PLywoEDB9CiRQudxUBE9FdGug6AqD61bt0aAHD//n2kpaVh/vz5SEtLQ48ePTBx4kRERUUhIyMD9+/fx+HDh9G1a1dkZWVh06ZNOH/+PGQyGczNzTFr1iyMGDFC6drnzp3D2rVrkZWVhTZt2mDkyJHV+t+yZQtiY2ORlpaGPXv2wNXVVXHst99+w9atW5GcnAwrKysYGhpi8ODB8PX1xePHjxEUFITs7GycOHEC3t7eAIApU6bAx8cHAPDrr79iy5YtSEtLAwA4OTkhODgYXbt2VYrh66+/xpdffglBEGBra4s5c+Zo9Du9du0awsPDcevWLRgYGKCiogIeHh6YOXNmjaMbubm5ePfdd/HHH38gMzMT7u7uWLZsGZo3b65oI5fLERYWhn//+98wNjZGRUUFXn/9dbz99tswNDTUKF4iqoFI1ARs27ZNdHFxEdPT05X2R0REiC4uLuJnn32m2Ofr6ysOGDBA3LhxoyiKovjkyRPRw8NDvHr1qpiXlycOHTpU9PX1FQsLC0VRFMW4uDixc+fO4g8//KC4xp07d8QePXqIy5cvF8vLy0VRFMXdu3eLAwYMEIcMGaIUQ0JCguji4iImJCQo9l25ckV88cUXxc2bN4sVFRWiKIri2bNnxe7du4vHjx9XtBsyZIj43nvvVft5f/31V7FHjx7i2rVrFfvWrl0r9urVS0xJSVHsO3TokOji4iIePnxYFEVRlMvl4uLFi8WePXvWeN2/O3DgQLXf665du8SgoCDxyZMnoiiKYm5urjhu3DgxJCSkxp/by8tLvH37tiiKonj37l1x8ODBor+/v1LbuXPnigMHDlTEfufOHXHgwIHiypUrldr5+vqKvr6+z4ybiJ6Ow/7UZF25cgWff/45WrdujbFjxyodk8vlmDdvHoDKyXp79uyBs7MzIiIikJGRgUWLFsHc3BwAMGzYMLi6umLLli2K83fs2AFRFPHuu+/CwKDyHyM/Pz9YWlrWKbb169fDwsIC8+bNgyAIAID+/fvj1VdfrVOlu379epibmyMwMFCxb8GCBRBFEbt27QIAiKKITz75BD169FCMHBgbG2PBggUoKiqqU5w1GT16ND744ANFld+8eXN4e3tj//79EGv4hvARI0bAyckJQOVIzJQpU5CQkICzZ88CABISEnD8+HEEBASgffv2AABHR0dMmDAB+/btw927d9WOlYhqxmF/alJmzpwJY2NjPHnyBJaWlvDy8sKsWbOUhpgBwMHBASYmJoptOzs7AMDPP/8MU1PTarPKXVxckJCQgLt376JNmza4ePEiHBwclK4rCAI6deqEa9euPTXG4uJiJCYmws3NDcbGxkrHtm7d+syfsbi4GBcuXICbm5vSz2BmZgYHBwckJCQAqHzUce/ePbi7uyudb29vDysrq2f2UxsrKyvs2bMH8fHxKCwshIGBAfLy8lBcXIycnJxqbxJ07txZafvFF18EAFy6dAkDBgzAzz//DADo06dPtfNEUcS5c+cwevRoteMlouqY/KlJ+eyzz9C2bdtntrOwsKhxf25uLsrLy6slm6KiIrRs2RK5ublo06YNsrOz0a1bt2rnN2vW7Jl95+fno6KiotoNSV1VnZ+UlKSo6Kvk5eUpRhKq3nCwtrZWK87aLFu2DKdPn8ZXX32l+B0cPHgQS5YsgVwur9b+76MhVfFkZWUBqPydV133rzdDpaWlaNmyJQoKCtSOlYhqxuRP9Bc2NjbIzc1FTEzMU9vZ2toiLy+v2v78/Pxn9mFlZQUDAwM8fvxYrRirzn/55ZcRFhb21BgB1NhPXeKsSUlJCWJjYzF+/Pgab35q8ueffyptV8VTNdpiY2MDANi8eTO6dOmiVlxEpBo+8yf6i0GDBiE/P7/awkCpqalYuHAhysrKAFQulpOenq6UWEVRxB9//PHMPszMzNC3b19cu3YNpaWlSsdWrlyJH374QbFtZGSkeI7+6NEjnDlzRnH+9evXUVFRoXR+XFwcQkNDAQDPP/882rRpg6SkJKU2mZmZ1RJyXZWVlaG8vFwxz6FKTk5OrefcvHlTafvKlSsAgF69egGo/J0DwNWrV5XalZeX491330VycrJasRJR7Zj8if5i8uTJcHBwwEcffYTCwkIAlVXyhx9+CDs7OxgZVQ6WzZkzB4IgYNOmTYoEHBkZ+dQk+FeLFi1CQUEBtm/frth38uRJnDhxQul1wLZt2+L+/fsAgGPHjuHTTz9VnJ+Tk4OwsDDFzcHt27exZs0aRUUuCAIWLFiA33//XTGSUVpaio0bNyrNFVCFpaUl+vXrh9jYWKSnpwOovJmIjo6u9ZxDhw7hzp07AIB79+4hIiIC/fv3x4ABAwAArq6u8PT0xI4dOxSvLZaVlWHbtm1ITU1VTBYkIu0RxJqm5xLpiZKSEowbNw4PHjzAgwcP4OzsDGNj4xqH7XNzcxEQEKBIMA4ODvD19a32JkBOTg42b96MM2fOwNraGoaGhhg1ahSmTZumVPFWved///59PP/883B3d8e9e/fw73//G87OzlixYgVOnz6teM/fwcEBnp6eCA4OBlD5nv+WLVuQnJwMa2trtGrVCosWLVKaIHfp0iUsX74cgiDA2NgYq1atUkyYS0pKwtatW3Hr1i20bNkSpqammDp1Kl599VWln+df//oXwsPDIQgCnnvuOUydOhUbNmxAQUEB7O3tsW/fPpiamlb7fQUGBuLy5cvIzMyEs7Mzxo8fD39/f2RnZ2PNmjVITExE69at0aJFC7Rr1w67d++Gs7MzZs6ciatXr+Knn35CWloa1q5di2PHjiEjIwNZWVk1vudfWlqKTz/9FN999x2MjY1hbGyMXr16ITAwEM2bN8ft27cRFBSk9LcLCwur0/wOIqqOyZ+IiEhiOOxPREQkMUz+REREEsPkT0REJDFM/kRERBLD5E9ERCQxTP5EREQSw+RPREQkMUz+REREEsPkT0REJDFM/kRERBLD5E9ERCQxTP5EREQS8/8B8j6UE/bTUvQAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TEST\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize variables\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "# Define loss criterion\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Track loss and accuracy per batch\n",
    "batch_results = []\n",
    "\n",
    "# Disable gradient calculation for inference\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(test_loader):\n",
    "        # Move data to the appropriate device (GPU/CPU)\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        outputs = conformer(X_batch)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs, 1)  # Get the class with the highest score\n",
    "        correct_predictions += (predicted == y_batch).sum().item()\n",
    "        total_predictions += y_batch.size(0)\n",
    "        \n",
    "        # Store labels and predictions for confusion matrix\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "        # Store individual batch results\n",
    "        batch_results.append({\n",
    "            'Batch': batch_idx + 1,\n",
    "            'Loss': loss.item(),\n",
    "            'Accuracy': (predicted == y_batch).sum().item() / y_batch.size(0)\n",
    "        })\n",
    "\n",
    "# Calculate average loss and overall accuracy\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Create DataFrame for detailed batch results\n",
    "df_results = pd.DataFrame(batch_results)\n",
    "\n",
    "# Print detailed report\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"{'Test Report':^60}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total Batches: {len(test_loader)}\")\n",
    "print(f\"Average Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Overall Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nBatch-wise Results:\")\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-22T20:26:04.730291900Z",
     "start_time": "2025-01-22T20:26:04.600776500Z"
    }
   },
   "id": "3be90cbee620b6b8",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "327df23e3ae4939f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
