{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# XDAWN Decoding From EEG data\n",
    "\n",
    "ERP decoding with Xdawn :footcite:`RivetEtAl2009,RivetEtAl2011`. For each event\n",
    "type, a set of spatial Xdawn filters are trained and applied on the signal.\n",
    "Channels are concatenated and rescaled to create features vectors that will be\n",
    "fed into a logistic regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Authors: Alexandre Barachant <alexandre.barachant@gmail.com>\n",
    "#\n",
    "# License: BSD-3-Clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import (LogisticRegression, ARDRegression,\n",
    "    BayesianRidge,\n",
    "    ElasticNet,\n",
    "    ElasticNetCV,\n",
    "    Hinge,\n",
    "    Huber,\n",
    "    HuberRegressor,\n",
    "    Lars,\n",
    "    LarsCV,\n",
    "    Lasso,\n",
    "    LassoCV,\n",
    "    LassoLars,\n",
    "    LassoLarsCV,\n",
    "    LassoLarsIC,\n",
    "    LinearRegression,\n",
    "    Log,\n",
    "    LogisticRegression,\n",
    "    LogisticRegressionCV,\n",
    "    ModifiedHuber,\n",
    "    MultiTaskElasticNet,\n",
    "    MultiTaskElasticNetCV,\n",
    "    MultiTaskLasso,\n",
    "    MultiTaskLassoCV,\n",
    "    OrthogonalMatchingPursuit,\n",
    "    OrthogonalMatchingPursuitCV,\n",
    "    PassiveAggressiveClassifier,\n",
    "    PassiveAggressiveRegressor,\n",
    "    Perceptron,\n",
    "    QuantileRegressor,\n",
    "    Ridge,\n",
    "    RidgeCV,\n",
    "    RidgeClassifier,\n",
    "    RidgeClassifierCV,\n",
    "    SGDClassifier,\n",
    "    SGDRegressor,\n",
    "    SGDOneClassSVM,\n",
    "    SquaredLoss,\n",
    "    TheilSenRegressor,\n",
    "    enet_path,\n",
    "    lars_path,\n",
    "    lars_path_gram,\n",
    "    lasso_path,\n",
    "    orthogonal_mp,\n",
    "    orthogonal_mp_gram,\n",
    "    ridge_regression,\n",
    "    RANSACRegressor,\n",
    "    PoissonRegressor,\n",
    "    GammaRegressor)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from mne import io, pick_types, read_events, Epochs, EvokedArray, create_info, events_from_annotations\n",
    "from mne.datasets import sample\n",
    "from mne.preprocessing import Xdawn\n",
    "from mne.decoding import Vectorizer\n",
    "from share import datasets_basic_infos\n",
    "from data_loaders import load_data_labels_based_on_dataset\n",
    "print(__doc__)\n",
    "\n",
    "data_path = sample.data_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters and read data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "606 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "# This one needs the data to be load in epochs, not in dimensions\n",
    "subject_id = 1\n",
    "dataset_name = 'coretto' # Maybe it takes too long because of the sampling. We have to try downsampling from 10124 to 250\n",
    "\n",
    "\n",
    "dataset_foldername = dataset_name + '_dataset'\n",
    "computer_root_path = \"/Users/almacuevas/work_projects/voting_system_platform/Datasets/\" # MAC\n",
    "#computer_root_path = \"/Users/rosit/Documents/MCC/voting_system_platform/Datasets/\"  # OMEN\n",
    "\n",
    "data_path = computer_root_path + dataset_foldername\n",
    "\n",
    "dataset_info = datasets_basic_infos[dataset_name]\n",
    "\n",
    "epochs, y = load_data_labels_based_on_dataset(dataset_name, subject_id, data_path, array_format=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank='full'\n",
      "    EEG: rank 6 from info\n",
      "Reducing data rank from 6 -> 6\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "n_filter = 5\n",
    "# Create classification pipeline\n",
    "clf = make_pipeline(\n",
    "    Xdawn(n_components=n_filter),\n",
    "    Vectorizer(),\n",
    "    MinMaxScaler(),\n",
    "    LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", multi_class=\"auto\"),\n",
    ")\n",
    "\n",
    "# Get the labels\n",
    "labels = epochs.events[:, -1]\n",
    "\n",
    "# Cross validator\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Do cross-validation\n",
    "preds = np.empty(len(labels))\n",
    "for train, test in cv.split(epochs, labels):\n",
    "    clf.fit(epochs[train], labels[train])\n",
    "    preds[test] = clf.predict(epochs[test])\n",
    "\n",
    "# To see the array of predictions\n",
    "# array = clf.predict_proba(epochs[1])\n",
    "\n",
    "# Classification report\n",
    "target_names = dataset_info['target_names']\n",
    "report = classification_report(labels, preds, target_names=target_names)\n",
    "print(report)\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "cm_normalized = cm.astype(float) / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots(1)\n",
    "im = ax.imshow(cm_normalized, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "ax.set(title=\"Normalized Confusion matrix\")\n",
    "fig.colorbar(im)\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "fig.tight_layout()\n",
    "ax.set(ylabel=\"True label\", xlabel=\"Predicted label\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``patterns_`` attribute of a fitted Xdawn instance (here from the last\n",
    "cross-validation fold) can be used for visualization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=len(event_id), ncols=n_filter, figsize=(n_filter, len(event_id) * 2)\n",
    ")\n",
    "fitted_xdawn = clf.steps[0][1]\n",
    "info = create_info(epochs.ch_names, 1, epochs.get_channel_types())\n",
    "info.set_montage(epochs.get_montage())\n",
    "for ii, cur_class in enumerate(sorted(event_id)):\n",
    "    cur_patterns = fitted_xdawn.patterns_[cur_class]\n",
    "    pattern_evoked = EvokedArray(cur_patterns[:n_filter].T, info, tmin=0)\n",
    "    pattern_evoked.plot_topomap(\n",
    "        times=np.arange(n_filter),\n",
    "        time_format=\"Component %d\" if ii == 0 else \"\",\n",
    "        colorbar=False,\n",
    "        show_names=False,\n",
    "        axes=axes[ii],\n",
    "        show=False,\n",
    "    )\n",
    "    axes[ii, 0].set(ylabel=cur_class)\n",
    "fig.tight_layout(h_pad=1.0, w_pad=1.0, pad=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    ".. footbibliography::\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
